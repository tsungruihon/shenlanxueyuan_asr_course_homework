{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Forever 24 Kobe Bryant and 2 Gigi Bryant **\n",
    "\n",
    "<hr> \n",
    "\n",
    "- DNN for speech digit recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import kaldi_io\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list = ['Z', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "targets_mapping = {}\n",
    "for i, x in enumerate(targets_list):\n",
    "    targets_mapping[x] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function by input\n",
    "        Args:\n",
    "            input: input, B * N matrix, B for batch size\n",
    "        Returns:\n",
    "            output when applied this layer\n",
    "        \"\"\"\n",
    "        raise \"Not implement error\"\n",
    "        \n",
    "    def backward(self, input, output, d_output):\n",
    "        \"\"\"Compute gradient of this layer's input by (input, output, d_output)\n",
    "           as well as compute the gradient of the parameter of this layer\n",
    "        Args:\n",
    "            input: input of this layer\n",
    "            output: output of this layer\n",
    "            d_output: accumulated gradient from final output to this\n",
    "                      layer's output\n",
    "        Returns:\n",
    "            accumulated gradient from final output to this layer's input.\n",
    "        \"\"\"\n",
    "        raise \"Not implement error\"\n",
    "        \n",
    "    def set_learning_rate(self, lr):\n",
    "        \"\"\"Set learning rate of this layer\"\"\"\n",
    "        self.learning_rate = lr\n",
    "        \n",
    "    def update(self):\n",
    "        \"\"\"Update this layers parameter if it has or do nothing\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU类直接继承了Layer类\n",
    "# ReLU: f(x) = max(0, x) = x if x_i > 0 else 0\n",
    "class ReLU(Layer):\n",
    "    \n",
    "    def forward(self, Z):\n",
    "        \n",
    "        \"\"\"\n",
    "        Z -- output of the linear layer\n",
    "        \n",
    "        Returns:\n",
    "        A -- Post-activation parameter, of the same shape as Z\n",
    "        \"\"\"\n",
    "        A = np.maximum(0, Z)\n",
    "        assert(A.shape == Z.shape)\n",
    "        \n",
    "        return A.T\n",
    "                \n",
    "    def backward(self, input, output, dA):\n",
    "        \n",
    "        # When z <= 0, set dz to 0. When z > 0, set dz to 1.\n",
    "        dZ = np.array(dA, copy=True)\n",
    "        dZ[input <= 0] = 0\n",
    "#         dZ = 1.0 * (dZ > 0)\n",
    "        assert(dZ.shape == input.shape)\n",
    "        \n",
    "        return dZ.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_forward_test():\n",
    "    relu = ReLU()\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                      'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    batch_size = 100\n",
    "    _input = inputs[:batch_size]\n",
    "    relu_forward = relu.forward(_input)\n",
    "\n",
    "    print(\"|> _input shape is {}\".format(_input.shape))\n",
    "    print(\"|> \", relu_forward)\n",
    "    print(\"|> relu forward result shape is {}\".format(relu_forward.shape))\n",
    "\n",
    "# relu_forward_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FullyConnect层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnect(Layer):\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        in_dim -- size of the input layer\n",
    "        hidden_dim -- size of the hidden layer\n",
    "        \"\"\"\n",
    "        self.w = np.random.randn(hidden_dim, in_dim) * np.sqrt(2.0 / in_dim)\n",
    "        self.b = np.zeros((hidden_dim, 1))\n",
    "        self.dw = np.zeros((hidden_dim, in_dim))\n",
    "        self.db = np.zeros((hidden_dim, 1))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # Z = W · A + b\n",
    "        # self.w shape is (out_dim, in_dim)\n",
    "        # input shape is (batch_size, in_dim)\n",
    "        Z = np.dot(self.w, input.T) + self.b\n",
    "        assert Z.shape == (self.w.shape[0], input.shape[0])\n",
    "        return Z\n",
    "        \n",
    "    def backward(self, A_prev, output, dZ):\n",
    "        \"\"\"\n",
    "        dZ(hidden_dim, in_dim) -- Gradient of the cost respect to the linear output (of current layer L)\n",
    "        \n",
    "        Returns:\n",
    "        dA_prev(batch_size, in_dim) -- Gradient of the cost with respect to the activation (of the previous layer L - 1), same shape as A_prev\n",
    "        \"\"\"\n",
    "        batch_size = A_prev.shape[0]\n",
    "        \n",
    "        self.dw = np.dot(dZ, A_prev) / batch_size\n",
    "        self.db = np.sum(dZ, axis=1, keepdims=True) / batch_size\n",
    "        dA_prev = np.dot(self.w.T, dZ)\n",
    "        \n",
    "        assert (dA_prev.shape == A_prev.T.shape)\n",
    "        assert (self.dw.shape == self.w.shape)\n",
    "        assert (self.db.shape == self.b.shape)\n",
    "        \n",
    "        # Normalize dw/db by batch size\n",
    "        self.dw = self.dw / batch_size\n",
    "        self.db = self.db / batch_size\n",
    "        return dA_prev.T\n",
    "    \n",
    "    def update(self):\n",
    "        self.w = self.w - self.learning_rate * self.dw\n",
    "        self.b = self.b - self.learning_rate * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullyConnect_forward_test():\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                          'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    batch_size = 100\n",
    "    _input = inputs[:batch_size]\n",
    "    \n",
    "    # 429 is feature dim \n",
    "    # 128 is hidden dim \n",
    "    fullyconnect = FullyConnect(429, 128)\n",
    "    return fullyconnect.forward(_input)\n",
    "    \n",
    "# FullyConnect_forward_test()\n",
    "\n",
    "def FullyConnect_backward_test():\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                              'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    batch_size = 100\n",
    "    hidden_dim = 128\n",
    "    in_dim = 429\n",
    "    _input = inputs[:batch_size]\n",
    "\n",
    "    np.random.seed(242)\n",
    "    fullyconnect = FullyConnect(in_dim, hidden_dim)\n",
    "    dZ = np.random.randn(hidden_dim, batch_size)\n",
    "    return fullyconnect.backward(_input, _, dZ)\n",
    "\n",
    "# FullyConnect_backward_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    \n",
    "    def forward(self, input):\n",
    "        _input = input.T\n",
    "        row_max = _input.max(axis=1).reshape(_input.shape[0], 1)\n",
    "        x = _input - row_max\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1).reshape(x.shape[0], 1)\n",
    "    \n",
    "    def backward(self, input, output, d_output):\n",
    "        \"\"\"Directly return the d_output as we show below, the grad is to\n",
    "            the activation(input) of softmax\n",
    "        \"\"\"\n",
    "        return d_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN 层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, hidden_dim, layer_nums):\n",
    "        self.layers = []\n",
    "        self.layers.append(FullyConnect(in_dim, hidden_dim))\n",
    "        self.layers.append(ReLU())\n",
    "        for i in range(layer_nums):\n",
    "            self.layers.append(FullyConnect(hidden_dim, hidden_dim))\n",
    "            self.layers.append(ReLU())\n",
    "        self.layers.append(FullyConnect(hidden_dim, out_dim))\n",
    "        self.layers.append(Softmax())\n",
    "        \n",
    "    def set_learning_rate(self, lr):\n",
    "        for layer in self.layers:\n",
    "            layer.set_learning_rate(lr)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        self.forward_buf = []\n",
    "        out = input\n",
    "        self.forward_buf.append(out)\n",
    "        for i in range(len(self.layers)):\n",
    "            out = self.layers[i].forward(out)\n",
    "            self.forward_buf.append(out)\n",
    "            \n",
    "        assert (len(self.forward_buf) == len(self.layers) + 1)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            grad: the grad is to the activation before softmax\n",
    "        \"\"\"\n",
    "        self.backward_buf = [None] * len(self.layers)\n",
    "        self.backward_buf[len(self.layers) - 1] = grad\n",
    "        for i in range(len(self.layers) - 2, -1, -1):\n",
    "            grad = self.layers[i].backward(self.forward_buf[i],\n",
    "                                          self.forward_buf[i + 1],\n",
    "                                          self.backward_buf[i + 1].T)\n",
    "            self.backward_buf[i] = grad\n",
    "        \n",
    "    def update(self):\n",
    "        for layer in self.layers:\n",
    "            layer.update() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, total_label):\n",
    "    output = np.zeros((labels.shape[0], total_label))\n",
    "    for i in range(labels.shape[0]):\n",
    "        output[i][labels[i]] = 1.0\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_forward_test():\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                              'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    batch_size = 32\n",
    "    permute = np.random.permutation(inputs.shape[0])\n",
    "    inputs = inputs[permute]\n",
    "    labels = labels[permute]\n",
    "    _input = inputs[:batch_size]\n",
    "    _label = labels[:batch_size]\n",
    "    dnn = DNN(429, 11, 128, 1)\n",
    "    dnn.set_learning_rate(1e-2)\n",
    "    \n",
    "    for i in range(len(dnn.layers)):\n",
    "        print(dnn.layers[i])\n",
    "    \n",
    "    out = dnn.forward(_input)\n",
    "\n",
    "    # out = dnn.layers[0].forward(_input)\n",
    "    # out = dnn.layers[1].forward(out)\n",
    "    # out = dnn.layers[2].forward(out)\n",
    "    # out = dnn.layers[3].forward(out)\n",
    "    # out = dnn.layers[4].forward(out)\n",
    "    return out\n",
    "\n",
    "# dnn_forward_test()\n",
    "\n",
    "def dnn_backward_test():\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                              'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    batch_size = 32\n",
    "    permute = np.random.permutation(inputs.shape[0])\n",
    "    inputs = inputs[permute]\n",
    "    labels = labels[permute]\n",
    "    _input = inputs[:batch_size]\n",
    "    _label = labels[:batch_size]\n",
    "    dnn = DNN(429, 11, 128, 1)\n",
    "    dnn.set_learning_rate(1e-2)\n",
    "    \n",
    "    out = dnn.forward(_input)\n",
    "    one_hot_label = one_hot(_label, out.shape[1])\n",
    "    grad = out - one_hot_label\n",
    "    \n",
    "    dnn.backward_buf = [None] * len(dnn.layers)\n",
    "    dnn.backward_buf[len(dnn.layers) - 1] = grad\n",
    "    \n",
    "    for i in range(len(dnn.layers) - 2, -1, -1):\n",
    "        grad = dnn.layers[i].backward(dnn.forward_buf[i],\n",
    "                                      dnn.forward_buf[i + 1],\n",
    "                                      dnn.backward_buf[i + 1].T)\n",
    "        dnn.backward_buf[i] = grad\n",
    "        \n",
    "    return dnn.backward_buf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dnn):\n",
    "    utt2feat, utt2target = read_feats_and_targets('train/feats.scp',\n",
    "                                                  'train/text')\n",
    "    inputs, labels = build_input(targets_mapping, utt2feat, utt2target)\n",
    "    num_samples = inputs.shape[0]\n",
    "    # shuffle data\n",
    "    permute = np.random.permutation(num_samples)\n",
    "    inputs = inputs[permute]\n",
    "    labels = labels[permute]\n",
    "    num_epochs = 100\n",
    "    batch_size = 100\n",
    "    for i in range(num_epochs):\n",
    "        cur = 0\n",
    "        while cur < num_samples:\n",
    "            end = min(cur + batch_size, num_samples)\n",
    "            input = inputs[cur:end]\n",
    "            label = labels[cur:end]\n",
    "            # Step1: forward\n",
    "            out = dnn.forward(input)\n",
    "            one_hot_label = one_hot(label, out.shape[1])\n",
    "            # Step2: compute cross entropy loss and backward\n",
    "            loss = -np.sum(np.log(out + 1e-20) * one_hot_label) / out.shape[0]\n",
    "            # The grad is to activation before softmax\n",
    "            grad = out - one_hot_label\n",
    "            dnn.backward(grad)\n",
    "            # Step3: update parameters\n",
    "            dnn.update()\n",
    "            print('Epoch {} num_samples {} loss {}'.format(i, cur, loss))\n",
    "            cur += batch_size\n",
    "            \n",
    "def test(dnn):\n",
    "    utt2feat, utt2target = read_feats_and_targets('test/feats.scp',\n",
    "                                                  'test/text')\n",
    "    total = len(utt2feat)\n",
    "    correct = 0\n",
    "    for utt in utt2feat:\n",
    "        t = utt2target[utt]\n",
    "        ark = utt2feat[utt]\n",
    "        mat = kaldi_io.read_mat(ark)\n",
    "        mat = splice(mat, 5, 5)\n",
    "        posterior = dnn.forward(mat)\n",
    "        posterior = np.sum(posterior, axis=0) / float(mat.shape[0])\n",
    "        predict = targets_list[np.argmax(posterior)]\n",
    "        if t == predict: correct += 1\n",
    "        print('label: {} predict: {}'.format(t, predict))\n",
    "    print('Acc: {:.3f}'.format(float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 num_samples 0 loss 17.16087425558523\n",
      "Epoch 0 num_samples 100 loss 18.30438824488586\n",
      "Epoch 0 num_samples 200 loss 11.109657785227927\n",
      "Epoch 0 num_samples 300 loss 8.886464483634008\n",
      "Epoch 0 num_samples 400 loss 9.80744541644064\n",
      "Epoch 0 num_samples 500 loss 7.9626844393742156\n",
      "Epoch 0 num_samples 600 loss 8.812555081493828\n",
      "Epoch 0 num_samples 700 loss 8.758557403710599\n",
      "Epoch 0 num_samples 800 loss 8.442973745109903\n",
      "Epoch 0 num_samples 900 loss 7.855848609177367\n",
      "Epoch 0 num_samples 1000 loss 8.075113199222155\n",
      "Epoch 0 num_samples 1100 loss 6.8369329396964895\n",
      "Epoch 0 num_samples 1200 loss 6.988409854597134\n",
      "Epoch 0 num_samples 1300 loss 6.5198158809919615\n",
      "Epoch 0 num_samples 1400 loss 6.749792350708947\n",
      "Epoch 0 num_samples 1500 loss 5.678345019414771\n",
      "Epoch 0 num_samples 1600 loss 5.147394780225227\n",
      "Epoch 0 num_samples 1700 loss 5.615616947627879\n",
      "Epoch 0 num_samples 1800 loss 5.077236615397718\n",
      "Epoch 0 num_samples 1900 loss 5.53220385510183\n",
      "Epoch 0 num_samples 2000 loss 5.0421108039176445\n",
      "Epoch 0 num_samples 2100 loss 6.1586752260191675\n",
      "Epoch 0 num_samples 2200 loss 6.093848579207893\n",
      "Epoch 0 num_samples 2300 loss 5.814453569443093\n",
      "Epoch 0 num_samples 2400 loss 5.815442704701633\n",
      "Epoch 0 num_samples 2500 loss 5.052221547995772\n",
      "Epoch 0 num_samples 2600 loss 4.985166672093307\n",
      "Epoch 0 num_samples 2700 loss 4.424423447386593\n",
      "Epoch 0 num_samples 2800 loss 4.754143838321197\n",
      "Epoch 0 num_samples 2900 loss 4.935179348465506\n",
      "Epoch 0 num_samples 3000 loss 4.711911674293857\n",
      "Epoch 0 num_samples 3100 loss 3.990690887568212\n",
      "Epoch 0 num_samples 3200 loss 5.046399095175142\n",
      "Epoch 0 num_samples 3300 loss 4.536705338750971\n",
      "Epoch 0 num_samples 3400 loss 4.258690757815879\n",
      "Epoch 0 num_samples 3500 loss 4.208463600508144\n",
      "Epoch 0 num_samples 3600 loss 4.089557177787363\n",
      "Epoch 0 num_samples 3700 loss 4.421723599438371\n",
      "Epoch 0 num_samples 3800 loss 4.411337132998445\n",
      "Epoch 0 num_samples 3900 loss 4.21756900792065\n",
      "Epoch 0 num_samples 4000 loss 3.7708576470302\n",
      "Epoch 0 num_samples 4100 loss 3.982677100412457\n",
      "Epoch 0 num_samples 4200 loss 3.388122010016017\n",
      "Epoch 0 num_samples 4300 loss 3.520270984844581\n",
      "Epoch 0 num_samples 4400 loss 4.400432763245957\n",
      "Epoch 0 num_samples 4500 loss 3.6401588991989975\n",
      "Epoch 0 num_samples 4600 loss 3.69758087924441\n",
      "Epoch 0 num_samples 4700 loss 3.688902169671358\n",
      "Epoch 0 num_samples 4800 loss 3.7416431270550055\n",
      "Epoch 0 num_samples 4900 loss 3.7069447116032825\n",
      "Epoch 0 num_samples 5000 loss 3.805733691972874\n",
      "Epoch 0 num_samples 5100 loss 3.365559499640324\n",
      "Epoch 0 num_samples 5200 loss 3.1236210640753717\n",
      "Epoch 0 num_samples 5300 loss 3.1306568675547415\n",
      "Epoch 0 num_samples 5400 loss 4.064614173349159\n",
      "Epoch 0 num_samples 5500 loss 3.100473192412504\n",
      "Epoch 0 num_samples 5600 loss 3.3457629881124613\n",
      "Epoch 0 num_samples 5700 loss 3.336606245483496\n",
      "Epoch 0 num_samples 5800 loss 3.326801268785404\n",
      "Epoch 0 num_samples 5900 loss 3.204614800908503\n",
      "Epoch 0 num_samples 6000 loss 2.65613373512997\n",
      "Epoch 0 num_samples 6100 loss 2.6892287928156065\n",
      "Epoch 0 num_samples 6200 loss 3.884876244226703\n",
      "Epoch 0 num_samples 6300 loss 3.951725709209688\n",
      "Epoch 0 num_samples 6400 loss 3.1515080496134646\n",
      "Epoch 0 num_samples 6500 loss 2.9938252592880144\n",
      "Epoch 0 num_samples 6600 loss 2.967294543015239\n",
      "Epoch 0 num_samples 6700 loss 2.7864892811698065\n",
      "Epoch 0 num_samples 6800 loss 3.287066890832967\n",
      "Epoch 0 num_samples 6900 loss 3.527029219804693\n",
      "Epoch 0 num_samples 7000 loss 2.9072574711416133\n",
      "Epoch 0 num_samples 7100 loss 2.7042293107604984\n",
      "Epoch 0 num_samples 7200 loss 2.6140248649393043\n",
      "Epoch 0 num_samples 7300 loss 2.675734937194262\n",
      "Epoch 0 num_samples 7400 loss 2.67106335735533\n",
      "Epoch 0 num_samples 7500 loss 2.8731373207995032\n",
      "Epoch 0 num_samples 7600 loss 2.9826900015361595\n",
      "Epoch 0 num_samples 7700 loss 2.7407088349463278\n",
      "Epoch 0 num_samples 7800 loss 2.3793013450447034\n",
      "Epoch 0 num_samples 7900 loss 2.509084580295532\n",
      "Epoch 0 num_samples 8000 loss 2.470793735139621\n",
      "Epoch 0 num_samples 8100 loss 3.2262084189267215\n",
      "Epoch 0 num_samples 8200 loss 2.438130316097294\n",
      "Epoch 0 num_samples 8300 loss 2.8091042298296\n",
      "Epoch 0 num_samples 8400 loss 2.511336369165751\n",
      "Epoch 0 num_samples 8500 loss 2.5575102365550584\n",
      "Epoch 0 num_samples 8600 loss 2.448453288704723\n",
      "Epoch 0 num_samples 8700 loss 2.531949762951303\n",
      "Epoch 0 num_samples 8800 loss 2.2165414581112217\n",
      "Epoch 0 num_samples 8900 loss 2.759332543030331\n",
      "Epoch 0 num_samples 9000 loss 2.278232846741142\n",
      "Epoch 0 num_samples 9100 loss 2.278985664747982\n",
      "Epoch 0 num_samples 9200 loss 2.9056858031013193\n",
      "Epoch 0 num_samples 9300 loss 2.2063333222050385\n",
      "Epoch 0 num_samples 9400 loss 2.3398791149796967\n",
      "Epoch 0 num_samples 9500 loss 2.131439226453299\n",
      "Epoch 0 num_samples 9600 loss 2.350629839989642\n",
      "Epoch 0 num_samples 9700 loss 2.795001212220374\n",
      "Epoch 0 num_samples 9800 loss 1.74925697054667\n",
      "Epoch 0 num_samples 9900 loss 3.3248580423456793\n",
      "Epoch 0 num_samples 10000 loss 2.1030338759282916\n",
      "Epoch 0 num_samples 10100 loss 1.7037006309285812\n",
      "Epoch 0 num_samples 10200 loss 2.4471520732933483\n",
      "Epoch 0 num_samples 10300 loss 2.728977346554466\n",
      "Epoch 0 num_samples 10400 loss 2.43430153719455\n",
      "Epoch 0 num_samples 10500 loss 2.488988854435212\n",
      "Epoch 0 num_samples 10600 loss 2.344478896130882\n",
      "Epoch 0 num_samples 10700 loss 2.2066765804329616\n",
      "Epoch 0 num_samples 10800 loss 2.4484310514635057\n",
      "Epoch 0 num_samples 10900 loss 2.394458162901541\n",
      "Epoch 0 num_samples 11000 loss 2.1368483772919022\n",
      "Epoch 0 num_samples 11100 loss 2.4154626958813155\n",
      "Epoch 0 num_samples 11200 loss 1.9132637772159398\n",
      "Epoch 0 num_samples 11300 loss 2.6606984687319506\n",
      "Epoch 0 num_samples 11400 loss 2.2823925609610827\n",
      "Epoch 0 num_samples 11500 loss 2.429468476027552\n",
      "Epoch 0 num_samples 11600 loss 2.415571996145435\n",
      "Epoch 0 num_samples 11700 loss 2.0406381830496296\n",
      "Epoch 0 num_samples 11800 loss 1.9275764416734973\n",
      "Epoch 0 num_samples 11900 loss 2.531731734297758\n",
      "Epoch 0 num_samples 12000 loss 1.8745980908823965\n",
      "Epoch 0 num_samples 12100 loss 1.7715077016934955\n",
      "Epoch 0 num_samples 12200 loss 1.6818909000734055\n",
      "Epoch 0 num_samples 12300 loss 1.9731525206369298\n",
      "Epoch 0 num_samples 12400 loss 1.983014648306795\n",
      "Epoch 0 num_samples 12500 loss 1.8030135694855045\n",
      "Epoch 0 num_samples 12600 loss 2.025887566002545\n",
      "Epoch 0 num_samples 12700 loss 1.8800143060403138\n",
      "Epoch 0 num_samples 12800 loss 2.0480581143437986\n",
      "Epoch 0 num_samples 12900 loss 1.509806645759794\n",
      "Epoch 0 num_samples 13000 loss 1.6071929164663792\n",
      "Epoch 0 num_samples 13100 loss 2.129758351941901\n",
      "Epoch 0 num_samples 13200 loss 1.9177532569290212\n",
      "Epoch 0 num_samples 13300 loss 2.2395656953758225\n",
      "Epoch 0 num_samples 13400 loss 1.9583175770447427\n",
      "Epoch 0 num_samples 13500 loss 1.690230572915429\n",
      "Epoch 0 num_samples 13600 loss 2.033273207800463\n",
      "Epoch 0 num_samples 13700 loss 2.2510559686751717\n",
      "Epoch 0 num_samples 13800 loss 1.7789201923438294\n",
      "Epoch 0 num_samples 13900 loss 1.885747346837451\n",
      "Epoch 0 num_samples 14000 loss 1.5800022699386778\n",
      "Epoch 0 num_samples 14100 loss 1.8336791566819999\n",
      "Epoch 0 num_samples 14200 loss 1.4138605475272132\n",
      "Epoch 0 num_samples 14300 loss 2.098853395110463\n",
      "Epoch 0 num_samples 14400 loss 1.885203544902589\n",
      "Epoch 0 num_samples 14500 loss 2.0174046217780375\n",
      "Epoch 0 num_samples 14600 loss 2.021708753905383\n",
      "Epoch 0 num_samples 14700 loss 1.8608555422983277\n",
      "Epoch 0 num_samples 14800 loss 1.8901591667437918\n",
      "Epoch 0 num_samples 14900 loss 1.8418391960693532\n",
      "Epoch 0 num_samples 15000 loss 1.4815122646916714\n",
      "Epoch 0 num_samples 15100 loss 2.1496158637516665\n",
      "Epoch 0 num_samples 15200 loss 1.8312168648183969\n",
      "Epoch 0 num_samples 15300 loss 1.935617973917512\n",
      "Epoch 0 num_samples 15400 loss 1.4812660871477583\n",
      "Epoch 0 num_samples 15500 loss 1.445912976239814\n",
      "Epoch 0 num_samples 15600 loss 1.9278079422628767\n",
      "Epoch 0 num_samples 15700 loss 1.7627176238720679\n",
      "Epoch 0 num_samples 15800 loss 1.9506295822668318\n",
      "Epoch 0 num_samples 15900 loss 1.8788217968481637\n",
      "Epoch 0 num_samples 16000 loss 1.9152667554847154\n",
      "Epoch 0 num_samples 16100 loss 1.9549042709958717\n",
      "Epoch 0 num_samples 16200 loss 1.6265456243021552\n",
      "Epoch 0 num_samples 16300 loss 1.9317594840790813\n",
      "Epoch 0 num_samples 16400 loss 1.5928537788922312\n",
      "Epoch 0 num_samples 16500 loss 1.940680153538566\n",
      "Epoch 0 num_samples 16600 loss 1.567276646492706\n",
      "Epoch 0 num_samples 16700 loss 1.5580131033880928\n",
      "Epoch 0 num_samples 16800 loss 1.7560219973379914\n",
      "Epoch 0 num_samples 16900 loss 1.7013083682296344\n",
      "Epoch 0 num_samples 17000 loss 1.6025640705743072\n",
      "Epoch 0 num_samples 17100 loss 1.6130029766493021\n",
      "Epoch 0 num_samples 17200 loss 1.2446099731094042\n",
      "Epoch 0 num_samples 17300 loss 1.920038333217252\n",
      "Epoch 0 num_samples 17400 loss 1.837551299310745\n",
      "Epoch 0 num_samples 17500 loss 1.5185033086565547\n",
      "Epoch 0 num_samples 17600 loss 2.0521992919344023\n",
      "Epoch 0 num_samples 17700 loss 1.9247538696601274\n",
      "Epoch 0 num_samples 17800 loss 1.5618177148121604\n",
      "Epoch 0 num_samples 17900 loss 1.5774165232880069\n",
      "Epoch 0 num_samples 18000 loss 1.493066262931332\n",
      "Epoch 0 num_samples 18100 loss 1.517544842342196\n",
      "Epoch 0 num_samples 18200 loss 1.6208468066394313\n",
      "Epoch 0 num_samples 18300 loss 1.3973384927774704\n",
      "Epoch 0 num_samples 18400 loss 1.6177929710641867\n",
      "Epoch 0 num_samples 18500 loss 1.85113595165112\n",
      "Epoch 1 num_samples 0 loss 1.681120641594639\n",
      "Epoch 1 num_samples 100 loss 1.2893738223748317\n",
      "Epoch 1 num_samples 200 loss 1.5396761915915036\n",
      "Epoch 1 num_samples 300 loss 1.3313946809038655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 num_samples 400 loss 1.5474038851017429\n",
      "Epoch 1 num_samples 500 loss 1.5984403468492001\n",
      "Epoch 1 num_samples 600 loss 1.4948973080618948\n",
      "Epoch 1 num_samples 700 loss 1.2951585958611307\n",
      "Epoch 1 num_samples 800 loss 1.5283275528545572\n",
      "Epoch 1 num_samples 900 loss 1.3392994141810244\n",
      "Epoch 1 num_samples 1000 loss 1.3140029144778236\n",
      "Epoch 1 num_samples 1100 loss 1.4118410560307615\n",
      "Epoch 1 num_samples 1200 loss 1.098628448222979\n",
      "Epoch 1 num_samples 1300 loss 1.3172736886436853\n",
      "Epoch 1 num_samples 1400 loss 1.385394529816408\n",
      "Epoch 1 num_samples 1500 loss 1.154712179140676\n",
      "Epoch 1 num_samples 1600 loss 1.2188025101106057\n",
      "Epoch 1 num_samples 1700 loss 1.391699178796202\n",
      "Epoch 1 num_samples 1800 loss 1.1435096619677578\n",
      "Epoch 1 num_samples 1900 loss 1.2039154016348086\n",
      "Epoch 1 num_samples 2000 loss 1.4095783303307232\n",
      "Epoch 1 num_samples 2100 loss 1.3513548141077598\n",
      "Epoch 1 num_samples 2200 loss 1.30204736165637\n",
      "Epoch 1 num_samples 2300 loss 1.234618109912567\n",
      "Epoch 1 num_samples 2400 loss 1.5516035027298012\n",
      "Epoch 1 num_samples 2500 loss 1.480596226543538\n",
      "Epoch 1 num_samples 2600 loss 1.2068666603383364\n",
      "Epoch 1 num_samples 2700 loss 1.1403680031302932\n",
      "Epoch 1 num_samples 2800 loss 1.377899839563614\n",
      "Epoch 1 num_samples 2900 loss 1.4916355217183426\n",
      "Epoch 1 num_samples 3000 loss 1.2191937967475743\n",
      "Epoch 1 num_samples 3100 loss 1.2531661680503818\n",
      "Epoch 1 num_samples 3200 loss 1.5696279361033054\n",
      "Epoch 1 num_samples 3300 loss 1.2546919267195935\n",
      "Epoch 1 num_samples 3400 loss 1.2060942764638098\n",
      "Epoch 1 num_samples 3500 loss 1.351334095550992\n",
      "Epoch 1 num_samples 3600 loss 1.0452741333113835\n",
      "Epoch 1 num_samples 3700 loss 1.4540024065387007\n",
      "Epoch 1 num_samples 3800 loss 1.3448878991461912\n",
      "Epoch 1 num_samples 3900 loss 1.462858594372254\n",
      "Epoch 1 num_samples 4000 loss 1.4353617715089109\n",
      "Epoch 1 num_samples 4100 loss 1.4192068983062995\n",
      "Epoch 1 num_samples 4200 loss 0.9756971318676895\n",
      "Epoch 1 num_samples 4300 loss 1.2437723681300206\n",
      "Epoch 1 num_samples 4400 loss 1.3925244042516156\n",
      "Epoch 1 num_samples 4500 loss 1.3243497064669185\n",
      "Epoch 1 num_samples 4600 loss 1.2623710802079935\n",
      "Epoch 1 num_samples 4700 loss 1.1034654640586516\n",
      "Epoch 1 num_samples 4800 loss 1.1812169352466677\n",
      "Epoch 1 num_samples 4900 loss 1.1555515050337248\n",
      "Epoch 1 num_samples 5000 loss 1.549413171699658\n",
      "Epoch 1 num_samples 5100 loss 1.4499502927038048\n",
      "Epoch 1 num_samples 5200 loss 1.1233398517813575\n",
      "Epoch 1 num_samples 5300 loss 1.095931192767054\n",
      "Epoch 1 num_samples 5400 loss 1.7894998948827439\n",
      "Epoch 1 num_samples 5500 loss 1.2188830344684154\n",
      "Epoch 1 num_samples 5600 loss 1.0577696970034907\n",
      "Epoch 1 num_samples 5700 loss 1.4160931392312255\n",
      "Epoch 1 num_samples 5800 loss 1.329533844255129\n",
      "Epoch 1 num_samples 5900 loss 1.2694151983002084\n",
      "Epoch 1 num_samples 6000 loss 1.10843365917667\n",
      "Epoch 1 num_samples 6100 loss 0.8190359352036956\n",
      "Epoch 1 num_samples 6200 loss 1.6152766852487395\n",
      "Epoch 1 num_samples 6300 loss 1.8130558639061451\n",
      "Epoch 1 num_samples 6400 loss 1.3281199804217132\n",
      "Epoch 1 num_samples 6500 loss 1.4159365849603482\n",
      "Epoch 1 num_samples 6600 loss 1.418434512532752\n",
      "Epoch 1 num_samples 6700 loss 0.9009218708314958\n",
      "Epoch 1 num_samples 6800 loss 1.0479019694031686\n",
      "Epoch 1 num_samples 6900 loss 1.4866321808420273\n",
      "Epoch 1 num_samples 7000 loss 1.2010929403629051\n",
      "Epoch 1 num_samples 7100 loss 1.0919232903419427\n",
      "Epoch 1 num_samples 7200 loss 1.2269244833096236\n",
      "Epoch 1 num_samples 7300 loss 1.2100332335383848\n",
      "Epoch 1 num_samples 7400 loss 1.1912581813876688\n",
      "Epoch 1 num_samples 7500 loss 1.2191667608716867\n",
      "Epoch 1 num_samples 7600 loss 1.3987124685098236\n",
      "Epoch 1 num_samples 7700 loss 1.2107931459759933\n",
      "Epoch 1 num_samples 7800 loss 0.8489964790188921\n",
      "Epoch 1 num_samples 7900 loss 1.1469692467193706\n",
      "Epoch 1 num_samples 8000 loss 0.9398058248432093\n",
      "Epoch 1 num_samples 8100 loss 1.3910905302848744\n",
      "Epoch 1 num_samples 8200 loss 1.08282834205848\n",
      "Epoch 1 num_samples 8300 loss 1.1201106688885112\n",
      "Epoch 1 num_samples 8400 loss 1.1736840327140527\n",
      "Epoch 1 num_samples 8500 loss 1.2214271154241882\n",
      "Epoch 1 num_samples 8600 loss 0.9297936308980249\n",
      "Epoch 1 num_samples 8700 loss 1.1582412693017219\n",
      "Epoch 1 num_samples 8800 loss 1.130881954586816\n",
      "Epoch 1 num_samples 8900 loss 1.3917158026607461\n",
      "Epoch 1 num_samples 9000 loss 1.0340401775697228\n",
      "Epoch 1 num_samples 9100 loss 1.1743798459446613\n",
      "Epoch 1 num_samples 9200 loss 1.178181700907296\n",
      "Epoch 1 num_samples 9300 loss 1.1049605980321227\n",
      "Epoch 1 num_samples 9400 loss 0.951969607680418\n",
      "Epoch 1 num_samples 9500 loss 1.06109664830431\n",
      "Epoch 1 num_samples 9600 loss 1.108268470969024\n",
      "Epoch 1 num_samples 9700 loss 1.4988364877658278\n",
      "Epoch 1 num_samples 9800 loss 0.841360593971796\n",
      "Epoch 1 num_samples 9900 loss 1.5684130432282777\n",
      "Epoch 1 num_samples 10000 loss 1.0119180455539183\n",
      "Epoch 1 num_samples 10100 loss 0.7601132099228494\n",
      "Epoch 1 num_samples 10200 loss 1.2005189827094147\n",
      "Epoch 1 num_samples 10300 loss 1.3440319888266001\n",
      "Epoch 1 num_samples 10400 loss 1.2248210703555402\n",
      "Epoch 1 num_samples 10500 loss 1.3632197410384963\n",
      "Epoch 1 num_samples 10600 loss 1.0787886999870606\n",
      "Epoch 1 num_samples 10700 loss 1.061244490076851\n",
      "Epoch 1 num_samples 10800 loss 1.1779344686242323\n",
      "Epoch 1 num_samples 10900 loss 1.337769806710745\n",
      "Epoch 1 num_samples 11000 loss 0.9380075289873195\n",
      "Epoch 1 num_samples 11100 loss 1.3496976817914317\n",
      "Epoch 1 num_samples 11200 loss 1.0049875720379005\n",
      "Epoch 1 num_samples 11300 loss 1.509166730492517\n",
      "Epoch 1 num_samples 11400 loss 1.1946908695269776\n",
      "Epoch 1 num_samples 11500 loss 1.1966927030113117\n",
      "Epoch 1 num_samples 11600 loss 1.1905563164657087\n",
      "Epoch 1 num_samples 11700 loss 1.1013239949795481\n",
      "Epoch 1 num_samples 11800 loss 0.8954841971824262\n",
      "Epoch 1 num_samples 11900 loss 1.1959005748830203\n",
      "Epoch 1 num_samples 12000 loss 0.9874608696775437\n",
      "Epoch 1 num_samples 12100 loss 0.9306721783439731\n",
      "Epoch 1 num_samples 12200 loss 1.0307013807721819\n",
      "Epoch 1 num_samples 12300 loss 0.9983789065750404\n",
      "Epoch 1 num_samples 12400 loss 1.1024077689988017\n",
      "Epoch 1 num_samples 12500 loss 0.9632755720628247\n",
      "Epoch 1 num_samples 12600 loss 1.0478196454415385\n",
      "Epoch 1 num_samples 12700 loss 1.0897031628215474\n",
      "Epoch 1 num_samples 12800 loss 1.0515894926194034\n",
      "Epoch 1 num_samples 12900 loss 0.6076351541716826\n",
      "Epoch 1 num_samples 13000 loss 0.901312231758847\n",
      "Epoch 1 num_samples 13100 loss 1.3252930673335388\n",
      "Epoch 1 num_samples 13200 loss 1.1308246745392105\n",
      "Epoch 1 num_samples 13300 loss 1.2892751278238521\n",
      "Epoch 1 num_samples 13400 loss 1.0528521545074607\n",
      "Epoch 1 num_samples 13500 loss 0.8059029371120018\n",
      "Epoch 1 num_samples 13600 loss 1.1002848895301645\n",
      "Epoch 1 num_samples 13700 loss 1.1982390018444762\n",
      "Epoch 1 num_samples 13800 loss 0.9363560559214509\n",
      "Epoch 1 num_samples 13900 loss 1.007931009424485\n",
      "Epoch 1 num_samples 14000 loss 0.8047889140976768\n",
      "Epoch 1 num_samples 14100 loss 0.9112369078797873\n",
      "Epoch 1 num_samples 14200 loss 0.7666780816533344\n",
      "Epoch 1 num_samples 14300 loss 1.1712052189012232\n",
      "Epoch 1 num_samples 14400 loss 1.0703748666841453\n",
      "Epoch 1 num_samples 14500 loss 1.1906607214575557\n",
      "Epoch 1 num_samples 14600 loss 1.1788792866951987\n",
      "Epoch 1 num_samples 14700 loss 1.0404147662231518\n",
      "Epoch 1 num_samples 14800 loss 0.9356883260613823\n",
      "Epoch 1 num_samples 14900 loss 1.1407803029525092\n",
      "Epoch 1 num_samples 15000 loss 0.8084252018564001\n",
      "Epoch 1 num_samples 15100 loss 1.3395293587777548\n",
      "Epoch 1 num_samples 15200 loss 1.0677918571170326\n",
      "Epoch 1 num_samples 15300 loss 1.135562017745896\n",
      "Epoch 1 num_samples 15400 loss 0.7401157042859592\n",
      "Epoch 1 num_samples 15500 loss 0.846740487242989\n",
      "Epoch 1 num_samples 15600 loss 1.2540420483816035\n",
      "Epoch 1 num_samples 15700 loss 0.9100426572420411\n",
      "Epoch 1 num_samples 15800 loss 1.1001550193543241\n",
      "Epoch 1 num_samples 15900 loss 1.0497020358193963\n",
      "Epoch 1 num_samples 16000 loss 1.2535309586994579\n",
      "Epoch 1 num_samples 16100 loss 1.1606355077301673\n",
      "Epoch 1 num_samples 16200 loss 0.790806094872789\n",
      "Epoch 1 num_samples 16300 loss 1.1018243436163253\n",
      "Epoch 1 num_samples 16400 loss 0.9217038030350099\n",
      "Epoch 1 num_samples 16500 loss 1.2186022971567367\n",
      "Epoch 1 num_samples 16600 loss 1.0777541989047887\n",
      "Epoch 1 num_samples 16700 loss 0.8421549885586478\n",
      "Epoch 1 num_samples 16800 loss 0.9499103660184367\n",
      "Epoch 1 num_samples 16900 loss 1.0602969513972567\n",
      "Epoch 1 num_samples 17000 loss 0.8738661799454082\n",
      "Epoch 1 num_samples 17100 loss 0.9692271023860956\n",
      "Epoch 1 num_samples 17200 loss 0.7922876548998689\n",
      "Epoch 1 num_samples 17300 loss 1.1196338140872526\n",
      "Epoch 1 num_samples 17400 loss 1.1423734584996956\n",
      "Epoch 1 num_samples 17500 loss 1.0337281389271877\n",
      "Epoch 1 num_samples 17600 loss 1.175611927991372\n",
      "Epoch 1 num_samples 17700 loss 1.1579899330644485\n",
      "Epoch 1 num_samples 17800 loss 0.9206321061902397\n",
      "Epoch 1 num_samples 17900 loss 0.9719359125376943\n",
      "Epoch 1 num_samples 18000 loss 0.8963320294616736\n",
      "Epoch 1 num_samples 18100 loss 0.9545894585013049\n",
      "Epoch 1 num_samples 18200 loss 0.9149354734480643\n",
      "Epoch 1 num_samples 18300 loss 0.8905695154663225\n",
      "Epoch 1 num_samples 18400 loss 1.1234099543322917\n",
      "Epoch 1 num_samples 18500 loss 1.0509748198749365\n",
      "Epoch 2 num_samples 0 loss 1.03624767672522\n",
      "Epoch 2 num_samples 100 loss 0.8264752177103069\n",
      "Epoch 2 num_samples 200 loss 0.9793482561070203\n",
      "Epoch 2 num_samples 300 loss 0.8445133847904907\n",
      "Epoch 2 num_samples 400 loss 0.9371160077744161\n",
      "Epoch 2 num_samples 500 loss 0.9451731565221031\n",
      "Epoch 2 num_samples 600 loss 0.9604545871949266\n",
      "Epoch 2 num_samples 700 loss 0.7803779927450424\n",
      "Epoch 2 num_samples 800 loss 0.9835401350881532\n",
      "Epoch 2 num_samples 900 loss 0.7930549871043198\n",
      "Epoch 2 num_samples 1000 loss 0.8341039307754837\n",
      "Epoch 2 num_samples 1100 loss 0.9690051066920097\n",
      "Epoch 2 num_samples 1200 loss 0.7142494830024779\n",
      "Epoch 2 num_samples 1300 loss 0.8698055555420171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 num_samples 1400 loss 1.0309334349721633\n",
      "Epoch 2 num_samples 1500 loss 0.8033139370272173\n",
      "Epoch 2 num_samples 1600 loss 0.878467211290895\n",
      "Epoch 2 num_samples 1700 loss 0.93007150526612\n",
      "Epoch 2 num_samples 1800 loss 0.7561219126091817\n",
      "Epoch 2 num_samples 1900 loss 0.7823987929488623\n",
      "Epoch 2 num_samples 2000 loss 0.9426038929472633\n",
      "Epoch 2 num_samples 2100 loss 0.8365832456349215\n",
      "Epoch 2 num_samples 2200 loss 0.7485533387834138\n",
      "Epoch 2 num_samples 2300 loss 0.7822097818971604\n",
      "Epoch 2 num_samples 2400 loss 0.9065545579343496\n",
      "Epoch 2 num_samples 2500 loss 1.0188016535584825\n",
      "Epoch 2 num_samples 2600 loss 0.8260637133911115\n",
      "Epoch 2 num_samples 2700 loss 0.7778281736584931\n",
      "Epoch 2 num_samples 2800 loss 0.9629512460827631\n",
      "Epoch 2 num_samples 2900 loss 0.9509262151852539\n",
      "Epoch 2 num_samples 3000 loss 0.7876712348217124\n",
      "Epoch 2 num_samples 3100 loss 0.8091735679602868\n",
      "Epoch 2 num_samples 3200 loss 1.0456896813823597\n",
      "Epoch 2 num_samples 3300 loss 0.8107575294867192\n",
      "Epoch 2 num_samples 3400 loss 0.8044105018531438\n",
      "Epoch 2 num_samples 3500 loss 0.8596230548334944\n",
      "Epoch 2 num_samples 3600 loss 0.6779248447772404\n",
      "Epoch 2 num_samples 3700 loss 0.9324008277275121\n",
      "Epoch 2 num_samples 3800 loss 0.9087423143694696\n",
      "Epoch 2 num_samples 3900 loss 1.0341232349903693\n",
      "Epoch 2 num_samples 4000 loss 1.011971765879692\n",
      "Epoch 2 num_samples 4100 loss 1.008771891172556\n",
      "Epoch 2 num_samples 4200 loss 0.7107433864206706\n",
      "Epoch 2 num_samples 4300 loss 0.8422554345814476\n",
      "Epoch 2 num_samples 4400 loss 0.9315078146212187\n",
      "Epoch 2 num_samples 4500 loss 0.9427304203040918\n",
      "Epoch 2 num_samples 4600 loss 0.8646716402605574\n",
      "Epoch 2 num_samples 4700 loss 0.6650641337835569\n",
      "Epoch 2 num_samples 4800 loss 0.7739303537730648\n",
      "Epoch 2 num_samples 4900 loss 0.8192900830724485\n",
      "Epoch 2 num_samples 5000 loss 1.0943944062119086\n",
      "Epoch 2 num_samples 5100 loss 1.028334998141756\n",
      "Epoch 2 num_samples 5200 loss 0.7886182693629923\n",
      "Epoch 2 num_samples 5300 loss 0.7416718081260691\n",
      "Epoch 2 num_samples 5400 loss 1.2527906818151717\n",
      "Epoch 2 num_samples 5500 loss 0.8636008157197739\n",
      "Epoch 2 num_samples 5600 loss 0.714320308482032\n",
      "Epoch 2 num_samples 5700 loss 1.0571775703344108\n",
      "Epoch 2 num_samples 5800 loss 0.9193305858896885\n",
      "Epoch 2 num_samples 5900 loss 0.8690133071522503\n",
      "Epoch 2 num_samples 6000 loss 0.8172653331658417\n",
      "Epoch 2 num_samples 6100 loss 0.5422000531457779\n",
      "Epoch 2 num_samples 6200 loss 1.1030969445344716\n",
      "Epoch 2 num_samples 6300 loss 1.2692671358990548\n",
      "Epoch 2 num_samples 6400 loss 0.8736302855993542\n",
      "Epoch 2 num_samples 6500 loss 0.9286883533775991\n",
      "Epoch 2 num_samples 6600 loss 1.0267349764776381\n",
      "Epoch 2 num_samples 6700 loss 0.6339341463108435\n",
      "Epoch 2 num_samples 6800 loss 0.6344415420750729\n",
      "Epoch 2 num_samples 6900 loss 1.0962142209827679\n",
      "Epoch 2 num_samples 7000 loss 0.8670446981309344\n",
      "Epoch 2 num_samples 7100 loss 0.6854378828147222\n",
      "Epoch 2 num_samples 7200 loss 0.9039272719260413\n",
      "Epoch 2 num_samples 7300 loss 0.8189668499962984\n",
      "Epoch 2 num_samples 7400 loss 0.822585951656873\n",
      "Epoch 2 num_samples 7500 loss 0.8770805469899301\n",
      "Epoch 2 num_samples 7600 loss 0.9970084260767774\n",
      "Epoch 2 num_samples 7700 loss 0.9089676996267829\n",
      "Epoch 2 num_samples 7800 loss 0.547465064243045\n",
      "Epoch 2 num_samples 7900 loss 0.8370199978833722\n",
      "Epoch 2 num_samples 8000 loss 0.636030890179503\n",
      "Epoch 2 num_samples 8100 loss 0.9450866397331533\n",
      "Epoch 2 num_samples 8200 loss 0.7491192702968823\n",
      "Epoch 2 num_samples 8300 loss 0.7449700613587157\n",
      "Epoch 2 num_samples 8400 loss 0.8050643323461371\n",
      "Epoch 2 num_samples 8500 loss 0.869027997132041\n",
      "Epoch 2 num_samples 8600 loss 0.6385996202366797\n",
      "Epoch 2 num_samples 8700 loss 0.8144244139033034\n",
      "Epoch 2 num_samples 8800 loss 0.7660203692917181\n",
      "Epoch 2 num_samples 8900 loss 1.0289301942289109\n",
      "Epoch 2 num_samples 9000 loss 0.74362829974975\n",
      "Epoch 2 num_samples 9100 loss 0.8796537932646092\n",
      "Epoch 2 num_samples 9200 loss 0.7803238744442765\n",
      "Epoch 2 num_samples 9300 loss 0.8645555037787996\n",
      "Epoch 2 num_samples 9400 loss 0.6344208091450746\n",
      "Epoch 2 num_samples 9500 loss 0.8048244129450134\n",
      "Epoch 2 num_samples 9600 loss 0.79266437986424\n",
      "Epoch 2 num_samples 9700 loss 1.112684675864556\n",
      "Epoch 2 num_samples 9800 loss 0.5801909301609182\n",
      "Epoch 2 num_samples 9900 loss 1.0591869332350246\n",
      "Epoch 2 num_samples 10000 loss 0.7282989123773416\n",
      "Epoch 2 num_samples 10100 loss 0.5303032440102232\n",
      "Epoch 2 num_samples 10200 loss 0.8841184984369742\n",
      "Epoch 2 num_samples 10300 loss 0.9690625178253203\n",
      "Epoch 2 num_samples 10400 loss 0.9250413299973116\n",
      "Epoch 2 num_samples 10500 loss 0.9384575582115025\n",
      "Epoch 2 num_samples 10600 loss 0.7602419346007003\n",
      "Epoch 2 num_samples 10700 loss 0.7161085420745309\n",
      "Epoch 2 num_samples 10800 loss 0.8045363025066224\n",
      "Epoch 2 num_samples 10900 loss 0.9679691716245048\n",
      "Epoch 2 num_samples 11000 loss 0.6262734235470903\n",
      "Epoch 2 num_samples 11100 loss 0.9949592249932104\n",
      "Epoch 2 num_samples 11200 loss 0.7507232504099273\n",
      "Epoch 2 num_samples 11300 loss 1.0727584253024987\n",
      "Epoch 2 num_samples 11400 loss 0.8974875168691869\n",
      "Epoch 2 num_samples 11500 loss 0.8079720562773144\n",
      "Epoch 2 num_samples 11600 loss 0.8232465302820734\n",
      "Epoch 2 num_samples 11700 loss 0.811129717787637\n",
      "Epoch 2 num_samples 11800 loss 0.5769722393099856\n",
      "Epoch 2 num_samples 11900 loss 0.7794355635380191\n",
      "Epoch 2 num_samples 12000 loss 0.7246883606612693\n",
      "Epoch 2 num_samples 12100 loss 0.6782826644156347\n",
      "Epoch 2 num_samples 12200 loss 0.7424699852770857\n",
      "Epoch 2 num_samples 12300 loss 0.691450154744459\n",
      "Epoch 2 num_samples 12400 loss 0.7897622014388241\n",
      "Epoch 2 num_samples 12500 loss 0.7047652208450773\n",
      "Epoch 2 num_samples 12600 loss 0.749582429935379\n",
      "Epoch 2 num_samples 12700 loss 0.8100467514562159\n",
      "Epoch 2 num_samples 12800 loss 0.80770568531941\n",
      "Epoch 2 num_samples 12900 loss 0.43259772062520385\n",
      "Epoch 2 num_samples 13000 loss 0.6786793948540835\n",
      "Epoch 2 num_samples 13100 loss 0.9787341110727639\n",
      "Epoch 2 num_samples 13200 loss 0.8487601350407743\n",
      "Epoch 2 num_samples 13300 loss 0.8796275460804577\n",
      "Epoch 2 num_samples 13400 loss 0.730145016222294\n",
      "Epoch 2 num_samples 13500 loss 0.5744035968557343\n",
      "Epoch 2 num_samples 13600 loss 0.8042552152039641\n",
      "Epoch 2 num_samples 13700 loss 0.8481428096394135\n",
      "Epoch 2 num_samples 13800 loss 0.6463377433486736\n",
      "Epoch 2 num_samples 13900 loss 0.7321708052240787\n",
      "Epoch 2 num_samples 14000 loss 0.5498783471354033\n",
      "Epoch 2 num_samples 14100 loss 0.6431625523212992\n",
      "Epoch 2 num_samples 14200 loss 0.5625057116432558\n",
      "Epoch 2 num_samples 14300 loss 0.8357873212189585\n",
      "Epoch 2 num_samples 14400 loss 0.8403369967782066\n",
      "Epoch 2 num_samples 14500 loss 0.8924388802304105\n",
      "Epoch 2 num_samples 14600 loss 0.8816822250074244\n",
      "Epoch 2 num_samples 14700 loss 0.8181502683334173\n",
      "Epoch 2 num_samples 14800 loss 0.6341273773970808\n",
      "Epoch 2 num_samples 14900 loss 0.856255982105418\n",
      "Epoch 2 num_samples 15000 loss 0.5711229147435384\n",
      "Epoch 2 num_samples 15100 loss 0.9812014308015032\n",
      "Epoch 2 num_samples 15200 loss 0.7894624676854093\n",
      "Epoch 2 num_samples 15300 loss 0.8122343805439257\n",
      "Epoch 2 num_samples 15400 loss 0.5476911641659642\n",
      "Epoch 2 num_samples 15500 loss 0.6440627695727172\n",
      "Epoch 2 num_samples 15600 loss 0.9223775365646607\n",
      "Epoch 2 num_samples 15700 loss 0.6275941316353406\n",
      "Epoch 2 num_samples 15800 loss 0.8209867580249883\n",
      "Epoch 2 num_samples 15900 loss 0.7433383875511237\n",
      "Epoch 2 num_samples 16000 loss 0.9852609948107913\n",
      "Epoch 2 num_samples 16100 loss 0.8412483905443742\n",
      "Epoch 2 num_samples 16200 loss 0.5714634735475435\n",
      "Epoch 2 num_samples 16300 loss 0.7997831991058979\n",
      "Epoch 2 num_samples 16400 loss 0.6970030521593817\n",
      "Epoch 2 num_samples 16500 loss 0.8944251105223736\n",
      "Epoch 2 num_samples 16600 loss 0.8657159433162842\n",
      "Epoch 2 num_samples 16700 loss 0.5894752491175789\n",
      "Epoch 2 num_samples 16800 loss 0.6647799366092947\n",
      "Epoch 2 num_samples 16900 loss 0.8151182103053384\n",
      "Epoch 2 num_samples 17000 loss 0.6498954486132362\n",
      "Epoch 2 num_samples 17100 loss 0.7430085362483716\n",
      "Epoch 2 num_samples 17200 loss 0.6076990082851212\n",
      "Epoch 2 num_samples 17300 loss 0.8418949274959524\n",
      "Epoch 2 num_samples 17400 loss 0.849656158522048\n",
      "Epoch 2 num_samples 17500 loss 0.8127710893022333\n",
      "Epoch 2 num_samples 17600 loss 0.8405427716667865\n",
      "Epoch 2 num_samples 17700 loss 0.8247473637348586\n",
      "Epoch 2 num_samples 17800 loss 0.6902601655408078\n",
      "Epoch 2 num_samples 17900 loss 0.7341070561577918\n",
      "Epoch 2 num_samples 18000 loss 0.6708054679117242\n",
      "Epoch 2 num_samples 18100 loss 0.6998245021359557\n",
      "Epoch 2 num_samples 18200 loss 0.6758213607729365\n",
      "Epoch 2 num_samples 18300 loss 0.7110657825637671\n",
      "Epoch 2 num_samples 18400 loss 0.9024877793871713\n",
      "Epoch 2 num_samples 18500 loss 0.747984748819223\n",
      "Epoch 3 num_samples 0 loss 0.7556138009208769\n",
      "Epoch 3 num_samples 100 loss 0.6201430198711125\n",
      "Epoch 3 num_samples 200 loss 0.7284342159947513\n",
      "Epoch 3 num_samples 300 loss 0.6389984145611796\n",
      "Epoch 3 num_samples 400 loss 0.6326264802906891\n",
      "Epoch 3 num_samples 500 loss 0.722344507328567\n",
      "Epoch 3 num_samples 600 loss 0.7121507533332208\n",
      "Epoch 3 num_samples 700 loss 0.6145002912336355\n",
      "Epoch 3 num_samples 800 loss 0.7588097699467656\n",
      "Epoch 3 num_samples 900 loss 0.5833398216552128\n",
      "Epoch 3 num_samples 1000 loss 0.6068859543505188\n",
      "Epoch 3 num_samples 1100 loss 0.7715622079014477\n",
      "Epoch 3 num_samples 1200 loss 0.5563563632102282\n",
      "Epoch 3 num_samples 1300 loss 0.6747532637521814\n",
      "Epoch 3 num_samples 1400 loss 0.8679382108565136\n",
      "Epoch 3 num_samples 1500 loss 0.647208733624458\n",
      "Epoch 3 num_samples 1600 loss 0.7121277492614607\n",
      "Epoch 3 num_samples 1700 loss 0.7390029608587483\n",
      "Epoch 3 num_samples 1800 loss 0.596036594910484\n",
      "Epoch 3 num_samples 1900 loss 0.601873183239233\n",
      "Epoch 3 num_samples 2000 loss 0.7572919219280044\n",
      "Epoch 3 num_samples 2100 loss 0.6378837615544777\n",
      "Epoch 3 num_samples 2200 loss 0.5298264553937778\n",
      "Epoch 3 num_samples 2300 loss 0.6020036531893167\n",
      "Epoch 3 num_samples 2400 loss 0.6404021839782863\n",
      "Epoch 3 num_samples 2500 loss 0.7790877183059643\n",
      "Epoch 3 num_samples 2600 loss 0.6670486939048046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 num_samples 2700 loss 0.6108219129878967\n",
      "Epoch 3 num_samples 2800 loss 0.7497145701611692\n",
      "Epoch 3 num_samples 2900 loss 0.6973764823386154\n",
      "Epoch 3 num_samples 3000 loss 0.6005740037823244\n",
      "Epoch 3 num_samples 3100 loss 0.62875693365673\n",
      "Epoch 3 num_samples 3200 loss 0.826791145813057\n",
      "Epoch 3 num_samples 3300 loss 0.6094001387387076\n",
      "Epoch 3 num_samples 3400 loss 0.6350471089702758\n",
      "Epoch 3 num_samples 3500 loss 0.6634920775581873\n",
      "Epoch 3 num_samples 3600 loss 0.5185889742827918\n",
      "Epoch 3 num_samples 3700 loss 0.6929982524830284\n",
      "Epoch 3 num_samples 3800 loss 0.6599144459689055\n",
      "Epoch 3 num_samples 3900 loss 0.7691633044242792\n",
      "Epoch 3 num_samples 4000 loss 0.8095788662337171\n",
      "Epoch 3 num_samples 4100 loss 0.82164262549603\n",
      "Epoch 3 num_samples 4200 loss 0.587100681999503\n",
      "Epoch 3 num_samples 4300 loss 0.6600179893339404\n",
      "Epoch 3 num_samples 4400 loss 0.6963099238706296\n",
      "Epoch 3 num_samples 4500 loss 0.755379627863126\n",
      "Epoch 3 num_samples 4600 loss 0.6675774885251655\n",
      "Epoch 3 num_samples 4700 loss 0.4682420067678127\n",
      "Epoch 3 num_samples 4800 loss 0.583939798305676\n",
      "Epoch 3 num_samples 4900 loss 0.676039626830051\n",
      "Epoch 3 num_samples 5000 loss 0.853682598448184\n",
      "Epoch 3 num_samples 5100 loss 0.8317083834994188\n",
      "Epoch 3 num_samples 5200 loss 0.6298484787538706\n",
      "Epoch 3 num_samples 5300 loss 0.6054045705000155\n",
      "Epoch 3 num_samples 5400 loss 0.9624583738776262\n",
      "Epoch 3 num_samples 5500 loss 0.6488155339886199\n",
      "Epoch 3 num_samples 5600 loss 0.5729592784410827\n",
      "Epoch 3 num_samples 5700 loss 0.8921895254441747\n",
      "Epoch 3 num_samples 5800 loss 0.7500185237720807\n",
      "Epoch 3 num_samples 5900 loss 0.6609883937287904\n",
      "Epoch 3 num_samples 6000 loss 0.6462725640893545\n",
      "Epoch 3 num_samples 6100 loss 0.4259421619116411\n",
      "Epoch 3 num_samples 6200 loss 0.8254070801852762\n",
      "Epoch 3 num_samples 6300 loss 0.9980592000709703\n",
      "Epoch 3 num_samples 6400 loss 0.6774609041206325\n",
      "Epoch 3 num_samples 6500 loss 0.6889567572930865\n",
      "Epoch 3 num_samples 6600 loss 0.8175482722782944\n",
      "Epoch 3 num_samples 6700 loss 0.5229273703564263\n",
      "Epoch 3 num_samples 6800 loss 0.4519080007659958\n",
      "Epoch 3 num_samples 6900 loss 0.9211375319504755\n",
      "Epoch 3 num_samples 7000 loss 0.7071919829039848\n",
      "Epoch 3 num_samples 7100 loss 0.5177766140422989\n",
      "Epoch 3 num_samples 7200 loss 0.7111660682076937\n",
      "Epoch 3 num_samples 7300 loss 0.6519263517795654\n",
      "Epoch 3 num_samples 7400 loss 0.6359889799213757\n",
      "Epoch 3 num_samples 7500 loss 0.7098473815573356\n",
      "Epoch 3 num_samples 7600 loss 0.7868835153000237\n",
      "Epoch 3 num_samples 7700 loss 0.7510314137881319\n",
      "Epoch 3 num_samples 7800 loss 0.4162280969523839\n",
      "Epoch 3 num_samples 7900 loss 0.6513928674052096\n",
      "Epoch 3 num_samples 8000 loss 0.46215075800732336\n",
      "Epoch 3 num_samples 8100 loss 0.7393057913308012\n",
      "Epoch 3 num_samples 8200 loss 0.5795028975785729\n",
      "Epoch 3 num_samples 8300 loss 0.560633178870358\n",
      "Epoch 3 num_samples 8400 loss 0.6369875088714914\n",
      "Epoch 3 num_samples 8500 loss 0.6644607362556871\n",
      "Epoch 3 num_samples 8600 loss 0.4774398322364838\n",
      "Epoch 3 num_samples 8700 loss 0.6513445426181838\n",
      "Epoch 3 num_samples 8800 loss 0.612546281976613\n",
      "Epoch 3 num_samples 8900 loss 0.8236935650457039\n",
      "Epoch 3 num_samples 9000 loss 0.6109419256520775\n",
      "Epoch 3 num_samples 9100 loss 0.7251046477475352\n",
      "Epoch 3 num_samples 9200 loss 0.60998270987439\n",
      "Epoch 3 num_samples 9300 loss 0.7170748631391607\n",
      "Epoch 3 num_samples 9400 loss 0.5166945088308238\n",
      "Epoch 3 num_samples 9500 loss 0.6598527746769716\n",
      "Epoch 3 num_samples 9600 loss 0.6169369934867732\n",
      "Epoch 3 num_samples 9700 loss 0.8782153537176324\n",
      "Epoch 3 num_samples 9800 loss 0.4535691415498079\n",
      "Epoch 3 num_samples 9900 loss 0.8368484224718681\n",
      "Epoch 3 num_samples 10000 loss 0.543852429767242\n",
      "Epoch 3 num_samples 10100 loss 0.4100754058017981\n",
      "Epoch 3 num_samples 10200 loss 0.720902964269579\n",
      "Epoch 3 num_samples 10300 loss 0.7809674104458523\n",
      "Epoch 3 num_samples 10400 loss 0.733261867805922\n",
      "Epoch 3 num_samples 10500 loss 0.7235020708022737\n",
      "Epoch 3 num_samples 10600 loss 0.6013679519319014\n",
      "Epoch 3 num_samples 10700 loss 0.5483208594183034\n",
      "Epoch 3 num_samples 10800 loss 0.6338075567373777\n",
      "Epoch 3 num_samples 10900 loss 0.7590888175232279\n",
      "Epoch 3 num_samples 11000 loss 0.47513615885991634\n",
      "Epoch 3 num_samples 11100 loss 0.8026367258197817\n",
      "Epoch 3 num_samples 11200 loss 0.6062542946733765\n",
      "Epoch 3 num_samples 11300 loss 0.8509694269743963\n",
      "Epoch 3 num_samples 11400 loss 0.7280179025397304\n",
      "Epoch 3 num_samples 11500 loss 0.6241452360080874\n",
      "Epoch 3 num_samples 11600 loss 0.6444729298775036\n",
      "Epoch 3 num_samples 11700 loss 0.6513662852084348\n",
      "Epoch 3 num_samples 11800 loss 0.44156486452210375\n",
      "Epoch 3 num_samples 11900 loss 0.5808712112244365\n",
      "Epoch 3 num_samples 12000 loss 0.5668176119085041\n",
      "Epoch 3 num_samples 12100 loss 0.5355170329689496\n",
      "Epoch 3 num_samples 12200 loss 0.592128615473684\n",
      "Epoch 3 num_samples 12300 loss 0.5372822337186252\n",
      "Epoch 3 num_samples 12400 loss 0.6253703054837854\n",
      "Epoch 3 num_samples 12500 loss 0.5607146886560873\n",
      "Epoch 3 num_samples 12600 loss 0.5887480004568889\n",
      "Epoch 3 num_samples 12700 loss 0.6558406791820659\n",
      "Epoch 3 num_samples 12800 loss 0.674660736984104\n",
      "Epoch 3 num_samples 12900 loss 0.35941671581168977\n",
      "Epoch 3 num_samples 13000 loss 0.5508537647242963\n",
      "Epoch 3 num_samples 13100 loss 0.7712491686779278\n",
      "Epoch 3 num_samples 13200 loss 0.6635616526695988\n",
      "Epoch 3 num_samples 13300 loss 0.6570095906052995\n",
      "Epoch 3 num_samples 13400 loss 0.5738777182512473\n",
      "Epoch 3 num_samples 13500 loss 0.46082967673103764\n",
      "Epoch 3 num_samples 13600 loss 0.6444642334114651\n",
      "Epoch 3 num_samples 13700 loss 0.654523811455509\n",
      "Epoch 3 num_samples 13800 loss 0.4921966141165731\n",
      "Epoch 3 num_samples 13900 loss 0.589583870363963\n",
      "Epoch 3 num_samples 14000 loss 0.4193395772021667\n",
      "Epoch 3 num_samples 14100 loss 0.5392018376950689\n",
      "Epoch 3 num_samples 14200 loss 0.45535290720818145\n",
      "Epoch 3 num_samples 14300 loss 0.6610098263446232\n",
      "Epoch 3 num_samples 14400 loss 0.6940537352547298\n",
      "Epoch 3 num_samples 14500 loss 0.7272269646109126\n",
      "Epoch 3 num_samples 14600 loss 0.703562793514532\n",
      "Epoch 3 num_samples 14700 loss 0.6776778295122887\n",
      "Epoch 3 num_samples 14800 loss 0.46888493889634164\n",
      "Epoch 3 num_samples 14900 loss 0.7102713067574988\n",
      "Epoch 3 num_samples 15000 loss 0.46339500039870174\n",
      "Epoch 3 num_samples 15100 loss 0.7687413554042483\n",
      "Epoch 3 num_samples 15200 loss 0.6145557268076844\n",
      "Epoch 3 num_samples 15300 loss 0.6535260341862567\n",
      "Epoch 3 num_samples 15400 loss 0.453195591362403\n",
      "Epoch 3 num_samples 15500 loss 0.5372698006017871\n",
      "Epoch 3 num_samples 15600 loss 0.723703614949391\n",
      "Epoch 3 num_samples 15700 loss 0.500357213313749\n",
      "Epoch 3 num_samples 15800 loss 0.6678033117842656\n",
      "Epoch 3 num_samples 15900 loss 0.5423278090495969\n",
      "Epoch 3 num_samples 16000 loss 0.8187919942593207\n",
      "Epoch 3 num_samples 16100 loss 0.6520968740428128\n",
      "Epoch 3 num_samples 16200 loss 0.4698963580613868\n",
      "Epoch 3 num_samples 16300 loss 0.6403894287864837\n",
      "Epoch 3 num_samples 16400 loss 0.5781234544142403\n",
      "Epoch 3 num_samples 16500 loss 0.6981273492471459\n",
      "Epoch 3 num_samples 16600 loss 0.723589780921367\n",
      "Epoch 3 num_samples 16700 loss 0.4594699734657567\n",
      "Epoch 3 num_samples 16800 loss 0.4857039947509968\n",
      "Epoch 3 num_samples 16900 loss 0.666874827315375\n",
      "Epoch 3 num_samples 17000 loss 0.5166568957853918\n",
      "Epoch 3 num_samples 17100 loss 0.6460670762524799\n",
      "Epoch 3 num_samples 17200 loss 0.48736689081418\n",
      "Epoch 3 num_samples 17300 loss 0.6725303838017013\n",
      "Epoch 3 num_samples 17400 loss 0.6772633442981991\n",
      "Epoch 3 num_samples 17500 loss 0.6818348981289449\n",
      "Epoch 3 num_samples 17600 loss 0.674350419785306\n",
      "Epoch 3 num_samples 17700 loss 0.6300115670973452\n",
      "Epoch 3 num_samples 17800 loss 0.5979959482078582\n",
      "Epoch 3 num_samples 17900 loss 0.6013446715151485\n",
      "Epoch 3 num_samples 18000 loss 0.5285502438799683\n",
      "Epoch 3 num_samples 18100 loss 0.5662402520445581\n",
      "Epoch 3 num_samples 18200 loss 0.53589235876169\n",
      "Epoch 3 num_samples 18300 loss 0.5961011800267709\n",
      "Epoch 3 num_samples 18400 loss 0.7812828083728013\n",
      "Epoch 3 num_samples 18500 loss 0.5798458576568036\n",
      "Epoch 4 num_samples 0 loss 0.5961918792375246\n",
      "Epoch 4 num_samples 100 loss 0.5163097743556925\n",
      "Epoch 4 num_samples 200 loss 0.583728812979644\n",
      "Epoch 4 num_samples 300 loss 0.5290511486074582\n",
      "Epoch 4 num_samples 400 loss 0.48468796049801893\n",
      "Epoch 4 num_samples 500 loss 0.5979500240005088\n",
      "Epoch 4 num_samples 600 loss 0.5700220760643107\n",
      "Epoch 4 num_samples 700 loss 0.5182139826105954\n",
      "Epoch 4 num_samples 800 loss 0.6572207198270382\n",
      "Epoch 4 num_samples 900 loss 0.4599117387700882\n",
      "Epoch 4 num_samples 1000 loss 0.47179114801355354\n",
      "Epoch 4 num_samples 1100 loss 0.6447615378162126\n",
      "Epoch 4 num_samples 1200 loss 0.46500153287814355\n",
      "Epoch 4 num_samples 1300 loss 0.5362632704405763\n",
      "Epoch 4 num_samples 1400 loss 0.7488215125457736\n",
      "Epoch 4 num_samples 1500 loss 0.5451290699988429\n",
      "Epoch 4 num_samples 1600 loss 0.6001445735817049\n",
      "Epoch 4 num_samples 1700 loss 0.6205001850622645\n",
      "Epoch 4 num_samples 1800 loss 0.4952937703341338\n",
      "Epoch 4 num_samples 1900 loss 0.49887877436966255\n",
      "Epoch 4 num_samples 2000 loss 0.6358464963428654\n",
      "Epoch 4 num_samples 2100 loss 0.5165698569967718\n",
      "Epoch 4 num_samples 2200 loss 0.41790668990037516\n",
      "Epoch 4 num_samples 2300 loss 0.4870396984982041\n",
      "Epoch 4 num_samples 2400 loss 0.5003420068041518\n",
      "Epoch 4 num_samples 2500 loss 0.6344144337605269\n",
      "Epoch 4 num_samples 2600 loss 0.5843335925779121\n",
      "Epoch 4 num_samples 2700 loss 0.5027099270944718\n",
      "Epoch 4 num_samples 2800 loss 0.5964324339732323\n",
      "Epoch 4 num_samples 2900 loss 0.5650224239077272\n",
      "Epoch 4 num_samples 3000 loss 0.4925139885603835\n",
      "Epoch 4 num_samples 3100 loss 0.5122002336025919\n",
      "Epoch 4 num_samples 3200 loss 0.7087876545788327\n",
      "Epoch 4 num_samples 3300 loss 0.4944116429891444\n",
      "Epoch 4 num_samples 3400 loss 0.5185861711860642\n",
      "Epoch 4 num_samples 3500 loss 0.5310290329505958\n",
      "Epoch 4 num_samples 3600 loss 0.4235281174457253\n",
      "Epoch 4 num_samples 3700 loss 0.5423619423140124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 num_samples 3800 loss 0.5231910691104126\n",
      "Epoch 4 num_samples 3900 loss 0.6316119936623155\n",
      "Epoch 4 num_samples 4000 loss 0.6853293720201404\n",
      "Epoch 4 num_samples 4100 loss 0.6950897826066417\n",
      "Epoch 4 num_samples 4200 loss 0.49401469242243623\n",
      "Epoch 4 num_samples 4300 loss 0.5466444519464885\n",
      "Epoch 4 num_samples 4400 loss 0.5574235274419543\n",
      "Epoch 4 num_samples 4500 loss 0.6376974896125123\n",
      "Epoch 4 num_samples 4600 loss 0.5461141331898137\n",
      "Epoch 4 num_samples 4700 loss 0.3677375159872361\n",
      "Epoch 4 num_samples 4800 loss 0.4598742675539755\n",
      "Epoch 4 num_samples 4900 loss 0.570167385633141\n",
      "Epoch 4 num_samples 5000 loss 0.698381999996073\n",
      "Epoch 4 num_samples 5100 loss 0.6953489570121912\n",
      "Epoch 4 num_samples 5200 loss 0.5331250625480919\n",
      "Epoch 4 num_samples 5300 loss 0.5104641303507478\n",
      "Epoch 4 num_samples 5400 loss 0.7626901982320902\n",
      "Epoch 4 num_samples 5500 loss 0.5188530348763997\n",
      "Epoch 4 num_samples 5600 loss 0.49802599499093786\n",
      "Epoch 4 num_samples 5700 loss 0.7569638269205069\n",
      "Epoch 4 num_samples 5800 loss 0.636482996282617\n",
      "Epoch 4 num_samples 5900 loss 0.549891224790733\n",
      "Epoch 4 num_samples 6000 loss 0.5422155635847654\n",
      "Epoch 4 num_samples 6100 loss 0.35557982803378374\n",
      "Epoch 4 num_samples 6200 loss 0.6723654177351527\n",
      "Epoch 4 num_samples 6300 loss 0.8135158790561732\n",
      "Epoch 4 num_samples 6400 loss 0.5423588981558742\n",
      "Epoch 4 num_samples 6500 loss 0.5614040854412354\n",
      "Epoch 4 num_samples 6600 loss 0.6909846927512556\n",
      "Epoch 4 num_samples 6700 loss 0.4391295132307024\n",
      "Epoch 4 num_samples 6800 loss 0.34692243888439583\n",
      "Epoch 4 num_samples 6900 loss 0.8010622962506367\n",
      "Epoch 4 num_samples 7000 loss 0.6042630224604646\n",
      "Epoch 4 num_samples 7100 loss 0.4061219019581726\n",
      "Epoch 4 num_samples 7200 loss 0.5898567021588647\n",
      "Epoch 4 num_samples 7300 loss 0.546993121727962\n",
      "Epoch 4 num_samples 7400 loss 0.5207743413227738\n",
      "Epoch 4 num_samples 7500 loss 0.5944913397488946\n",
      "Epoch 4 num_samples 7600 loss 0.667414926224773\n",
      "Epoch 4 num_samples 7700 loss 0.6654811430060079\n",
      "Epoch 4 num_samples 7800 loss 0.3423303785632204\n",
      "Epoch 4 num_samples 7900 loss 0.5620293126985731\n",
      "Epoch 4 num_samples 8000 loss 0.3587556711636596\n",
      "Epoch 4 num_samples 8100 loss 0.6186201238945064\n",
      "Epoch 4 num_samples 8200 loss 0.4670987524368806\n",
      "Epoch 4 num_samples 8300 loss 0.4556738355017096\n",
      "Epoch 4 num_samples 8400 loss 0.532485295867072\n",
      "Epoch 4 num_samples 8500 loss 0.527268699829455\n",
      "Epoch 4 num_samples 8600 loss 0.38616760250857574\n",
      "Epoch 4 num_samples 8700 loss 0.5443626894910321\n",
      "Epoch 4 num_samples 8800 loss 0.5195248212821939\n",
      "Epoch 4 num_samples 8900 loss 0.6841883511393391\n",
      "Epoch 4 num_samples 9000 loss 0.5288771202712881\n",
      "Epoch 4 num_samples 9100 loss 0.6056331449393112\n",
      "Epoch 4 num_samples 9200 loss 0.5161171716942929\n",
      "Epoch 4 num_samples 9300 loss 0.6121652289035481\n",
      "Epoch 4 num_samples 9400 loss 0.43837635520636864\n",
      "Epoch 4 num_samples 9500 loss 0.5728194437967702\n",
      "Epoch 4 num_samples 9600 loss 0.49598598992581716\n",
      "Epoch 4 num_samples 9700 loss 0.7001298997995042\n",
      "Epoch 4 num_samples 9800 loss 0.37531899545598696\n",
      "Epoch 4 num_samples 9900 loss 0.7029947563524389\n",
      "Epoch 4 num_samples 10000 loss 0.43608488262891454\n",
      "Epoch 4 num_samples 10100 loss 0.31944955105205863\n",
      "Epoch 4 num_samples 10200 loss 0.6115753937302928\n",
      "Epoch 4 num_samples 10300 loss 0.6438915186194094\n",
      "Epoch 4 num_samples 10400 loss 0.6075741845484689\n",
      "Epoch 4 num_samples 10500 loss 0.578836713001505\n",
      "Epoch 4 num_samples 10600 loss 0.49453512848882214\n",
      "Epoch 4 num_samples 10700 loss 0.44027922348416837\n",
      "Epoch 4 num_samples 10800 loss 0.540236662134565\n",
      "Epoch 4 num_samples 10900 loss 0.6294055636942784\n",
      "Epoch 4 num_samples 11000 loss 0.38205703952629655\n",
      "Epoch 4 num_samples 11100 loss 0.6882885873173993\n",
      "Epoch 4 num_samples 11200 loss 0.5241378619003201\n",
      "Epoch 4 num_samples 11300 loss 0.7142782486457153\n",
      "Epoch 4 num_samples 11400 loss 0.6152242533120206\n",
      "Epoch 4 num_samples 11500 loss 0.5167575672681077\n",
      "Epoch 4 num_samples 11600 loss 0.5327696329890643\n",
      "Epoch 4 num_samples 11700 loss 0.5542478764983785\n",
      "Epoch 4 num_samples 11800 loss 0.3682235360252579\n",
      "Epoch 4 num_samples 11900 loss 0.4660985433422016\n",
      "Epoch 4 num_samples 12000 loss 0.4675097370756548\n",
      "Epoch 4 num_samples 12100 loss 0.44900078588403297\n",
      "Epoch 4 num_samples 12200 loss 0.4845792948592863\n",
      "Epoch 4 num_samples 12300 loss 0.4462986723763233\n",
      "Epoch 4 num_samples 12400 loss 0.5231136894505788\n",
      "Epoch 4 num_samples 12500 loss 0.48479605725931324\n",
      "Epoch 4 num_samples 12600 loss 0.48465774944575\n",
      "Epoch 4 num_samples 12700 loss 0.5534848792146376\n",
      "Epoch 4 num_samples 12800 loss 0.5862609453397211\n",
      "Epoch 4 num_samples 12900 loss 0.3128455194491528\n",
      "Epoch 4 num_samples 13000 loss 0.47179750780658464\n",
      "Epoch 4 num_samples 13100 loss 0.6533117972599547\n",
      "Epoch 4 num_samples 13200 loss 0.5272514840866193\n",
      "Epoch 4 num_samples 13300 loss 0.5262136215776042\n",
      "Epoch 4 num_samples 13400 loss 0.4609051549124964\n",
      "Epoch 4 num_samples 13500 loss 0.3992203141354703\n",
      "Epoch 4 num_samples 13600 loss 0.5450614684519447\n",
      "Epoch 4 num_samples 13700 loss 0.531958418459697\n",
      "Epoch 4 num_samples 13800 loss 0.4095698081296305\n",
      "Epoch 4 num_samples 13900 loss 0.49194277231684125\n",
      "Epoch 4 num_samples 14000 loss 0.3316564697443451\n",
      "Epoch 4 num_samples 14100 loss 0.46020359387015347\n",
      "Epoch 4 num_samples 14200 loss 0.38087401562440676\n",
      "Epoch 4 num_samples 14300 loss 0.5461860464327914\n",
      "Epoch 4 num_samples 14400 loss 0.5964245215080906\n",
      "Epoch 4 num_samples 14500 loss 0.6220354356408997\n",
      "Epoch 4 num_samples 14600 loss 0.5886336297194465\n",
      "Epoch 4 num_samples 14700 loss 0.573907338502236\n",
      "Epoch 4 num_samples 14800 loss 0.38009005804535534\n",
      "Epoch 4 num_samples 14900 loss 0.609235977413662\n",
      "Epoch 4 num_samples 15000 loss 0.3976680231316713\n",
      "Epoch 4 num_samples 15100 loss 0.6368261188199309\n",
      "Epoch 4 num_samples 15200 loss 0.5154795218472515\n",
      "Epoch 4 num_samples 15300 loss 0.5478477287455217\n",
      "Epoch 4 num_samples 15400 loss 0.3914633730187924\n",
      "Epoch 4 num_samples 15500 loss 0.45507045441617633\n",
      "Epoch 4 num_samples 15600 loss 0.5903427701359517\n",
      "Epoch 4 num_samples 15700 loss 0.4127954551563462\n",
      "Epoch 4 num_samples 15800 loss 0.5765333878374497\n",
      "Epoch 4 num_samples 15900 loss 0.4115815619239237\n",
      "Epoch 4 num_samples 16000 loss 0.7210750701896741\n",
      "Epoch 4 num_samples 16100 loss 0.5175217946930225\n",
      "Epoch 4 num_samples 16200 loss 0.40137502424277555\n",
      "Epoch 4 num_samples 16300 loss 0.5479836850267665\n",
      "Epoch 4 num_samples 16400 loss 0.4892939838508489\n",
      "Epoch 4 num_samples 16500 loss 0.5704298193946069\n",
      "Epoch 4 num_samples 16600 loss 0.6377927994169488\n",
      "Epoch 4 num_samples 16700 loss 0.37379633551627195\n",
      "Epoch 4 num_samples 16800 loss 0.38450870946340904\n",
      "Epoch 4 num_samples 16900 loss 0.5677154072484641\n",
      "Epoch 4 num_samples 17000 loss 0.41604996339793515\n",
      "Epoch 4 num_samples 17100 loss 0.5720644742864744\n",
      "Epoch 4 num_samples 17200 loss 0.4092240650005553\n",
      "Epoch 4 num_samples 17300 loss 0.5438983891283788\n",
      "Epoch 4 num_samples 17400 loss 0.574747482488402\n",
      "Epoch 4 num_samples 17500 loss 0.6037226194632669\n",
      "Epoch 4 num_samples 17600 loss 0.5722669307523244\n",
      "Epoch 4 num_samples 17700 loss 0.5067359134945935\n",
      "Epoch 4 num_samples 17800 loss 0.532049579746233\n",
      "Epoch 4 num_samples 17900 loss 0.5121252504360715\n",
      "Epoch 4 num_samples 18000 loss 0.43351382046975134\n",
      "Epoch 4 num_samples 18100 loss 0.48050737217417405\n",
      "Epoch 4 num_samples 18200 loss 0.45844776080050303\n",
      "Epoch 4 num_samples 18300 loss 0.5203592819623664\n",
      "Epoch 4 num_samples 18400 loss 0.6838139202164945\n",
      "Epoch 4 num_samples 18500 loss 0.46566033924143363\n",
      "Epoch 5 num_samples 0 loss 0.4883283467680181\n",
      "Epoch 5 num_samples 100 loss 0.4596511702230079\n",
      "Epoch 5 num_samples 200 loss 0.4840249472440942\n",
      "Epoch 5 num_samples 300 loss 0.45962295325880886\n",
      "Epoch 5 num_samples 400 loss 0.40559145916373024\n",
      "Epoch 5 num_samples 500 loss 0.5076244806031721\n",
      "Epoch 5 num_samples 600 loss 0.4737609520733384\n",
      "Epoch 5 num_samples 700 loss 0.46111506022990595\n",
      "Epoch 5 num_samples 800 loss 0.5776575248774811\n",
      "Epoch 5 num_samples 900 loss 0.3806245508214953\n",
      "Epoch 5 num_samples 1000 loss 0.38832063737120687\n",
      "Epoch 5 num_samples 1100 loss 0.5630432851547111\n",
      "Epoch 5 num_samples 1200 loss 0.40580114441430043\n",
      "Epoch 5 num_samples 1300 loss 0.4360509185610475\n",
      "Epoch 5 num_samples 1400 loss 0.6526075132852633\n",
      "Epoch 5 num_samples 1500 loss 0.4814784609483855\n",
      "Epoch 5 num_samples 1600 loss 0.5028345946715669\n",
      "Epoch 5 num_samples 1700 loss 0.537773840395642\n",
      "Epoch 5 num_samples 1800 loss 0.422220048894431\n",
      "Epoch 5 num_samples 1900 loss 0.4240457087222599\n",
      "Epoch 5 num_samples 2000 loss 0.5631903507333934\n",
      "Epoch 5 num_samples 2100 loss 0.4234522994557392\n",
      "Epoch 5 num_samples 2200 loss 0.3476848623885349\n",
      "Epoch 5 num_samples 2300 loss 0.4107600933328201\n",
      "Epoch 5 num_samples 2400 loss 0.41408847175802876\n",
      "Epoch 5 num_samples 2500 loss 0.5361576309315058\n",
      "Epoch 5 num_samples 2600 loss 0.5103575779940484\n",
      "Epoch 5 num_samples 2700 loss 0.4347507635875621\n",
      "Epoch 5 num_samples 2800 loss 0.4935360626647892\n",
      "Epoch 5 num_samples 2900 loss 0.46843233372407794\n",
      "Epoch 5 num_samples 3000 loss 0.4105552265747407\n",
      "Epoch 5 num_samples 3100 loss 0.43903702010537693\n",
      "Epoch 5 num_samples 3200 loss 0.6282602623096581\n",
      "Epoch 5 num_samples 3300 loss 0.4109341813557593\n",
      "Epoch 5 num_samples 3400 loss 0.4417760568293585\n",
      "Epoch 5 num_samples 3500 loss 0.44182610553690366\n",
      "Epoch 5 num_samples 3600 loss 0.35093266126057443\n",
      "Epoch 5 num_samples 3700 loss 0.4474056753341247\n",
      "Epoch 5 num_samples 3800 loss 0.436074268238026\n",
      "Epoch 5 num_samples 3900 loss 0.542024259724721\n",
      "Epoch 5 num_samples 4000 loss 0.5910256340703394\n",
      "Epoch 5 num_samples 4100 loss 0.5920512001580609\n",
      "Epoch 5 num_samples 4200 loss 0.4273937810043726\n",
      "Epoch 5 num_samples 4300 loss 0.47744844220512134\n",
      "Epoch 5 num_samples 4400 loss 0.4618496488010982\n",
      "Epoch 5 num_samples 4500 loss 0.5534866412495948\n",
      "Epoch 5 num_samples 4600 loss 0.47001214655598855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 num_samples 4700 loss 0.3054848326532392\n",
      "Epoch 5 num_samples 4800 loss 0.37337461186785253\n",
      "Epoch 5 num_samples 4900 loss 0.48894364335083595\n",
      "Epoch 5 num_samples 5000 loss 0.5701960848976805\n",
      "Epoch 5 num_samples 5100 loss 0.601807779384914\n",
      "Epoch 5 num_samples 5200 loss 0.45758676677813015\n",
      "Epoch 5 num_samples 5300 loss 0.4395515545023291\n",
      "Epoch 5 num_samples 5400 loss 0.6318301260202404\n",
      "Epoch 5 num_samples 5500 loss 0.42757736447700295\n",
      "Epoch 5 num_samples 5600 loss 0.45049355005975783\n",
      "Epoch 5 num_samples 5700 loss 0.641700478935702\n",
      "Epoch 5 num_samples 5800 loss 0.5546746494346871\n",
      "Epoch 5 num_samples 5900 loss 0.4704374987390267\n",
      "Epoch 5 num_samples 6000 loss 0.4664139337765497\n",
      "Epoch 5 num_samples 6100 loss 0.29659869315520526\n",
      "Epoch 5 num_samples 6200 loss 0.5669077983978034\n",
      "Epoch 5 num_samples 6300 loss 0.6959711516141123\n",
      "Epoch 5 num_samples 6400 loss 0.45143587902810567\n",
      "Epoch 5 num_samples 6500 loss 0.4633378049261061\n",
      "Epoch 5 num_samples 6600 loss 0.606220319605387\n",
      "Epoch 5 num_samples 6700 loss 0.37956867277481765\n",
      "Epoch 5 num_samples 6800 loss 0.2760407126167797\n",
      "Epoch 5 num_samples 6900 loss 0.7104770669338972\n",
      "Epoch 5 num_samples 7000 loss 0.5226374921413687\n",
      "Epoch 5 num_samples 7100 loss 0.3424737738289331\n",
      "Epoch 5 num_samples 7200 loss 0.4943945444261081\n",
      "Epoch 5 num_samples 7300 loss 0.4808106693304478\n",
      "Epoch 5 num_samples 7400 loss 0.4347670886283612\n",
      "Epoch 5 num_samples 7500 loss 0.5204093093529363\n",
      "Epoch 5 num_samples 7600 loss 0.5642567201872715\n",
      "Epoch 5 num_samples 7700 loss 0.5849011096874761\n",
      "Epoch 5 num_samples 7800 loss 0.28375277836158186\n",
      "Epoch 5 num_samples 7900 loss 0.4934986683264853\n",
      "Epoch 5 num_samples 8000 loss 0.29181488262329713\n",
      "Epoch 5 num_samples 8100 loss 0.5156237381630546\n",
      "Epoch 5 num_samples 8200 loss 0.3875767403283106\n",
      "Epoch 5 num_samples 8300 loss 0.3873793870497401\n",
      "Epoch 5 num_samples 8400 loss 0.45507268448330634\n",
      "Epoch 5 num_samples 8500 loss 0.43819738445446776\n",
      "Epoch 5 num_samples 8600 loss 0.3252356316240678\n",
      "Epoch 5 num_samples 8700 loss 0.4588035409159243\n",
      "Epoch 5 num_samples 8800 loss 0.4578207856912398\n",
      "Epoch 5 num_samples 8900 loss 0.5865470272192838\n",
      "Epoch 5 num_samples 9000 loss 0.47452729628853263\n",
      "Epoch 5 num_samples 9100 loss 0.5191697597865246\n",
      "Epoch 5 num_samples 9200 loss 0.45801985296200115\n",
      "Epoch 5 num_samples 9300 loss 0.5234649368455518\n",
      "Epoch 5 num_samples 9400 loss 0.37894784219893396\n",
      "Epoch 5 num_samples 9500 loss 0.5058966006622592\n",
      "Epoch 5 num_samples 9600 loss 0.41731199810728264\n",
      "Epoch 5 num_samples 9700 loss 0.57621721424801\n",
      "Epoch 5 num_samples 9800 loss 0.32048753546501646\n",
      "Epoch 5 num_samples 9900 loss 0.6159800719064111\n",
      "Epoch 5 num_samples 10000 loss 0.35734881357279863\n",
      "Epoch 5 num_samples 10100 loss 0.265730785495831\n",
      "Epoch 5 num_samples 10200 loss 0.5357988846521993\n",
      "Epoch 5 num_samples 10300 loss 0.5517385571606952\n",
      "Epoch 5 num_samples 10400 loss 0.5198713642260578\n",
      "Epoch 5 num_samples 10500 loss 0.47154201070970075\n",
      "Epoch 5 num_samples 10600 loss 0.42877039675726325\n",
      "Epoch 5 num_samples 10700 loss 0.3772273423112316\n",
      "Epoch 5 num_samples 10800 loss 0.46783611238284195\n",
      "Epoch 5 num_samples 10900 loss 0.5261287129231762\n",
      "Epoch 5 num_samples 11000 loss 0.3165869398606814\n",
      "Epoch 5 num_samples 11100 loss 0.6020321070820769\n",
      "Epoch 5 num_samples 11200 loss 0.45658194049182854\n",
      "Epoch 5 num_samples 11300 loss 0.6177974712073772\n",
      "Epoch 5 num_samples 11400 loss 0.5354844227473154\n",
      "Epoch 5 num_samples 11500 loss 0.4353823619764197\n",
      "Epoch 5 num_samples 11600 loss 0.4489816646040803\n",
      "Epoch 5 num_samples 11700 loss 0.4887389593628799\n",
      "Epoch 5 num_samples 11800 loss 0.3239586996604594\n",
      "Epoch 5 num_samples 11900 loss 0.3889360547936782\n",
      "Epoch 5 num_samples 12000 loss 0.39061791100007803\n",
      "Epoch 5 num_samples 12100 loss 0.3861048328600042\n",
      "Epoch 5 num_samples 12200 loss 0.42707002613800477\n",
      "Epoch 5 num_samples 12300 loss 0.37305653434627417\n",
      "Epoch 5 num_samples 12400 loss 0.4403802948925049\n",
      "Epoch 5 num_samples 12500 loss 0.42702736264703245\n",
      "Epoch 5 num_samples 12600 loss 0.42057837463402004\n",
      "Epoch 5 num_samples 12700 loss 0.477549187673422\n",
      "Epoch 5 num_samples 12800 loss 0.5293018095412243\n",
      "Epoch 5 num_samples 12900 loss 0.28436257248793606\n",
      "Epoch 5 num_samples 13000 loss 0.40165044597937066\n",
      "Epoch 5 num_samples 13100 loss 0.5764398509402221\n",
      "Epoch 5 num_samples 13200 loss 0.43385156175030204\n",
      "Epoch 5 num_samples 13300 loss 0.4300436619768744\n",
      "Epoch 5 num_samples 13400 loss 0.3856110426044832\n",
      "Epoch 5 num_samples 13500 loss 0.35634770424829204\n",
      "Epoch 5 num_samples 13600 loss 0.4802889221317203\n",
      "Epoch 5 num_samples 13700 loss 0.44283497589645576\n",
      "Epoch 5 num_samples 13800 loss 0.3478249053705193\n",
      "Epoch 5 num_samples 13900 loss 0.41012117297372924\n",
      "Epoch 5 num_samples 14000 loss 0.2787918259865531\n",
      "Epoch 5 num_samples 14100 loss 0.3965948250200518\n",
      "Epoch 5 num_samples 14200 loss 0.32228672174684136\n",
      "Epoch 5 num_samples 14300 loss 0.472780717400424\n",
      "Epoch 5 num_samples 14400 loss 0.5153446550748515\n",
      "Epoch 5 num_samples 14500 loss 0.5428161325321939\n",
      "Epoch 5 num_samples 14600 loss 0.5007840453423618\n",
      "Epoch 5 num_samples 14700 loss 0.502597726042428\n",
      "Epoch 5 num_samples 14800 loss 0.3273507484469745\n",
      "Epoch 5 num_samples 14900 loss 0.5328613427108233\n",
      "Epoch 5 num_samples 15000 loss 0.3367617724166129\n",
      "Epoch 5 num_samples 15100 loss 0.5400687237036896\n",
      "Epoch 5 num_samples 15200 loss 0.4542122662498035\n",
      "Epoch 5 num_samples 15300 loss 0.4796333361594138\n",
      "Epoch 5 num_samples 15400 loss 0.3354909235931612\n",
      "Epoch 5 num_samples 15500 loss 0.3930182095055382\n",
      "Epoch 5 num_samples 15600 loss 0.4893091971973936\n",
      "Epoch 5 num_samples 15700 loss 0.355072326424114\n",
      "Epoch 5 num_samples 15800 loss 0.5128761607464363\n",
      "Epoch 5 num_samples 15900 loss 0.33870940561250373\n",
      "Epoch 5 num_samples 16000 loss 0.637335450629077\n",
      "Epoch 5 num_samples 16100 loss 0.4348934920337464\n",
      "Epoch 5 num_samples 16200 loss 0.34805023557652165\n",
      "Epoch 5 num_samples 16300 loss 0.485453857978532\n",
      "Epoch 5 num_samples 16400 loss 0.4185925540549609\n",
      "Epoch 5 num_samples 16500 loss 0.4773141325953039\n",
      "Epoch 5 num_samples 16600 loss 0.5661044127911267\n",
      "Epoch 5 num_samples 16700 loss 0.3271561501217949\n",
      "Epoch 5 num_samples 16800 loss 0.32104323811975144\n",
      "Epoch 5 num_samples 16900 loss 0.49155781831914935\n",
      "Epoch 5 num_samples 17000 loss 0.3482097020256951\n",
      "Epoch 5 num_samples 17100 loss 0.520268522259772\n",
      "Epoch 5 num_samples 17200 loss 0.36670396071378575\n",
      "Epoch 5 num_samples 17300 loss 0.44725224145689424\n",
      "Epoch 5 num_samples 17400 loss 0.5118365213759505\n",
      "Epoch 5 num_samples 17500 loss 0.5369215446194054\n",
      "Epoch 5 num_samples 17600 loss 0.48616949463283876\n",
      "Epoch 5 num_samples 17700 loss 0.4183092586882649\n",
      "Epoch 5 num_samples 17800 loss 0.47706818825742886\n",
      "Epoch 5 num_samples 17900 loss 0.4476726855266629\n",
      "Epoch 5 num_samples 18000 loss 0.36191396730627057\n",
      "Epoch 5 num_samples 18100 loss 0.41652912827296384\n",
      "Epoch 5 num_samples 18200 loss 0.4070893977347743\n",
      "Epoch 5 num_samples 18300 loss 0.44795097898237957\n",
      "Epoch 5 num_samples 18400 loss 0.5972206819959257\n",
      "Epoch 5 num_samples 18500 loss 0.39410392388500715\n",
      "Epoch 6 num_samples 0 loss 0.4229456186024205\n",
      "Epoch 6 num_samples 100 loss 0.4096662087268811\n",
      "Epoch 6 num_samples 200 loss 0.4075901812407002\n",
      "Epoch 6 num_samples 300 loss 0.40648531976422964\n",
      "Epoch 6 num_samples 400 loss 0.3472794188652517\n",
      "Epoch 6 num_samples 500 loss 0.43635955304585167\n",
      "Epoch 6 num_samples 600 loss 0.4008475471663108\n",
      "Epoch 6 num_samples 700 loss 0.4191530783639731\n",
      "Epoch 6 num_samples 800 loss 0.5267356802031251\n",
      "Epoch 6 num_samples 900 loss 0.3230146398090521\n",
      "Epoch 6 num_samples 1000 loss 0.33171629812133235\n",
      "Epoch 6 num_samples 1100 loss 0.4986479279316277\n",
      "Epoch 6 num_samples 1200 loss 0.35958337812184754\n",
      "Epoch 6 num_samples 1300 loss 0.3613226721517763\n",
      "Epoch 6 num_samples 1400 loss 0.5639111092973738\n",
      "Epoch 6 num_samples 1500 loss 0.4282464778027641\n",
      "Epoch 6 num_samples 1600 loss 0.42627957764372\n",
      "Epoch 6 num_samples 1700 loss 0.4731581240253647\n",
      "Epoch 6 num_samples 1800 loss 0.3681082409942568\n",
      "Epoch 6 num_samples 1900 loss 0.3597895939018596\n",
      "Epoch 6 num_samples 2000 loss 0.5151899204124846\n",
      "Epoch 6 num_samples 2100 loss 0.3580474124190467\n",
      "Epoch 6 num_samples 2200 loss 0.2993824857868623\n",
      "Epoch 6 num_samples 2300 loss 0.3537936098397882\n",
      "Epoch 6 num_samples 2400 loss 0.3431157957502359\n",
      "Epoch 6 num_samples 2500 loss 0.46368972452850826\n",
      "Epoch 6 num_samples 2600 loss 0.4524486019248117\n",
      "Epoch 6 num_samples 2700 loss 0.3833372756917759\n",
      "Epoch 6 num_samples 2800 loss 0.4250780522765625\n",
      "Epoch 6 num_samples 2900 loss 0.4059437551458058\n",
      "Epoch 6 num_samples 3000 loss 0.346287132141951\n",
      "Epoch 6 num_samples 3100 loss 0.3799251768519071\n",
      "Epoch 6 num_samples 3200 loss 0.5709319037209168\n",
      "Epoch 6 num_samples 3300 loss 0.35691409470448626\n",
      "Epoch 6 num_samples 3400 loss 0.3774022982174319\n",
      "Epoch 6 num_samples 3500 loss 0.3781690281091879\n",
      "Epoch 6 num_samples 3600 loss 0.2938315436077903\n",
      "Epoch 6 num_samples 3700 loss 0.3846261289158479\n",
      "Epoch 6 num_samples 3800 loss 0.3754264938237288\n",
      "Epoch 6 num_samples 3900 loss 0.47198345007726744\n",
      "Epoch 6 num_samples 4000 loss 0.5159777650463188\n",
      "Epoch 6 num_samples 4100 loss 0.5207642558043627\n",
      "Epoch 6 num_samples 4200 loss 0.3738961309745878\n",
      "Epoch 6 num_samples 4300 loss 0.422779304027546\n",
      "Epoch 6 num_samples 4400 loss 0.38946213540707303\n",
      "Epoch 6 num_samples 4500 loss 0.49377806753571035\n",
      "Epoch 6 num_samples 4600 loss 0.4120890496333162\n",
      "Epoch 6 num_samples 4700 loss 0.26188507368801334\n",
      "Epoch 6 num_samples 4800 loss 0.3132430756933894\n",
      "Epoch 6 num_samples 4900 loss 0.43130751183132643\n",
      "Epoch 6 num_samples 5000 loss 0.46753298691353007\n",
      "Epoch 6 num_samples 5100 loss 0.5290315891142413\n",
      "Epoch 6 num_samples 5200 loss 0.39464715811761125\n",
      "Epoch 6 num_samples 5300 loss 0.38970469300656274\n",
      "Epoch 6 num_samples 5400 loss 0.5343635019801279\n",
      "Epoch 6 num_samples 5500 loss 0.361186477853242\n",
      "Epoch 6 num_samples 5600 loss 0.40916013363236714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 num_samples 5700 loss 0.549119685295832\n",
      "Epoch 6 num_samples 5800 loss 0.49097726815493803\n",
      "Epoch 6 num_samples 5900 loss 0.41599552966377806\n",
      "Epoch 6 num_samples 6000 loss 0.41114574191880615\n",
      "Epoch 6 num_samples 6100 loss 0.25738781769910607\n",
      "Epoch 6 num_samples 6200 loss 0.49364411120794566\n",
      "Epoch 6 num_samples 6300 loss 0.6022624210386582\n",
      "Epoch 6 num_samples 6400 loss 0.3884604650380838\n",
      "Epoch 6 num_samples 6500 loss 0.38777621726391664\n",
      "Epoch 6 num_samples 6600 loss 0.532122873142994\n",
      "Epoch 6 num_samples 6700 loss 0.3297487267155576\n",
      "Epoch 6 num_samples 6800 loss 0.22452081225023882\n",
      "Epoch 6 num_samples 6900 loss 0.6384075027873208\n",
      "Epoch 6 num_samples 7000 loss 0.4533287657295172\n",
      "Epoch 6 num_samples 7100 loss 0.29603561008227763\n",
      "Epoch 6 num_samples 7200 loss 0.42095062698176017\n",
      "Epoch 6 num_samples 7300 loss 0.42105947402937616\n",
      "Epoch 6 num_samples 7400 loss 0.359615208131479\n",
      "Epoch 6 num_samples 7500 loss 0.4729086736276311\n",
      "Epoch 6 num_samples 7600 loss 0.4876324426359872\n",
      "Epoch 6 num_samples 7700 loss 0.5278559053439483\n",
      "Epoch 6 num_samples 7800 loss 0.23772373761424162\n",
      "Epoch 6 num_samples 7900 loss 0.43549787444165317\n",
      "Epoch 6 num_samples 8000 loss 0.2485131873904836\n",
      "Epoch 6 num_samples 8100 loss 0.4354569708631765\n",
      "Epoch 6 num_samples 8200 loss 0.328629820898758\n",
      "Epoch 6 num_samples 8300 loss 0.3363528601424721\n",
      "Epoch 6 num_samples 8400 loss 0.3932733073053784\n",
      "Epoch 6 num_samples 8500 loss 0.38081245363725796\n",
      "Epoch 6 num_samples 8600 loss 0.2781014670152632\n",
      "Epoch 6 num_samples 8700 loss 0.39597635661052677\n",
      "Epoch 6 num_samples 8800 loss 0.40992443632652786\n",
      "Epoch 6 num_samples 8900 loss 0.5065362022748433\n",
      "Epoch 6 num_samples 9000 loss 0.4192140643501647\n",
      "Epoch 6 num_samples 9100 loss 0.44489423820524043\n",
      "Epoch 6 num_samples 9200 loss 0.40459654797448663\n",
      "Epoch 6 num_samples 9300 loss 0.4536274078080123\n",
      "Epoch 6 num_samples 9400 loss 0.3247230465595834\n",
      "Epoch 6 num_samples 9500 loss 0.4518611717113882\n",
      "Epoch 6 num_samples 9600 loss 0.35811020006369815\n",
      "Epoch 6 num_samples 9700 loss 0.4859245112552433\n",
      "Epoch 6 num_samples 9800 loss 0.2768797462511967\n",
      "Epoch 6 num_samples 9900 loss 0.555482541978643\n",
      "Epoch 6 num_samples 10000 loss 0.3024902419724674\n",
      "Epoch 6 num_samples 10100 loss 0.22596493815898383\n",
      "Epoch 6 num_samples 10200 loss 0.4746094166523038\n",
      "Epoch 6 num_samples 10300 loss 0.4826357641207943\n",
      "Epoch 6 num_samples 10400 loss 0.44357494112971824\n",
      "Epoch 6 num_samples 10500 loss 0.3956835785072241\n",
      "Epoch 6 num_samples 10600 loss 0.37418241350142056\n",
      "Epoch 6 num_samples 10700 loss 0.3226329723145905\n",
      "Epoch 6 num_samples 10800 loss 0.42156416136422414\n",
      "Epoch 6 num_samples 10900 loss 0.4358692905239047\n",
      "Epoch 6 num_samples 11000 loss 0.2647377964126548\n",
      "Epoch 6 num_samples 11100 loss 0.5347806267716991\n",
      "Epoch 6 num_samples 11200 loss 0.3984617478045772\n",
      "Epoch 6 num_samples 11300 loss 0.5409317638434894\n",
      "Epoch 6 num_samples 11400 loss 0.47658776510042855\n",
      "Epoch 6 num_samples 11500 loss 0.36706897523042437\n",
      "Epoch 6 num_samples 11600 loss 0.38462320260651245\n",
      "Epoch 6 num_samples 11700 loss 0.43524076601569034\n",
      "Epoch 6 num_samples 11800 loss 0.2863544914360679\n",
      "Epoch 6 num_samples 11900 loss 0.33884577011421496\n",
      "Epoch 6 num_samples 12000 loss 0.3351931448925283\n",
      "Epoch 6 num_samples 12100 loss 0.3346045396620464\n",
      "Epoch 6 num_samples 12200 loss 0.3842778344746512\n",
      "Epoch 6 num_samples 12300 loss 0.31117266296107204\n",
      "Epoch 6 num_samples 12400 loss 0.39465457704385587\n",
      "Epoch 6 num_samples 12500 loss 0.37921295656145004\n",
      "Epoch 6 num_samples 12600 loss 0.3647557401815761\n",
      "Epoch 6 num_samples 12700 loss 0.4190302992137464\n",
      "Epoch 6 num_samples 12800 loss 0.4883700797151235\n",
      "Epoch 6 num_samples 12900 loss 0.25997552855781453\n",
      "Epoch 6 num_samples 13000 loss 0.35256256219202753\n",
      "Epoch 6 num_samples 13100 loss 0.5126475488855378\n",
      "Epoch 6 num_samples 13200 loss 0.35785770974145975\n",
      "Epoch 6 num_samples 13300 loss 0.35508799934231616\n",
      "Epoch 6 num_samples 13400 loss 0.32717796451028136\n",
      "Epoch 6 num_samples 13500 loss 0.31846234365622833\n",
      "Epoch 6 num_samples 13600 loss 0.4254457971646755\n",
      "Epoch 6 num_samples 13700 loss 0.3783714104633406\n",
      "Epoch 6 num_samples 13800 loss 0.30363890625132334\n",
      "Epoch 6 num_samples 13900 loss 0.35114630465143604\n",
      "Epoch 6 num_samples 14000 loss 0.23784980857280305\n",
      "Epoch 6 num_samples 14100 loss 0.3526701971221081\n",
      "Epoch 6 num_samples 14200 loss 0.2799104754131777\n",
      "Epoch 6 num_samples 14300 loss 0.41772241121617154\n",
      "Epoch 6 num_samples 14400 loss 0.4518209053161674\n",
      "Epoch 6 num_samples 14500 loss 0.47992749524147443\n",
      "Epoch 6 num_samples 14600 loss 0.4314935004168045\n",
      "Epoch 6 num_samples 14700 loss 0.43222421141668577\n",
      "Epoch 6 num_samples 14800 loss 0.28107050272520745\n",
      "Epoch 6 num_samples 14900 loss 0.46212408654880266\n",
      "Epoch 6 num_samples 15000 loss 0.2951803368929827\n",
      "Epoch 6 num_samples 15100 loss 0.471110804815798\n",
      "Epoch 6 num_samples 15200 loss 0.40469757433822545\n",
      "Epoch 6 num_samples 15300 loss 0.4266406675662929\n",
      "Epoch 6 num_samples 15400 loss 0.2972903357987892\n",
      "Epoch 6 num_samples 15500 loss 0.3447766815728302\n",
      "Epoch 6 num_samples 15600 loss 0.42046093798937817\n",
      "Epoch 6 num_samples 15700 loss 0.3085968744799024\n",
      "Epoch 6 num_samples 15800 loss 0.46094491330837317\n",
      "Epoch 6 num_samples 15900 loss 0.28483262473139964\n",
      "Epoch 6 num_samples 16000 loss 0.5738028151746881\n",
      "Epoch 6 num_samples 16100 loss 0.37928604201032057\n",
      "Epoch 6 num_samples 16200 loss 0.30875653778679846\n",
      "Epoch 6 num_samples 16300 loss 0.43999504502902953\n",
      "Epoch 6 num_samples 16400 loss 0.3633935688032722\n",
      "Epoch 6 num_samples 16500 loss 0.41383493418974493\n",
      "Epoch 6 num_samples 16600 loss 0.5005940321706559\n",
      "Epoch 6 num_samples 16700 loss 0.2913311043316535\n",
      "Epoch 6 num_samples 16800 loss 0.27546192945711534\n",
      "Epoch 6 num_samples 16900 loss 0.432635085550953\n",
      "Epoch 6 num_samples 17000 loss 0.3004516840857867\n",
      "Epoch 6 num_samples 17100 loss 0.48594273309376446\n",
      "Epoch 6 num_samples 17200 loss 0.32884404147397134\n",
      "Epoch 6 num_samples 17300 loss 0.38709145656751914\n",
      "Epoch 6 num_samples 17400 loss 0.45661038662794\n",
      "Epoch 6 num_samples 17500 loss 0.47807961718051756\n",
      "Epoch 6 num_samples 17600 loss 0.4220104637870582\n",
      "Epoch 6 num_samples 17700 loss 0.35658452914535455\n",
      "Epoch 6 num_samples 17800 loss 0.42472298201255887\n",
      "Epoch 6 num_samples 17900 loss 0.40332049682683824\n",
      "Epoch 6 num_samples 18000 loss 0.3076150021661243\n",
      "Epoch 6 num_samples 18100 loss 0.36345168403723493\n",
      "Epoch 6 num_samples 18200 loss 0.3587310694774539\n",
      "Epoch 6 num_samples 18300 loss 0.3866210219641645\n",
      "Epoch 6 num_samples 18400 loss 0.5176089046080454\n",
      "Epoch 6 num_samples 18500 loss 0.34182938469573\n",
      "Epoch 7 num_samples 0 loss 0.3741521714310657\n",
      "Epoch 7 num_samples 100 loss 0.364209038738629\n",
      "Epoch 7 num_samples 200 loss 0.3544174004900741\n",
      "Epoch 7 num_samples 300 loss 0.3644481105845357\n",
      "Epoch 7 num_samples 400 loss 0.2974460851782672\n",
      "Epoch 7 num_samples 500 loss 0.38183639731053703\n",
      "Epoch 7 num_samples 600 loss 0.35926029994928216\n",
      "Epoch 7 num_samples 700 loss 0.3882038352497129\n",
      "Epoch 7 num_samples 800 loss 0.4769439697152306\n",
      "Epoch 7 num_samples 900 loss 0.2810960496619609\n",
      "Epoch 7 num_samples 1000 loss 0.29480371172833547\n",
      "Epoch 7 num_samples 1100 loss 0.43243128484276006\n",
      "Epoch 7 num_samples 1200 loss 0.3225674469991569\n",
      "Epoch 7 num_samples 1300 loss 0.3037470198310561\n",
      "Epoch 7 num_samples 1400 loss 0.49142071175942986\n",
      "Epoch 7 num_samples 1500 loss 0.3932840177311512\n",
      "Epoch 7 num_samples 1600 loss 0.37249656176280027\n",
      "Epoch 7 num_samples 1700 loss 0.4222438715380656\n",
      "Epoch 7 num_samples 1800 loss 0.33213680315518457\n",
      "Epoch 7 num_samples 1900 loss 0.30938146055884613\n",
      "Epoch 7 num_samples 2000 loss 0.4672740637795749\n",
      "Epoch 7 num_samples 2100 loss 0.31021066983837686\n",
      "Epoch 7 num_samples 2200 loss 0.26091535503984004\n",
      "Epoch 7 num_samples 2300 loss 0.31386323462672927\n",
      "Epoch 7 num_samples 2400 loss 0.2938435966102327\n",
      "Epoch 7 num_samples 2500 loss 0.41099720104211906\n",
      "Epoch 7 num_samples 2600 loss 0.40618503322413235\n",
      "Epoch 7 num_samples 2700 loss 0.3426371964578512\n",
      "Epoch 7 num_samples 2800 loss 0.37472174655655394\n",
      "Epoch 7 num_samples 2900 loss 0.3544353770770456\n",
      "Epoch 7 num_samples 3000 loss 0.30059102599435833\n",
      "Epoch 7 num_samples 3100 loss 0.3244683430175192\n",
      "Epoch 7 num_samples 3200 loss 0.5270247259613033\n",
      "Epoch 7 num_samples 3300 loss 0.30488974395848417\n",
      "Epoch 7 num_samples 3400 loss 0.32940049203990923\n",
      "Epoch 7 num_samples 3500 loss 0.3303816636658768\n",
      "Epoch 7 num_samples 3600 loss 0.25000131456803276\n",
      "Epoch 7 num_samples 3700 loss 0.3410656193029476\n",
      "Epoch 7 num_samples 3800 loss 0.33741218833302716\n",
      "Epoch 7 num_samples 3900 loss 0.4206357967585902\n",
      "Epoch 7 num_samples 4000 loss 0.44835700825485275\n",
      "Epoch 7 num_samples 4100 loss 0.46935343085723935\n",
      "Epoch 7 num_samples 4200 loss 0.3258907555399409\n",
      "Epoch 7 num_samples 4300 loss 0.378844173498655\n",
      "Epoch 7 num_samples 4400 loss 0.33735199641323277\n",
      "Epoch 7 num_samples 4500 loss 0.44226142801279944\n",
      "Epoch 7 num_samples 4600 loss 0.3633598205138894\n",
      "Epoch 7 num_samples 4700 loss 0.23112374638578473\n",
      "Epoch 7 num_samples 4800 loss 0.26788351895458645\n",
      "Epoch 7 num_samples 4900 loss 0.3819957682216334\n",
      "Epoch 7 num_samples 5000 loss 0.3937683603381714\n",
      "Epoch 7 num_samples 5100 loss 0.47137239281920557\n",
      "Epoch 7 num_samples 5200 loss 0.3388650567972909\n",
      "Epoch 7 num_samples 5300 loss 0.3504461442820053\n",
      "Epoch 7 num_samples 5400 loss 0.47294004285179836\n",
      "Epoch 7 num_samples 5500 loss 0.30851544500008626\n",
      "Epoch 7 num_samples 5600 loss 0.37607012049090544\n",
      "Epoch 7 num_samples 5700 loss 0.4777095022907379\n",
      "Epoch 7 num_samples 5800 loss 0.440671782047787\n",
      "Epoch 7 num_samples 5900 loss 0.3704216765916401\n",
      "Epoch 7 num_samples 6000 loss 0.3693647176057033\n",
      "Epoch 7 num_samples 6100 loss 0.23026467565856515\n",
      "Epoch 7 num_samples 6200 loss 0.43077140682660314\n",
      "Epoch 7 num_samples 6300 loss 0.5236137888839016\n",
      "Epoch 7 num_samples 6400 loss 0.3394591916444263\n",
      "Epoch 7 num_samples 6500 loss 0.3291155108101792\n",
      "Epoch 7 num_samples 6600 loss 0.47836124917465156\n",
      "Epoch 7 num_samples 6700 loss 0.2857628849151196\n",
      "Epoch 7 num_samples 6800 loss 0.18518371148583598\n",
      "Epoch 7 num_samples 6900 loss 0.5786548672564688\n",
      "Epoch 7 num_samples 7000 loss 0.4032166171606433\n",
      "Epoch 7 num_samples 7100 loss 0.26199448981030193\n",
      "Epoch 7 num_samples 7200 loss 0.3695909402511131\n",
      "Epoch 7 num_samples 7300 loss 0.37575168279596016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 num_samples 7400 loss 0.30614066969838116\n",
      "Epoch 7 num_samples 7500 loss 0.4322518054397667\n",
      "Epoch 7 num_samples 7600 loss 0.4293517760140564\n",
      "Epoch 7 num_samples 7700 loss 0.4750742699014643\n",
      "Epoch 7 num_samples 7800 loss 0.20187978889700758\n",
      "Epoch 7 num_samples 7900 loss 0.3860891502927061\n",
      "Epoch 7 num_samples 8000 loss 0.21516182353123958\n",
      "Epoch 7 num_samples 8100 loss 0.3712020593551389\n",
      "Epoch 7 num_samples 8200 loss 0.2862872918485702\n",
      "Epoch 7 num_samples 8300 loss 0.29990932452605046\n",
      "Epoch 7 num_samples 8400 loss 0.34219873090837216\n",
      "Epoch 7 num_samples 8500 loss 0.3391902481219031\n",
      "Epoch 7 num_samples 8600 loss 0.2406749027233068\n",
      "Epoch 7 num_samples 8700 loss 0.3451412029537515\n",
      "Epoch 7 num_samples 8800 loss 0.370106831662998\n",
      "Epoch 7 num_samples 8900 loss 0.44505199130524303\n",
      "Epoch 7 num_samples 9000 loss 0.3682880906174708\n",
      "Epoch 7 num_samples 9100 loss 0.38648510053236523\n",
      "Epoch 7 num_samples 9200 loss 0.3536626341538168\n",
      "Epoch 7 num_samples 9300 loss 0.3996964056516809\n",
      "Epoch 7 num_samples 9400 loss 0.28151985493362824\n",
      "Epoch 7 num_samples 9500 loss 0.40884087733665403\n",
      "Epoch 7 num_samples 9600 loss 0.30337644131829783\n",
      "Epoch 7 num_samples 9700 loss 0.41953675151955205\n",
      "Epoch 7 num_samples 9800 loss 0.24237835432389798\n",
      "Epoch 7 num_samples 9900 loss 0.5001572306333769\n",
      "Epoch 7 num_samples 10000 loss 0.2685905532991501\n",
      "Epoch 7 num_samples 10100 loss 0.1975598835829397\n",
      "Epoch 7 num_samples 10200 loss 0.42518619179694406\n",
      "Epoch 7 num_samples 10300 loss 0.42441635591093835\n",
      "Epoch 7 num_samples 10400 loss 0.3838063202562245\n",
      "Epoch 7 num_samples 10500 loss 0.3397078711414355\n",
      "Epoch 7 num_samples 10600 loss 0.33516493249316\n",
      "Epoch 7 num_samples 10700 loss 0.28041495273796857\n",
      "Epoch 7 num_samples 10800 loss 0.3827753513507801\n",
      "Epoch 7 num_samples 10900 loss 0.3724700883793139\n",
      "Epoch 7 num_samples 11000 loss 0.2244855798130019\n",
      "Epoch 7 num_samples 11100 loss 0.477915885835173\n",
      "Epoch 7 num_samples 11200 loss 0.35550097118775453\n",
      "Epoch 7 num_samples 11300 loss 0.48276854547727494\n",
      "Epoch 7 num_samples 11400 loss 0.4288729994806769\n",
      "Epoch 7 num_samples 11500 loss 0.3064356738174622\n",
      "Epoch 7 num_samples 11600 loss 0.3376078974688108\n",
      "Epoch 7 num_samples 11700 loss 0.3897887461296014\n",
      "Epoch 7 num_samples 11800 loss 0.2556906962562629\n",
      "Epoch 7 num_samples 11900 loss 0.3025462530063262\n",
      "Epoch 7 num_samples 12000 loss 0.2866595805767567\n",
      "Epoch 7 num_samples 12100 loss 0.2933238548520334\n",
      "Epoch 7 num_samples 12200 loss 0.35046124861831524\n",
      "Epoch 7 num_samples 12300 loss 0.26652162846213323\n",
      "Epoch 7 num_samples 12400 loss 0.35611414633057514\n",
      "Epoch 7 num_samples 12500 loss 0.3405928403059067\n",
      "Epoch 7 num_samples 12600 loss 0.3156411174520655\n",
      "Epoch 7 num_samples 12700 loss 0.37075245151544506\n",
      "Epoch 7 num_samples 12800 loss 0.455753858343525\n",
      "Epoch 7 num_samples 12900 loss 0.24210991134067264\n",
      "Epoch 7 num_samples 13000 loss 0.30898868049121975\n",
      "Epoch 7 num_samples 13100 loss 0.46630517105292696\n",
      "Epoch 7 num_samples 13200 loss 0.3021150933032742\n",
      "Epoch 7 num_samples 13300 loss 0.2926708591544848\n",
      "Epoch 7 num_samples 13400 loss 0.28109547053828565\n",
      "Epoch 7 num_samples 13500 loss 0.28158511485783444\n",
      "Epoch 7 num_samples 13600 loss 0.3728733210167849\n",
      "Epoch 7 num_samples 13700 loss 0.33391256838886846\n",
      "Epoch 7 num_samples 13800 loss 0.27126977156062304\n",
      "Epoch 7 num_samples 13900 loss 0.2992281132532637\n",
      "Epoch 7 num_samples 14000 loss 0.21099652288160362\n",
      "Epoch 7 num_samples 14100 loss 0.3156919136766214\n",
      "Epoch 7 num_samples 14200 loss 0.24756885374957968\n",
      "Epoch 7 num_samples 14300 loss 0.3688975401249978\n",
      "Epoch 7 num_samples 14400 loss 0.4006997038090621\n",
      "Epoch 7 num_samples 14500 loss 0.4316417951356675\n",
      "Epoch 7 num_samples 14600 loss 0.37388021132126426\n",
      "Epoch 7 num_samples 14700 loss 0.370997716866494\n",
      "Epoch 7 num_samples 14800 loss 0.24556670888322643\n",
      "Epoch 7 num_samples 14900 loss 0.414333992805909\n",
      "Epoch 7 num_samples 15000 loss 0.25728152567867046\n",
      "Epoch 7 num_samples 15100 loss 0.40884519297487626\n",
      "Epoch 7 num_samples 15200 loss 0.3669196313388497\n",
      "Epoch 7 num_samples 15300 loss 0.380608051265946\n",
      "Epoch 7 num_samples 15400 loss 0.26432835589489523\n",
      "Epoch 7 num_samples 15500 loss 0.30218397758438725\n",
      "Epoch 7 num_samples 15600 loss 0.36751632797640194\n",
      "Epoch 7 num_samples 15700 loss 0.2710451227817744\n",
      "Epoch 7 num_samples 15800 loss 0.4145312751300046\n",
      "Epoch 7 num_samples 15900 loss 0.24020871033938307\n",
      "Epoch 7 num_samples 16000 loss 0.5197411805630735\n",
      "Epoch 7 num_samples 16100 loss 0.33296321707281534\n",
      "Epoch 7 num_samples 16200 loss 0.27558873736125533\n",
      "Epoch 7 num_samples 16300 loss 0.39797647829818894\n",
      "Epoch 7 num_samples 16400 loss 0.3229727071541528\n",
      "Epoch 7 num_samples 16500 loss 0.3633356486310638\n",
      "Epoch 7 num_samples 16600 loss 0.4401745376442331\n",
      "Epoch 7 num_samples 16700 loss 0.2604642431963159\n",
      "Epoch 7 num_samples 16800 loss 0.24255810794494256\n",
      "Epoch 7 num_samples 16900 loss 0.3879418697940706\n",
      "Epoch 7 num_samples 17000 loss 0.25995291065769704\n",
      "Epoch 7 num_samples 17100 loss 0.4577097292431248\n",
      "Epoch 7 num_samples 17200 loss 0.30242638625440493\n",
      "Epoch 7 num_samples 17300 loss 0.3415555981644031\n",
      "Epoch 7 num_samples 17400 loss 0.4190886480713425\n",
      "Epoch 7 num_samples 17500 loss 0.42554060149643047\n",
      "Epoch 7 num_samples 17600 loss 0.37445162173156354\n",
      "Epoch 7 num_samples 17700 loss 0.30751777397247204\n",
      "Epoch 7 num_samples 17800 loss 0.3812638955434312\n",
      "Epoch 7 num_samples 17900 loss 0.3645119065560133\n",
      "Epoch 7 num_samples 18000 loss 0.26555975511392726\n",
      "Epoch 7 num_samples 18100 loss 0.3208399243814003\n",
      "Epoch 7 num_samples 18200 loss 0.31862515347822784\n",
      "Epoch 7 num_samples 18300 loss 0.3379280422417644\n",
      "Epoch 7 num_samples 18400 loss 0.4531413486409285\n",
      "Epoch 7 num_samples 18500 loss 0.3022617615506257\n",
      "Epoch 8 num_samples 0 loss 0.3328278083686517\n",
      "Epoch 8 num_samples 100 loss 0.3279719711972347\n",
      "Epoch 8 num_samples 200 loss 0.30915823670157117\n",
      "Epoch 8 num_samples 300 loss 0.3309107870624355\n",
      "Epoch 8 num_samples 400 loss 0.2611875216558042\n",
      "Epoch 8 num_samples 500 loss 0.3326784039697438\n",
      "Epoch 8 num_samples 600 loss 0.32230322684572826\n",
      "Epoch 8 num_samples 700 loss 0.3625020758236712\n",
      "Epoch 8 num_samples 800 loss 0.43208249861500336\n",
      "Epoch 8 num_samples 900 loss 0.25080181215778163\n",
      "Epoch 8 num_samples 1000 loss 0.26895379509986894\n",
      "Epoch 8 num_samples 1100 loss 0.3790427428059992\n",
      "Epoch 8 num_samples 1200 loss 0.2912820786813487\n",
      "Epoch 8 num_samples 1300 loss 0.25671032504365315\n",
      "Epoch 8 num_samples 1400 loss 0.42762872229916354\n",
      "Epoch 8 num_samples 1500 loss 0.3641832121904515\n",
      "Epoch 8 num_samples 1600 loss 0.3261691226356126\n",
      "Epoch 8 num_samples 1700 loss 0.37583272820264824\n",
      "Epoch 8 num_samples 1800 loss 0.2979682710988747\n",
      "Epoch 8 num_samples 1900 loss 0.27200805207194184\n",
      "Epoch 8 num_samples 2000 loss 0.4292296922139128\n",
      "Epoch 8 num_samples 2100 loss 0.2747716323355126\n",
      "Epoch 8 num_samples 2200 loss 0.22672872448150208\n",
      "Epoch 8 num_samples 2300 loss 0.28389731057635836\n",
      "Epoch 8 num_samples 2400 loss 0.2588072291918729\n",
      "Epoch 8 num_samples 2500 loss 0.37091537191225127\n",
      "Epoch 8 num_samples 2600 loss 0.37045113789254336\n",
      "Epoch 8 num_samples 2700 loss 0.31320160033604943\n",
      "Epoch 8 num_samples 2800 loss 0.3353896941598482\n",
      "Epoch 8 num_samples 2900 loss 0.3163308984571481\n",
      "Epoch 8 num_samples 3000 loss 0.2634333509400143\n",
      "Epoch 8 num_samples 3100 loss 0.28066540949696267\n",
      "Epoch 8 num_samples 3200 loss 0.4855529276620881\n",
      "Epoch 8 num_samples 3300 loss 0.2669849568236929\n",
      "Epoch 8 num_samples 3400 loss 0.28746848179150525\n",
      "Epoch 8 num_samples 3500 loss 0.2932226308467568\n",
      "Epoch 8 num_samples 3600 loss 0.21603151036287851\n",
      "Epoch 8 num_samples 3700 loss 0.31049335899873326\n",
      "Epoch 8 num_samples 3800 loss 0.30988173675847835\n",
      "Epoch 8 num_samples 3900 loss 0.38074725696915707\n",
      "Epoch 8 num_samples 4000 loss 0.40065551547898987\n",
      "Epoch 8 num_samples 4100 loss 0.4314382184061361\n",
      "Epoch 8 num_samples 4200 loss 0.2882109270994834\n",
      "Epoch 8 num_samples 4300 loss 0.3444786082789687\n",
      "Epoch 8 num_samples 4400 loss 0.29746108158521806\n",
      "Epoch 8 num_samples 4500 loss 0.40488698796147654\n",
      "Epoch 8 num_samples 4600 loss 0.3264375200628153\n",
      "Epoch 8 num_samples 4700 loss 0.20355699407411998\n",
      "Epoch 8 num_samples 4800 loss 0.2320779740036284\n",
      "Epoch 8 num_samples 4900 loss 0.33714267687617183\n",
      "Epoch 8 num_samples 5000 loss 0.3375944521520705\n",
      "Epoch 8 num_samples 5100 loss 0.42719905918056056\n",
      "Epoch 8 num_samples 5200 loss 0.2931686500554917\n",
      "Epoch 8 num_samples 5300 loss 0.3181339808796176\n",
      "Epoch 8 num_samples 5400 loss 0.42204716280906296\n",
      "Epoch 8 num_samples 5500 loss 0.26651406783828496\n",
      "Epoch 8 num_samples 5600 loss 0.352054658233464\n",
      "Epoch 8 num_samples 5700 loss 0.4210016203332539\n",
      "Epoch 8 num_samples 5800 loss 0.3925739485836603\n",
      "Epoch 8 num_samples 5900 loss 0.3335493291685382\n",
      "Epoch 8 num_samples 6000 loss 0.33279780384861285\n",
      "Epoch 8 num_samples 6100 loss 0.20729676070844782\n",
      "Epoch 8 num_samples 6200 loss 0.37950289372169416\n",
      "Epoch 8 num_samples 6300 loss 0.45729527098837297\n",
      "Epoch 8 num_samples 6400 loss 0.2975333813812473\n",
      "Epoch 8 num_samples 6500 loss 0.28275452957949004\n",
      "Epoch 8 num_samples 6600 loss 0.4336500358914445\n",
      "Epoch 8 num_samples 6700 loss 0.2475072955336137\n",
      "Epoch 8 num_samples 6800 loss 0.15452986865203402\n",
      "Epoch 8 num_samples 6900 loss 0.5307656762843508\n",
      "Epoch 8 num_samples 7000 loss 0.3647962170814057\n",
      "Epoch 8 num_samples 7100 loss 0.23486088747199374\n",
      "Epoch 8 num_samples 7200 loss 0.3253288208856441\n",
      "Epoch 8 num_samples 7300 loss 0.3379173895395165\n",
      "Epoch 8 num_samples 7400 loss 0.2663563775690546\n",
      "Epoch 8 num_samples 7500 loss 0.3971369540534782\n",
      "Epoch 8 num_samples 7600 loss 0.37859061470497496\n",
      "Epoch 8 num_samples 7700 loss 0.42703925025795264\n",
      "Epoch 8 num_samples 7800 loss 0.1778597867025859\n",
      "Epoch 8 num_samples 7900 loss 0.34748763930869686\n",
      "Epoch 8 num_samples 8000 loss 0.1877144542891621\n",
      "Epoch 8 num_samples 8100 loss 0.32160707846104175\n",
      "Epoch 8 num_samples 8200 loss 0.25496164478495215\n",
      "Epoch 8 num_samples 8300 loss 0.27363836549261045\n",
      "Epoch 8 num_samples 8400 loss 0.30479349397408606\n",
      "Epoch 8 num_samples 8500 loss 0.30512581576290654\n",
      "Epoch 8 num_samples 8600 loss 0.21040404331632445\n",
      "Epoch 8 num_samples 8700 loss 0.3062998921410618\n",
      "Epoch 8 num_samples 8800 loss 0.3391176452454478\n",
      "Epoch 8 num_samples 8900 loss 0.3951074733741756\n",
      "Epoch 8 num_samples 9000 loss 0.32662231739240005\n",
      "Epoch 8 num_samples 9100 loss 0.3404893692300852\n",
      "Epoch 8 num_samples 9200 loss 0.3132750413778905\n",
      "Epoch 8 num_samples 9300 loss 0.3549370359755944\n",
      "Epoch 8 num_samples 9400 loss 0.24597075002855956\n",
      "Epoch 8 num_samples 9500 loss 0.3720152283938177\n",
      "Epoch 8 num_samples 9600 loss 0.2572994402685452\n",
      "Epoch 8 num_samples 9700 loss 0.3711569209349891\n",
      "Epoch 8 num_samples 9800 loss 0.21395862353429085\n",
      "Epoch 8 num_samples 9900 loss 0.45886645056429076\n",
      "Epoch 8 num_samples 10000 loss 0.24021100864059025\n",
      "Epoch 8 num_samples 10100 loss 0.1749112132916081\n",
      "Epoch 8 num_samples 10200 loss 0.3813370241350998\n",
      "Epoch 8 num_samples 10300 loss 0.37699206818236297\n",
      "Epoch 8 num_samples 10400 loss 0.3362084462270251\n",
      "Epoch 8 num_samples 10500 loss 0.29735020551493935\n",
      "Epoch 8 num_samples 10600 loss 0.306332162827397\n",
      "Epoch 8 num_samples 10700 loss 0.25136999800996773\n",
      "Epoch 8 num_samples 10800 loss 0.3493641096880736\n",
      "Epoch 8 num_samples 10900 loss 0.32031464898146594\n",
      "Epoch 8 num_samples 11000 loss 0.19362776145341415\n",
      "Epoch 8 num_samples 11100 loss 0.4333522283262868\n",
      "Epoch 8 num_samples 11200 loss 0.31874296876900876\n",
      "Epoch 8 num_samples 11300 loss 0.4345264644173247\n",
      "Epoch 8 num_samples 11400 loss 0.38819821635908736\n",
      "Epoch 8 num_samples 11500 loss 0.26078136697682663\n",
      "Epoch 8 num_samples 11600 loss 0.29675787695559336\n",
      "Epoch 8 num_samples 11700 loss 0.3517281370363652\n",
      "Epoch 8 num_samples 11800 loss 0.23146039487768172\n",
      "Epoch 8 num_samples 11900 loss 0.27283837244651027\n",
      "Epoch 8 num_samples 12000 loss 0.25156004645103347\n",
      "Epoch 8 num_samples 12100 loss 0.2595372557080462\n",
      "Epoch 8 num_samples 12200 loss 0.31914864836601525\n",
      "Epoch 8 num_samples 12300 loss 0.22947404323610202\n",
      "Epoch 8 num_samples 12400 loss 0.32267083538177715\n",
      "Epoch 8 num_samples 12500 loss 0.30755252856249393\n",
      "Epoch 8 num_samples 12600 loss 0.2752076370555047\n",
      "Epoch 8 num_samples 12700 loss 0.3344000588564458\n",
      "Epoch 8 num_samples 12800 loss 0.4260488621784973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 num_samples 12900 loss 0.22954561862149972\n",
      "Epoch 8 num_samples 13000 loss 0.271278553162637\n",
      "Epoch 8 num_samples 13100 loss 0.42645042759800583\n",
      "Epoch 8 num_samples 13200 loss 0.25801376867136205\n",
      "Epoch 8 num_samples 13300 loss 0.24758349387570278\n",
      "Epoch 8 num_samples 13400 loss 0.24624589813532288\n",
      "Epoch 8 num_samples 13500 loss 0.25109680770456927\n",
      "Epoch 8 num_samples 13600 loss 0.3363581426647508\n",
      "Epoch 8 num_samples 13700 loss 0.3000484984891403\n",
      "Epoch 8 num_samples 13800 loss 0.24460072437526395\n",
      "Epoch 8 num_samples 13900 loss 0.26046443761187554\n",
      "Epoch 8 num_samples 14000 loss 0.18510796453841627\n",
      "Epoch 8 num_samples 14100 loss 0.28476413300916886\n",
      "Epoch 8 num_samples 14200 loss 0.21900543667510944\n",
      "Epoch 8 num_samples 14300 loss 0.32999658318538416\n",
      "Epoch 8 num_samples 14400 loss 0.3575089967286916\n",
      "Epoch 8 num_samples 14500 loss 0.3871838496679676\n",
      "Epoch 8 num_samples 14600 loss 0.3263903161718957\n",
      "Epoch 8 num_samples 14700 loss 0.325956700872411\n",
      "Epoch 8 num_samples 14800 loss 0.2205118263294574\n",
      "Epoch 8 num_samples 14900 loss 0.3743306467766233\n",
      "Epoch 8 num_samples 15000 loss 0.22891186724823878\n",
      "Epoch 8 num_samples 15100 loss 0.35868658589808095\n",
      "Epoch 8 num_samples 15200 loss 0.33899436680388717\n",
      "Epoch 8 num_samples 15300 loss 0.3417476093915907\n",
      "Epoch 8 num_samples 15400 loss 0.23666098203102418\n",
      "Epoch 8 num_samples 15500 loss 0.27243268080288296\n",
      "Epoch 8 num_samples 15600 loss 0.326407021378151\n",
      "Epoch 8 num_samples 15700 loss 0.23753436418032664\n",
      "Epoch 8 num_samples 15800 loss 0.3770989498115225\n",
      "Epoch 8 num_samples 15900 loss 0.20749244241355363\n",
      "Epoch 8 num_samples 16000 loss 0.4730884942483107\n",
      "Epoch 8 num_samples 16100 loss 0.29676079465934585\n",
      "Epoch 8 num_samples 16200 loss 0.2496545291032458\n",
      "Epoch 8 num_samples 16300 loss 0.3621480908272134\n",
      "Epoch 8 num_samples 16400 loss 0.28910584750753576\n",
      "Epoch 8 num_samples 16500 loss 0.3181551549403937\n",
      "Epoch 8 num_samples 16600 loss 0.3967244502075913\n",
      "Epoch 8 num_samples 16700 loss 0.2332816969095808\n",
      "Epoch 8 num_samples 16800 loss 0.2142221673705305\n",
      "Epoch 8 num_samples 16900 loss 0.3495712874757315\n",
      "Epoch 8 num_samples 17000 loss 0.22675536439351218\n",
      "Epoch 8 num_samples 17100 loss 0.4280800593132982\n",
      "Epoch 8 num_samples 17200 loss 0.281378626546351\n",
      "Epoch 8 num_samples 17300 loss 0.3040710728782373\n",
      "Epoch 8 num_samples 17400 loss 0.38411152138314053\n",
      "Epoch 8 num_samples 17500 loss 0.3893074018870817\n",
      "Epoch 8 num_samples 17600 loss 0.33683605154152346\n",
      "Epoch 8 num_samples 17700 loss 0.2699830586457017\n",
      "Epoch 8 num_samples 17800 loss 0.3460566199665277\n",
      "Epoch 8 num_samples 17900 loss 0.3289163603783877\n",
      "Epoch 8 num_samples 18000 loss 0.2305144572095852\n",
      "Epoch 8 num_samples 18100 loss 0.28416020653848817\n",
      "Epoch 8 num_samples 18200 loss 0.285289950886931\n",
      "Epoch 8 num_samples 18300 loss 0.2974385600539534\n",
      "Epoch 8 num_samples 18400 loss 0.403304656865958\n",
      "Epoch 8 num_samples 18500 loss 0.2716523170926103\n",
      "Epoch 9 num_samples 0 loss 0.29953663540397535\n",
      "Epoch 9 num_samples 100 loss 0.30225556114655605\n",
      "Epoch 9 num_samples 200 loss 0.2707379485735792\n",
      "Epoch 9 num_samples 300 loss 0.3009605261651452\n",
      "Epoch 9 num_samples 400 loss 0.23218630065098161\n",
      "Epoch 9 num_samples 500 loss 0.29269201176066934\n",
      "Epoch 9 num_samples 600 loss 0.2934710787163153\n",
      "Epoch 9 num_samples 700 loss 0.34026325991149703\n",
      "Epoch 9 num_samples 800 loss 0.39168732796080513\n",
      "Epoch 9 num_samples 900 loss 0.22228446612744443\n",
      "Epoch 9 num_samples 1000 loss 0.24675079623030866\n",
      "Epoch 9 num_samples 1100 loss 0.33633547629428606\n",
      "Epoch 9 num_samples 1200 loss 0.2633467432880783\n",
      "Epoch 9 num_samples 1300 loss 0.2215833510807041\n",
      "Epoch 9 num_samples 1400 loss 0.37050459779960826\n",
      "Epoch 9 num_samples 1500 loss 0.341744803762759\n",
      "Epoch 9 num_samples 1600 loss 0.28983676868458935\n",
      "Epoch 9 num_samples 1700 loss 0.3370819095495804\n",
      "Epoch 9 num_samples 1800 loss 0.27148734247260786\n",
      "Epoch 9 num_samples 1900 loss 0.24211552675053805\n",
      "Epoch 9 num_samples 2000 loss 0.38673025496142066\n",
      "Epoch 9 num_samples 2100 loss 0.24355902470812724\n",
      "Epoch 9 num_samples 2200 loss 0.19949116901276373\n",
      "Epoch 9 num_samples 2300 loss 0.25308499734149487\n",
      "Epoch 9 num_samples 2400 loss 0.22828439526222702\n",
      "Epoch 9 num_samples 2500 loss 0.33908052533149297\n",
      "Epoch 9 num_samples 2600 loss 0.33344600403393826\n",
      "Epoch 9 num_samples 2700 loss 0.28783897623042787\n",
      "Epoch 9 num_samples 2800 loss 0.3037102847127891\n",
      "Epoch 9 num_samples 2900 loss 0.28523493782389747\n",
      "Epoch 9 num_samples 3000 loss 0.23176643163199842\n",
      "Epoch 9 num_samples 3100 loss 0.2496275932481582\n",
      "Epoch 9 num_samples 3200 loss 0.4505318346433637\n",
      "Epoch 9 num_samples 3300 loss 0.2338221027709912\n",
      "Epoch 9 num_samples 3400 loss 0.25493356921816807\n",
      "Epoch 9 num_samples 3500 loss 0.2623406710351628\n",
      "Epoch 9 num_samples 3600 loss 0.18975667758443518\n",
      "Epoch 9 num_samples 3700 loss 0.2845617088168167\n",
      "Epoch 9 num_samples 3800 loss 0.2839147722572617\n",
      "Epoch 9 num_samples 3900 loss 0.3460208461847013\n",
      "Epoch 9 num_samples 4000 loss 0.3647328601966564\n",
      "Epoch 9 num_samples 4100 loss 0.4002112202345067\n",
      "Epoch 9 num_samples 4200 loss 0.26080631572180196\n",
      "Epoch 9 num_samples 4300 loss 0.3115001331902905\n",
      "Epoch 9 num_samples 4400 loss 0.26342802342821936\n",
      "Epoch 9 num_samples 4500 loss 0.3678497002923578\n",
      "Epoch 9 num_samples 4600 loss 0.2969187068663652\n",
      "Epoch 9 num_samples 4700 loss 0.17953944647440945\n",
      "Epoch 9 num_samples 4800 loss 0.2040165121991104\n",
      "Epoch 9 num_samples 4900 loss 0.2937771678167184\n",
      "Epoch 9 num_samples 5000 loss 0.29113873213780783\n",
      "Epoch 9 num_samples 5100 loss 0.389274387404823\n",
      "Epoch 9 num_samples 5200 loss 0.2530635388179918\n",
      "Epoch 9 num_samples 5300 loss 0.28968083494436236\n",
      "Epoch 9 num_samples 5400 loss 0.3814832392601407\n",
      "Epoch 9 num_samples 5500 loss 0.23644526813718506\n",
      "Epoch 9 num_samples 5600 loss 0.33125095150147843\n",
      "Epoch 9 num_samples 5700 loss 0.3698175810468278\n",
      "Epoch 9 num_samples 5800 loss 0.35689453567616075\n",
      "Epoch 9 num_samples 5900 loss 0.3006546126473972\n",
      "Epoch 9 num_samples 6000 loss 0.3021574398932061\n",
      "Epoch 9 num_samples 6100 loss 0.18774050741484546\n",
      "Epoch 9 num_samples 6200 loss 0.3377256254351571\n",
      "Epoch 9 num_samples 6300 loss 0.4012850823956846\n",
      "Epoch 9 num_samples 6400 loss 0.2592775284338337\n",
      "Epoch 9 num_samples 6500 loss 0.24442991544688522\n",
      "Epoch 9 num_samples 6600 loss 0.3964780947169723\n",
      "Epoch 9 num_samples 6700 loss 0.2150059243948651\n",
      "Epoch 9 num_samples 6800 loss 0.1311173669951623\n",
      "Epoch 9 num_samples 6900 loss 0.4847030189772689\n",
      "Epoch 9 num_samples 7000 loss 0.33754783280248696\n",
      "Epoch 9 num_samples 7100 loss 0.21283164815692235\n",
      "Epoch 9 num_samples 7200 loss 0.2929593106453253\n",
      "Epoch 9 num_samples 7300 loss 0.30456612401029376\n",
      "Epoch 9 num_samples 7400 loss 0.2378841360246536\n",
      "Epoch 9 num_samples 7500 loss 0.36684754452371493\n",
      "Epoch 9 num_samples 7600 loss 0.3346744252895104\n",
      "Epoch 9 num_samples 7700 loss 0.38900726673745933\n",
      "Epoch 9 num_samples 7800 loss 0.15845203477864706\n",
      "Epoch 9 num_samples 7900 loss 0.31201630801033914\n",
      "Epoch 9 num_samples 8000 loss 0.16785110501833486\n",
      "Epoch 9 num_samples 8100 loss 0.2789677638309758\n",
      "Epoch 9 num_samples 8200 loss 0.22608219180373276\n",
      "Epoch 9 num_samples 8300 loss 0.25064079969764685\n",
      "Epoch 9 num_samples 8400 loss 0.2714784038847324\n",
      "Epoch 9 num_samples 8500 loss 0.2794883439646413\n",
      "Epoch 9 num_samples 8600 loss 0.18613308616428953\n",
      "Epoch 9 num_samples 8700 loss 0.272148202206912\n",
      "Epoch 9 num_samples 8800 loss 0.31474948009771053\n",
      "Epoch 9 num_samples 8900 loss 0.3505267795656819\n",
      "Epoch 9 num_samples 9000 loss 0.2923956449934843\n",
      "Epoch 9 num_samples 9100 loss 0.29773457952762394\n",
      "Epoch 9 num_samples 9200 loss 0.279560511181157\n",
      "Epoch 9 num_samples 9300 loss 0.3179001655460423\n",
      "Epoch 9 num_samples 9400 loss 0.21790045191658902\n",
      "Epoch 9 num_samples 9500 loss 0.338788150441557\n",
      "Epoch 9 num_samples 9600 loss 0.22334889470923533\n",
      "Epoch 9 num_samples 9700 loss 0.33206381893422277\n",
      "Epoch 9 num_samples 9800 loss 0.19042371279264697\n",
      "Epoch 9 num_samples 9900 loss 0.4224721150805739\n",
      "Epoch 9 num_samples 10000 loss 0.21539344678115668\n",
      "Epoch 9 num_samples 10100 loss 0.1573635307258743\n",
      "Epoch 9 num_samples 10200 loss 0.34794378470163695\n",
      "Epoch 9 num_samples 10300 loss 0.3382172054212232\n",
      "Epoch 9 num_samples 10400 loss 0.30113072608020025\n",
      "Epoch 9 num_samples 10500 loss 0.2609989745179244\n",
      "Epoch 9 num_samples 10600 loss 0.28058856642325897\n",
      "Epoch 9 num_samples 10700 loss 0.22686604064661245\n",
      "Epoch 9 num_samples 10800 loss 0.3242272369190944\n",
      "Epoch 9 num_samples 10900 loss 0.2842355721548906\n",
      "Epoch 9 num_samples 11000 loss 0.16605393838076815\n",
      "Epoch 9 num_samples 11100 loss 0.38497799161852425\n",
      "Epoch 9 num_samples 11200 loss 0.2883517445627313\n",
      "Epoch 9 num_samples 11300 loss 0.39453109758460264\n",
      "Epoch 9 num_samples 11400 loss 0.35266443982523865\n",
      "Epoch 9 num_samples 11500 loss 0.22045393971092872\n",
      "Epoch 9 num_samples 11600 loss 0.2621499315000116\n",
      "Epoch 9 num_samples 11700 loss 0.320734160524487\n",
      "Epoch 9 num_samples 11800 loss 0.20983272805754566\n",
      "Epoch 9 num_samples 11900 loss 0.2436018274221232\n",
      "Epoch 9 num_samples 12000 loss 0.22179535145097337\n",
      "Epoch 9 num_samples 12100 loss 0.23267962561486122\n",
      "Epoch 9 num_samples 12200 loss 0.2957726357853306\n",
      "Epoch 9 num_samples 12300 loss 0.20024326855016875\n",
      "Epoch 9 num_samples 12400 loss 0.29427500021601466\n",
      "Epoch 9 num_samples 12500 loss 0.2789501575739081\n",
      "Epoch 9 num_samples 12600 loss 0.24891317043134414\n",
      "Epoch 9 num_samples 12700 loss 0.2971769652990094\n",
      "Epoch 9 num_samples 12800 loss 0.394803802754343\n",
      "Epoch 9 num_samples 12900 loss 0.21392684470106868\n",
      "Epoch 9 num_samples 13000 loss 0.24118342029458506\n",
      "Epoch 9 num_samples 13100 loss 0.3877786407396196\n",
      "Epoch 9 num_samples 13200 loss 0.22460661218987205\n",
      "Epoch 9 num_samples 13300 loss 0.21160475439564572\n",
      "Epoch 9 num_samples 13400 loss 0.21610028999322686\n",
      "Epoch 9 num_samples 13500 loss 0.22478908352777915\n",
      "Epoch 9 num_samples 13600 loss 0.3066306226755746\n",
      "Epoch 9 num_samples 13700 loss 0.27342858837395895\n",
      "Epoch 9 num_samples 13800 loss 0.22184212085552132\n",
      "Epoch 9 num_samples 13900 loss 0.2292163955916081\n",
      "Epoch 9 num_samples 14000 loss 0.16447895786540037\n",
      "Epoch 9 num_samples 14100 loss 0.25871722519750034\n",
      "Epoch 9 num_samples 14200 loss 0.19281587093209485\n",
      "Epoch 9 num_samples 14300 loss 0.3013697409266109\n",
      "Epoch 9 num_samples 14400 loss 0.3201195203516835\n",
      "Epoch 9 num_samples 14500 loss 0.347941256608637\n",
      "Epoch 9 num_samples 14600 loss 0.28856108151187343\n",
      "Epoch 9 num_samples 14700 loss 0.29086234895864904\n",
      "Epoch 9 num_samples 14800 loss 0.1974083167785059\n",
      "Epoch 9 num_samples 14900 loss 0.3437022526276112\n",
      "Epoch 9 num_samples 15000 loss 0.2040807711854307\n",
      "Epoch 9 num_samples 15100 loss 0.3205620422485792\n",
      "Epoch 9 num_samples 15200 loss 0.31477252209151324\n",
      "Epoch 9 num_samples 15300 loss 0.30894524102225274\n",
      "Epoch 9 num_samples 15400 loss 0.21530073857024884\n",
      "Epoch 9 num_samples 15500 loss 0.2473166004770421\n",
      "Epoch 9 num_samples 15600 loss 0.2918904782287744\n",
      "Epoch 9 num_samples 15700 loss 0.2075974852679355\n",
      "Epoch 9 num_samples 15800 loss 0.3490226740528999\n",
      "Epoch 9 num_samples 15900 loss 0.1782259654006425\n",
      "Epoch 9 num_samples 16000 loss 0.43169228761711986\n",
      "Epoch 9 num_samples 16100 loss 0.25952933125116706\n",
      "Epoch 9 num_samples 16200 loss 0.23137795725426522\n",
      "Epoch 9 num_samples 16300 loss 0.33379153555075797\n",
      "Epoch 9 num_samples 16400 loss 0.2628777070576554\n",
      "Epoch 9 num_samples 16500 loss 0.27975463278711393\n",
      "Epoch 9 num_samples 16600 loss 0.3547950176368698\n",
      "Epoch 9 num_samples 16700 loss 0.20891774287136738\n",
      "Epoch 9 num_samples 16800 loss 0.19508616050981378\n",
      "Epoch 9 num_samples 16900 loss 0.31225124705335977\n",
      "Epoch 9 num_samples 17000 loss 0.19743401388235224\n",
      "Epoch 9 num_samples 17100 loss 0.39770309014543304\n",
      "Epoch 9 num_samples 17200 loss 0.25946329431897086\n",
      "Epoch 9 num_samples 17300 loss 0.2777606394836486\n",
      "Epoch 9 num_samples 17400 loss 0.3543419739580715\n",
      "Epoch 9 num_samples 17500 loss 0.3498722232690479\n",
      "Epoch 9 num_samples 17600 loss 0.30571100446808325\n",
      "Epoch 9 num_samples 17700 loss 0.23438341101249877\n",
      "Epoch 9 num_samples 17800 loss 0.3155928015854437\n",
      "Epoch 9 num_samples 17900 loss 0.29751524962889536\n",
      "Epoch 9 num_samples 18000 loss 0.2026302590942897\n",
      "Epoch 9 num_samples 18100 loss 0.25622646330135007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 num_samples 18200 loss 0.2590756396724217\n",
      "Epoch 9 num_samples 18300 loss 0.26333128694555197\n",
      "Epoch 9 num_samples 18400 loss 0.36619513524562036\n",
      "Epoch 9 num_samples 18500 loss 0.2453696372765605\n",
      "Epoch 10 num_samples 0 loss 0.2674149746899207\n",
      "Epoch 10 num_samples 100 loss 0.27857142626904474\n",
      "Epoch 10 num_samples 200 loss 0.23938619057662508\n",
      "Epoch 10 num_samples 300 loss 0.2751747330483045\n",
      "Epoch 10 num_samples 400 loss 0.20819999819270335\n",
      "Epoch 10 num_samples 500 loss 0.2604337446389115\n",
      "Epoch 10 num_samples 600 loss 0.26825895740129707\n",
      "Epoch 10 num_samples 700 loss 0.3200429831487017\n",
      "Epoch 10 num_samples 800 loss 0.35477574157944247\n",
      "Epoch 10 num_samples 900 loss 0.20438885861546563\n",
      "Epoch 10 num_samples 1000 loss 0.22690109187020233\n",
      "Epoch 10 num_samples 1100 loss 0.3043537692444028\n",
      "Epoch 10 num_samples 1200 loss 0.241444969413998\n",
      "Epoch 10 num_samples 1300 loss 0.19497437189714303\n",
      "Epoch 10 num_samples 1400 loss 0.3285740043763786\n",
      "Epoch 10 num_samples 1500 loss 0.3201247655773754\n",
      "Epoch 10 num_samples 1600 loss 0.25969159139302944\n",
      "Epoch 10 num_samples 1700 loss 0.29731584934919136\n",
      "Epoch 10 num_samples 1800 loss 0.24374422836643228\n",
      "Epoch 10 num_samples 1900 loss 0.2162508181344819\n",
      "Epoch 10 num_samples 2000 loss 0.35455142912961013\n",
      "Epoch 10 num_samples 2100 loss 0.21650683139283886\n",
      "Epoch 10 num_samples 2200 loss 0.1782599791610094\n",
      "Epoch 10 num_samples 2300 loss 0.22353618666722017\n",
      "Epoch 10 num_samples 2400 loss 0.20345895577994522\n",
      "Epoch 10 num_samples 2500 loss 0.3149054777188687\n",
      "Epoch 10 num_samples 2600 loss 0.2983955744205639\n",
      "Epoch 10 num_samples 2700 loss 0.26848859493343386\n",
      "Epoch 10 num_samples 2800 loss 0.276481132481417\n",
      "Epoch 10 num_samples 2900 loss 0.2595948613796064\n",
      "Epoch 10 num_samples 3000 loss 0.21122815881293358\n",
      "Epoch 10 num_samples 3100 loss 0.2274828423187331\n",
      "Epoch 10 num_samples 3200 loss 0.41809179826467274\n",
      "Epoch 10 num_samples 3300 loss 0.20706571107159782\n",
      "Epoch 10 num_samples 3400 loss 0.22897128538846576\n",
      "Epoch 10 num_samples 3500 loss 0.23171083413561613\n",
      "Epoch 10 num_samples 3600 loss 0.16750240960926846\n",
      "Epoch 10 num_samples 3700 loss 0.26314448348378605\n",
      "Epoch 10 num_samples 3800 loss 0.2617411647805928\n",
      "Epoch 10 num_samples 3900 loss 0.31432743548019115\n",
      "Epoch 10 num_samples 4000 loss 0.32884878312045024\n",
      "Epoch 10 num_samples 4100 loss 0.36938590904453944\n",
      "Epoch 10 num_samples 4200 loss 0.23576621938857756\n",
      "Epoch 10 num_samples 4300 loss 0.2843123831539327\n",
      "Epoch 10 num_samples 4400 loss 0.23547303629910488\n",
      "Epoch 10 num_samples 4500 loss 0.33618729231246675\n",
      "Epoch 10 num_samples 4600 loss 0.27373848375957605\n",
      "Epoch 10 num_samples 4700 loss 0.15927956631634463\n",
      "Epoch 10 num_samples 4800 loss 0.18304234517221174\n",
      "Epoch 10 num_samples 4900 loss 0.256477785579679\n",
      "Epoch 10 num_samples 5000 loss 0.25547813791486057\n",
      "Epoch 10 num_samples 5100 loss 0.35608434413278334\n",
      "Epoch 10 num_samples 5200 loss 0.22241149689197912\n",
      "Epoch 10 num_samples 5300 loss 0.263701787692079\n",
      "Epoch 10 num_samples 5400 loss 0.34670448775307244\n",
      "Epoch 10 num_samples 5500 loss 0.21125831035117046\n",
      "Epoch 10 num_samples 5600 loss 0.3103486102982562\n",
      "Epoch 10 num_samples 5700 loss 0.33239281531079784\n",
      "Epoch 10 num_samples 5800 loss 0.33101720486619324\n",
      "Epoch 10 num_samples 5900 loss 0.2745873262338892\n",
      "Epoch 10 num_samples 6000 loss 0.2726417789269549\n",
      "Epoch 10 num_samples 6100 loss 0.17117548667062404\n",
      "Epoch 10 num_samples 6200 loss 0.3013401671829008\n",
      "Epoch 10 num_samples 6300 loss 0.34934898458393493\n",
      "Epoch 10 num_samples 6400 loss 0.22654829051539666\n",
      "Epoch 10 num_samples 6500 loss 0.21184996600578804\n",
      "Epoch 10 num_samples 6600 loss 0.36462281744087766\n",
      "Epoch 10 num_samples 6700 loss 0.18681561039448924\n",
      "Epoch 10 num_samples 6800 loss 0.11545214336679983\n",
      "Epoch 10 num_samples 6900 loss 0.4407742938618011\n",
      "Epoch 10 num_samples 7000 loss 0.3145708669288366\n",
      "Epoch 10 num_samples 7100 loss 0.19537029207962092\n",
      "Epoch 10 num_samples 7200 loss 0.2605679892101739\n",
      "Epoch 10 num_samples 7300 loss 0.27780330055394264\n",
      "Epoch 10 num_samples 7400 loss 0.2130096899333475\n",
      "Epoch 10 num_samples 7500 loss 0.3408170370697691\n",
      "Epoch 10 num_samples 7600 loss 0.29809254417886516\n",
      "Epoch 10 num_samples 7700 loss 0.3573426328944642\n",
      "Epoch 10 num_samples 7800 loss 0.14092100200219865\n",
      "Epoch 10 num_samples 7900 loss 0.27940519078858506\n",
      "Epoch 10 num_samples 8000 loss 0.15208523645232574\n",
      "Epoch 10 num_samples 8100 loss 0.24657104694571444\n",
      "Epoch 10 num_samples 8200 loss 0.20353284248743506\n",
      "Epoch 10 num_samples 8300 loss 0.22647402931220115\n",
      "Epoch 10 num_samples 8400 loss 0.24232473059208062\n",
      "Epoch 10 num_samples 8500 loss 0.2560152421046294\n",
      "Epoch 10 num_samples 8600 loss 0.1696655820012583\n",
      "Epoch 10 num_samples 8700 loss 0.2447708867431851\n",
      "Epoch 10 num_samples 8800 loss 0.29316743801992984\n",
      "Epoch 10 num_samples 8900 loss 0.31202930974073056\n",
      "Epoch 10 num_samples 9000 loss 0.2641564294344994\n",
      "Epoch 10 num_samples 9100 loss 0.26358570895477096\n",
      "Epoch 10 num_samples 9200 loss 0.25158406119115\n",
      "Epoch 10 num_samples 9300 loss 0.28213571279855887\n",
      "Epoch 10 num_samples 9400 loss 0.19721048983683453\n",
      "Epoch 10 num_samples 9500 loss 0.3089366845620168\n",
      "Epoch 10 num_samples 9600 loss 0.19731389179338163\n",
      "Epoch 10 num_samples 9700 loss 0.2993755543367971\n",
      "Epoch 10 num_samples 9800 loss 0.1698006607746197\n",
      "Epoch 10 num_samples 9900 loss 0.39031598454464617\n",
      "Epoch 10 num_samples 10000 loss 0.19410741548266264\n",
      "Epoch 10 num_samples 10100 loss 0.14230493238517838\n",
      "Epoch 10 num_samples 10200 loss 0.31667092773488714\n",
      "Epoch 10 num_samples 10300 loss 0.3057995644115483\n",
      "Epoch 10 num_samples 10400 loss 0.27702895843902986\n",
      "Epoch 10 num_samples 10500 loss 0.23131645550164542\n",
      "Epoch 10 num_samples 10600 loss 0.25968096189061507\n",
      "Epoch 10 num_samples 10700 loss 0.20670059235443883\n",
      "Epoch 10 num_samples 10800 loss 0.30274948981733746\n",
      "Epoch 10 num_samples 10900 loss 0.2552234777614497\n",
      "Epoch 10 num_samples 11000 loss 0.14501696015440424\n",
      "Epoch 10 num_samples 11100 loss 0.34152565701643867\n",
      "Epoch 10 num_samples 11200 loss 0.2578649073583964\n",
      "Epoch 10 num_samples 11300 loss 0.36003449446150865\n",
      "Epoch 10 num_samples 11400 loss 0.3214184950325162\n",
      "Epoch 10 num_samples 11500 loss 0.1907665452315527\n",
      "Epoch 10 num_samples 11600 loss 0.23297061502819838\n",
      "Epoch 10 num_samples 11700 loss 0.29241096833548325\n",
      "Epoch 10 num_samples 11800 loss 0.19387737967149235\n",
      "Epoch 10 num_samples 11900 loss 0.2198642623516157\n",
      "Epoch 10 num_samples 12000 loss 0.1948410841530056\n",
      "Epoch 10 num_samples 12100 loss 0.21130454273215893\n",
      "Epoch 10 num_samples 12200 loss 0.27333130218521434\n",
      "Epoch 10 num_samples 12300 loss 0.175069730667335\n",
      "Epoch 10 num_samples 12400 loss 0.27331776580873846\n",
      "Epoch 10 num_samples 12500 loss 0.25096551277602225\n",
      "Epoch 10 num_samples 12600 loss 0.22849443220885043\n",
      "Epoch 10 num_samples 12700 loss 0.26485607808401324\n",
      "Epoch 10 num_samples 12800 loss 0.36432218190640336\n",
      "Epoch 10 num_samples 12900 loss 0.2025526867578039\n",
      "Epoch 10 num_samples 13000 loss 0.21710093675660658\n",
      "Epoch 10 num_samples 13100 loss 0.35637866990495426\n",
      "Epoch 10 num_samples 13200 loss 0.19772639860947153\n",
      "Epoch 10 num_samples 13300 loss 0.1836303412354161\n",
      "Epoch 10 num_samples 13400 loss 0.18867241701370105\n",
      "Epoch 10 num_samples 13500 loss 0.20450626962936044\n",
      "Epoch 10 num_samples 13600 loss 0.2858256892972638\n",
      "Epoch 10 num_samples 13700 loss 0.2483068123600545\n",
      "Epoch 10 num_samples 13800 loss 0.20211869371127678\n",
      "Epoch 10 num_samples 13900 loss 0.20023497321363543\n",
      "Epoch 10 num_samples 14000 loss 0.1486120829353571\n",
      "Epoch 10 num_samples 14100 loss 0.235342400909933\n",
      "Epoch 10 num_samples 14200 loss 0.17098853153236304\n",
      "Epoch 10 num_samples 14300 loss 0.27428466926009226\n",
      "Epoch 10 num_samples 14400 loss 0.29000258963233366\n",
      "Epoch 10 num_samples 14500 loss 0.31077889115531865\n",
      "Epoch 10 num_samples 14600 loss 0.25311708559234225\n",
      "Epoch 10 num_samples 14700 loss 0.259048843344799\n",
      "Epoch 10 num_samples 14800 loss 0.17907774429278878\n",
      "Epoch 10 num_samples 14900 loss 0.3175405962107006\n",
      "Epoch 10 num_samples 15000 loss 0.1828580778349801\n",
      "Epoch 10 num_samples 15100 loss 0.28462485429325796\n",
      "Epoch 10 num_samples 15200 loss 0.29372522933119866\n",
      "Epoch 10 num_samples 15300 loss 0.27720628608725373\n",
      "Epoch 10 num_samples 15400 loss 0.1954151317804794\n",
      "Epoch 10 num_samples 15500 loss 0.22828569277529107\n",
      "Epoch 10 num_samples 15600 loss 0.2606931657678169\n",
      "Epoch 10 num_samples 15700 loss 0.18381174890051655\n",
      "Epoch 10 num_samples 15800 loss 0.32350931377851944\n",
      "Epoch 10 num_samples 15900 loss 0.15683860368965877\n",
      "Epoch 10 num_samples 16000 loss 0.3962070016940271\n",
      "Epoch 10 num_samples 16100 loss 0.23015008182400223\n",
      "Epoch 10 num_samples 16200 loss 0.21202400331556379\n",
      "Epoch 10 num_samples 16300 loss 0.30812534064383507\n",
      "Epoch 10 num_samples 16400 loss 0.23710094276854618\n",
      "Epoch 10 num_samples 16500 loss 0.2500060633939041\n",
      "Epoch 10 num_samples 16600 loss 0.32161977348481585\n",
      "Epoch 10 num_samples 16700 loss 0.19005749760206092\n",
      "Epoch 10 num_samples 16800 loss 0.17674133113370766\n",
      "Epoch 10 num_samples 16900 loss 0.2829603965512142\n",
      "Epoch 10 num_samples 17000 loss 0.17230305619096364\n",
      "Epoch 10 num_samples 17100 loss 0.3723629599785208\n",
      "Epoch 10 num_samples 17200 loss 0.23958147169582616\n",
      "Epoch 10 num_samples 17300 loss 0.2530246021599396\n",
      "Epoch 10 num_samples 17400 loss 0.3243510115175824\n",
      "Epoch 10 num_samples 17500 loss 0.3166285698034504\n",
      "Epoch 10 num_samples 17600 loss 0.27893660414367755\n",
      "Epoch 10 num_samples 17700 loss 0.20817453773308395\n",
      "Epoch 10 num_samples 17800 loss 0.2870078914015973\n",
      "Epoch 10 num_samples 17900 loss 0.2710606434876865\n",
      "Epoch 10 num_samples 18000 loss 0.17922676321059827\n",
      "Epoch 10 num_samples 18100 loss 0.23300453702415552\n",
      "Epoch 10 num_samples 18200 loss 0.2331249159686466\n",
      "Epoch 10 num_samples 18300 loss 0.23210443949225126\n",
      "Epoch 10 num_samples 18400 loss 0.3311306939591856\n",
      "Epoch 10 num_samples 18500 loss 0.2231043344661707\n",
      "Epoch 11 num_samples 0 loss 0.24037903982537168\n",
      "Epoch 11 num_samples 100 loss 0.2558947850112939\n",
      "Epoch 11 num_samples 200 loss 0.21281707395640267\n",
      "Epoch 11 num_samples 300 loss 0.25027081909527854\n",
      "Epoch 11 num_samples 400 loss 0.18621008642306688\n",
      "Epoch 11 num_samples 500 loss 0.2322445246758317\n",
      "Epoch 11 num_samples 600 loss 0.24658471249252678\n",
      "Epoch 11 num_samples 700 loss 0.30235754325989217\n",
      "Epoch 11 num_samples 800 loss 0.32258449698584896\n",
      "Epoch 11 num_samples 900 loss 0.18612873855815493\n",
      "Epoch 11 num_samples 1000 loss 0.20709537318395388\n",
      "Epoch 11 num_samples 1100 loss 0.2747079907688614\n",
      "Epoch 11 num_samples 1200 loss 0.22396227158926008\n",
      "Epoch 11 num_samples 1300 loss 0.17134364281713865\n",
      "Epoch 11 num_samples 1400 loss 0.2943504884523734\n",
      "Epoch 11 num_samples 1500 loss 0.3027957860325465\n",
      "Epoch 11 num_samples 1600 loss 0.23155919502374417\n",
      "Epoch 11 num_samples 1700 loss 0.26420957021390185\n",
      "Epoch 11 num_samples 1800 loss 0.2214701121254649\n",
      "Epoch 11 num_samples 1900 loss 0.1970091855253732\n",
      "Epoch 11 num_samples 2000 loss 0.324657066704376\n",
      "Epoch 11 num_samples 2100 loss 0.19494282004226704\n",
      "Epoch 11 num_samples 2200 loss 0.16142284928725043\n",
      "Epoch 11 num_samples 2300 loss 0.2004307800782367\n",
      "Epoch 11 num_samples 2400 loss 0.18252479478790223\n",
      "Epoch 11 num_samples 2500 loss 0.2911284687814988\n",
      "Epoch 11 num_samples 2600 loss 0.268329536103199\n",
      "Epoch 11 num_samples 2700 loss 0.2501731650391882\n",
      "Epoch 11 num_samples 2800 loss 0.25352350115616346\n",
      "Epoch 11 num_samples 2900 loss 0.2405425017219972\n",
      "Epoch 11 num_samples 3000 loss 0.19193490312148792\n",
      "Epoch 11 num_samples 3100 loss 0.2120925033718208\n",
      "Epoch 11 num_samples 3200 loss 0.3861769101427521\n",
      "Epoch 11 num_samples 3300 loss 0.18529993291986885\n",
      "Epoch 11 num_samples 3400 loss 0.2074547130920016\n",
      "Epoch 11 num_samples 3500 loss 0.2096084422976144\n",
      "Epoch 11 num_samples 3600 loss 0.15029210552056985\n",
      "Epoch 11 num_samples 3700 loss 0.24317183687784025\n",
      "Epoch 11 num_samples 3800 loss 0.2411512219122781\n",
      "Epoch 11 num_samples 3900 loss 0.28418414271215797\n",
      "Epoch 11 num_samples 4000 loss 0.2948681142334579\n",
      "Epoch 11 num_samples 4100 loss 0.34343101731328746\n",
      "Epoch 11 num_samples 4200 loss 0.21561946007728544\n",
      "Epoch 11 num_samples 4300 loss 0.2603077097313666\n",
      "Epoch 11 num_samples 4400 loss 0.21755952772284048\n",
      "Epoch 11 num_samples 4500 loss 0.30762806322691366\n",
      "Epoch 11 num_samples 4600 loss 0.2531385978005606\n",
      "Epoch 11 num_samples 4700 loss 0.14127263014479627\n",
      "Epoch 11 num_samples 4800 loss 0.16195274403181942\n",
      "Epoch 11 num_samples 4900 loss 0.2254407836175344\n",
      "Epoch 11 num_samples 5000 loss 0.22694244602340008\n",
      "Epoch 11 num_samples 5100 loss 0.32707100360379615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 num_samples 5200 loss 0.1954925793906975\n",
      "Epoch 11 num_samples 5300 loss 0.24040365077961645\n",
      "Epoch 11 num_samples 5400 loss 0.315397559269142\n",
      "Epoch 11 num_samples 5500 loss 0.18918370560056885\n",
      "Epoch 11 num_samples 5600 loss 0.2936520880558335\n",
      "Epoch 11 num_samples 5700 loss 0.30227563660066226\n",
      "Epoch 11 num_samples 5800 loss 0.3063682559748155\n",
      "Epoch 11 num_samples 5900 loss 0.2532080193680126\n",
      "Epoch 11 num_samples 6000 loss 0.2497846447150643\n",
      "Epoch 11 num_samples 6100 loss 0.15689727383563062\n",
      "Epoch 11 num_samples 6200 loss 0.2682850249951682\n",
      "Epoch 11 num_samples 6300 loss 0.3079719136244121\n",
      "Epoch 11 num_samples 6400 loss 0.20185025994587222\n",
      "Epoch 11 num_samples 6500 loss 0.18549563620289544\n",
      "Epoch 11 num_samples 6600 loss 0.3388023365521702\n",
      "Epoch 11 num_samples 6700 loss 0.16537399839487615\n",
      "Epoch 11 num_samples 6800 loss 0.1023186725798637\n",
      "Epoch 11 num_samples 6900 loss 0.4070121412651032\n",
      "Epoch 11 num_samples 7000 loss 0.2969146966689026\n",
      "Epoch 11 num_samples 7100 loss 0.17665195609908943\n",
      "Epoch 11 num_samples 7200 loss 0.23506085560890191\n",
      "Epoch 11 num_samples 7300 loss 0.2528229859349201\n",
      "Epoch 11 num_samples 7400 loss 0.19034785678891863\n",
      "Epoch 11 num_samples 7500 loss 0.3183986142067477\n",
      "Epoch 11 num_samples 7600 loss 0.26840205393387584\n",
      "Epoch 11 num_samples 7700 loss 0.3289502870146625\n",
      "Epoch 11 num_samples 7800 loss 0.12803475637140832\n",
      "Epoch 11 num_samples 7900 loss 0.24921519149804783\n",
      "Epoch 11 num_samples 8000 loss 0.14176489088364733\n",
      "Epoch 11 num_samples 8100 loss 0.22089744581036413\n",
      "Epoch 11 num_samples 8200 loss 0.18382970829998801\n",
      "Epoch 11 num_samples 8300 loss 0.20768811272179882\n",
      "Epoch 11 num_samples 8400 loss 0.2179162481780892\n",
      "Epoch 11 num_samples 8500 loss 0.23595969773345893\n",
      "Epoch 11 num_samples 8600 loss 0.15521520574247955\n",
      "Epoch 11 num_samples 8700 loss 0.21964264135040465\n",
      "Epoch 11 num_samples 8800 loss 0.2725750030928939\n",
      "Epoch 11 num_samples 8900 loss 0.28571291718502645\n",
      "Epoch 11 num_samples 9000 loss 0.23635206438451312\n",
      "Epoch 11 num_samples 9100 loss 0.23066168147923324\n",
      "Epoch 11 num_samples 9200 loss 0.22747429174090272\n",
      "Epoch 11 num_samples 9300 loss 0.2526207572882826\n",
      "Epoch 11 num_samples 9400 loss 0.17964921587506474\n",
      "Epoch 11 num_samples 9500 loss 0.280077116792287\n",
      "Epoch 11 num_samples 9600 loss 0.17489348957187587\n",
      "Epoch 11 num_samples 9700 loss 0.2699319611771628\n",
      "Epoch 11 num_samples 9800 loss 0.15301995646117844\n",
      "Epoch 11 num_samples 9900 loss 0.3591049351110937\n",
      "Epoch 11 num_samples 10000 loss 0.17728221049298284\n",
      "Epoch 11 num_samples 10100 loss 0.12815104265196034\n",
      "Epoch 11 num_samples 10200 loss 0.29229705459378147\n",
      "Epoch 11 num_samples 10300 loss 0.2771214143014094\n",
      "Epoch 11 num_samples 10400 loss 0.25160903788203626\n",
      "Epoch 11 num_samples 10500 loss 0.20649806160007933\n",
      "Epoch 11 num_samples 10600 loss 0.2419653382767433\n",
      "Epoch 11 num_samples 10700 loss 0.18503775626573685\n",
      "Epoch 11 num_samples 10800 loss 0.28184996192382095\n",
      "Epoch 11 num_samples 10900 loss 0.22511240888863412\n",
      "Epoch 11 num_samples 11000 loss 0.1269725832590391\n",
      "Epoch 11 num_samples 11100 loss 0.3038931627855487\n",
      "Epoch 11 num_samples 11200 loss 0.23229442087157737\n",
      "Epoch 11 num_samples 11300 loss 0.32986819121947747\n",
      "Epoch 11 num_samples 11400 loss 0.29170118215558316\n",
      "Epoch 11 num_samples 11500 loss 0.16777127517687596\n",
      "Epoch 11 num_samples 11600 loss 0.20719600205371547\n",
      "Epoch 11 num_samples 11700 loss 0.2650974594581602\n",
      "Epoch 11 num_samples 11800 loss 0.17785950993566554\n",
      "Epoch 11 num_samples 11900 loss 0.19914057031184165\n",
      "Epoch 11 num_samples 12000 loss 0.16899013995923368\n",
      "Epoch 11 num_samples 12100 loss 0.19272494194045697\n",
      "Epoch 11 num_samples 12200 loss 0.252813482918315\n",
      "Epoch 11 num_samples 12300 loss 0.15552007134014123\n",
      "Epoch 11 num_samples 12400 loss 0.25097208120337056\n",
      "Epoch 11 num_samples 12500 loss 0.22907429868448653\n",
      "Epoch 11 num_samples 12600 loss 0.21222598659446235\n",
      "Epoch 11 num_samples 12700 loss 0.23980424786045937\n",
      "Epoch 11 num_samples 12800 loss 0.3343270997972904\n",
      "Epoch 11 num_samples 12900 loss 0.19140043809729973\n",
      "Epoch 11 num_samples 13000 loss 0.1978749929476193\n",
      "Epoch 11 num_samples 13100 loss 0.3306268869083064\n",
      "Epoch 11 num_samples 13200 loss 0.17886231451717108\n",
      "Epoch 11 num_samples 13300 loss 0.16379197642386203\n",
      "Epoch 11 num_samples 13400 loss 0.16439750957932417\n",
      "Epoch 11 num_samples 13500 loss 0.18817117492532517\n",
      "Epoch 11 num_samples 13600 loss 0.2657333275891362\n",
      "Epoch 11 num_samples 13700 loss 0.22735852003912782\n",
      "Epoch 11 num_samples 13800 loss 0.18336782285889597\n",
      "Epoch 11 num_samples 13900 loss 0.17401622332921068\n",
      "Epoch 11 num_samples 14000 loss 0.1342106170002234\n",
      "Epoch 11 num_samples 14100 loss 0.2107756432478648\n",
      "Epoch 11 num_samples 14200 loss 0.15087863113150088\n",
      "Epoch 11 num_samples 14300 loss 0.2531673111064461\n",
      "Epoch 11 num_samples 14400 loss 0.25965658759880134\n",
      "Epoch 11 num_samples 14500 loss 0.2790145136947495\n",
      "Epoch 11 num_samples 14600 loss 0.22343418563630102\n",
      "Epoch 11 num_samples 14700 loss 0.2300771346840487\n",
      "Epoch 11 num_samples 14800 loss 0.1595422570086807\n",
      "Epoch 11 num_samples 14900 loss 0.2905878199554866\n",
      "Epoch 11 num_samples 15000 loss 0.16368924831202925\n",
      "Epoch 11 num_samples 15100 loss 0.25468634467917517\n",
      "Epoch 11 num_samples 15200 loss 0.27714637706853384\n",
      "Epoch 11 num_samples 15300 loss 0.2466760967754361\n",
      "Epoch 11 num_samples 15400 loss 0.17780337316696485\n",
      "Epoch 11 num_samples 15500 loss 0.21454022626157163\n",
      "Epoch 11 num_samples 15600 loss 0.234556767628399\n",
      "Epoch 11 num_samples 15700 loss 0.16357304052312027\n",
      "Epoch 11 num_samples 15800 loss 0.30205796527158935\n",
      "Epoch 11 num_samples 15900 loss 0.13938781969996697\n",
      "Epoch 11 num_samples 16000 loss 0.36340327409950746\n",
      "Epoch 11 num_samples 16100 loss 0.2032164502579781\n",
      "Epoch 11 num_samples 16200 loss 0.19748114154733906\n",
      "Epoch 11 num_samples 16300 loss 0.28364099198954007\n",
      "Epoch 11 num_samples 16400 loss 0.2152888710123904\n",
      "Epoch 11 num_samples 16500 loss 0.22556259526168979\n",
      "Epoch 11 num_samples 16600 loss 0.29407277383613384\n",
      "Epoch 11 num_samples 16700 loss 0.17325012747978838\n",
      "Epoch 11 num_samples 16800 loss 0.16195930881492854\n",
      "Epoch 11 num_samples 16900 loss 0.25303633570430806\n",
      "Epoch 11 num_samples 17000 loss 0.15452743955687637\n",
      "Epoch 11 num_samples 17100 loss 0.349575962078627\n",
      "Epoch 11 num_samples 17200 loss 0.22040358212800396\n",
      "Epoch 11 num_samples 17300 loss 0.23816593792688118\n",
      "Epoch 11 num_samples 17400 loss 0.29970262928991437\n",
      "Epoch 11 num_samples 17500 loss 0.2893353276060816\n",
      "Epoch 11 num_samples 17600 loss 0.2562458607045908\n",
      "Epoch 11 num_samples 17700 loss 0.18382028286729324\n",
      "Epoch 11 num_samples 17800 loss 0.2625469596848575\n",
      "Epoch 11 num_samples 17900 loss 0.2502417431698705\n",
      "Epoch 11 num_samples 18000 loss 0.15948339982006338\n",
      "Epoch 11 num_samples 18100 loss 0.21382707572234602\n",
      "Epoch 11 num_samples 18200 loss 0.21265270215022866\n",
      "Epoch 11 num_samples 18300 loss 0.20724756006553477\n",
      "Epoch 11 num_samples 18400 loss 0.30298344596000576\n",
      "Epoch 11 num_samples 18500 loss 0.20160771907442707\n",
      "Epoch 12 num_samples 0 loss 0.21412831505353416\n",
      "Epoch 12 num_samples 100 loss 0.2364184078100565\n",
      "Epoch 12 num_samples 200 loss 0.19115930349627303\n",
      "Epoch 12 num_samples 300 loss 0.22233627069636433\n",
      "Epoch 12 num_samples 400 loss 0.1668503380020715\n",
      "Epoch 12 num_samples 500 loss 0.20654857806552393\n",
      "Epoch 12 num_samples 600 loss 0.22935028363917268\n",
      "Epoch 12 num_samples 700 loss 0.2875886375080368\n",
      "Epoch 12 num_samples 800 loss 0.2928702904696781\n",
      "Epoch 12 num_samples 900 loss 0.1737155098037858\n",
      "Epoch 12 num_samples 1000 loss 0.18928446817585326\n",
      "Epoch 12 num_samples 1100 loss 0.250242018096712\n",
      "Epoch 12 num_samples 1200 loss 0.20731774979122541\n",
      "Epoch 12 num_samples 1300 loss 0.1532991703998715\n",
      "Epoch 12 num_samples 1400 loss 0.26503052065813726\n",
      "Epoch 12 num_samples 1500 loss 0.28936220061276097\n",
      "Epoch 12 num_samples 1600 loss 0.2086055635978267\n",
      "Epoch 12 num_samples 1700 loss 0.23540031032344275\n",
      "Epoch 12 num_samples 1800 loss 0.19884045376974996\n",
      "Epoch 12 num_samples 1900 loss 0.18022146013781432\n",
      "Epoch 12 num_samples 2000 loss 0.30102926852159706\n",
      "Epoch 12 num_samples 2100 loss 0.17894196769442874\n",
      "Epoch 12 num_samples 2200 loss 0.14652779742237768\n",
      "Epoch 12 num_samples 2300 loss 0.1836315590475716\n",
      "Epoch 12 num_samples 2400 loss 0.16565615010550414\n",
      "Epoch 12 num_samples 2500 loss 0.26899820456672013\n",
      "Epoch 12 num_samples 2600 loss 0.24242515968191597\n",
      "Epoch 12 num_samples 2700 loss 0.23277481176598191\n",
      "Epoch 12 num_samples 2800 loss 0.2352693304003979\n",
      "Epoch 12 num_samples 2900 loss 0.22089431772515694\n",
      "Epoch 12 num_samples 3000 loss 0.17545142417072424\n",
      "Epoch 12 num_samples 3100 loss 0.1981337851095403\n",
      "Epoch 12 num_samples 3200 loss 0.35988286200353853\n",
      "Epoch 12 num_samples 3300 loss 0.1685098704384927\n",
      "Epoch 12 num_samples 3400 loss 0.18808159199069427\n",
      "Epoch 12 num_samples 3500 loss 0.18995165811910936\n",
      "Epoch 12 num_samples 3600 loss 0.1342445458020476\n",
      "Epoch 12 num_samples 3700 loss 0.22489068562563305\n",
      "Epoch 12 num_samples 3800 loss 0.22023728832337547\n",
      "Epoch 12 num_samples 3900 loss 0.2601214270543329\n",
      "Epoch 12 num_samples 4000 loss 0.2667715845274655\n",
      "Epoch 12 num_samples 4100 loss 0.3199317968272535\n",
      "Epoch 12 num_samples 4200 loss 0.19874807946920037\n",
      "Epoch 12 num_samples 4300 loss 0.2351049048727153\n",
      "Epoch 12 num_samples 4400 loss 0.20051644678080244\n",
      "Epoch 12 num_samples 4500 loss 0.2842179492394431\n",
      "Epoch 12 num_samples 4600 loss 0.2337918635989823\n",
      "Epoch 12 num_samples 4700 loss 0.1242720590534722\n",
      "Epoch 12 num_samples 4800 loss 0.14781906361140418\n",
      "Epoch 12 num_samples 4900 loss 0.19749492307395738\n",
      "Epoch 12 num_samples 5000 loss 0.20270288553105534\n",
      "Epoch 12 num_samples 5100 loss 0.30029081954799675\n",
      "Epoch 12 num_samples 5200 loss 0.16943402094503968\n",
      "Epoch 12 num_samples 5300 loss 0.21884562524952042\n",
      "Epoch 12 num_samples 5400 loss 0.28474693150317965\n",
      "Epoch 12 num_samples 5500 loss 0.1710138473722793\n",
      "Epoch 12 num_samples 5600 loss 0.2783961639314495\n",
      "Epoch 12 num_samples 5700 loss 0.27756702507369296\n",
      "Epoch 12 num_samples 5800 loss 0.2815194813739667\n",
      "Epoch 12 num_samples 5900 loss 0.23661815919522403\n",
      "Epoch 12 num_samples 6000 loss 0.22685309570883852\n",
      "Epoch 12 num_samples 6100 loss 0.14580031926359127\n",
      "Epoch 12 num_samples 6200 loss 0.2409535358439218\n",
      "Epoch 12 num_samples 6300 loss 0.2759229187159362\n",
      "Epoch 12 num_samples 6400 loss 0.18246364127206996\n",
      "Epoch 12 num_samples 6500 loss 0.1645496256798955\n",
      "Epoch 12 num_samples 6600 loss 0.31229832644930716\n",
      "Epoch 12 num_samples 6700 loss 0.14356593086336628\n",
      "Epoch 12 num_samples 6800 loss 0.0914656641040545\n",
      "Epoch 12 num_samples 6900 loss 0.3771164487151145\n",
      "Epoch 12 num_samples 7000 loss 0.27963129508816115\n",
      "Epoch 12 num_samples 7100 loss 0.16292867470462355\n",
      "Epoch 12 num_samples 7200 loss 0.2104334407515487\n",
      "Epoch 12 num_samples 7300 loss 0.22861221346015487\n",
      "Epoch 12 num_samples 7400 loss 0.17386455133330408\n",
      "Epoch 12 num_samples 7500 loss 0.2981703851608841\n",
      "Epoch 12 num_samples 7600 loss 0.2373957291249752\n",
      "Epoch 12 num_samples 7700 loss 0.30286184607460437\n",
      "Epoch 12 num_samples 7800 loss 0.11678641434762631\n",
      "Epoch 12 num_samples 7900 loss 0.2296050849544364\n",
      "Epoch 12 num_samples 8000 loss 0.13164479506817794\n",
      "Epoch 12 num_samples 8100 loss 0.20028140600660302\n",
      "Epoch 12 num_samples 8200 loss 0.16823672525623132\n",
      "Epoch 12 num_samples 8300 loss 0.19286129622480253\n",
      "Epoch 12 num_samples 8400 loss 0.1970091769991112\n",
      "Epoch 12 num_samples 8500 loss 0.2201796076078641\n",
      "Epoch 12 num_samples 8600 loss 0.14347163444213962\n",
      "Epoch 12 num_samples 8700 loss 0.20126956542154353\n",
      "Epoch 12 num_samples 8800 loss 0.2521799648239159\n",
      "Epoch 12 num_samples 8900 loss 0.2589140844677375\n",
      "Epoch 12 num_samples 9000 loss 0.21305544266493848\n",
      "Epoch 12 num_samples 9100 loss 0.20404251332059473\n",
      "Epoch 12 num_samples 9200 loss 0.20612892962458715\n",
      "Epoch 12 num_samples 9300 loss 0.2262250964258039\n",
      "Epoch 12 num_samples 9400 loss 0.1636022218686775\n",
      "Epoch 12 num_samples 9500 loss 0.25366272685060953\n",
      "Epoch 12 num_samples 9600 loss 0.15753065709870004\n",
      "Epoch 12 num_samples 9700 loss 0.24698725916794004\n",
      "Epoch 12 num_samples 9800 loss 0.13679535157770117\n",
      "Epoch 12 num_samples 9900 loss 0.3296841652697816\n",
      "Epoch 12 num_samples 10000 loss 0.16312071072596587\n",
      "Epoch 12 num_samples 10100 loss 0.11752293574134054\n",
      "Epoch 12 num_samples 10200 loss 0.2714266467943046\n",
      "Epoch 12 num_samples 10300 loss 0.24935811906088418\n",
      "Epoch 12 num_samples 10400 loss 0.23089287067544098\n",
      "Epoch 12 num_samples 10500 loss 0.1845818019148126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 num_samples 10600 loss 0.22544058854586274\n",
      "Epoch 12 num_samples 10700 loss 0.17061732311168723\n",
      "Epoch 12 num_samples 10800 loss 0.2635987385778274\n",
      "Epoch 12 num_samples 10900 loss 0.2006845300126203\n",
      "Epoch 12 num_samples 11000 loss 0.11215218671044401\n",
      "Epoch 12 num_samples 11100 loss 0.2645881517725164\n",
      "Epoch 12 num_samples 11200 loss 0.20728969511404585\n",
      "Epoch 12 num_samples 11300 loss 0.30513027287932226\n",
      "Epoch 12 num_samples 11400 loss 0.26613712762617664\n",
      "Epoch 12 num_samples 11500 loss 0.14882351468373634\n",
      "Epoch 12 num_samples 11600 loss 0.18455757036107934\n",
      "Epoch 12 num_samples 11700 loss 0.23996735662686425\n",
      "Epoch 12 num_samples 11800 loss 0.16137845662289024\n",
      "Epoch 12 num_samples 11900 loss 0.18403105448721768\n",
      "Epoch 12 num_samples 12000 loss 0.1468898579635096\n",
      "Epoch 12 num_samples 12100 loss 0.17762888406656036\n",
      "Epoch 12 num_samples 12200 loss 0.23757551972021818\n",
      "Epoch 12 num_samples 12300 loss 0.1400863871141865\n",
      "Epoch 12 num_samples 12400 loss 0.2303262011697584\n",
      "Epoch 12 num_samples 12500 loss 0.21056990854083135\n",
      "Epoch 12 num_samples 12600 loss 0.19835328743296457\n",
      "Epoch 12 num_samples 12700 loss 0.21964569620277252\n",
      "Epoch 12 num_samples 12800 loss 0.30854653103822544\n",
      "Epoch 12 num_samples 12900 loss 0.17809346666831352\n",
      "Epoch 12 num_samples 13000 loss 0.17810846994029114\n",
      "Epoch 12 num_samples 13100 loss 0.3061839721965306\n",
      "Epoch 12 num_samples 13200 loss 0.16123696748511038\n",
      "Epoch 12 num_samples 13300 loss 0.1464335716565359\n",
      "Epoch 12 num_samples 13400 loss 0.14369866999475747\n",
      "Epoch 12 num_samples 13500 loss 0.17096840556968318\n",
      "Epoch 12 num_samples 13600 loss 0.24839167026992467\n",
      "Epoch 12 num_samples 13700 loss 0.20724433181667376\n",
      "Epoch 12 num_samples 13800 loss 0.17039903636016132\n",
      "Epoch 12 num_samples 13900 loss 0.1518518555982717\n",
      "Epoch 12 num_samples 14000 loss 0.12419173609542304\n",
      "Epoch 12 num_samples 14100 loss 0.19066659925700447\n",
      "Epoch 12 num_samples 14200 loss 0.13488953693190223\n",
      "Epoch 12 num_samples 14300 loss 0.23087055120781028\n",
      "Epoch 12 num_samples 14400 loss 0.23331156229316466\n",
      "Epoch 12 num_samples 14500 loss 0.25150256280669714\n",
      "Epoch 12 num_samples 14600 loss 0.1969463952384366\n",
      "Epoch 12 num_samples 14700 loss 0.20650239850460178\n",
      "Epoch 12 num_samples 14800 loss 0.14528338639924107\n",
      "Epoch 12 num_samples 14900 loss 0.2696821827636665\n",
      "Epoch 12 num_samples 15000 loss 0.14781894556739242\n",
      "Epoch 12 num_samples 15100 loss 0.2311383270505199\n",
      "Epoch 12 num_samples 15200 loss 0.2603239401635847\n",
      "Epoch 12 num_samples 15300 loss 0.2235027804744065\n",
      "Epoch 12 num_samples 15400 loss 0.15971252109241627\n",
      "Epoch 12 num_samples 15500 loss 0.19882009983094875\n",
      "Epoch 12 num_samples 15600 loss 0.2116051288356066\n",
      "Epoch 12 num_samples 15700 loss 0.14616322928704467\n",
      "Epoch 12 num_samples 15800 loss 0.2822247915553233\n",
      "Epoch 12 num_samples 15900 loss 0.12450989048722785\n",
      "Epoch 12 num_samples 16000 loss 0.3312291325319816\n",
      "Epoch 12 num_samples 16100 loss 0.18069394680329864\n",
      "Epoch 12 num_samples 16200 loss 0.18336806584433415\n",
      "Epoch 12 num_samples 16300 loss 0.25990709125082795\n",
      "Epoch 12 num_samples 16400 loss 0.19596028560229775\n",
      "Epoch 12 num_samples 16500 loss 0.20686636592321997\n",
      "Epoch 12 num_samples 16600 loss 0.2666308171995859\n",
      "Epoch 12 num_samples 16700 loss 0.1595566122341749\n",
      "Epoch 12 num_samples 16800 loss 0.14816075679920154\n",
      "Epoch 12 num_samples 16900 loss 0.2231137376143274\n",
      "Epoch 12 num_samples 17000 loss 0.1375726389830634\n",
      "Epoch 12 num_samples 17100 loss 0.3276879782607591\n",
      "Epoch 12 num_samples 17200 loss 0.2036249929039345\n",
      "Epoch 12 num_samples 17300 loss 0.2236209213676917\n",
      "Epoch 12 num_samples 17400 loss 0.2731241528174919\n",
      "Epoch 12 num_samples 17500 loss 0.2621979446723651\n",
      "Epoch 12 num_samples 17600 loss 0.23432582391757037\n",
      "Epoch 12 num_samples 17700 loss 0.16317621585655526\n",
      "Epoch 12 num_samples 17800 loss 0.24221509547897052\n",
      "Epoch 12 num_samples 17900 loss 0.2331881862800482\n",
      "Epoch 12 num_samples 18000 loss 0.14128495206490777\n",
      "Epoch 12 num_samples 18100 loss 0.19412030144384126\n",
      "Epoch 12 num_samples 18200 loss 0.1970363255993389\n",
      "Epoch 12 num_samples 18300 loss 0.18411473515322074\n",
      "Epoch 12 num_samples 18400 loss 0.28007610770825286\n",
      "Epoch 12 num_samples 18500 loss 0.1830566854907472\n",
      "Epoch 13 num_samples 0 loss 0.19449469874503592\n",
      "Epoch 13 num_samples 100 loss 0.2168975025465617\n",
      "Epoch 13 num_samples 200 loss 0.17496528891670976\n",
      "Epoch 13 num_samples 300 loss 0.1980583640181424\n",
      "Epoch 13 num_samples 400 loss 0.15067444913355885\n",
      "Epoch 13 num_samples 500 loss 0.18497011337467428\n",
      "Epoch 13 num_samples 600 loss 0.2130336342195817\n",
      "Epoch 13 num_samples 700 loss 0.2701177871776394\n",
      "Epoch 13 num_samples 800 loss 0.2668631928659777\n",
      "Epoch 13 num_samples 900 loss 0.15958076558871626\n",
      "Epoch 13 num_samples 1000 loss 0.1726644124823212\n",
      "Epoch 13 num_samples 1100 loss 0.22884813869609424\n",
      "Epoch 13 num_samples 1200 loss 0.19157536436089714\n",
      "Epoch 13 num_samples 1300 loss 0.13896063271613815\n",
      "Epoch 13 num_samples 1400 loss 0.2404866851508252\n",
      "Epoch 13 num_samples 1500 loss 0.2760021488048074\n",
      "Epoch 13 num_samples 1600 loss 0.18896388664481312\n",
      "Epoch 13 num_samples 1700 loss 0.21285875946310123\n",
      "Epoch 13 num_samples 1800 loss 0.17814623245245464\n",
      "Epoch 13 num_samples 1900 loss 0.16523737295997606\n",
      "Epoch 13 num_samples 2000 loss 0.277178158045537\n",
      "Epoch 13 num_samples 2100 loss 0.1639461512935849\n",
      "Epoch 13 num_samples 2200 loss 0.1325563478291186\n",
      "Epoch 13 num_samples 2300 loss 0.16730458365585377\n",
      "Epoch 13 num_samples 2400 loss 0.1532998493938953\n",
      "Epoch 13 num_samples 2500 loss 0.24837794766739107\n",
      "Epoch 13 num_samples 2600 loss 0.2239301509932626\n",
      "Epoch 13 num_samples 2700 loss 0.21877507813386982\n",
      "Epoch 13 num_samples 2800 loss 0.21991210591881669\n",
      "Epoch 13 num_samples 2900 loss 0.20437998551284145\n",
      "Epoch 13 num_samples 3000 loss 0.16020373481921055\n",
      "Epoch 13 num_samples 3100 loss 0.18398656228551416\n",
      "Epoch 13 num_samples 3200 loss 0.3379973325593276\n",
      "Epoch 13 num_samples 3300 loss 0.15380725479477686\n",
      "Epoch 13 num_samples 3400 loss 0.16798280455782624\n",
      "Epoch 13 num_samples 3500 loss 0.17419462295740637\n",
      "Epoch 13 num_samples 3600 loss 0.11997378603882329\n",
      "Epoch 13 num_samples 3700 loss 0.20925205652010867\n",
      "Epoch 13 num_samples 3800 loss 0.20397348759360936\n",
      "Epoch 13 num_samples 3900 loss 0.23603913337124177\n",
      "Epoch 13 num_samples 4000 loss 0.23814861033900223\n",
      "Epoch 13 num_samples 4100 loss 0.30016914944235085\n",
      "Epoch 13 num_samples 4200 loss 0.18328016192611207\n",
      "Epoch 13 num_samples 4300 loss 0.21514715157602857\n",
      "Epoch 13 num_samples 4400 loss 0.18529022953090224\n",
      "Epoch 13 num_samples 4500 loss 0.2594746501378104\n",
      "Epoch 13 num_samples 4600 loss 0.21478322750943885\n",
      "Epoch 13 num_samples 4700 loss 0.11071755704541243\n",
      "Epoch 13 num_samples 4800 loss 0.13315648877379982\n",
      "Epoch 13 num_samples 4900 loss 0.17336231347479272\n",
      "Epoch 13 num_samples 5000 loss 0.1803220852801009\n",
      "Epoch 13 num_samples 5100 loss 0.27381784772083634\n",
      "Epoch 13 num_samples 5200 loss 0.1486225212712562\n",
      "Epoch 13 num_samples 5300 loss 0.19914123299198327\n",
      "Epoch 13 num_samples 5400 loss 0.26036290537851525\n",
      "Epoch 13 num_samples 5500 loss 0.1550755553418148\n",
      "Epoch 13 num_samples 5600 loss 0.2640965750927043\n",
      "Epoch 13 num_samples 5700 loss 0.2534546721150238\n",
      "Epoch 13 num_samples 5800 loss 0.2597780950535724\n",
      "Epoch 13 num_samples 5900 loss 0.22160324952289567\n",
      "Epoch 13 num_samples 6000 loss 0.2114212978941589\n",
      "Epoch 13 num_samples 6100 loss 0.13428615210553116\n",
      "Epoch 13 num_samples 6200 loss 0.21899752762835853\n",
      "Epoch 13 num_samples 6300 loss 0.2464090653010032\n",
      "Epoch 13 num_samples 6400 loss 0.16530519435033222\n",
      "Epoch 13 num_samples 6500 loss 0.14636265092427803\n",
      "Epoch 13 num_samples 6600 loss 0.28642118804566324\n",
      "Epoch 13 num_samples 6700 loss 0.126595476957343\n",
      "Epoch 13 num_samples 6800 loss 0.08215845459804065\n",
      "Epoch 13 num_samples 6900 loss 0.34892841868954205\n",
      "Epoch 13 num_samples 7000 loss 0.2611480582882612\n",
      "Epoch 13 num_samples 7100 loss 0.15053934295001084\n",
      "Epoch 13 num_samples 7200 loss 0.18698437655722785\n",
      "Epoch 13 num_samples 7300 loss 0.20661882591794992\n",
      "Epoch 13 num_samples 7400 loss 0.15792090654847304\n",
      "Epoch 13 num_samples 7500 loss 0.275762623652076\n",
      "Epoch 13 num_samples 7600 loss 0.2113076703449277\n",
      "Epoch 13 num_samples 7700 loss 0.279384160887815\n",
      "Epoch 13 num_samples 7800 loss 0.10742609309831319\n",
      "Epoch 13 num_samples 7900 loss 0.21073629551740333\n",
      "Epoch 13 num_samples 8000 loss 0.12067045147809137\n",
      "Epoch 13 num_samples 8100 loss 0.1774138786219641\n",
      "Epoch 13 num_samples 8200 loss 0.15649065548429303\n",
      "Epoch 13 num_samples 8300 loss 0.18090893063750602\n",
      "Epoch 13 num_samples 8400 loss 0.17953065942973173\n",
      "Epoch 13 num_samples 8500 loss 0.2046725617648277\n",
      "Epoch 13 num_samples 8600 loss 0.1325173726159947\n",
      "Epoch 13 num_samples 8700 loss 0.18094388731098307\n",
      "Epoch 13 num_samples 8800 loss 0.237691850992994\n",
      "Epoch 13 num_samples 8900 loss 0.23442582496291442\n",
      "Epoch 13 num_samples 9000 loss 0.1929672614776046\n",
      "Epoch 13 num_samples 9100 loss 0.1854410607726146\n",
      "Epoch 13 num_samples 9200 loss 0.18462877403961941\n",
      "Epoch 13 num_samples 9300 loss 0.20511005677791175\n",
      "Epoch 13 num_samples 9400 loss 0.14740069296466335\n",
      "Epoch 13 num_samples 9500 loss 0.22943824348003555\n",
      "Epoch 13 num_samples 9600 loss 0.14123257697546804\n",
      "Epoch 13 num_samples 9700 loss 0.22571321749128567\n",
      "Epoch 13 num_samples 9800 loss 0.12342751461151458\n",
      "Epoch 13 num_samples 9900 loss 0.3023605568173916\n",
      "Epoch 13 num_samples 10000 loss 0.15225919392331833\n",
      "Epoch 13 num_samples 10100 loss 0.10727682529733086\n",
      "Epoch 13 num_samples 10200 loss 0.254099127433342\n",
      "Epoch 13 num_samples 10300 loss 0.22384640217741136\n",
      "Epoch 13 num_samples 10400 loss 0.21186679110576243\n",
      "Epoch 13 num_samples 10500 loss 0.16562626448850054\n",
      "Epoch 13 num_samples 10600 loss 0.2103073126653004\n",
      "Epoch 13 num_samples 10700 loss 0.1558610210609315\n",
      "Epoch 13 num_samples 10800 loss 0.2443840913095557\n",
      "Epoch 13 num_samples 10900 loss 0.18091312385497332\n",
      "Epoch 13 num_samples 11000 loss 0.10127023897209841\n",
      "Epoch 13 num_samples 11100 loss 0.2294587397252232\n",
      "Epoch 13 num_samples 11200 loss 0.18502370282786423\n",
      "Epoch 13 num_samples 11300 loss 0.28292947894007425\n",
      "Epoch 13 num_samples 11400 loss 0.2428565338335757\n",
      "Epoch 13 num_samples 11500 loss 0.134181835653187\n",
      "Epoch 13 num_samples 11600 loss 0.16591076151498962\n",
      "Epoch 13 num_samples 11700 loss 0.21727807601984903\n",
      "Epoch 13 num_samples 11800 loss 0.14870070368004634\n",
      "Epoch 13 num_samples 11900 loss 0.1692885035091105\n",
      "Epoch 13 num_samples 12000 loss 0.12568697788866814\n",
      "Epoch 13 num_samples 12100 loss 0.1639835641853965\n",
      "Epoch 13 num_samples 12200 loss 0.22361037756437824\n",
      "Epoch 13 num_samples 12300 loss 0.12450764300143352\n",
      "Epoch 13 num_samples 12400 loss 0.21388598716329393\n",
      "Epoch 13 num_samples 12500 loss 0.19153973555716558\n",
      "Epoch 13 num_samples 12600 loss 0.18657268263208782\n",
      "Epoch 13 num_samples 12700 loss 0.1986884720754945\n",
      "Epoch 13 num_samples 12800 loss 0.28281715117816036\n",
      "Epoch 13 num_samples 12900 loss 0.168255293016499\n",
      "Epoch 13 num_samples 13000 loss 0.16127777244321326\n",
      "Epoch 13 num_samples 13100 loss 0.2809046010217435\n",
      "Epoch 13 num_samples 13200 loss 0.1471641358445771\n",
      "Epoch 13 num_samples 13300 loss 0.13273496830347178\n",
      "Epoch 13 num_samples 13400 loss 0.12712603020090735\n",
      "Epoch 13 num_samples 13500 loss 0.1554885090861436\n",
      "Epoch 13 num_samples 13600 loss 0.22948186505075804\n",
      "Epoch 13 num_samples 13700 loss 0.1912024174735496\n",
      "Epoch 13 num_samples 13800 loss 0.15844868231804876\n",
      "Epoch 13 num_samples 13900 loss 0.13517122032444423\n",
      "Epoch 13 num_samples 14000 loss 0.11481250802100196\n",
      "Epoch 13 num_samples 14100 loss 0.17105161906254962\n",
      "Epoch 13 num_samples 14200 loss 0.12002130310644159\n",
      "Epoch 13 num_samples 14300 loss 0.21254816758280448\n",
      "Epoch 13 num_samples 14400 loss 0.2097440555620669\n",
      "Epoch 13 num_samples 14500 loss 0.22805031697494602\n",
      "Epoch 13 num_samples 14600 loss 0.17463451938443356\n",
      "Epoch 13 num_samples 14700 loss 0.18568780769203008\n",
      "Epoch 13 num_samples 14800 loss 0.13020364192183945\n",
      "Epoch 13 num_samples 14900 loss 0.24774524601506948\n",
      "Epoch 13 num_samples 15000 loss 0.13586630125473362\n",
      "Epoch 13 num_samples 15100 loss 0.2068641196803197\n",
      "Epoch 13 num_samples 15200 loss 0.2450066692926725\n",
      "Epoch 13 num_samples 15300 loss 0.1984661589333891\n",
      "Epoch 13 num_samples 15400 loss 0.14279472789708483\n",
      "Epoch 13 num_samples 15500 loss 0.1872254132376753\n",
      "Epoch 13 num_samples 15600 loss 0.19090210642635946\n",
      "Epoch 13 num_samples 15700 loss 0.13209108600988922\n",
      "Epoch 13 num_samples 15800 loss 0.2635431418026193\n",
      "Epoch 13 num_samples 15900 loss 0.1124265490296507\n",
      "Epoch 13 num_samples 16000 loss 0.2960977561098476\n",
      "Epoch 13 num_samples 16100 loss 0.1607305891756782\n",
      "Epoch 13 num_samples 16200 loss 0.1703975122253177\n",
      "Epoch 13 num_samples 16300 loss 0.24089007217511338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 num_samples 16400 loss 0.18172247195965888\n",
      "Epoch 13 num_samples 16500 loss 0.1904827277348243\n",
      "Epoch 13 num_samples 16600 loss 0.2426139389267441\n",
      "Epoch 13 num_samples 16700 loss 0.148924938032559\n",
      "Epoch 13 num_samples 16800 loss 0.1350743985482023\n",
      "Epoch 13 num_samples 16900 loss 0.19984206780207234\n",
      "Epoch 13 num_samples 17000 loss 0.12485494790402353\n",
      "Epoch 13 num_samples 17100 loss 0.30716565426310566\n",
      "Epoch 13 num_samples 17200 loss 0.18975010798320865\n",
      "Epoch 13 num_samples 17300 loss 0.20910876455813274\n",
      "Epoch 13 num_samples 17400 loss 0.24924347572348274\n",
      "Epoch 13 num_samples 17500 loss 0.23866978130347744\n",
      "Epoch 13 num_samples 17600 loss 0.21614625713375663\n",
      "Epoch 13 num_samples 17700 loss 0.14521869541534596\n",
      "Epoch 13 num_samples 17800 loss 0.22165686307922988\n",
      "Epoch 13 num_samples 17900 loss 0.21258527963962034\n",
      "Epoch 13 num_samples 18000 loss 0.12744681232511887\n",
      "Epoch 13 num_samples 18100 loss 0.17720860907485142\n",
      "Epoch 13 num_samples 18200 loss 0.1810899397551859\n",
      "Epoch 13 num_samples 18300 loss 0.16470734516905544\n",
      "Epoch 13 num_samples 18400 loss 0.2613763238768904\n",
      "Epoch 13 num_samples 18500 loss 0.16638646199675827\n",
      "Epoch 14 num_samples 0 loss 0.17548513980963548\n",
      "Epoch 14 num_samples 100 loss 0.19990696703733776\n",
      "Epoch 14 num_samples 200 loss 0.15757913975027474\n",
      "Epoch 14 num_samples 300 loss 0.17450142011224595\n",
      "Epoch 14 num_samples 400 loss 0.13632420812146562\n",
      "Epoch 14 num_samples 500 loss 0.16705619794384488\n",
      "Epoch 14 num_samples 600 loss 0.1997098418913083\n",
      "Epoch 14 num_samples 700 loss 0.2565779980470879\n",
      "Epoch 14 num_samples 800 loss 0.2411531800770956\n",
      "Epoch 14 num_samples 900 loss 0.14913908387602356\n",
      "Epoch 14 num_samples 1000 loss 0.1573793331821263\n",
      "Epoch 14 num_samples 1100 loss 0.2139109023546324\n",
      "Epoch 14 num_samples 1200 loss 0.17850594486926227\n",
      "Epoch 14 num_samples 1300 loss 0.12686927145589647\n",
      "Epoch 14 num_samples 1400 loss 0.2192745562975375\n",
      "Epoch 14 num_samples 1500 loss 0.2646164406079835\n",
      "Epoch 14 num_samples 1600 loss 0.17189317914717844\n",
      "Epoch 14 num_samples 1700 loss 0.19206133807893677\n",
      "Epoch 14 num_samples 1800 loss 0.16114820559986248\n",
      "Epoch 14 num_samples 1900 loss 0.1532034820067297\n",
      "Epoch 14 num_samples 2000 loss 0.254093967924281\n",
      "Epoch 14 num_samples 2100 loss 0.14822351201319503\n",
      "Epoch 14 num_samples 2200 loss 0.12086246656797144\n",
      "Epoch 14 num_samples 2300 loss 0.15064349335689203\n",
      "Epoch 14 num_samples 2400 loss 0.13954509567639395\n",
      "Epoch 14 num_samples 2500 loss 0.23009704145621268\n",
      "Epoch 14 num_samples 2600 loss 0.20636753940597977\n",
      "Epoch 14 num_samples 2700 loss 0.20760356366505303\n",
      "Epoch 14 num_samples 2800 loss 0.20164059830945427\n",
      "Epoch 14 num_samples 2900 loss 0.18948573368567437\n",
      "Epoch 14 num_samples 3000 loss 0.1471984894070463\n",
      "Epoch 14 num_samples 3100 loss 0.1710019181617783\n",
      "Epoch 14 num_samples 3200 loss 0.3185557909895012\n",
      "Epoch 14 num_samples 3300 loss 0.14071290523572824\n",
      "Epoch 14 num_samples 3400 loss 0.14982756447303167\n",
      "Epoch 14 num_samples 3500 loss 0.1599847930895563\n",
      "Epoch 14 num_samples 3600 loss 0.10701251974445995\n",
      "Epoch 14 num_samples 3700 loss 0.19591095770759673\n",
      "Epoch 14 num_samples 3800 loss 0.1880352922584027\n",
      "Epoch 14 num_samples 3900 loss 0.21477836951113807\n",
      "Epoch 14 num_samples 4000 loss 0.21340372351423006\n",
      "Epoch 14 num_samples 4100 loss 0.281601021877319\n",
      "Epoch 14 num_samples 4200 loss 0.16667055340036746\n",
      "Epoch 14 num_samples 4300 loss 0.19749210277033946\n",
      "Epoch 14 num_samples 4400 loss 0.17265293078319677\n",
      "Epoch 14 num_samples 4500 loss 0.23878637300716693\n",
      "Epoch 14 num_samples 4600 loss 0.1978567092730107\n",
      "Epoch 14 num_samples 4700 loss 0.10063277579712934\n",
      "Epoch 14 num_samples 4800 loss 0.11967850982868945\n",
      "Epoch 14 num_samples 4900 loss 0.1505519804433019\n",
      "Epoch 14 num_samples 5000 loss 0.16315404988262303\n",
      "Epoch 14 num_samples 5100 loss 0.2503113632884624\n",
      "Epoch 14 num_samples 5200 loss 0.13129377176173607\n",
      "Epoch 14 num_samples 5300 loss 0.18032039000819122\n",
      "Epoch 14 num_samples 5400 loss 0.23723606881345077\n",
      "Epoch 14 num_samples 5500 loss 0.14130603377519452\n",
      "Epoch 14 num_samples 5600 loss 0.25131153143289076\n",
      "Epoch 14 num_samples 5700 loss 0.22936633763803052\n",
      "Epoch 14 num_samples 5800 loss 0.23966872432908687\n",
      "Epoch 14 num_samples 5900 loss 0.20919397207635343\n",
      "Epoch 14 num_samples 6000 loss 0.1938455373252048\n",
      "Epoch 14 num_samples 6100 loss 0.12521023487921465\n",
      "Epoch 14 num_samples 6200 loss 0.2009340844006549\n",
      "Epoch 14 num_samples 6300 loss 0.22149041863889252\n",
      "Epoch 14 num_samples 6400 loss 0.14929056272425595\n",
      "Epoch 14 num_samples 6500 loss 0.12914884552987868\n",
      "Epoch 14 num_samples 6600 loss 0.26263430190571196\n",
      "Epoch 14 num_samples 6700 loss 0.11439409865177572\n",
      "Epoch 14 num_samples 6800 loss 0.07568468600808603\n",
      "Epoch 14 num_samples 6900 loss 0.3199837944350204\n",
      "Epoch 14 num_samples 7000 loss 0.24452955832668366\n",
      "Epoch 14 num_samples 7100 loss 0.13937834133445548\n",
      "Epoch 14 num_samples 7200 loss 0.16722072279220213\n",
      "Epoch 14 num_samples 7300 loss 0.19033851322668965\n",
      "Epoch 14 num_samples 7400 loss 0.14389203918475835\n",
      "Epoch 14 num_samples 7500 loss 0.25771750746752603\n",
      "Epoch 14 num_samples 7600 loss 0.1875760606852136\n",
      "Epoch 14 num_samples 7700 loss 0.25741287423416026\n",
      "Epoch 14 num_samples 7800 loss 0.09796037625035245\n",
      "Epoch 14 num_samples 7900 loss 0.1931862444582284\n",
      "Epoch 14 num_samples 8000 loss 0.11175247655127028\n",
      "Epoch 14 num_samples 8100 loss 0.16047547460757386\n",
      "Epoch 14 num_samples 8200 loss 0.14651565323977886\n",
      "Epoch 14 num_samples 8300 loss 0.16799348750712745\n",
      "Epoch 14 num_samples 8400 loss 0.16144418571305977\n",
      "Epoch 14 num_samples 8500 loss 0.1908874977026586\n",
      "Epoch 14 num_samples 8600 loss 0.1230408148595739\n",
      "Epoch 14 num_samples 8700 loss 0.16702880190868669\n",
      "Epoch 14 num_samples 8800 loss 0.2227409222803557\n",
      "Epoch 14 num_samples 8900 loss 0.21469301381173875\n",
      "Epoch 14 num_samples 9000 loss 0.17615467530542253\n",
      "Epoch 14 num_samples 9100 loss 0.1679585605051863\n",
      "Epoch 14 num_samples 9200 loss 0.16714627493658596\n",
      "Epoch 14 num_samples 9300 loss 0.18656988929297857\n",
      "Epoch 14 num_samples 9400 loss 0.13286098089035042\n",
      "Epoch 14 num_samples 9500 loss 0.20879833324349825\n",
      "Epoch 14 num_samples 9600 loss 0.12687879662027984\n",
      "Epoch 14 num_samples 9700 loss 0.20715727118716998\n",
      "Epoch 14 num_samples 9800 loss 0.11138701144687455\n",
      "Epoch 14 num_samples 9900 loss 0.28025856616261957\n",
      "Epoch 14 num_samples 10000 loss 0.1424603530037157\n",
      "Epoch 14 num_samples 10100 loss 0.09921609438244502\n",
      "Epoch 14 num_samples 10200 loss 0.23865159570700073\n",
      "Epoch 14 num_samples 10300 loss 0.20358224473448913\n",
      "Epoch 14 num_samples 10400 loss 0.19262006979815602\n",
      "Epoch 14 num_samples 10500 loss 0.1497753053666402\n",
      "Epoch 14 num_samples 10600 loss 0.19695621224537174\n",
      "Epoch 14 num_samples 10700 loss 0.14385487629264776\n",
      "Epoch 14 num_samples 10800 loss 0.2294601912192069\n",
      "Epoch 14 num_samples 10900 loss 0.16060555441228394\n",
      "Epoch 14 num_samples 11000 loss 0.09160641721851188\n",
      "Epoch 14 num_samples 11100 loss 0.20187793889789432\n",
      "Epoch 14 num_samples 11200 loss 0.16659818675062776\n",
      "Epoch 14 num_samples 11300 loss 0.26217900015022694\n",
      "Epoch 14 num_samples 11400 loss 0.22559606398852936\n",
      "Epoch 14 num_samples 11500 loss 0.12289174264886854\n",
      "Epoch 14 num_samples 11600 loss 0.14964332749652084\n",
      "Epoch 14 num_samples 11700 loss 0.198272586385484\n",
      "Epoch 14 num_samples 11800 loss 0.13636578992648218\n",
      "Epoch 14 num_samples 11900 loss 0.15690328726063332\n",
      "Epoch 14 num_samples 12000 loss 0.1091456139228919\n",
      "Epoch 14 num_samples 12100 loss 0.15192746104169988\n",
      "Epoch 14 num_samples 12200 loss 0.20879763014496702\n",
      "Epoch 14 num_samples 12300 loss 0.11163929651633026\n",
      "Epoch 14 num_samples 12400 loss 0.19854723541972227\n",
      "Epoch 14 num_samples 12500 loss 0.17341371962265678\n",
      "Epoch 14 num_samples 12600 loss 0.17666818579975124\n",
      "Epoch 14 num_samples 12700 loss 0.17997899965831785\n",
      "Epoch 14 num_samples 12800 loss 0.2614718122177234\n",
      "Epoch 14 num_samples 12900 loss 0.15794849429989316\n",
      "Epoch 14 num_samples 13000 loss 0.14281380679770247\n",
      "Epoch 14 num_samples 13100 loss 0.2560282394085602\n",
      "Epoch 14 num_samples 13200 loss 0.1336182584272853\n",
      "Epoch 14 num_samples 13300 loss 0.12239915403796468\n",
      "Epoch 14 num_samples 13400 loss 0.11109996886602708\n",
      "Epoch 14 num_samples 13500 loss 0.14328574435134603\n",
      "Epoch 14 num_samples 13600 loss 0.21157390848147425\n",
      "Epoch 14 num_samples 13700 loss 0.17480284932013318\n",
      "Epoch 14 num_samples 13800 loss 0.14584267420016558\n",
      "Epoch 14 num_samples 13900 loss 0.11904088638142447\n",
      "Epoch 14 num_samples 14000 loss 0.10582944922942424\n",
      "Epoch 14 num_samples 14100 loss 0.15429996401761228\n",
      "Epoch 14 num_samples 14200 loss 0.10639040989723872\n",
      "Epoch 14 num_samples 14300 loss 0.1950723809855791\n",
      "Epoch 14 num_samples 14400 loss 0.18855681385374268\n",
      "Epoch 14 num_samples 14500 loss 0.2056477055182364\n",
      "Epoch 14 num_samples 14600 loss 0.15579204539076652\n",
      "Epoch 14 num_samples 14700 loss 0.16874843476922835\n",
      "Epoch 14 num_samples 14800 loss 0.11876059898810903\n",
      "Epoch 14 num_samples 14900 loss 0.23223903185623676\n",
      "Epoch 14 num_samples 15000 loss 0.12406064116035705\n",
      "Epoch 14 num_samples 15100 loss 0.18846001279419133\n",
      "Epoch 14 num_samples 15200 loss 0.23065027159345652\n",
      "Epoch 14 num_samples 15300 loss 0.17693579434746196\n",
      "Epoch 14 num_samples 15400 loss 0.12951899734227545\n",
      "Epoch 14 num_samples 15500 loss 0.17560428334966957\n",
      "Epoch 14 num_samples 15600 loss 0.17077768920902828\n",
      "Epoch 14 num_samples 15700 loss 0.12063826662220965\n",
      "Epoch 14 num_samples 15800 loss 0.24714333473895522\n",
      "Epoch 14 num_samples 15900 loss 0.10089993944084212\n",
      "Epoch 14 num_samples 16000 loss 0.26315131649825074\n",
      "Epoch 14 num_samples 16100 loss 0.14291154356149993\n",
      "Epoch 14 num_samples 16200 loss 0.15718727643606412\n",
      "Epoch 14 num_samples 16300 loss 0.22168701826404238\n",
      "Epoch 14 num_samples 16400 loss 0.1683792370825339\n",
      "Epoch 14 num_samples 16500 loss 0.17692226615769685\n",
      "Epoch 14 num_samples 16600 loss 0.21992649367239267\n",
      "Epoch 14 num_samples 16700 loss 0.13579125644215773\n",
      "Epoch 14 num_samples 16800 loss 0.12299258445911367\n",
      "Epoch 14 num_samples 16900 loss 0.17945143043409867\n",
      "Epoch 14 num_samples 17000 loss 0.11331518995514488\n",
      "Epoch 14 num_samples 17100 loss 0.2875947237302533\n",
      "Epoch 14 num_samples 17200 loss 0.17564028837326787\n",
      "Epoch 14 num_samples 17300 loss 0.19637066014300056\n",
      "Epoch 14 num_samples 17400 loss 0.22885813491649615\n",
      "Epoch 14 num_samples 17500 loss 0.21564741357778913\n",
      "Epoch 14 num_samples 17600 loss 0.20118224825862835\n",
      "Epoch 14 num_samples 17700 loss 0.1293864397688949\n",
      "Epoch 14 num_samples 17800 loss 0.20299915176629632\n",
      "Epoch 14 num_samples 17900 loss 0.19794044744140354\n",
      "Epoch 14 num_samples 18000 loss 0.11727051157043836\n",
      "Epoch 14 num_samples 18100 loss 0.16496521457561739\n",
      "Epoch 14 num_samples 18200 loss 0.16762300279202694\n",
      "Epoch 14 num_samples 18300 loss 0.14704556856263673\n",
      "Epoch 14 num_samples 18400 loss 0.24519266382141489\n",
      "Epoch 14 num_samples 18500 loss 0.15244915734995917\n",
      "Epoch 15 num_samples 0 loss 0.15822240566255816\n",
      "Epoch 15 num_samples 100 loss 0.1837612549285871\n",
      "Epoch 15 num_samples 200 loss 0.14309864316226562\n",
      "Epoch 15 num_samples 300 loss 0.15800392229447457\n",
      "Epoch 15 num_samples 400 loss 0.124079289493103\n",
      "Epoch 15 num_samples 500 loss 0.15203423842031305\n",
      "Epoch 15 num_samples 600 loss 0.18407359467516837\n",
      "Epoch 15 num_samples 700 loss 0.24233286174887175\n",
      "Epoch 15 num_samples 800 loss 0.21775624266642382\n",
      "Epoch 15 num_samples 900 loss 0.14043937724033204\n",
      "Epoch 15 num_samples 1000 loss 0.14365158449409826\n",
      "Epoch 15 num_samples 1100 loss 0.1993569762967374\n",
      "Epoch 15 num_samples 1200 loss 0.16616504702920715\n",
      "Epoch 15 num_samples 1300 loss 0.11550248969894686\n",
      "Epoch 15 num_samples 1400 loss 0.19801451030836156\n",
      "Epoch 15 num_samples 1500 loss 0.25101101091615097\n",
      "Epoch 15 num_samples 1600 loss 0.15609952154903822\n",
      "Epoch 15 num_samples 1700 loss 0.17296349907080724\n",
      "Epoch 15 num_samples 1800 loss 0.14606983118436653\n",
      "Epoch 15 num_samples 1900 loss 0.1421794084123543\n",
      "Epoch 15 num_samples 2000 loss 0.23445226485585446\n",
      "Epoch 15 num_samples 2100 loss 0.1337350096998238\n",
      "Epoch 15 num_samples 2200 loss 0.1102473195482586\n",
      "Epoch 15 num_samples 2300 loss 0.13438538598734634\n",
      "Epoch 15 num_samples 2400 loss 0.12760570535477533\n",
      "Epoch 15 num_samples 2500 loss 0.21298109997442552\n",
      "Epoch 15 num_samples 2600 loss 0.18890432291753678\n",
      "Epoch 15 num_samples 2700 loss 0.19557670197532545\n",
      "Epoch 15 num_samples 2800 loss 0.18874399512825563\n",
      "Epoch 15 num_samples 2900 loss 0.17437040633823694\n",
      "Epoch 15 num_samples 3000 loss 0.1344184216149576\n",
      "Epoch 15 num_samples 3100 loss 0.15975176650936462\n",
      "Epoch 15 num_samples 3200 loss 0.2992208128529522\n",
      "Epoch 15 num_samples 3300 loss 0.1299186845878364\n",
      "Epoch 15 num_samples 3400 loss 0.1353547153371625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 num_samples 3500 loss 0.14771112128313552\n",
      "Epoch 15 num_samples 3600 loss 0.09579173126986423\n",
      "Epoch 15 num_samples 3700 loss 0.18398571441610806\n",
      "Epoch 15 num_samples 3800 loss 0.1748481924969605\n",
      "Epoch 15 num_samples 3900 loss 0.19521563615321255\n",
      "Epoch 15 num_samples 4000 loss 0.19545337592134335\n",
      "Epoch 15 num_samples 4100 loss 0.26495561444546484\n",
      "Epoch 15 num_samples 4200 loss 0.15280360011829827\n",
      "Epoch 15 num_samples 4300 loss 0.17896784067952665\n",
      "Epoch 15 num_samples 4400 loss 0.16048238160076855\n",
      "Epoch 15 num_samples 4500 loss 0.21757851188751906\n",
      "Epoch 15 num_samples 4600 loss 0.1813309056447906\n",
      "Epoch 15 num_samples 4700 loss 0.09155804210044428\n",
      "Epoch 15 num_samples 4800 loss 0.10857977128315727\n",
      "Epoch 15 num_samples 4900 loss 0.13217136435381807\n",
      "Epoch 15 num_samples 5000 loss 0.14807340981445188\n",
      "Epoch 15 num_samples 5100 loss 0.22820438862089876\n",
      "Epoch 15 num_samples 5200 loss 0.1154621598608086\n",
      "Epoch 15 num_samples 5300 loss 0.16174544705054777\n",
      "Epoch 15 num_samples 5400 loss 0.21688249363598117\n",
      "Epoch 15 num_samples 5500 loss 0.12864762553138573\n",
      "Epoch 15 num_samples 5600 loss 0.2392328332929128\n",
      "Epoch 15 num_samples 5700 loss 0.2109914160184584\n",
      "Epoch 15 num_samples 5800 loss 0.22233089015771257\n",
      "Epoch 15 num_samples 5900 loss 0.19639275014088495\n",
      "Epoch 15 num_samples 6000 loss 0.18098469572011638\n",
      "Epoch 15 num_samples 6100 loss 0.1161751604070733\n",
      "Epoch 15 num_samples 6200 loss 0.18353266918451352\n",
      "Epoch 15 num_samples 6300 loss 0.20257099048384258\n",
      "Epoch 15 num_samples 6400 loss 0.134785213009601\n",
      "Epoch 15 num_samples 6500 loss 0.11484870205616068\n",
      "Epoch 15 num_samples 6600 loss 0.2442209662173198\n",
      "Epoch 15 num_samples 6700 loss 0.10387504817442032\n",
      "Epoch 15 num_samples 6800 loss 0.07064130492212478\n",
      "Epoch 15 num_samples 6900 loss 0.29479809952372443\n",
      "Epoch 15 num_samples 7000 loss 0.22932521804756462\n",
      "Epoch 15 num_samples 7100 loss 0.1280448546459628\n",
      "Epoch 15 num_samples 7200 loss 0.14795186759471202\n",
      "Epoch 15 num_samples 7300 loss 0.17341484905505333\n",
      "Epoch 15 num_samples 7400 loss 0.131724441213507\n",
      "Epoch 15 num_samples 7500 loss 0.24040033288244922\n",
      "Epoch 15 num_samples 7600 loss 0.16803371248640261\n",
      "Epoch 15 num_samples 7700 loss 0.23725336165648764\n",
      "Epoch 15 num_samples 7800 loss 0.08939037915123717\n",
      "Epoch 15 num_samples 7900 loss 0.18004908907171743\n",
      "Epoch 15 num_samples 8000 loss 0.10385291816340286\n",
      "Epoch 15 num_samples 8100 loss 0.14626503402465796\n",
      "Epoch 15 num_samples 8200 loss 0.13855794127700935\n",
      "Epoch 15 num_samples 8300 loss 0.1556309678658107\n",
      "Epoch 15 num_samples 8400 loss 0.14672167999740054\n",
      "Epoch 15 num_samples 8500 loss 0.1785928684770443\n",
      "Epoch 15 num_samples 8600 loss 0.11461173037439859\n",
      "Epoch 15 num_samples 8700 loss 0.1516098614646714\n",
      "Epoch 15 num_samples 8800 loss 0.2103389623629964\n",
      "Epoch 15 num_samples 8900 loss 0.1967976898897331\n",
      "Epoch 15 num_samples 9000 loss 0.16197034731836232\n",
      "Epoch 15 num_samples 9100 loss 0.15284383544775695\n",
      "Epoch 15 num_samples 9200 loss 0.15256638504718367\n",
      "Epoch 15 num_samples 9300 loss 0.17011556590725094\n",
      "Epoch 15 num_samples 9400 loss 0.12103257438698947\n",
      "Epoch 15 num_samples 9500 loss 0.19055904849546704\n",
      "Epoch 15 num_samples 9600 loss 0.11520061223754195\n",
      "Epoch 15 num_samples 9700 loss 0.19072269787120924\n",
      "Epoch 15 num_samples 9800 loss 0.10045405710294238\n",
      "Epoch 15 num_samples 9900 loss 0.26004451361468095\n",
      "Epoch 15 num_samples 10000 loss 0.13468344433117743\n",
      "Epoch 15 num_samples 10100 loss 0.09116328677594275\n",
      "Epoch 15 num_samples 10200 loss 0.22576005340097793\n",
      "Epoch 15 num_samples 10300 loss 0.18666633657768286\n",
      "Epoch 15 num_samples 10400 loss 0.17663786194217415\n",
      "Epoch 15 num_samples 10500 loss 0.1367350779933446\n",
      "Epoch 15 num_samples 10600 loss 0.18520715951413774\n",
      "Epoch 15 num_samples 10700 loss 0.13332143166475596\n",
      "Epoch 15 num_samples 10800 loss 0.21428803322094567\n",
      "Epoch 15 num_samples 10900 loss 0.14406082586721147\n",
      "Epoch 15 num_samples 11000 loss 0.08339321560181613\n",
      "Epoch 15 num_samples 11100 loss 0.1787866484398311\n",
      "Epoch 15 num_samples 11200 loss 0.1504132691240666\n",
      "Epoch 15 num_samples 11300 loss 0.24230939469102403\n",
      "Epoch 15 num_samples 11400 loss 0.20911786091058823\n",
      "Epoch 15 num_samples 11500 loss 0.1134340984589407\n",
      "Epoch 15 num_samples 11600 loss 0.1342879312121766\n",
      "Epoch 15 num_samples 11700 loss 0.18305538908650668\n",
      "Epoch 15 num_samples 11800 loss 0.12612779160778506\n",
      "Epoch 15 num_samples 11900 loss 0.1450315168141813\n",
      "Epoch 15 num_samples 12000 loss 0.09624858514878458\n",
      "Epoch 15 num_samples 12100 loss 0.1414209573181736\n",
      "Epoch 15 num_samples 12200 loss 0.19604212026642348\n",
      "Epoch 15 num_samples 12300 loss 0.10094362007210603\n",
      "Epoch 15 num_samples 12400 loss 0.1822018549152633\n",
      "Epoch 15 num_samples 12500 loss 0.15995449456597277\n",
      "Epoch 15 num_samples 12600 loss 0.16469264873914105\n",
      "Epoch 15 num_samples 12700 loss 0.16784995025376495\n",
      "Epoch 15 num_samples 12800 loss 0.23991794984267467\n",
      "Epoch 15 num_samples 12900 loss 0.1485318518596388\n",
      "Epoch 15 num_samples 13000 loss 0.12816045813086988\n",
      "Epoch 15 num_samples 13100 loss 0.23587336566725497\n",
      "Epoch 15 num_samples 13200 loss 0.12255729857765636\n",
      "Epoch 15 num_samples 13300 loss 0.11133876042792236\n",
      "Epoch 15 num_samples 13400 loss 0.09885154387806963\n",
      "Epoch 15 num_samples 13500 loss 0.1306952139105605\n",
      "Epoch 15 num_samples 13600 loss 0.19697879180562924\n",
      "Epoch 15 num_samples 13700 loss 0.16086831209836552\n",
      "Epoch 15 num_samples 13800 loss 0.13407733482457843\n",
      "Epoch 15 num_samples 13900 loss 0.10536092076630582\n",
      "Epoch 15 num_samples 14000 loss 0.09741288792438524\n",
      "Epoch 15 num_samples 14100 loss 0.1420991811733704\n",
      "Epoch 15 num_samples 14200 loss 0.09596137262153678\n",
      "Epoch 15 num_samples 14300 loss 0.17917594363705627\n",
      "Epoch 15 num_samples 14400 loss 0.17163909173682548\n",
      "Epoch 15 num_samples 14500 loss 0.18636946438420618\n",
      "Epoch 15 num_samples 14600 loss 0.1392421463899938\n",
      "Epoch 15 num_samples 14700 loss 0.15422107205532193\n",
      "Epoch 15 num_samples 14800 loss 0.10993541251291765\n",
      "Epoch 15 num_samples 14900 loss 0.21704391763914338\n",
      "Epoch 15 num_samples 15000 loss 0.11361279052570246\n",
      "Epoch 15 num_samples 15100 loss 0.17107617859001042\n",
      "Epoch 15 num_samples 15200 loss 0.21587370301834038\n",
      "Epoch 15 num_samples 15300 loss 0.15921934324237338\n",
      "Epoch 15 num_samples 15400 loss 0.11661171353606484\n",
      "Epoch 15 num_samples 15500 loss 0.16508140933554152\n",
      "Epoch 15 num_samples 15600 loss 0.15435712066350948\n",
      "Epoch 15 num_samples 15700 loss 0.10876350320623494\n",
      "Epoch 15 num_samples 15800 loss 0.2313783610450573\n",
      "Epoch 15 num_samples 15900 loss 0.09107555158410645\n",
      "Epoch 15 num_samples 16000 loss 0.2335535584003036\n",
      "Epoch 15 num_samples 16100 loss 0.12627580164520885\n",
      "Epoch 15 num_samples 16200 loss 0.14819658074900147\n",
      "Epoch 15 num_samples 16300 loss 0.20460078482501204\n",
      "Epoch 15 num_samples 16400 loss 0.15620556388293663\n",
      "Epoch 15 num_samples 16500 loss 0.16106654544430554\n",
      "Epoch 15 num_samples 16600 loss 0.19910158968121053\n",
      "Epoch 15 num_samples 16700 loss 0.12301275140844328\n",
      "Epoch 15 num_samples 16800 loss 0.112563446998163\n",
      "Epoch 15 num_samples 16900 loss 0.15831728729135608\n",
      "Epoch 15 num_samples 17000 loss 0.10305818482800184\n",
      "Epoch 15 num_samples 17100 loss 0.2700612248616164\n",
      "Epoch 15 num_samples 17200 loss 0.16430847818850894\n",
      "Epoch 15 num_samples 17300 loss 0.18388541417393647\n",
      "Epoch 15 num_samples 17400 loss 0.21086173501615776\n",
      "Epoch 15 num_samples 17500 loss 0.19492664596730933\n",
      "Epoch 15 num_samples 17600 loss 0.18477721202599323\n",
      "Epoch 15 num_samples 17700 loss 0.11773905608157914\n",
      "Epoch 15 num_samples 17800 loss 0.18557834844374824\n",
      "Epoch 15 num_samples 17900 loss 0.18263962430589775\n",
      "Epoch 15 num_samples 18000 loss 0.106967271204612\n",
      "Epoch 15 num_samples 18100 loss 0.15214818052941462\n",
      "Epoch 15 num_samples 18200 loss 0.15689413150801537\n",
      "Epoch 15 num_samples 18300 loss 0.13164330243095956\n",
      "Epoch 15 num_samples 18400 loss 0.22861476024116645\n",
      "Epoch 15 num_samples 18500 loss 0.13964510698358223\n",
      "Epoch 16 num_samples 0 loss 0.14299617355850194\n",
      "Epoch 16 num_samples 100 loss 0.17154843228973174\n",
      "Epoch 16 num_samples 200 loss 0.12941759209435502\n",
      "Epoch 16 num_samples 300 loss 0.14039601910889316\n",
      "Epoch 16 num_samples 400 loss 0.11399846253386257\n",
      "Epoch 16 num_samples 500 loss 0.13731777079529014\n",
      "Epoch 16 num_samples 600 loss 0.171348932752\n",
      "Epoch 16 num_samples 700 loss 0.22985108309566057\n",
      "Epoch 16 num_samples 800 loss 0.19537306657178324\n",
      "Epoch 16 num_samples 900 loss 0.1319097867665268\n",
      "Epoch 16 num_samples 1000 loss 0.13018496910621408\n",
      "Epoch 16 num_samples 1100 loss 0.1867011741773941\n",
      "Epoch 16 num_samples 1200 loss 0.1536778638933386\n",
      "Epoch 16 num_samples 1300 loss 0.10786624892362912\n",
      "Epoch 16 num_samples 1400 loss 0.18110055414597587\n",
      "Epoch 16 num_samples 1500 loss 0.24057024515329295\n",
      "Epoch 16 num_samples 1600 loss 0.14419695288386783\n",
      "Epoch 16 num_samples 1700 loss 0.15657849601124962\n",
      "Epoch 16 num_samples 1800 loss 0.13110543736844993\n",
      "Epoch 16 num_samples 1900 loss 0.1314081452258913\n",
      "Epoch 16 num_samples 2000 loss 0.2153491255086859\n",
      "Epoch 16 num_samples 2100 loss 0.12127001665833405\n",
      "Epoch 16 num_samples 2200 loss 0.10025466580850743\n",
      "Epoch 16 num_samples 2300 loss 0.1204877213873166\n",
      "Epoch 16 num_samples 2400 loss 0.11788789721831495\n",
      "Epoch 16 num_samples 2500 loss 0.1957123261346149\n",
      "Epoch 16 num_samples 2600 loss 0.1713722187155205\n",
      "Epoch 16 num_samples 2700 loss 0.18316520402153647\n",
      "Epoch 16 num_samples 2800 loss 0.17411446671586575\n",
      "Epoch 16 num_samples 2900 loss 0.1615297368203062\n",
      "Epoch 16 num_samples 3000 loss 0.1229899740409514\n",
      "Epoch 16 num_samples 3100 loss 0.15005807880712965\n",
      "Epoch 16 num_samples 3200 loss 0.28152024203496784\n",
      "Epoch 16 num_samples 3300 loss 0.12106016562899928\n",
      "Epoch 16 num_samples 3400 loss 0.12015099128192971\n",
      "Epoch 16 num_samples 3500 loss 0.1359026908021994\n",
      "Epoch 16 num_samples 3600 loss 0.08651193233871705\n",
      "Epoch 16 num_samples 3700 loss 0.17267826500500663\n",
      "Epoch 16 num_samples 3800 loss 0.1621598926332518\n",
      "Epoch 16 num_samples 3900 loss 0.17934424929527246\n",
      "Epoch 16 num_samples 4000 loss 0.17835676693390695\n",
      "Epoch 16 num_samples 4100 loss 0.2486483661154656\n",
      "Epoch 16 num_samples 4200 loss 0.13981204413119094\n",
      "Epoch 16 num_samples 4300 loss 0.1666698357426509\n",
      "Epoch 16 num_samples 4400 loss 0.1496496005939019\n",
      "Epoch 16 num_samples 4500 loss 0.20105681400227574\n",
      "Epoch 16 num_samples 4600 loss 0.16602925240294428\n",
      "Epoch 16 num_samples 4700 loss 0.08294960357604854\n",
      "Epoch 16 num_samples 4800 loss 0.09803554074509456\n",
      "Epoch 16 num_samples 4900 loss 0.11672106561097415\n",
      "Epoch 16 num_samples 5000 loss 0.13384707502443746\n",
      "Epoch 16 num_samples 5100 loss 0.20896894658679183\n",
      "Epoch 16 num_samples 5200 loss 0.10198104556732528\n",
      "Epoch 16 num_samples 5300 loss 0.14673251120287123\n",
      "Epoch 16 num_samples 5400 loss 0.19758682744946252\n",
      "Epoch 16 num_samples 5500 loss 0.11776949983327459\n",
      "Epoch 16 num_samples 5600 loss 0.22922817436938978\n",
      "Epoch 16 num_samples 5700 loss 0.19656951639878437\n",
      "Epoch 16 num_samples 5800 loss 0.20435213404324956\n",
      "Epoch 16 num_samples 5900 loss 0.18378905502155415\n",
      "Epoch 16 num_samples 6000 loss 0.16953550672705067\n",
      "Epoch 16 num_samples 6100 loss 0.10739289062768087\n",
      "Epoch 16 num_samples 6200 loss 0.16751564202542138\n",
      "Epoch 16 num_samples 6300 loss 0.1859831604358478\n",
      "Epoch 16 num_samples 6400 loss 0.12225598225031803\n",
      "Epoch 16 num_samples 6500 loss 0.1034941770911733\n",
      "Epoch 16 num_samples 6600 loss 0.22251948362755633\n",
      "Epoch 16 num_samples 6700 loss 0.09379328619822427\n",
      "Epoch 16 num_samples 6800 loss 0.06484592590537236\n",
      "Epoch 16 num_samples 6900 loss 0.27158021817946026\n",
      "Epoch 16 num_samples 7000 loss 0.2148062131142548\n",
      "Epoch 16 num_samples 7100 loss 0.11915951925379992\n",
      "Epoch 16 num_samples 7200 loss 0.1335040522994647\n",
      "Epoch 16 num_samples 7300 loss 0.15885537201699335\n",
      "Epoch 16 num_samples 7400 loss 0.12091585523946297\n",
      "Epoch 16 num_samples 7500 loss 0.22395642572606647\n",
      "Epoch 16 num_samples 7600 loss 0.15233373144046783\n",
      "Epoch 16 num_samples 7700 loss 0.21947281626313603\n",
      "Epoch 16 num_samples 7800 loss 0.08375140385345527\n",
      "Epoch 16 num_samples 7900 loss 0.16474738505059278\n",
      "Epoch 16 num_samples 8000 loss 0.0961305431874429\n",
      "Epoch 16 num_samples 8100 loss 0.13377867461689527\n",
      "Epoch 16 num_samples 8200 loss 0.13311646338856067\n",
      "Epoch 16 num_samples 8300 loss 0.14534334941276783\n",
      "Epoch 16 num_samples 8400 loss 0.13143278678689863\n",
      "Epoch 16 num_samples 8500 loss 0.1677218909695338\n",
      "Epoch 16 num_samples 8600 loss 0.10624083131940991\n",
      "Epoch 16 num_samples 8700 loss 0.13971980901401912\n",
      "Epoch 16 num_samples 8800 loss 0.19855957265132282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 num_samples 8900 loss 0.1781996069791527\n",
      "Epoch 16 num_samples 9000 loss 0.14775061874409703\n",
      "Epoch 16 num_samples 9100 loss 0.1412221738095278\n",
      "Epoch 16 num_samples 9200 loss 0.13823447252015145\n",
      "Epoch 16 num_samples 9300 loss 0.1547547916353446\n",
      "Epoch 16 num_samples 9400 loss 0.1105656533564813\n",
      "Epoch 16 num_samples 9500 loss 0.17309311140364236\n",
      "Epoch 16 num_samples 9600 loss 0.10624771880934436\n",
      "Epoch 16 num_samples 9700 loss 0.17584697233807225\n",
      "Epoch 16 num_samples 9800 loss 0.09034957994991011\n",
      "Epoch 16 num_samples 9900 loss 0.2419130650766903\n",
      "Epoch 16 num_samples 10000 loss 0.1275736720719502\n",
      "Epoch 16 num_samples 10100 loss 0.08381435771565883\n",
      "Epoch 16 num_samples 10200 loss 0.2131777377302412\n",
      "Epoch 16 num_samples 10300 loss 0.17061320807717123\n",
      "Epoch 16 num_samples 10400 loss 0.1618204152729205\n",
      "Epoch 16 num_samples 10500 loss 0.12387428054765483\n",
      "Epoch 16 num_samples 10600 loss 0.1745105512668805\n",
      "Epoch 16 num_samples 10700 loss 0.12540892275371315\n",
      "Epoch 16 num_samples 10800 loss 0.20114766427128955\n",
      "Epoch 16 num_samples 10900 loss 0.13041638746643558\n",
      "Epoch 16 num_samples 11000 loss 0.07812550940187434\n",
      "Epoch 16 num_samples 11100 loss 0.15938402098863702\n",
      "Epoch 16 num_samples 11200 loss 0.13574440237239682\n",
      "Epoch 16 num_samples 11300 loss 0.22330195111521134\n",
      "Epoch 16 num_samples 11400 loss 0.1937403721447691\n",
      "Epoch 16 num_samples 11500 loss 0.10718741871014587\n",
      "Epoch 16 num_samples 11600 loss 0.12108214437169398\n",
      "Epoch 16 num_samples 11700 loss 0.16808532142630345\n",
      "Epoch 16 num_samples 11800 loss 0.11663078608254353\n",
      "Epoch 16 num_samples 11900 loss 0.132869551301702\n",
      "Epoch 16 num_samples 12000 loss 0.08611682284203653\n",
      "Epoch 16 num_samples 12100 loss 0.13108178870644052\n",
      "Epoch 16 num_samples 12200 loss 0.1823066388543806\n",
      "Epoch 16 num_samples 12300 loss 0.09086364411938802\n",
      "Epoch 16 num_samples 12400 loss 0.16765481662355047\n",
      "Epoch 16 num_samples 12500 loss 0.14752630809820583\n",
      "Epoch 16 num_samples 12600 loss 0.1556195247628688\n",
      "Epoch 16 num_samples 12700 loss 0.15351821421966494\n",
      "Epoch 16 num_samples 12800 loss 0.2217276607737629\n",
      "Epoch 16 num_samples 12900 loss 0.13938850418785034\n",
      "Epoch 16 num_samples 13000 loss 0.11654771360258291\n",
      "Epoch 16 num_samples 13100 loss 0.21930629888421577\n",
      "Epoch 16 num_samples 13200 loss 0.11261962384743329\n",
      "Epoch 16 num_samples 13300 loss 0.10334626674711327\n",
      "Epoch 16 num_samples 13400 loss 0.08751981606043983\n",
      "Epoch 16 num_samples 13500 loss 0.11873804604469228\n",
      "Epoch 16 num_samples 13600 loss 0.18194137585744077\n",
      "Epoch 16 num_samples 13700 loss 0.1477116766021813\n",
      "Epoch 16 num_samples 13800 loss 0.12350733481250004\n",
      "Epoch 16 num_samples 13900 loss 0.09330516129421149\n",
      "Epoch 16 num_samples 14000 loss 0.0900655330846001\n",
      "Epoch 16 num_samples 14100 loss 0.12987245440032652\n",
      "Epoch 16 num_samples 14200 loss 0.08652038333796394\n",
      "Epoch 16 num_samples 14300 loss 0.1633453231423033\n",
      "Epoch 16 num_samples 14400 loss 0.15717068779642024\n",
      "Epoch 16 num_samples 14500 loss 0.17061004886794662\n",
      "Epoch 16 num_samples 14600 loss 0.12680715054699893\n",
      "Epoch 16 num_samples 14700 loss 0.1411341297276703\n",
      "Epoch 16 num_samples 14800 loss 0.10140692510994107\n",
      "Epoch 16 num_samples 14900 loss 0.20085851068558191\n",
      "Epoch 16 num_samples 15000 loss 0.1049744654428514\n",
      "Epoch 16 num_samples 15100 loss 0.1579367452700458\n",
      "Epoch 16 num_samples 15200 loss 0.20161760031476292\n",
      "Epoch 16 num_samples 15300 loss 0.1452635251384523\n",
      "Epoch 16 num_samples 15400 loss 0.10548070072693629\n",
      "Epoch 16 num_samples 15500 loss 0.15580673866695643\n",
      "Epoch 16 num_samples 15600 loss 0.14011795734692098\n",
      "Epoch 16 num_samples 15700 loss 0.09877643201550676\n",
      "Epoch 16 num_samples 15800 loss 0.2145793478241253\n",
      "Epoch 16 num_samples 15900 loss 0.08250844801588969\n",
      "Epoch 16 num_samples 16000 loss 0.20945669055059404\n",
      "Epoch 16 num_samples 16100 loss 0.11252376282068648\n",
      "Epoch 16 num_samples 16200 loss 0.13836877614339152\n",
      "Epoch 16 num_samples 16300 loss 0.18959071025957747\n",
      "Epoch 16 num_samples 16400 loss 0.14606644341220115\n",
      "Epoch 16 num_samples 16500 loss 0.1490177706199856\n",
      "Epoch 16 num_samples 16600 loss 0.18326233341990217\n",
      "Epoch 16 num_samples 16700 loss 0.11063804767830428\n",
      "Epoch 16 num_samples 16800 loss 0.10401098662615908\n",
      "Epoch 16 num_samples 16900 loss 0.141009737281235\n",
      "Epoch 16 num_samples 17000 loss 0.09523282209741563\n",
      "Epoch 16 num_samples 17100 loss 0.255370662211967\n",
      "Epoch 16 num_samples 17200 loss 0.15044506374055394\n",
      "Epoch 16 num_samples 17300 loss 0.17249251774490304\n",
      "Epoch 16 num_samples 17400 loss 0.1917187704340767\n",
      "Epoch 16 num_samples 17500 loss 0.17711769620503148\n",
      "Epoch 16 num_samples 17600 loss 0.17167398896705532\n",
      "Epoch 16 num_samples 17700 loss 0.10576510953221957\n",
      "Epoch 16 num_samples 17800 loss 0.17170907429671675\n",
      "Epoch 16 num_samples 17900 loss 0.1687867484152811\n",
      "Epoch 16 num_samples 18000 loss 0.09823382938377914\n",
      "Epoch 16 num_samples 18100 loss 0.14172754849891012\n",
      "Epoch 16 num_samples 18200 loss 0.14328245009534674\n",
      "Epoch 16 num_samples 18300 loss 0.1175656065894965\n",
      "Epoch 16 num_samples 18400 loss 0.2141346155681238\n",
      "Epoch 16 num_samples 18500 loss 0.12969806621822141\n",
      "Epoch 17 num_samples 0 loss 0.13068024456107982\n",
      "Epoch 17 num_samples 100 loss 0.16053835403665867\n",
      "Epoch 17 num_samples 200 loss 0.11772951253797909\n",
      "Epoch 17 num_samples 300 loss 0.1284846624573999\n",
      "Epoch 17 num_samples 400 loss 0.10528785966755577\n",
      "Epoch 17 num_samples 500 loss 0.12837394936652516\n",
      "Epoch 17 num_samples 600 loss 0.1618264422028035\n",
      "Epoch 17 num_samples 700 loss 0.21512804532717425\n",
      "Epoch 17 num_samples 800 loss 0.17558750626611505\n",
      "Epoch 17 num_samples 900 loss 0.12285999687943548\n",
      "Epoch 17 num_samples 1000 loss 0.11944130452790588\n",
      "Epoch 17 num_samples 1100 loss 0.1739793974686708\n",
      "Epoch 17 num_samples 1200 loss 0.14222921231795269\n",
      "Epoch 17 num_samples 1300 loss 0.09833290778137549\n",
      "Epoch 17 num_samples 1400 loss 0.16711764756855374\n",
      "Epoch 17 num_samples 1500 loss 0.22826702040738575\n",
      "Epoch 17 num_samples 1600 loss 0.13097477315432776\n",
      "Epoch 17 num_samples 1700 loss 0.14221371706011415\n",
      "Epoch 17 num_samples 1800 loss 0.11675461968472507\n",
      "Epoch 17 num_samples 1900 loss 0.12145450067748284\n",
      "Epoch 17 num_samples 2000 loss 0.1989302632403671\n",
      "Epoch 17 num_samples 2100 loss 0.1095418592503077\n",
      "Epoch 17 num_samples 2200 loss 0.09191827264826266\n",
      "Epoch 17 num_samples 2300 loss 0.10845530468751922\n",
      "Epoch 17 num_samples 2400 loss 0.10973739857677564\n",
      "Epoch 17 num_samples 2500 loss 0.18113389269446167\n",
      "Epoch 17 num_samples 2600 loss 0.1572641336148567\n",
      "Epoch 17 num_samples 2700 loss 0.17203860589256031\n",
      "Epoch 17 num_samples 2800 loss 0.16097967098497956\n",
      "Epoch 17 num_samples 2900 loss 0.1494266481813971\n",
      "Epoch 17 num_samples 3000 loss 0.11322787775774204\n",
      "Epoch 17 num_samples 3100 loss 0.14033624407253814\n",
      "Epoch 17 num_samples 3200 loss 0.26732917962731373\n",
      "Epoch 17 num_samples 3300 loss 0.11306996522666926\n",
      "Epoch 17 num_samples 3400 loss 0.10767259475571304\n",
      "Epoch 17 num_samples 3500 loss 0.12527601511016473\n",
      "Epoch 17 num_samples 3600 loss 0.07847927872987669\n",
      "Epoch 17 num_samples 3700 loss 0.16328199251799405\n",
      "Epoch 17 num_samples 3800 loss 0.15057448659008382\n",
      "Epoch 17 num_samples 3900 loss 0.16388856210875624\n",
      "Epoch 17 num_samples 4000 loss 0.16349159278094863\n",
      "Epoch 17 num_samples 4100 loss 0.2348043852172616\n",
      "Epoch 17 num_samples 4200 loss 0.12951904148816656\n",
      "Epoch 17 num_samples 4300 loss 0.1538753476110153\n",
      "Epoch 17 num_samples 4400 loss 0.14142305833264768\n",
      "Epoch 17 num_samples 4500 loss 0.18411951531569962\n",
      "Epoch 17 num_samples 4600 loss 0.1511399053497948\n",
      "Epoch 17 num_samples 4700 loss 0.07466713364183634\n",
      "Epoch 17 num_samples 4800 loss 0.08920330023782412\n",
      "Epoch 17 num_samples 4900 loss 0.10355815439080188\n",
      "Epoch 17 num_samples 5000 loss 0.12062057208300414\n",
      "Epoch 17 num_samples 5100 loss 0.19183193939802923\n",
      "Epoch 17 num_samples 5200 loss 0.09100662095553845\n",
      "Epoch 17 num_samples 5300 loss 0.13309349095418901\n",
      "Epoch 17 num_samples 5400 loss 0.18107997309631338\n",
      "Epoch 17 num_samples 5500 loss 0.10769858157268819\n",
      "Epoch 17 num_samples 5600 loss 0.2190212016837787\n",
      "Epoch 17 num_samples 5700 loss 0.18225594467828468\n",
      "Epoch 17 num_samples 5800 loss 0.18751716498715368\n",
      "Epoch 17 num_samples 5900 loss 0.17148888537423126\n",
      "Epoch 17 num_samples 6000 loss 0.157944439375877\n",
      "Epoch 17 num_samples 6100 loss 0.09977524555601082\n",
      "Epoch 17 num_samples 6200 loss 0.1530186856523614\n",
      "Epoch 17 num_samples 6300 loss 0.17175753934993998\n",
      "Epoch 17 num_samples 6400 loss 0.11062280970679961\n",
      "Epoch 17 num_samples 6500 loss 0.09437075398019981\n",
      "Epoch 17 num_samples 6600 loss 0.20474812983598756\n",
      "Epoch 17 num_samples 6700 loss 0.08447951920212113\n",
      "Epoch 17 num_samples 6800 loss 0.06025740823768987\n",
      "Epoch 17 num_samples 6900 loss 0.2506072470750532\n",
      "Epoch 17 num_samples 7000 loss 0.20134336120575264\n",
      "Epoch 17 num_samples 7100 loss 0.10997143613671714\n",
      "Epoch 17 num_samples 7200 loss 0.12080345567268709\n",
      "Epoch 17 num_samples 7300 loss 0.1440596707263525\n",
      "Epoch 17 num_samples 7400 loss 0.11126700421409018\n",
      "Epoch 17 num_samples 7500 loss 0.20862398290948517\n",
      "Epoch 17 num_samples 7600 loss 0.13685774997016742\n",
      "Epoch 17 num_samples 7700 loss 0.20533781785677363\n",
      "Epoch 17 num_samples 7800 loss 0.07768974752227037\n",
      "Epoch 17 num_samples 7900 loss 0.15171922234173577\n",
      "Epoch 17 num_samples 8000 loss 0.08889039160257188\n",
      "Epoch 17 num_samples 8100 loss 0.12218509863873717\n",
      "Epoch 17 num_samples 8200 loss 0.12722161310740351\n",
      "Epoch 17 num_samples 8300 loss 0.1351566089893395\n",
      "Epoch 17 num_samples 8400 loss 0.11921112566362646\n",
      "Epoch 17 num_samples 8500 loss 0.15725704626313783\n",
      "Epoch 17 num_samples 8600 loss 0.09896396589067305\n",
      "Epoch 17 num_samples 8700 loss 0.12884634780015708\n",
      "Epoch 17 num_samples 8800 loss 0.1866402742568784\n",
      "Epoch 17 num_samples 8900 loss 0.1608969767747789\n",
      "Epoch 17 num_samples 9000 loss 0.1339437569493924\n",
      "Epoch 17 num_samples 9100 loss 0.13028105761937667\n",
      "Epoch 17 num_samples 9200 loss 0.1252579956100873\n",
      "Epoch 17 num_samples 9300 loss 0.13984076610074084\n",
      "Epoch 17 num_samples 9400 loss 0.10094281620256808\n",
      "Epoch 17 num_samples 9500 loss 0.15777235553177543\n",
      "Epoch 17 num_samples 9600 loss 0.09813628960453916\n",
      "Epoch 17 num_samples 9700 loss 0.16336246529810283\n",
      "Epoch 17 num_samples 9800 loss 0.08165914310169091\n",
      "Epoch 17 num_samples 9900 loss 0.22511274686651292\n",
      "Epoch 17 num_samples 10000 loss 0.12165632199866624\n",
      "Epoch 17 num_samples 10100 loss 0.07797796803399205\n",
      "Epoch 17 num_samples 10200 loss 0.20104563870990816\n",
      "Epoch 17 num_samples 10300 loss 0.15654037797103673\n",
      "Epoch 17 num_samples 10400 loss 0.15035048712684726\n",
      "Epoch 17 num_samples 10500 loss 0.11276091913725096\n",
      "Epoch 17 num_samples 10600 loss 0.1649822757673401\n",
      "Epoch 17 num_samples 10700 loss 0.11674534169923088\n",
      "Epoch 17 num_samples 10800 loss 0.1881472906136262\n",
      "Epoch 17 num_samples 10900 loss 0.11907118225295278\n",
      "Epoch 17 num_samples 11000 loss 0.07146107103539391\n",
      "Epoch 17 num_samples 11100 loss 0.14303245137393067\n",
      "Epoch 17 num_samples 11200 loss 0.12332664810069811\n",
      "Epoch 17 num_samples 11300 loss 0.2066996627491211\n",
      "Epoch 17 num_samples 11400 loss 0.18073274606484385\n",
      "Epoch 17 num_samples 11500 loss 0.10069804634652804\n",
      "Epoch 17 num_samples 11600 loss 0.11053990179471071\n",
      "Epoch 17 num_samples 11700 loss 0.15407441733680882\n",
      "Epoch 17 num_samples 11800 loss 0.11009104110201338\n",
      "Epoch 17 num_samples 11900 loss 0.12310001537061378\n",
      "Epoch 17 num_samples 12000 loss 0.0770196768691413\n",
      "Epoch 17 num_samples 12100 loss 0.12214967834253092\n",
      "Epoch 17 num_samples 12200 loss 0.17127733199985443\n",
      "Epoch 17 num_samples 12300 loss 0.08233319832006634\n",
      "Epoch 17 num_samples 12400 loss 0.1552451750543847\n",
      "Epoch 17 num_samples 12500 loss 0.1360978231136546\n",
      "Epoch 17 num_samples 12600 loss 0.14730033383096525\n",
      "Epoch 17 num_samples 12700 loss 0.14090559989466975\n",
      "Epoch 17 num_samples 12800 loss 0.20525233669843368\n",
      "Epoch 17 num_samples 12900 loss 0.13025559724702393\n",
      "Epoch 17 num_samples 13000 loss 0.10653923956617531\n",
      "Epoch 17 num_samples 13100 loss 0.20616255122800212\n",
      "Epoch 17 num_samples 13200 loss 0.1041379931421686\n",
      "Epoch 17 num_samples 13300 loss 0.09471809127887658\n",
      "Epoch 17 num_samples 13400 loss 0.0781685736768299\n",
      "Epoch 17 num_samples 13500 loss 0.10801987138310125\n",
      "Epoch 17 num_samples 13600 loss 0.16767976938926657\n",
      "Epoch 17 num_samples 13700 loss 0.1365879531449355\n",
      "Epoch 17 num_samples 13800 loss 0.1150859168940391\n",
      "Epoch 17 num_samples 13900 loss 0.08165284159237146\n",
      "Epoch 17 num_samples 14000 loss 0.08336204290018881\n",
      "Epoch 17 num_samples 14100 loss 0.12051193371584581\n",
      "Epoch 17 num_samples 14200 loss 0.07972766130884516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 num_samples 14300 loss 0.14964102539419152\n",
      "Epoch 17 num_samples 14400 loss 0.14264381796719255\n",
      "Epoch 17 num_samples 14500 loss 0.15489309319091138\n",
      "Epoch 17 num_samples 14600 loss 0.11559859165511482\n",
      "Epoch 17 num_samples 14700 loss 0.1274301845521513\n",
      "Epoch 17 num_samples 14800 loss 0.09388921234242625\n",
      "Epoch 17 num_samples 14900 loss 0.18764270810654135\n",
      "Epoch 17 num_samples 15000 loss 0.09572846372477738\n",
      "Epoch 17 num_samples 15100 loss 0.143648237573788\n",
      "Epoch 17 num_samples 15200 loss 0.18816712224826973\n",
      "Epoch 17 num_samples 15300 loss 0.13092616219299213\n",
      "Epoch 17 num_samples 15400 loss 0.0954580586513844\n",
      "Epoch 17 num_samples 15500 loss 0.14662744968177274\n",
      "Epoch 17 num_samples 15600 loss 0.12553588990195608\n",
      "Epoch 17 num_samples 15700 loss 0.08871957444888375\n",
      "Epoch 17 num_samples 15800 loss 0.19905692815924708\n",
      "Epoch 17 num_samples 15900 loss 0.07487491923266995\n",
      "Epoch 17 num_samples 16000 loss 0.1884982803357991\n",
      "Epoch 17 num_samples 16100 loss 0.1021502951969532\n",
      "Epoch 17 num_samples 16200 loss 0.12841038196178128\n",
      "Epoch 17 num_samples 16300 loss 0.17606856542193491\n",
      "Epoch 17 num_samples 16400 loss 0.13732081265187893\n",
      "Epoch 17 num_samples 16500 loss 0.1368774073706419\n",
      "Epoch 17 num_samples 16600 loss 0.1671333201835956\n",
      "Epoch 17 num_samples 16700 loss 0.0988469527225609\n",
      "Epoch 17 num_samples 16800 loss 0.09559515379987772\n",
      "Epoch 17 num_samples 16900 loss 0.1261786952019036\n",
      "Epoch 17 num_samples 17000 loss 0.08691796923764838\n",
      "Epoch 17 num_samples 17100 loss 0.2413965004476657\n",
      "Epoch 17 num_samples 17200 loss 0.13995338321223447\n",
      "Epoch 17 num_samples 17300 loss 0.1587723123353432\n",
      "Epoch 17 num_samples 17400 loss 0.17201998661679724\n",
      "Epoch 17 num_samples 17500 loss 0.1592419561014342\n",
      "Epoch 17 num_samples 17600 loss 0.15932250240788023\n",
      "Epoch 17 num_samples 17700 loss 0.0969993278385638\n",
      "Epoch 17 num_samples 17800 loss 0.158220383700783\n",
      "Epoch 17 num_samples 17900 loss 0.1575501577530625\n",
      "Epoch 17 num_samples 18000 loss 0.08988437015953821\n",
      "Epoch 17 num_samples 18100 loss 0.1320689274473257\n",
      "Epoch 17 num_samples 18200 loss 0.13236854651172292\n",
      "Epoch 17 num_samples 18300 loss 0.1075403272527846\n",
      "Epoch 17 num_samples 18400 loss 0.19926967544003538\n",
      "Epoch 17 num_samples 18500 loss 0.11992733887865584\n",
      "Epoch 18 num_samples 0 loss 0.11860440724126452\n",
      "Epoch 18 num_samples 100 loss 0.1493756990242618\n",
      "Epoch 18 num_samples 200 loss 0.10607727130828405\n",
      "Epoch 18 num_samples 300 loss 0.11435199551870408\n",
      "Epoch 18 num_samples 400 loss 0.09698178134849446\n",
      "Epoch 18 num_samples 500 loss 0.11939488387993911\n",
      "Epoch 18 num_samples 600 loss 0.1515723325079956\n",
      "Epoch 18 num_samples 700 loss 0.20195061619879634\n",
      "Epoch 18 num_samples 800 loss 0.15854606951777103\n",
      "Epoch 18 num_samples 900 loss 0.11631584008348245\n",
      "Epoch 18 num_samples 1000 loss 0.10864181752598694\n",
      "Epoch 18 num_samples 1100 loss 0.16384251080866682\n",
      "Epoch 18 num_samples 1200 loss 0.12938545326939335\n",
      "Epoch 18 num_samples 1300 loss 0.09204356706522807\n",
      "Epoch 18 num_samples 1400 loss 0.15308038732810428\n",
      "Epoch 18 num_samples 1500 loss 0.21818310658789986\n",
      "Epoch 18 num_samples 1600 loss 0.12156448215569099\n",
      "Epoch 18 num_samples 1700 loss 0.12860469096314933\n",
      "Epoch 18 num_samples 1800 loss 0.10611355363282211\n",
      "Epoch 18 num_samples 1900 loss 0.11216018074965436\n",
      "Epoch 18 num_samples 2000 loss 0.18354056517829606\n",
      "Epoch 18 num_samples 2100 loss 0.09842995826221547\n",
      "Epoch 18 num_samples 2200 loss 0.08493953340110531\n",
      "Epoch 18 num_samples 2300 loss 0.09700262875664016\n",
      "Epoch 18 num_samples 2400 loss 0.10145836515839662\n",
      "Epoch 18 num_samples 2500 loss 0.16803436627914528\n",
      "Epoch 18 num_samples 2600 loss 0.143876151350241\n",
      "Epoch 18 num_samples 2700 loss 0.1608650023447121\n",
      "Epoch 18 num_samples 2800 loss 0.14982873746555186\n",
      "Epoch 18 num_samples 2900 loss 0.1372918896160219\n",
      "Epoch 18 num_samples 3000 loss 0.1044402752929955\n",
      "Epoch 18 num_samples 3100 loss 0.1325138516753943\n",
      "Epoch 18 num_samples 3200 loss 0.25389853369863885\n",
      "Epoch 18 num_samples 3300 loss 0.10617783881826214\n",
      "Epoch 18 num_samples 3400 loss 0.09486482728757585\n",
      "Epoch 18 num_samples 3500 loss 0.11620030164612682\n",
      "Epoch 18 num_samples 3600 loss 0.07181714038780093\n",
      "Epoch 18 num_samples 3700 loss 0.1545264997775527\n",
      "Epoch 18 num_samples 3800 loss 0.13786326794858197\n",
      "Epoch 18 num_samples 3900 loss 0.14855215687415468\n",
      "Epoch 18 num_samples 4000 loss 0.14990747923087494\n",
      "Epoch 18 num_samples 4100 loss 0.21947543350870716\n",
      "Epoch 18 num_samples 4200 loss 0.11997951138051886\n",
      "Epoch 18 num_samples 4300 loss 0.14239031096276303\n",
      "Epoch 18 num_samples 4400 loss 0.13400209354599665\n",
      "Epoch 18 num_samples 4500 loss 0.1723624888494637\n",
      "Epoch 18 num_samples 4600 loss 0.13742093266892824\n",
      "Epoch 18 num_samples 4700 loss 0.06843065429560445\n",
      "Epoch 18 num_samples 4800 loss 0.0820105870935164\n",
      "Epoch 18 num_samples 4900 loss 0.09229622471784196\n",
      "Epoch 18 num_samples 5000 loss 0.10873094531203334\n",
      "Epoch 18 num_samples 5100 loss 0.1745370091605596\n",
      "Epoch 18 num_samples 5200 loss 0.0812364647256154\n",
      "Epoch 18 num_samples 5300 loss 0.12074907018538461\n",
      "Epoch 18 num_samples 5400 loss 0.1659324320645073\n",
      "Epoch 18 num_samples 5500 loss 0.09798317366924075\n",
      "Epoch 18 num_samples 5600 loss 0.21213426696284843\n",
      "Epoch 18 num_samples 5700 loss 0.16880062735286827\n",
      "Epoch 18 num_samples 5800 loss 0.17230254010601917\n",
      "Epoch 18 num_samples 5900 loss 0.1615501294794306\n",
      "Epoch 18 num_samples 6000 loss 0.14812194159656314\n",
      "Epoch 18 num_samples 6100 loss 0.09248478217827476\n",
      "Epoch 18 num_samples 6200 loss 0.1421023273904112\n",
      "Epoch 18 num_samples 6300 loss 0.16044186572097105\n",
      "Epoch 18 num_samples 6400 loss 0.10074854248408524\n",
      "Epoch 18 num_samples 6500 loss 0.0859802764167033\n",
      "Epoch 18 num_samples 6600 loss 0.18705523088929613\n",
      "Epoch 18 num_samples 6700 loss 0.07640504852850823\n",
      "Epoch 18 num_samples 6800 loss 0.05584745839881917\n",
      "Epoch 18 num_samples 6900 loss 0.2334001973950617\n",
      "Epoch 18 num_samples 7000 loss 0.18810276730403794\n",
      "Epoch 18 num_samples 7100 loss 0.10098718796380478\n",
      "Epoch 18 num_samples 7200 loss 0.1087345809890718\n",
      "Epoch 18 num_samples 7300 loss 0.1301612773806644\n",
      "Epoch 18 num_samples 7400 loss 0.10218823814423579\n",
      "Epoch 18 num_samples 7500 loss 0.19408324515936315\n",
      "Epoch 18 num_samples 7600 loss 0.12365013503388919\n",
      "Epoch 18 num_samples 7700 loss 0.1916362473885082\n",
      "Epoch 18 num_samples 7800 loss 0.07224303565447786\n",
      "Epoch 18 num_samples 7900 loss 0.13832399250691751\n",
      "Epoch 18 num_samples 8000 loss 0.0826293161479368\n",
      "Epoch 18 num_samples 8100 loss 0.11062126192535875\n",
      "Epoch 18 num_samples 8200 loss 0.1202555788512321\n",
      "Epoch 18 num_samples 8300 loss 0.12569656721873798\n",
      "Epoch 18 num_samples 8400 loss 0.10825132500555654\n",
      "Epoch 18 num_samples 8500 loss 0.14633395187131343\n",
      "Epoch 18 num_samples 8600 loss 0.09286683598191313\n",
      "Epoch 18 num_samples 8700 loss 0.12020930726132029\n",
      "Epoch 18 num_samples 8800 loss 0.17516882842107365\n",
      "Epoch 18 num_samples 8900 loss 0.14631673718702082\n",
      "Epoch 18 num_samples 9000 loss 0.12161869590220237\n",
      "Epoch 18 num_samples 9100 loss 0.11988043075069506\n",
      "Epoch 18 num_samples 9200 loss 0.11495970737157753\n",
      "Epoch 18 num_samples 9300 loss 0.12626808512406346\n",
      "Epoch 18 num_samples 9400 loss 0.09333057559949719\n",
      "Epoch 18 num_samples 9500 loss 0.14435251098719284\n",
      "Epoch 18 num_samples 9600 loss 0.09087206549511816\n",
      "Epoch 18 num_samples 9700 loss 0.15044448675005395\n",
      "Epoch 18 num_samples 9800 loss 0.07470892166043314\n",
      "Epoch 18 num_samples 9900 loss 0.2083723208305215\n",
      "Epoch 18 num_samples 10000 loss 0.1155343036681454\n",
      "Epoch 18 num_samples 10100 loss 0.0733181071652555\n",
      "Epoch 18 num_samples 10200 loss 0.1908507774412321\n",
      "Epoch 18 num_samples 10300 loss 0.14387614928135617\n",
      "Epoch 18 num_samples 10400 loss 0.13950486445476326\n",
      "Epoch 18 num_samples 10500 loss 0.10319378171683981\n",
      "Epoch 18 num_samples 10600 loss 0.15576804450266016\n",
      "Epoch 18 num_samples 10700 loss 0.10771323326161732\n",
      "Epoch 18 num_samples 10800 loss 0.17589760392217926\n",
      "Epoch 18 num_samples 10900 loss 0.10938423045127543\n",
      "Epoch 18 num_samples 11000 loss 0.06683243142514236\n",
      "Epoch 18 num_samples 11100 loss 0.1293783906082018\n",
      "Epoch 18 num_samples 11200 loss 0.11343771458607571\n",
      "Epoch 18 num_samples 11300 loss 0.19254675039397984\n",
      "Epoch 18 num_samples 11400 loss 0.16831693134567857\n",
      "Epoch 18 num_samples 11500 loss 0.09456108910320121\n",
      "Epoch 18 num_samples 11600 loss 0.09966869585345496\n",
      "Epoch 18 num_samples 11700 loss 0.1421807900363915\n",
      "Epoch 18 num_samples 11800 loss 0.10220928617188266\n",
      "Epoch 18 num_samples 11900 loss 0.1133306312365248\n",
      "Epoch 18 num_samples 12000 loss 0.0703269223603177\n",
      "Epoch 18 num_samples 12100 loss 0.1140083358063676\n",
      "Epoch 18 num_samples 12200 loss 0.16002852170662596\n",
      "Epoch 18 num_samples 12300 loss 0.07535828872504698\n",
      "Epoch 18 num_samples 12400 loss 0.14414904342466708\n",
      "Epoch 18 num_samples 12500 loss 0.12498062815194143\n",
      "Epoch 18 num_samples 12600 loss 0.1389087011045124\n",
      "Epoch 18 num_samples 12700 loss 0.13227073256241212\n",
      "Epoch 18 num_samples 12800 loss 0.18822892494846358\n",
      "Epoch 18 num_samples 12900 loss 0.12029370592555816\n",
      "Epoch 18 num_samples 13000 loss 0.09563309648141537\n",
      "Epoch 18 num_samples 13100 loss 0.19412676828247113\n",
      "Epoch 18 num_samples 13200 loss 0.09694044085376241\n",
      "Epoch 18 num_samples 13300 loss 0.08839999392425436\n",
      "Epoch 18 num_samples 13400 loss 0.06978577899344426\n",
      "Epoch 18 num_samples 13500 loss 0.09800327871911275\n",
      "Epoch 18 num_samples 13600 loss 0.15421254602669332\n",
      "Epoch 18 num_samples 13700 loss 0.12384051565273588\n",
      "Epoch 18 num_samples 13800 loss 0.10663111502440109\n",
      "Epoch 18 num_samples 13900 loss 0.0722215976752628\n",
      "Epoch 18 num_samples 14000 loss 0.0773978922912685\n",
      "Epoch 18 num_samples 14100 loss 0.11127903137535997\n",
      "Epoch 18 num_samples 14200 loss 0.07357028120454649\n",
      "Epoch 18 num_samples 14300 loss 0.13763179073762108\n",
      "Epoch 18 num_samples 14400 loss 0.12844416978198342\n",
      "Epoch 18 num_samples 14500 loss 0.1403444007527969\n",
      "Epoch 18 num_samples 14600 loss 0.10489291007048922\n",
      "Epoch 18 num_samples 14700 loss 0.11582551127016552\n",
      "Epoch 18 num_samples 14800 loss 0.08622522117710049\n",
      "Epoch 18 num_samples 14900 loss 0.17341021354076466\n",
      "Epoch 18 num_samples 15000 loss 0.0878006979221297\n",
      "Epoch 18 num_samples 15100 loss 0.1310162500491014\n",
      "Epoch 18 num_samples 15200 loss 0.17646004106060698\n",
      "Epoch 18 num_samples 15300 loss 0.11825348357160703\n",
      "Epoch 18 num_samples 15400 loss 0.08706187752125444\n",
      "Epoch 18 num_samples 15500 loss 0.13869437994433426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 num_samples 15600 loss 0.11383923691755823\n",
      "Epoch 18 num_samples 15700 loss 0.08024030241265954\n",
      "Epoch 18 num_samples 15800 loss 0.18432845411869717\n",
      "Epoch 18 num_samples 15900 loss 0.06844414474326298\n",
      "Epoch 18 num_samples 16000 loss 0.16855027075273774\n",
      "Epoch 18 num_samples 16100 loss 0.09206390562839811\n",
      "Epoch 18 num_samples 16200 loss 0.12033851704282827\n",
      "Epoch 18 num_samples 16300 loss 0.16397971802331426\n",
      "Epoch 18 num_samples 16400 loss 0.12900312444591225\n",
      "Epoch 18 num_samples 16500 loss 0.12504053201532433\n",
      "Epoch 18 num_samples 16600 loss 0.15227524649553886\n",
      "Epoch 18 num_samples 16700 loss 0.08890063115723239\n",
      "Epoch 18 num_samples 16800 loss 0.0879278044679232\n",
      "Epoch 18 num_samples 16900 loss 0.11342195784640001\n",
      "Epoch 18 num_samples 17000 loss 0.07902052625846138\n",
      "Epoch 18 num_samples 17100 loss 0.2277178555772448\n",
      "Epoch 18 num_samples 17200 loss 0.1282730848841348\n",
      "Epoch 18 num_samples 17300 loss 0.14924728101290555\n",
      "Epoch 18 num_samples 17400 loss 0.15657659402524754\n",
      "Epoch 18 num_samples 17500 loss 0.14331551259294997\n",
      "Epoch 18 num_samples 17600 loss 0.14696625021773335\n",
      "Epoch 18 num_samples 17700 loss 0.08843586340044318\n",
      "Epoch 18 num_samples 17800 loss 0.14712182768096438\n",
      "Epoch 18 num_samples 17900 loss 0.14669423692834146\n",
      "Epoch 18 num_samples 18000 loss 0.08409461233377653\n",
      "Epoch 18 num_samples 18100 loss 0.12253102343772984\n",
      "Epoch 18 num_samples 18200 loss 0.12383928283613561\n",
      "Epoch 18 num_samples 18300 loss 0.09807794938409374\n",
      "Epoch 18 num_samples 18400 loss 0.18663673563066024\n",
      "Epoch 18 num_samples 18500 loss 0.11396419621718078\n",
      "Epoch 19 num_samples 0 loss 0.10718544881253775\n",
      "Epoch 19 num_samples 100 loss 0.13993032557698623\n",
      "Epoch 19 num_samples 200 loss 0.09759316890177441\n",
      "Epoch 19 num_samples 300 loss 0.10315601454091163\n",
      "Epoch 19 num_samples 400 loss 0.08919130430362557\n",
      "Epoch 19 num_samples 500 loss 0.11070524237730464\n",
      "Epoch 19 num_samples 600 loss 0.14270507829935894\n",
      "Epoch 19 num_samples 700 loss 0.1893199899474361\n",
      "Epoch 19 num_samples 800 loss 0.14245945114646633\n",
      "Epoch 19 num_samples 900 loss 0.10943654245427187\n",
      "Epoch 19 num_samples 1000 loss 0.10043982059771253\n",
      "Epoch 19 num_samples 1100 loss 0.15514208131554078\n",
      "Epoch 19 num_samples 1200 loss 0.11940555246348211\n",
      "Epoch 19 num_samples 1300 loss 0.08552105872952875\n",
      "Epoch 19 num_samples 1400 loss 0.14360918746350582\n",
      "Epoch 19 num_samples 1500 loss 0.20697615203659553\n",
      "Epoch 19 num_samples 1600 loss 0.11069277498652173\n",
      "Epoch 19 num_samples 1700 loss 0.1167989458127718\n",
      "Epoch 19 num_samples 1800 loss 0.09773451110717542\n",
      "Epoch 19 num_samples 1900 loss 0.10280802270344992\n",
      "Epoch 19 num_samples 2000 loss 0.16964282181369947\n",
      "Epoch 19 num_samples 2100 loss 0.08866353092688174\n",
      "Epoch 19 num_samples 2200 loss 0.07763786976168338\n",
      "Epoch 19 num_samples 2300 loss 0.08649419186716006\n",
      "Epoch 19 num_samples 2400 loss 0.09372385035483959\n",
      "Epoch 19 num_samples 2500 loss 0.15683286617437106\n",
      "Epoch 19 num_samples 2600 loss 0.1314291204826605\n",
      "Epoch 19 num_samples 2700 loss 0.14981807769143532\n",
      "Epoch 19 num_samples 2800 loss 0.1398759453923139\n",
      "Epoch 19 num_samples 2900 loss 0.12822158810270531\n",
      "Epoch 19 num_samples 3000 loss 0.09597939330975906\n",
      "Epoch 19 num_samples 3100 loss 0.12678444300863984\n",
      "Epoch 19 num_samples 3200 loss 0.2419309562628943\n",
      "Epoch 19 num_samples 3300 loss 0.10037833941451632\n",
      "Epoch 19 num_samples 3400 loss 0.08583921473228863\n",
      "Epoch 19 num_samples 3500 loss 0.10795647671640092\n",
      "Epoch 19 num_samples 3600 loss 0.06538986023011914\n",
      "Epoch 19 num_samples 3700 loss 0.14779266101505395\n",
      "Epoch 19 num_samples 3800 loss 0.1280229872322109\n",
      "Epoch 19 num_samples 3900 loss 0.13604065704465543\n",
      "Epoch 19 num_samples 4000 loss 0.13644103985160683\n",
      "Epoch 19 num_samples 4100 loss 0.20738900760672363\n",
      "Epoch 19 num_samples 4200 loss 0.11173697127758654\n",
      "Epoch 19 num_samples 4300 loss 0.1329780178126678\n",
      "Epoch 19 num_samples 4400 loss 0.12474475361385304\n",
      "Epoch 19 num_samples 4500 loss 0.1594315521660018\n",
      "Epoch 19 num_samples 4600 loss 0.12668914194446002\n",
      "Epoch 19 num_samples 4700 loss 0.0627453359601793\n",
      "Epoch 19 num_samples 4800 loss 0.0747004672700727\n",
      "Epoch 19 num_samples 4900 loss 0.08335949457093837\n",
      "Epoch 19 num_samples 5000 loss 0.09904202878624836\n",
      "Epoch 19 num_samples 5100 loss 0.1594317488135914\n",
      "Epoch 19 num_samples 5200 loss 0.07388612832692483\n",
      "Epoch 19 num_samples 5300 loss 0.11111563171627183\n",
      "Epoch 19 num_samples 5400 loss 0.15299355831752412\n",
      "Epoch 19 num_samples 5500 loss 0.09022471600020583\n",
      "Epoch 19 num_samples 5600 loss 0.2045953897159209\n",
      "Epoch 19 num_samples 5700 loss 0.15676285803301326\n",
      "Epoch 19 num_samples 5800 loss 0.1569678149779853\n",
      "Epoch 19 num_samples 5900 loss 0.1534205582487807\n",
      "Epoch 19 num_samples 6000 loss 0.1387093715971549\n",
      "Epoch 19 num_samples 6100 loss 0.08658777226487953\n",
      "Epoch 19 num_samples 6200 loss 0.12868075829258716\n",
      "Epoch 19 num_samples 6300 loss 0.14844864126795213\n",
      "Epoch 19 num_samples 6400 loss 0.09111594036570604\n",
      "Epoch 19 num_samples 6500 loss 0.07854350303157562\n",
      "Epoch 19 num_samples 6600 loss 0.17070499827826402\n",
      "Epoch 19 num_samples 6700 loss 0.06945617006757125\n",
      "Epoch 19 num_samples 6800 loss 0.05243050264309236\n",
      "Epoch 19 num_samples 6900 loss 0.21464459862489307\n",
      "Epoch 19 num_samples 7000 loss 0.1758079759720046\n",
      "Epoch 19 num_samples 7100 loss 0.0940488114354467\n",
      "Epoch 19 num_samples 7200 loss 0.09920637739067172\n",
      "Epoch 19 num_samples 7300 loss 0.11808720037904656\n",
      "Epoch 19 num_samples 7400 loss 0.09376051855624884\n",
      "Epoch 19 num_samples 7500 loss 0.18098112327399765\n",
      "Epoch 19 num_samples 7600 loss 0.11200587269099377\n",
      "Epoch 19 num_samples 7700 loss 0.17976186222643606\n",
      "Epoch 19 num_samples 7800 loss 0.06696881104135677\n",
      "Epoch 19 num_samples 7900 loss 0.12626604811320452\n",
      "Epoch 19 num_samples 8000 loss 0.07637457017842601\n",
      "Epoch 19 num_samples 8100 loss 0.10174414647768187\n",
      "Epoch 19 num_samples 8200 loss 0.1135039996476808\n",
      "Epoch 19 num_samples 8300 loss 0.11773822294361203\n",
      "Epoch 19 num_samples 8400 loss 0.09850485204698183\n",
      "Epoch 19 num_samples 8500 loss 0.13589388539262065\n",
      "Epoch 19 num_samples 8600 loss 0.08818861369496046\n",
      "Epoch 19 num_samples 8700 loss 0.11274935614298194\n",
      "Epoch 19 num_samples 8800 loss 0.16382432476077505\n",
      "Epoch 19 num_samples 8900 loss 0.13319190367401398\n",
      "Epoch 19 num_samples 9000 loss 0.11072591902304031\n",
      "Epoch 19 num_samples 9100 loss 0.11146364565634366\n",
      "Epoch 19 num_samples 9200 loss 0.10538379994942418\n",
      "Epoch 19 num_samples 9300 loss 0.11518097609625576\n",
      "Epoch 19 num_samples 9400 loss 0.08564588359508615\n",
      "Epoch 19 num_samples 9500 loss 0.1313568951603521\n",
      "Epoch 19 num_samples 9600 loss 0.0833792110872034\n",
      "Epoch 19 num_samples 9700 loss 0.13938022129295416\n",
      "Epoch 19 num_samples 9800 loss 0.0683519836699495\n",
      "Epoch 19 num_samples 9900 loss 0.19432800257629043\n",
      "Epoch 19 num_samples 10000 loss 0.10951570267933\n",
      "Epoch 19 num_samples 10100 loss 0.06850645227758363\n",
      "Epoch 19 num_samples 10200 loss 0.17920890667091185\n",
      "Epoch 19 num_samples 10300 loss 0.13109062330416033\n",
      "Epoch 19 num_samples 10400 loss 0.1311796940181168\n",
      "Epoch 19 num_samples 10500 loss 0.0940879330836497\n",
      "Epoch 19 num_samples 10600 loss 0.14697851616872284\n",
      "Epoch 19 num_samples 10700 loss 0.10057353682382324\n",
      "Epoch 19 num_samples 10800 loss 0.1648976237856958\n",
      "Epoch 19 num_samples 10900 loss 0.10001407299054693\n",
      "Epoch 19 num_samples 11000 loss 0.06218718469514647\n",
      "Epoch 19 num_samples 11100 loss 0.11805545710090573\n",
      "Epoch 19 num_samples 11200 loss 0.10292745244284647\n",
      "Epoch 19 num_samples 11300 loss 0.17971247017800246\n",
      "Epoch 19 num_samples 11400 loss 0.15764279252818264\n",
      "Epoch 19 num_samples 11500 loss 0.08860818869722595\n",
      "Epoch 19 num_samples 11600 loss 0.09133668594494317\n",
      "Epoch 19 num_samples 11700 loss 0.13113065386356257\n",
      "Epoch 19 num_samples 11800 loss 0.09564680477315082\n",
      "Epoch 19 num_samples 11900 loss 0.10384328611294352\n",
      "Epoch 19 num_samples 12000 loss 0.06415467298750309\n",
      "Epoch 19 num_samples 12100 loss 0.10718521798766055\n",
      "Epoch 19 num_samples 12200 loss 0.14992775257398944\n",
      "Epoch 19 num_samples 12300 loss 0.06952715715148412\n",
      "Epoch 19 num_samples 12400 loss 0.13432761663294474\n",
      "Epoch 19 num_samples 12500 loss 0.11554228901954289\n",
      "Epoch 19 num_samples 12600 loss 0.13127087076508695\n",
      "Epoch 19 num_samples 12700 loss 0.12252502497921433\n",
      "Epoch 19 num_samples 12800 loss 0.1749419006414711\n",
      "Epoch 19 num_samples 12900 loss 0.11214481117643395\n",
      "Epoch 19 num_samples 13000 loss 0.08741335760869026\n",
      "Epoch 19 num_samples 13100 loss 0.18381310390847078\n",
      "Epoch 19 num_samples 13200 loss 0.08946726656371734\n",
      "Epoch 19 num_samples 13300 loss 0.08202971399457923\n",
      "Epoch 19 num_samples 13400 loss 0.06252500453548834\n",
      "Epoch 19 num_samples 13500 loss 0.08957997983172522\n",
      "Epoch 19 num_samples 13600 loss 0.1433916839034703\n",
      "Epoch 19 num_samples 13700 loss 0.11366040882128953\n",
      "Epoch 19 num_samples 13800 loss 0.09910505940457057\n",
      "Epoch 19 num_samples 13900 loss 0.06442841776262308\n",
      "Epoch 19 num_samples 14000 loss 0.0720103817114879\n",
      "Epoch 19 num_samples 14100 loss 0.10275091748097949\n",
      "Epoch 19 num_samples 14200 loss 0.06866945463562374\n",
      "Epoch 19 num_samples 14300 loss 0.1270001024036115\n",
      "Epoch 19 num_samples 14400 loss 0.11629072554586774\n",
      "Epoch 19 num_samples 14500 loss 0.12664785218068345\n",
      "Epoch 19 num_samples 14600 loss 0.0961249422581254\n",
      "Epoch 19 num_samples 14700 loss 0.10736113448605561\n",
      "Epoch 19 num_samples 14800 loss 0.07957161282153578\n",
      "Epoch 19 num_samples 14900 loss 0.16142488688469736\n",
      "Epoch 19 num_samples 15000 loss 0.08064789714975937\n",
      "Epoch 19 num_samples 15100 loss 0.12054201517078827\n",
      "Epoch 19 num_samples 15200 loss 0.1647903979953724\n",
      "Epoch 19 num_samples 15300 loss 0.10716392111734065\n",
      "Epoch 19 num_samples 15400 loss 0.07994991057924591\n",
      "Epoch 19 num_samples 15500 loss 0.13191339560307416\n",
      "Epoch 19 num_samples 15600 loss 0.10391836014488379\n",
      "Epoch 19 num_samples 15700 loss 0.0730664940736183\n",
      "Epoch 19 num_samples 15800 loss 0.17109839862296494\n",
      "Epoch 19 num_samples 15900 loss 0.06285103706423131\n",
      "Epoch 19 num_samples 16000 loss 0.15130113285043154\n",
      "Epoch 19 num_samples 16100 loss 0.08443611165897963\n",
      "Epoch 19 num_samples 16200 loss 0.11230619628780893\n",
      "Epoch 19 num_samples 16300 loss 0.15246926591531365\n",
      "Epoch 19 num_samples 16400 loss 0.12009186233158392\n",
      "Epoch 19 num_samples 16500 loss 0.11514469928654783\n",
      "Epoch 19 num_samples 16600 loss 0.1399804928673787\n",
      "Epoch 19 num_samples 16700 loss 0.08076198862774288\n",
      "Epoch 19 num_samples 16800 loss 0.08205406327827651\n",
      "Epoch 19 num_samples 16900 loss 0.10219314829381783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 num_samples 17000 loss 0.07191576925483424\n",
      "Epoch 19 num_samples 17100 loss 0.21495540730083923\n",
      "Epoch 19 num_samples 17200 loss 0.12031347256841746\n",
      "Epoch 19 num_samples 17300 loss 0.13980012071348913\n",
      "Epoch 19 num_samples 17400 loss 0.14111970490634046\n",
      "Epoch 19 num_samples 17500 loss 0.12916704475172675\n",
      "Epoch 19 num_samples 17600 loss 0.13652808289462817\n",
      "Epoch 19 num_samples 17700 loss 0.08126113485068164\n",
      "Epoch 19 num_samples 17800 loss 0.13591990809390736\n",
      "Epoch 19 num_samples 17900 loss 0.13694026588401045\n",
      "Epoch 19 num_samples 18000 loss 0.07821922063864281\n",
      "Epoch 19 num_samples 18100 loss 0.11259857759641015\n",
      "Epoch 19 num_samples 18200 loss 0.11369828849490116\n",
      "Epoch 19 num_samples 18300 loss 0.08979338405437717\n",
      "Epoch 19 num_samples 18400 loss 0.17412091593479972\n",
      "Epoch 19 num_samples 18500 loss 0.10703036385863095\n",
      "Epoch 20 num_samples 0 loss 0.09590358007084795\n",
      "Epoch 20 num_samples 100 loss 0.1318970408212535\n",
      "Epoch 20 num_samples 200 loss 0.08951738364983923\n",
      "Epoch 20 num_samples 300 loss 0.09464464724044891\n",
      "Epoch 20 num_samples 400 loss 0.08343052631693025\n",
      "Epoch 20 num_samples 500 loss 0.10406826637153006\n",
      "Epoch 20 num_samples 600 loss 0.1344969492464885\n",
      "Epoch 20 num_samples 700 loss 0.17695079912485723\n",
      "Epoch 20 num_samples 800 loss 0.1282318124062102\n",
      "Epoch 20 num_samples 900 loss 0.10231748518217433\n",
      "Epoch 20 num_samples 1000 loss 0.09328240865577056\n",
      "Epoch 20 num_samples 1100 loss 0.1473696262383641\n",
      "Epoch 20 num_samples 1200 loss 0.11082787899735984\n",
      "Epoch 20 num_samples 1300 loss 0.07963025204736132\n",
      "Epoch 20 num_samples 1400 loss 0.13297458866696726\n",
      "Epoch 20 num_samples 1500 loss 0.19654595378215475\n",
      "Epoch 20 num_samples 1600 loss 0.101756899516426\n",
      "Epoch 20 num_samples 1700 loss 0.10647662001614674\n",
      "Epoch 20 num_samples 1800 loss 0.09053211764116675\n",
      "Epoch 20 num_samples 1900 loss 0.09518307015387834\n",
      "Epoch 20 num_samples 2000 loss 0.1580887820710947\n",
      "Epoch 20 num_samples 2100 loss 0.08077894855437727\n",
      "Epoch 20 num_samples 2200 loss 0.07198883649525006\n",
      "Epoch 20 num_samples 2300 loss 0.0780149420853176\n",
      "Epoch 20 num_samples 2400 loss 0.08698696992611163\n",
      "Epoch 20 num_samples 2500 loss 0.14521555185666107\n",
      "Epoch 20 num_samples 2600 loss 0.12173179173088446\n",
      "Epoch 20 num_samples 2700 loss 0.1403180438729545\n",
      "Epoch 20 num_samples 2800 loss 0.13093137943946997\n",
      "Epoch 20 num_samples 2900 loss 0.11897515246840154\n",
      "Epoch 20 num_samples 3000 loss 0.08935854405349662\n",
      "Epoch 20 num_samples 3100 loss 0.11829823298199774\n",
      "Epoch 20 num_samples 3200 loss 0.2290600441067284\n",
      "Epoch 20 num_samples 3300 loss 0.09610863432515139\n",
      "Epoch 20 num_samples 3400 loss 0.07801826419236722\n",
      "Epoch 20 num_samples 3500 loss 0.10029541017144698\n",
      "Epoch 20 num_samples 3600 loss 0.060461876248957866\n",
      "Epoch 20 num_samples 3700 loss 0.14139425003627223\n",
      "Epoch 20 num_samples 3800 loss 0.11768303707582914\n",
      "Epoch 20 num_samples 3900 loss 0.1252789113819265\n",
      "Epoch 20 num_samples 4000 loss 0.12716325330460354\n",
      "Epoch 20 num_samples 4100 loss 0.1938955452336787\n",
      "Epoch 20 num_samples 4200 loss 0.10331499361762639\n",
      "Epoch 20 num_samples 4300 loss 0.12383836969927409\n",
      "Epoch 20 num_samples 4400 loss 0.118366472858186\n",
      "Epoch 20 num_samples 4500 loss 0.1494568540831532\n",
      "Epoch 20 num_samples 4600 loss 0.11725697541627497\n",
      "Epoch 20 num_samples 4700 loss 0.05873658916744585\n",
      "Epoch 20 num_samples 4800 loss 0.06830082930367903\n",
      "Epoch 20 num_samples 4900 loss 0.07592843468677364\n",
      "Epoch 20 num_samples 5000 loss 0.0902415461105157\n",
      "Epoch 20 num_samples 5100 loss 0.1451852438063224\n",
      "Epoch 20 num_samples 5200 loss 0.06797208137861226\n",
      "Epoch 20 num_samples 5300 loss 0.10057656132188204\n",
      "Epoch 20 num_samples 5400 loss 0.14068868112607227\n",
      "Epoch 20 num_samples 5500 loss 0.08265119309941489\n",
      "Epoch 20 num_samples 5600 loss 0.1962250276843274\n",
      "Epoch 20 num_samples 5700 loss 0.1457847393154537\n",
      "Epoch 20 num_samples 5800 loss 0.14574071070072386\n",
      "Epoch 20 num_samples 5900 loss 0.14339769993286552\n",
      "Epoch 20 num_samples 6000 loss 0.13089326198305468\n",
      "Epoch 20 num_samples 6100 loss 0.08024125966945954\n",
      "Epoch 20 num_samples 6200 loss 0.11898132205374902\n",
      "Epoch 20 num_samples 6300 loss 0.1392278256012701\n",
      "Epoch 20 num_samples 6400 loss 0.08470768128687607\n",
      "Epoch 20 num_samples 6500 loss 0.07244527585595924\n",
      "Epoch 20 num_samples 6600 loss 0.15642738320410202\n",
      "Epoch 20 num_samples 6700 loss 0.0634161496703539\n",
      "Epoch 20 num_samples 6800 loss 0.04925997213208315\n",
      "Epoch 20 num_samples 6900 loss 0.19773484751746714\n",
      "Epoch 20 num_samples 7000 loss 0.16503320580772615\n",
      "Epoch 20 num_samples 7100 loss 0.08725700317273916\n",
      "Epoch 20 num_samples 7200 loss 0.09054689970229209\n",
      "Epoch 20 num_samples 7300 loss 0.10698177176947851\n",
      "Epoch 20 num_samples 7400 loss 0.08794946726759761\n",
      "Epoch 20 num_samples 7500 loss 0.1682527235564673\n",
      "Epoch 20 num_samples 7600 loss 0.10093714201427263\n",
      "Epoch 20 num_samples 7700 loss 0.1696373231316745\n",
      "Epoch 20 num_samples 7800 loss 0.062136920996185986\n",
      "Epoch 20 num_samples 7900 loss 0.11698051983620968\n",
      "Epoch 20 num_samples 8000 loss 0.07085713532326036\n",
      "Epoch 20 num_samples 8100 loss 0.09351818507402808\n",
      "Epoch 20 num_samples 8200 loss 0.10679071738003529\n",
      "Epoch 20 num_samples 8300 loss 0.1101491469034481\n",
      "Epoch 20 num_samples 8400 loss 0.08958505240316673\n",
      "Epoch 20 num_samples 8500 loss 0.12545448430162598\n",
      "Epoch 20 num_samples 8600 loss 0.08175085063657576\n",
      "Epoch 20 num_samples 8700 loss 0.10348596409719836\n",
      "Epoch 20 num_samples 8800 loss 0.15467793505793268\n",
      "Epoch 20 num_samples 8900 loss 0.12151744587583646\n",
      "Epoch 20 num_samples 9000 loss 0.1029983399275213\n",
      "Epoch 20 num_samples 9100 loss 0.10425305123236087\n",
      "Epoch 20 num_samples 9200 loss 0.09675933022604145\n",
      "Epoch 20 num_samples 9300 loss 0.10491471549214353\n",
      "Epoch 20 num_samples 9400 loss 0.07833439074044622\n",
      "Epoch 20 num_samples 9500 loss 0.1210446190468091\n",
      "Epoch 20 num_samples 9600 loss 0.07690600828683403\n",
      "Epoch 20 num_samples 9700 loss 0.12857215986352682\n",
      "Epoch 20 num_samples 9800 loss 0.06261127011230473\n",
      "Epoch 20 num_samples 9900 loss 0.18052195277814367\n",
      "Epoch 20 num_samples 10000 loss 0.103552113853629\n",
      "Epoch 20 num_samples 10100 loss 0.06432021511194334\n",
      "Epoch 20 num_samples 10200 loss 0.16820100821255543\n",
      "Epoch 20 num_samples 10300 loss 0.12241949245432807\n",
      "Epoch 20 num_samples 10400 loss 0.12239070657038688\n",
      "Epoch 20 num_samples 10500 loss 0.08640088612331161\n",
      "Epoch 20 num_samples 10600 loss 0.13824235093272644\n",
      "Epoch 20 num_samples 10700 loss 0.09280961832022971\n",
      "Epoch 20 num_samples 10800 loss 0.1555180016029601\n",
      "Epoch 20 num_samples 10900 loss 0.09171571335286482\n",
      "Epoch 20 num_samples 11000 loss 0.05828006614749141\n",
      "Epoch 20 num_samples 11100 loss 0.10836070422076764\n",
      "Epoch 20 num_samples 11200 loss 0.09413327810097742\n",
      "Epoch 20 num_samples 11300 loss 0.16811330195602253\n",
      "Epoch 20 num_samples 11400 loss 0.1469931994133463\n",
      "Epoch 20 num_samples 11500 loss 0.0839546584393619\n",
      "Epoch 20 num_samples 11600 loss 0.08416621958145004\n",
      "Epoch 20 num_samples 11700 loss 0.12191901815497058\n",
      "Epoch 20 num_samples 11800 loss 0.08883696527407031\n",
      "Epoch 20 num_samples 11900 loss 0.09593740639250607\n",
      "Epoch 20 num_samples 12000 loss 0.06000448371570909\n",
      "Epoch 20 num_samples 12100 loss 0.10099720138305018\n",
      "Epoch 20 num_samples 12200 loss 0.1406916500614312\n",
      "Epoch 20 num_samples 12300 loss 0.0635314710596476\n",
      "Epoch 20 num_samples 12400 loss 0.12498345091093079\n",
      "Epoch 20 num_samples 12500 loss 0.10737545318374077\n",
      "Epoch 20 num_samples 12600 loss 0.12261545204614743\n",
      "Epoch 20 num_samples 12700 loss 0.11432651008162602\n",
      "Epoch 20 num_samples 12800 loss 0.16136682442012243\n",
      "Epoch 20 num_samples 12900 loss 0.10413166067468943\n",
      "Epoch 20 num_samples 13000 loss 0.07969780676729338\n",
      "Epoch 20 num_samples 13100 loss 0.17441843723165584\n",
      "Epoch 20 num_samples 13200 loss 0.08301162259795865\n",
      "Epoch 20 num_samples 13300 loss 0.07672407682200089\n",
      "Epoch 20 num_samples 13400 loss 0.055955118785300725\n",
      "Epoch 20 num_samples 13500 loss 0.08179582512252419\n",
      "Epoch 20 num_samples 13600 loss 0.13374255737306304\n",
      "Epoch 20 num_samples 13700 loss 0.10483158943301657\n",
      "Epoch 20 num_samples 13800 loss 0.09224148581349643\n",
      "Epoch 20 num_samples 13900 loss 0.057079696246639625\n",
      "Epoch 20 num_samples 14000 loss 0.06772630087561078\n",
      "Epoch 20 num_samples 14100 loss 0.0956000435538168\n",
      "Epoch 20 num_samples 14200 loss 0.06366960824448462\n",
      "Epoch 20 num_samples 14300 loss 0.1167118657500728\n",
      "Epoch 20 num_samples 14400 loss 0.10609843980208943\n",
      "Epoch 20 num_samples 14500 loss 0.11658009613460645\n",
      "Epoch 20 num_samples 14600 loss 0.08830644752657951\n",
      "Epoch 20 num_samples 14700 loss 0.09960884728223533\n",
      "Epoch 20 num_samples 14800 loss 0.07408003149916285\n",
      "Epoch 20 num_samples 14900 loss 0.15013945998230127\n",
      "Epoch 20 num_samples 15000 loss 0.07532395679429961\n",
      "Epoch 20 num_samples 15100 loss 0.10978029964116053\n",
      "Epoch 20 num_samples 15200 loss 0.15436934512916417\n",
      "Epoch 20 num_samples 15300 loss 0.09774171233658865\n",
      "Epoch 20 num_samples 15400 loss 0.07280371048937483\n",
      "Epoch 20 num_samples 15500 loss 0.12581780545090857\n",
      "Epoch 20 num_samples 15600 loss 0.09562275296338825\n",
      "Epoch 20 num_samples 15700 loss 0.06664165054034021\n",
      "Epoch 20 num_samples 15800 loss 0.15783344637711283\n",
      "Epoch 20 num_samples 15900 loss 0.05834022917531282\n",
      "Epoch 20 num_samples 16000 loss 0.1372312427572743\n",
      "Epoch 20 num_samples 16100 loss 0.07706750774447568\n",
      "Epoch 20 num_samples 16200 loss 0.10455364211904168\n",
      "Epoch 20 num_samples 16300 loss 0.14218749331715463\n",
      "Epoch 20 num_samples 16400 loss 0.11315131155219142\n",
      "Epoch 20 num_samples 16500 loss 0.10669288954776278\n",
      "Epoch 20 num_samples 16600 loss 0.12931849390637656\n",
      "Epoch 20 num_samples 16700 loss 0.07201340415769567\n",
      "Epoch 20 num_samples 16800 loss 0.07570902304779674\n",
      "Epoch 20 num_samples 16900 loss 0.09215757024013817\n",
      "Epoch 20 num_samples 17000 loss 0.0663998877749351\n",
      "Epoch 20 num_samples 17100 loss 0.20344210538554164\n",
      "Epoch 20 num_samples 17200 loss 0.1129656562358018\n",
      "Epoch 20 num_samples 17300 loss 0.13129918026710263\n",
      "Epoch 20 num_samples 17400 loss 0.12683846593437473\n",
      "Epoch 20 num_samples 17500 loss 0.11560458336570605\n",
      "Epoch 20 num_samples 17600 loss 0.12497305384833685\n",
      "Epoch 20 num_samples 17700 loss 0.07447380649913274\n",
      "Epoch 20 num_samples 17800 loss 0.12584022988151766\n",
      "Epoch 20 num_samples 17900 loss 0.1298791525745067\n",
      "Epoch 20 num_samples 18000 loss 0.07325566155203628\n",
      "Epoch 20 num_samples 18100 loss 0.10461803046218669\n",
      "Epoch 20 num_samples 18200 loss 0.10798073019145624\n",
      "Epoch 20 num_samples 18300 loss 0.08325485607652268\n",
      "Epoch 20 num_samples 18400 loss 0.163362234059247\n",
      "Epoch 20 num_samples 18500 loss 0.10093902736144367\n",
      "Epoch 21 num_samples 0 loss 0.08768483560727873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 num_samples 100 loss 0.12326511658443191\n",
      "Epoch 21 num_samples 200 loss 0.08173913638755416\n",
      "Epoch 21 num_samples 300 loss 0.08507830259799416\n",
      "Epoch 21 num_samples 400 loss 0.07733599241249513\n",
      "Epoch 21 num_samples 500 loss 0.09708756843090864\n",
      "Epoch 21 num_samples 600 loss 0.1269323081904264\n",
      "Epoch 21 num_samples 700 loss 0.16401358336209224\n",
      "Epoch 21 num_samples 800 loss 0.11537191162723573\n",
      "Epoch 21 num_samples 900 loss 0.0979971171387761\n",
      "Epoch 21 num_samples 1000 loss 0.08672221533384829\n",
      "Epoch 21 num_samples 1100 loss 0.13911612670573817\n",
      "Epoch 21 num_samples 1200 loss 0.10200876410651796\n",
      "Epoch 21 num_samples 1300 loss 0.07404801734064537\n",
      "Epoch 21 num_samples 1400 loss 0.12378382027461463\n",
      "Epoch 21 num_samples 1500 loss 0.1865838240820704\n",
      "Epoch 21 num_samples 1600 loss 0.09353993544769461\n",
      "Epoch 21 num_samples 1700 loss 0.09644226251159022\n",
      "Epoch 21 num_samples 1800 loss 0.08375807156216725\n",
      "Epoch 21 num_samples 1900 loss 0.0892173654652491\n",
      "Epoch 21 num_samples 2000 loss 0.1435371449943671\n",
      "Epoch 21 num_samples 2100 loss 0.07311835451547266\n",
      "Epoch 21 num_samples 2200 loss 0.06707908906666596\n",
      "Epoch 21 num_samples 2300 loss 0.06974213966737139\n",
      "Epoch 21 num_samples 2400 loss 0.0812184518312418\n",
      "Epoch 21 num_samples 2500 loss 0.1350118690853011\n",
      "Epoch 21 num_samples 2600 loss 0.11351618655621283\n",
      "Epoch 21 num_samples 2700 loss 0.1293257208863298\n",
      "Epoch 21 num_samples 2800 loss 0.1205939647129199\n",
      "Epoch 21 num_samples 2900 loss 0.11078274410937858\n",
      "Epoch 21 num_samples 3000 loss 0.08338891895609626\n",
      "Epoch 21 num_samples 3100 loss 0.11191603728961734\n",
      "Epoch 21 num_samples 3200 loss 0.21845824723816654\n",
      "Epoch 21 num_samples 3300 loss 0.09279420207544681\n",
      "Epoch 21 num_samples 3400 loss 0.07212488405656575\n",
      "Epoch 21 num_samples 3500 loss 0.09363507862178612\n",
      "Epoch 21 num_samples 3600 loss 0.05541869372930992\n",
      "Epoch 21 num_samples 3700 loss 0.13419835945624464\n",
      "Epoch 21 num_samples 3800 loss 0.10787935117741158\n",
      "Epoch 21 num_samples 3900 loss 0.1154628339424931\n",
      "Epoch 21 num_samples 4000 loss 0.1169829184830417\n",
      "Epoch 21 num_samples 4100 loss 0.1811483187484433\n",
      "Epoch 21 num_samples 4200 loss 0.09634682110872672\n",
      "Epoch 21 num_samples 4300 loss 0.11383995953896323\n",
      "Epoch 21 num_samples 4400 loss 0.11148221654415964\n",
      "Epoch 21 num_samples 4500 loss 0.1391263952690533\n",
      "Epoch 21 num_samples 4600 loss 0.10794669099436044\n",
      "Epoch 21 num_samples 4700 loss 0.0542686131634833\n",
      "Epoch 21 num_samples 4800 loss 0.06265043412061519\n",
      "Epoch 21 num_samples 4900 loss 0.06941539520289938\n",
      "Epoch 21 num_samples 5000 loss 0.08256876152630122\n",
      "Epoch 21 num_samples 5100 loss 0.1313605247938728\n",
      "Epoch 21 num_samples 5200 loss 0.061112699285177915\n",
      "Epoch 21 num_samples 5300 loss 0.09270885469588253\n",
      "Epoch 21 num_samples 5400 loss 0.12987100570221513\n",
      "Epoch 21 num_samples 5500 loss 0.07557951249471336\n",
      "Epoch 21 num_samples 5600 loss 0.18955628578233416\n",
      "Epoch 21 num_samples 5700 loss 0.13773725591808225\n",
      "Epoch 21 num_samples 5800 loss 0.13288229286824066\n",
      "Epoch 21 num_samples 5900 loss 0.133391870004491\n",
      "Epoch 21 num_samples 6000 loss 0.12271200681565281\n",
      "Epoch 21 num_samples 6100 loss 0.07379965179566807\n",
      "Epoch 21 num_samples 6200 loss 0.10959692213218636\n",
      "Epoch 21 num_samples 6300 loss 0.13112609480127901\n",
      "Epoch 21 num_samples 6400 loss 0.0780806985167375\n",
      "Epoch 21 num_samples 6500 loss 0.06722325745630883\n",
      "Epoch 21 num_samples 6600 loss 0.14326808932369833\n",
      "Epoch 21 num_samples 6700 loss 0.058360303961261906\n",
      "Epoch 21 num_samples 6800 loss 0.04618795350420706\n",
      "Epoch 21 num_samples 6900 loss 0.18347841033879742\n",
      "Epoch 21 num_samples 7000 loss 0.15417673388291886\n",
      "Epoch 21 num_samples 7100 loss 0.08078955438008589\n",
      "Epoch 21 num_samples 7200 loss 0.08270274305731473\n",
      "Epoch 21 num_samples 7300 loss 0.09668599003121535\n",
      "Epoch 21 num_samples 7400 loss 0.0816116211870235\n",
      "Epoch 21 num_samples 7500 loss 0.1569996383420126\n",
      "Epoch 21 num_samples 7600 loss 0.09241295178095452\n",
      "Epoch 21 num_samples 7700 loss 0.15949504549453952\n",
      "Epoch 21 num_samples 7800 loss 0.057798096836759856\n",
      "Epoch 21 num_samples 7900 loss 0.10814901704898439\n",
      "Epoch 21 num_samples 8000 loss 0.06604260450632835\n",
      "Epoch 21 num_samples 8100 loss 0.0861544792653365\n",
      "Epoch 21 num_samples 8200 loss 0.10056396023756921\n",
      "Epoch 21 num_samples 8300 loss 0.10421039575454083\n",
      "Epoch 21 num_samples 8400 loss 0.08263274587051246\n",
      "Epoch 21 num_samples 8500 loss 0.11619101256424055\n",
      "Epoch 21 num_samples 8600 loss 0.07745426987897752\n",
      "Epoch 21 num_samples 8700 loss 0.09686936517384001\n",
      "Epoch 21 num_samples 8800 loss 0.14359471408636706\n",
      "Epoch 21 num_samples 8900 loss 0.11110669290560732\n",
      "Epoch 21 num_samples 9000 loss 0.09478090429703762\n",
      "Epoch 21 num_samples 9100 loss 0.09733682657952027\n",
      "Epoch 21 num_samples 9200 loss 0.08925892765162263\n",
      "Epoch 21 num_samples 9300 loss 0.09696934493605251\n",
      "Epoch 21 num_samples 9400 loss 0.07331787759005896\n",
      "Epoch 21 num_samples 9500 loss 0.11143668813023226\n",
      "Epoch 21 num_samples 9600 loss 0.0713636672110449\n",
      "Epoch 21 num_samples 9700 loss 0.11996545260200094\n",
      "Epoch 21 num_samples 9800 loss 0.057029422236391285\n",
      "Epoch 21 num_samples 9900 loss 0.16944722395714204\n",
      "Epoch 21 num_samples 10000 loss 0.09817823732487004\n",
      "Epoch 21 num_samples 10100 loss 0.06018209937452853\n",
      "Epoch 21 num_samples 10200 loss 0.15544656328064646\n",
      "Epoch 21 num_samples 10300 loss 0.11284589994859803\n",
      "Epoch 21 num_samples 10400 loss 0.11510148024836955\n",
      "Epoch 21 num_samples 10500 loss 0.07880736508530985\n",
      "Epoch 21 num_samples 10600 loss 0.13119843374607723\n",
      "Epoch 21 num_samples 10700 loss 0.08554971770056514\n",
      "Epoch 21 num_samples 10800 loss 0.14643790105192614\n",
      "Epoch 21 num_samples 10900 loss 0.08483112030790245\n",
      "Epoch 21 num_samples 11000 loss 0.05476015633916385\n",
      "Epoch 21 num_samples 11100 loss 0.09959785240683601\n",
      "Epoch 21 num_samples 11200 loss 0.08569164302754675\n",
      "Epoch 21 num_samples 11300 loss 0.1572745236155389\n",
      "Epoch 21 num_samples 11400 loss 0.1383438529377459\n",
      "Epoch 21 num_samples 11500 loss 0.07892889869850996\n",
      "Epoch 21 num_samples 11600 loss 0.07761494578337\n",
      "Epoch 21 num_samples 11700 loss 0.11199302472242334\n",
      "Epoch 21 num_samples 11800 loss 0.08327056867757619\n",
      "Epoch 21 num_samples 11900 loss 0.08841778113908155\n",
      "Epoch 21 num_samples 12000 loss 0.05600831474261001\n",
      "Epoch 21 num_samples 12100 loss 0.09562869905021644\n",
      "Epoch 21 num_samples 12200 loss 0.13159064380389932\n",
      "Epoch 21 num_samples 12300 loss 0.05908153760171798\n",
      "Epoch 21 num_samples 12400 loss 0.1170174958947075\n",
      "Epoch 21 num_samples 12500 loss 0.09907015228687\n",
      "Epoch 21 num_samples 12600 loss 0.1152224458746193\n",
      "Epoch 21 num_samples 12700 loss 0.10777754805792972\n",
      "Epoch 21 num_samples 12800 loss 0.14983569445654438\n",
      "Epoch 21 num_samples 12900 loss 0.09832225429583129\n",
      "Epoch 21 num_samples 13000 loss 0.07221868368265698\n",
      "Epoch 21 num_samples 13100 loss 0.16488586634573055\n",
      "Epoch 21 num_samples 13200 loss 0.07682559844934636\n",
      "Epoch 21 num_samples 13300 loss 0.07170767557391983\n",
      "Epoch 21 num_samples 13400 loss 0.05031198159639598\n",
      "Epoch 21 num_samples 13500 loss 0.07432705968414385\n",
      "Epoch 21 num_samples 13600 loss 0.12467090174043874\n",
      "Epoch 21 num_samples 13700 loss 0.0965388575287302\n",
      "Epoch 21 num_samples 13800 loss 0.08687630227177272\n",
      "Epoch 21 num_samples 13900 loss 0.05113419835692274\n",
      "Epoch 21 num_samples 14000 loss 0.0640643481008865\n",
      "Epoch 21 num_samples 14100 loss 0.08820442556087812\n",
      "Epoch 21 num_samples 14200 loss 0.059759385742284336\n",
      "Epoch 21 num_samples 14300 loss 0.10749045010681424\n",
      "Epoch 21 num_samples 14400 loss 0.09721933891226049\n",
      "Epoch 21 num_samples 14500 loss 0.10677892195514581\n",
      "Epoch 21 num_samples 14600 loss 0.0819611127617044\n",
      "Epoch 21 num_samples 14700 loss 0.0924178843090586\n",
      "Epoch 21 num_samples 14800 loss 0.06853946026128022\n",
      "Epoch 21 num_samples 14900 loss 0.1390447302194198\n",
      "Epoch 21 num_samples 15000 loss 0.06967340606651415\n",
      "Epoch 21 num_samples 15100 loss 0.10106966077124577\n",
      "Epoch 21 num_samples 15200 loss 0.14469365751685906\n",
      "Epoch 21 num_samples 15300 loss 0.08853964742051577\n",
      "Epoch 21 num_samples 15400 loss 0.06614668458467936\n",
      "Epoch 21 num_samples 15500 loss 0.11878893524954315\n",
      "Epoch 21 num_samples 15600 loss 0.08780760320548542\n",
      "Epoch 21 num_samples 15700 loss 0.060855855407657096\n",
      "Epoch 21 num_samples 15800 loss 0.14595040897589454\n",
      "Epoch 21 num_samples 15900 loss 0.054350376532247856\n",
      "Epoch 21 num_samples 16000 loss 0.1247699034317964\n",
      "Epoch 21 num_samples 16100 loss 0.07053054072660915\n",
      "Epoch 21 num_samples 16200 loss 0.09783212152670705\n",
      "Epoch 21 num_samples 16300 loss 0.13283418047858866\n",
      "Epoch 21 num_samples 16400 loss 0.10704341022321336\n",
      "Epoch 21 num_samples 16500 loss 0.09906422792252839\n",
      "Epoch 21 num_samples 16600 loss 0.11866333646954627\n",
      "Epoch 21 num_samples 16700 loss 0.0652745562766615\n",
      "Epoch 21 num_samples 16800 loss 0.07030281613727944\n",
      "Epoch 21 num_samples 16900 loss 0.08381469982149284\n",
      "Epoch 21 num_samples 17000 loss 0.06091405092022378\n",
      "Epoch 21 num_samples 17100 loss 0.19168367184370144\n",
      "Epoch 21 num_samples 17200 loss 0.10473784067088793\n",
      "Epoch 21 num_samples 17300 loss 0.12292193084003773\n",
      "Epoch 21 num_samples 17400 loss 0.11287321993526976\n",
      "Epoch 21 num_samples 17500 loss 0.103689158527068\n",
      "Epoch 21 num_samples 17600 loss 0.11359870311068936\n",
      "Epoch 21 num_samples 17700 loss 0.06794741432493807\n",
      "Epoch 21 num_samples 17800 loss 0.11658390977432638\n",
      "Epoch 21 num_samples 17900 loss 0.12153763787162727\n",
      "Epoch 21 num_samples 18000 loss 0.06832572885663787\n",
      "Epoch 21 num_samples 18100 loss 0.09768070687806771\n",
      "Epoch 21 num_samples 18200 loss 0.1008746181100689\n",
      "Epoch 21 num_samples 18300 loss 0.07690373879743968\n",
      "Epoch 21 num_samples 18400 loss 0.1511887731396257\n",
      "Epoch 21 num_samples 18500 loss 0.09420094619361606\n",
      "Epoch 22 num_samples 0 loss 0.07882873987529741\n",
      "Epoch 22 num_samples 100 loss 0.11589865811407307\n",
      "Epoch 22 num_samples 200 loss 0.07455015614340511\n",
      "Epoch 22 num_samples 300 loss 0.07779058649652361\n",
      "Epoch 22 num_samples 400 loss 0.07235503160667392\n",
      "Epoch 22 num_samples 500 loss 0.0913265566283151\n",
      "Epoch 22 num_samples 600 loss 0.11907722057295729\n",
      "Epoch 22 num_samples 700 loss 0.15331026470827797\n",
      "Epoch 22 num_samples 800 loss 0.10411799311875064\n",
      "Epoch 22 num_samples 900 loss 0.09216928996301398\n",
      "Epoch 22 num_samples 1000 loss 0.08009284672131184\n",
      "Epoch 22 num_samples 1100 loss 0.13201734963351605\n",
      "Epoch 22 num_samples 1200 loss 0.09429260949145571\n",
      "Epoch 22 num_samples 1300 loss 0.07034067739444622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 num_samples 1400 loss 0.11607829033627773\n",
      "Epoch 22 num_samples 1500 loss 0.1788294932300144\n",
      "Epoch 22 num_samples 1600 loss 0.0862146267589232\n",
      "Epoch 22 num_samples 1700 loss 0.08798451302086367\n",
      "Epoch 22 num_samples 1800 loss 0.0781893192983748\n",
      "Epoch 22 num_samples 1900 loss 0.08239742812973748\n",
      "Epoch 22 num_samples 2000 loss 0.1301615885383166\n",
      "Epoch 22 num_samples 2100 loss 0.06537070197927308\n",
      "Epoch 22 num_samples 2200 loss 0.06224089406926467\n",
      "Epoch 22 num_samples 2300 loss 0.06273595413175817\n",
      "Epoch 22 num_samples 2400 loss 0.07667905992351566\n",
      "Epoch 22 num_samples 2500 loss 0.1249647318365486\n",
      "Epoch 22 num_samples 2600 loss 0.10526801136207582\n",
      "Epoch 22 num_samples 2700 loss 0.11925202560712687\n",
      "Epoch 22 num_samples 2800 loss 0.11245781593910312\n",
      "Epoch 22 num_samples 2900 loss 0.1024317472850981\n",
      "Epoch 22 num_samples 3000 loss 0.07871059941486157\n",
      "Epoch 22 num_samples 3100 loss 0.103801178942938\n",
      "Epoch 22 num_samples 3200 loss 0.2089028146754381\n",
      "Epoch 22 num_samples 3300 loss 0.08947907633599084\n",
      "Epoch 22 num_samples 3400 loss 0.06658091234634819\n",
      "Epoch 22 num_samples 3500 loss 0.08622363189899536\n",
      "Epoch 22 num_samples 3600 loss 0.05132017187172485\n",
      "Epoch 22 num_samples 3700 loss 0.12651490132964907\n",
      "Epoch 22 num_samples 3800 loss 0.09864259361904945\n",
      "Epoch 22 num_samples 3900 loss 0.10625894926889995\n",
      "Epoch 22 num_samples 4000 loss 0.10585532567113455\n",
      "Epoch 22 num_samples 4100 loss 0.1689135162882892\n",
      "Epoch 22 num_samples 4200 loss 0.08832873207053321\n",
      "Epoch 22 num_samples 4300 loss 0.10483519164357873\n",
      "Epoch 22 num_samples 4400 loss 0.10458604426980758\n",
      "Epoch 22 num_samples 4500 loss 0.12936230120529857\n",
      "Epoch 22 num_samples 4600 loss 0.0995737252472961\n",
      "Epoch 22 num_samples 4700 loss 0.050803457822460596\n",
      "Epoch 22 num_samples 4800 loss 0.05872027551208591\n",
      "Epoch 22 num_samples 4900 loss 0.06436413134207161\n",
      "Epoch 22 num_samples 5000 loss 0.07535893055462722\n",
      "Epoch 22 num_samples 5100 loss 0.11963407934841186\n",
      "Epoch 22 num_samples 5200 loss 0.05605088307068327\n",
      "Epoch 22 num_samples 5300 loss 0.08514141980784977\n",
      "Epoch 22 num_samples 5400 loss 0.11845490570277327\n",
      "Epoch 22 num_samples 5500 loss 0.06944315694237052\n",
      "Epoch 22 num_samples 5600 loss 0.18295540000531227\n",
      "Epoch 22 num_samples 5700 loss 0.12980231659528843\n",
      "Epoch 22 num_samples 5800 loss 0.12197527835849228\n",
      "Epoch 22 num_samples 5900 loss 0.12610438422532583\n",
      "Epoch 22 num_samples 6000 loss 0.11636239123867766\n",
      "Epoch 22 num_samples 6100 loss 0.06983734038569064\n",
      "Epoch 22 num_samples 6200 loss 0.10043046053059497\n",
      "Epoch 22 num_samples 6300 loss 0.1228486874589804\n",
      "Epoch 22 num_samples 6400 loss 0.07184081331900599\n",
      "Epoch 22 num_samples 6500 loss 0.06241913889212907\n",
      "Epoch 22 num_samples 6600 loss 0.13114727386091996\n",
      "Epoch 22 num_samples 6700 loss 0.05334163936483231\n",
      "Epoch 22 num_samples 6800 loss 0.043600263890122705\n",
      "Epoch 22 num_samples 6900 loss 0.17084064643284472\n",
      "Epoch 22 num_samples 7000 loss 0.14454612725302501\n",
      "Epoch 22 num_samples 7100 loss 0.07439346647258308\n",
      "Epoch 22 num_samples 7200 loss 0.07551006662791102\n",
      "Epoch 22 num_samples 7300 loss 0.08891646599747613\n",
      "Epoch 22 num_samples 7400 loss 0.07475025059042288\n",
      "Epoch 22 num_samples 7500 loss 0.14660665200063522\n",
      "Epoch 22 num_samples 7600 loss 0.08518607313032095\n",
      "Epoch 22 num_samples 7700 loss 0.14936164209402356\n",
      "Epoch 22 num_samples 7800 loss 0.05415864190200294\n",
      "Epoch 22 num_samples 7900 loss 0.09951843600949635\n",
      "Epoch 22 num_samples 8000 loss 0.06181724176465595\n",
      "Epoch 22 num_samples 8100 loss 0.07970489566523196\n",
      "Epoch 22 num_samples 8200 loss 0.09374804295749925\n",
      "Epoch 22 num_samples 8300 loss 0.09795010096037897\n",
      "Epoch 22 num_samples 8400 loss 0.07680887853495752\n",
      "Epoch 22 num_samples 8500 loss 0.10778632358236337\n",
      "Epoch 22 num_samples 8600 loss 0.0729838028267145\n",
      "Epoch 22 num_samples 8700 loss 0.09076960292821525\n",
      "Epoch 22 num_samples 8800 loss 0.1337540935524885\n",
      "Epoch 22 num_samples 8900 loss 0.10163710135397341\n",
      "Epoch 22 num_samples 9000 loss 0.08799716803780022\n",
      "Epoch 22 num_samples 9100 loss 0.09027667155468194\n",
      "Epoch 22 num_samples 9200 loss 0.08172745161291939\n",
      "Epoch 22 num_samples 9300 loss 0.0894102375303995\n",
      "Epoch 22 num_samples 9400 loss 0.06835545019083292\n",
      "Epoch 22 num_samples 9500 loss 0.10280802153929511\n",
      "Epoch 22 num_samples 9600 loss 0.06698288455321608\n",
      "Epoch 22 num_samples 9700 loss 0.11036718933248853\n",
      "Epoch 22 num_samples 9800 loss 0.052102308648966617\n",
      "Epoch 22 num_samples 9900 loss 0.15726371790292204\n",
      "Epoch 22 num_samples 10000 loss 0.09212174520758509\n",
      "Epoch 22 num_samples 10100 loss 0.05629708672307975\n",
      "Epoch 22 num_samples 10200 loss 0.1443989095161889\n",
      "Epoch 22 num_samples 10300 loss 0.10384049036355465\n",
      "Epoch 22 num_samples 10400 loss 0.10900981813261819\n",
      "Epoch 22 num_samples 10500 loss 0.0721093793429108\n",
      "Epoch 22 num_samples 10600 loss 0.1238729259372921\n",
      "Epoch 22 num_samples 10700 loss 0.07868792447258452\n",
      "Epoch 22 num_samples 10800 loss 0.1369331563513583\n",
      "Epoch 22 num_samples 10900 loss 0.07759283876466448\n",
      "Epoch 22 num_samples 11000 loss 0.051703618313810436\n",
      "Epoch 22 num_samples 11100 loss 0.09130290922106168\n",
      "Epoch 22 num_samples 11200 loss 0.07802450204729203\n",
      "Epoch 22 num_samples 11300 loss 0.14796986276683238\n",
      "Epoch 22 num_samples 11400 loss 0.12936427400352593\n",
      "Epoch 22 num_samples 11500 loss 0.07413339593142837\n",
      "Epoch 22 num_samples 11600 loss 0.07156009528465286\n",
      "Epoch 22 num_samples 11700 loss 0.1055723497798628\n",
      "Epoch 22 num_samples 11800 loss 0.07781486972810926\n",
      "Epoch 22 num_samples 11900 loss 0.08102473960087757\n",
      "Epoch 22 num_samples 12000 loss 0.052318308198051916\n",
      "Epoch 22 num_samples 12100 loss 0.09117893720408629\n",
      "Epoch 22 num_samples 12200 loss 0.12414008464315333\n",
      "Epoch 22 num_samples 12300 loss 0.05463065043741918\n",
      "Epoch 22 num_samples 12400 loss 0.10996818813727426\n",
      "Epoch 22 num_samples 12500 loss 0.09237628778886954\n",
      "Epoch 22 num_samples 12600 loss 0.10744635860720533\n",
      "Epoch 22 num_samples 12700 loss 0.0998452658028646\n",
      "Epoch 22 num_samples 12800 loss 0.13962446067759632\n",
      "Epoch 22 num_samples 12900 loss 0.09097908839625299\n",
      "Epoch 22 num_samples 13000 loss 0.06658547039284611\n",
      "Epoch 22 num_samples 13100 loss 0.1571199375569914\n",
      "Epoch 22 num_samples 13200 loss 0.07022482774963318\n",
      "Epoch 22 num_samples 13300 loss 0.0661480831297909\n",
      "Epoch 22 num_samples 13400 loss 0.04543722541828649\n",
      "Epoch 22 num_samples 13500 loss 0.06883758133642791\n",
      "Epoch 22 num_samples 13600 loss 0.11571381031273116\n",
      "Epoch 22 num_samples 13700 loss 0.08860242208279302\n",
      "Epoch 22 num_samples 13800 loss 0.08203063370893768\n",
      "Epoch 22 num_samples 13900 loss 0.04579816500963025\n",
      "Epoch 22 num_samples 14000 loss 0.059090691866447026\n",
      "Epoch 22 num_samples 14100 loss 0.08151072044402664\n",
      "Epoch 22 num_samples 14200 loss 0.05562911997463326\n",
      "Epoch 22 num_samples 14300 loss 0.10008306184551014\n",
      "Epoch 22 num_samples 14400 loss 0.08850471633722369\n",
      "Epoch 22 num_samples 14500 loss 0.09794584123628516\n",
      "Epoch 22 num_samples 14600 loss 0.07655364515612588\n",
      "Epoch 22 num_samples 14700 loss 0.08485425202503803\n",
      "Epoch 22 num_samples 14800 loss 0.06353563324739556\n",
      "Epoch 22 num_samples 14900 loss 0.12759519648826576\n",
      "Epoch 22 num_samples 15000 loss 0.06417415224195938\n",
      "Epoch 22 num_samples 15100 loss 0.09219227497664009\n",
      "Epoch 22 num_samples 15200 loss 0.13506607655016215\n",
      "Epoch 22 num_samples 15300 loss 0.0819778680453277\n",
      "Epoch 22 num_samples 15400 loss 0.06063973495793234\n",
      "Epoch 22 num_samples 15500 loss 0.11283628233444092\n",
      "Epoch 22 num_samples 15600 loss 0.08094009414084295\n",
      "Epoch 22 num_samples 15700 loss 0.055602581202496705\n",
      "Epoch 22 num_samples 15800 loss 0.1352030926342057\n",
      "Epoch 22 num_samples 15900 loss 0.05069948807847045\n",
      "Epoch 22 num_samples 16000 loss 0.11465904370379999\n",
      "Epoch 22 num_samples 16100 loss 0.0644073533403085\n",
      "Epoch 22 num_samples 16200 loss 0.0918305181864757\n",
      "Epoch 22 num_samples 16300 loss 0.12501746035291916\n",
      "Epoch 22 num_samples 16400 loss 0.10080451114657228\n",
      "Epoch 22 num_samples 16500 loss 0.09159200560586524\n",
      "Epoch 22 num_samples 16600 loss 0.11010121217740629\n",
      "Epoch 22 num_samples 16700 loss 0.059562129720564225\n",
      "Epoch 22 num_samples 16800 loss 0.06498260580480897\n",
      "Epoch 22 num_samples 16900 loss 0.07705259967653591\n",
      "Epoch 22 num_samples 17000 loss 0.0554692677202568\n",
      "Epoch 22 num_samples 17100 loss 0.18038350244093157\n",
      "Epoch 22 num_samples 17200 loss 0.09692502051528713\n",
      "Epoch 22 num_samples 17300 loss 0.11566432729695908\n",
      "Epoch 22 num_samples 17400 loss 0.09984895230554348\n",
      "Epoch 22 num_samples 17500 loss 0.09352251887714327\n",
      "Epoch 22 num_samples 17600 loss 0.104208619013979\n",
      "Epoch 22 num_samples 17700 loss 0.06349407040057868\n",
      "Epoch 22 num_samples 17800 loss 0.10796351744600412\n",
      "Epoch 22 num_samples 17900 loss 0.11280816435739545\n",
      "Epoch 22 num_samples 18000 loss 0.06376559790696419\n",
      "Epoch 22 num_samples 18100 loss 0.0908084430365658\n",
      "Epoch 22 num_samples 18200 loss 0.09541277669461797\n",
      "Epoch 22 num_samples 18300 loss 0.07171893874193536\n",
      "Epoch 22 num_samples 18400 loss 0.14002181256817883\n",
      "Epoch 22 num_samples 18500 loss 0.08877590081604418\n",
      "Epoch 23 num_samples 0 loss 0.0720167425220905\n",
      "Epoch 23 num_samples 100 loss 0.10898561481371559\n",
      "Epoch 23 num_samples 200 loss 0.06751239757332575\n",
      "Epoch 23 num_samples 300 loss 0.0701186519279455\n",
      "Epoch 23 num_samples 400 loss 0.06825404955267687\n",
      "Epoch 23 num_samples 500 loss 0.08542026096336741\n",
      "Epoch 23 num_samples 600 loss 0.11229437911013009\n",
      "Epoch 23 num_samples 700 loss 0.14198632143162246\n",
      "Epoch 23 num_samples 800 loss 0.09432446257835232\n",
      "Epoch 23 num_samples 900 loss 0.08781746974854933\n",
      "Epoch 23 num_samples 1000 loss 0.07479149812889824\n",
      "Epoch 23 num_samples 1100 loss 0.12503531847898036\n",
      "Epoch 23 num_samples 1200 loss 0.08632014226088768\n",
      "Epoch 23 num_samples 1300 loss 0.06628871481017937\n",
      "Epoch 23 num_samples 1400 loss 0.10776460573528794\n",
      "Epoch 23 num_samples 1500 loss 0.17052256992931125\n",
      "Epoch 23 num_samples 1600 loss 0.07915212690950675\n",
      "Epoch 23 num_samples 1700 loss 0.08130650234387332\n",
      "Epoch 23 num_samples 1800 loss 0.07223447673927443\n",
      "Epoch 23 num_samples 1900 loss 0.07751620636458209\n",
      "Epoch 23 num_samples 2000 loss 0.11845209518115164\n",
      "Epoch 23 num_samples 2100 loss 0.0594429703400791\n",
      "Epoch 23 num_samples 2200 loss 0.05771856833373702\n",
      "Epoch 23 num_samples 2300 loss 0.05656636554738432\n",
      "Epoch 23 num_samples 2400 loss 0.07025618337761795\n",
      "Epoch 23 num_samples 2500 loss 0.11573533196939206\n",
      "Epoch 23 num_samples 2600 loss 0.0984283777044401\n",
      "Epoch 23 num_samples 2700 loss 0.10887446753360878\n",
      "Epoch 23 num_samples 2800 loss 0.10479247975828891\n",
      "Epoch 23 num_samples 2900 loss 0.0952168507698297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 num_samples 3000 loss 0.07406993536495539\n",
      "Epoch 23 num_samples 3100 loss 0.09607135592346366\n",
      "Epoch 23 num_samples 3200 loss 0.19889733040045712\n",
      "Epoch 23 num_samples 3300 loss 0.08529380505106605\n",
      "Epoch 23 num_samples 3400 loss 0.061470438461738046\n",
      "Epoch 23 num_samples 3500 loss 0.08027905373780506\n",
      "Epoch 23 num_samples 3600 loss 0.04717139501167903\n",
      "Epoch 23 num_samples 3700 loss 0.1195506859094499\n",
      "Epoch 23 num_samples 3800 loss 0.0915787824136607\n",
      "Epoch 23 num_samples 3900 loss 0.09789009130640629\n",
      "Epoch 23 num_samples 4000 loss 0.09682993764839458\n",
      "Epoch 23 num_samples 4100 loss 0.15686602518018591\n",
      "Epoch 23 num_samples 4200 loss 0.08273776835010237\n",
      "Epoch 23 num_samples 4300 loss 0.09667304098102561\n",
      "Epoch 23 num_samples 4400 loss 0.09866764275166943\n",
      "Epoch 23 num_samples 4500 loss 0.120357310889685\n",
      "Epoch 23 num_samples 4600 loss 0.09203458044823457\n",
      "Epoch 23 num_samples 4700 loss 0.04749153879905846\n",
      "Epoch 23 num_samples 4800 loss 0.05388131795411363\n",
      "Epoch 23 num_samples 4900 loss 0.05941033026364496\n",
      "Epoch 23 num_samples 5000 loss 0.06900278054140273\n",
      "Epoch 23 num_samples 5100 loss 0.10933762577109406\n",
      "Epoch 23 num_samples 5200 loss 0.052069516435716265\n",
      "Epoch 23 num_samples 5300 loss 0.07788217812016986\n",
      "Epoch 23 num_samples 5400 loss 0.11004353237589264\n",
      "Epoch 23 num_samples 5500 loss 0.06295969109556389\n",
      "Epoch 23 num_samples 5600 loss 0.17583561126863612\n",
      "Epoch 23 num_samples 5700 loss 0.12231961865514383\n",
      "Epoch 23 num_samples 5800 loss 0.11140029488263035\n",
      "Epoch 23 num_samples 5900 loss 0.1174307547398703\n",
      "Epoch 23 num_samples 6000 loss 0.1075298230283606\n",
      "Epoch 23 num_samples 6100 loss 0.06503145421294225\n",
      "Epoch 23 num_samples 6200 loss 0.09279153349730634\n",
      "Epoch 23 num_samples 6300 loss 0.11592531481874278\n",
      "Epoch 23 num_samples 6400 loss 0.06658514751422624\n",
      "Epoch 23 num_samples 6500 loss 0.0586970917652691\n",
      "Epoch 23 num_samples 6600 loss 0.12059260017791644\n",
      "Epoch 23 num_samples 6700 loss 0.049451451713303306\n",
      "Epoch 23 num_samples 6800 loss 0.04154814266552578\n",
      "Epoch 23 num_samples 6900 loss 0.15894745775377686\n",
      "Epoch 23 num_samples 7000 loss 0.13373930008513799\n",
      "Epoch 23 num_samples 7100 loss 0.06921907396683004\n",
      "Epoch 23 num_samples 7200 loss 0.0689586495883835\n",
      "Epoch 23 num_samples 7300 loss 0.07951314203951594\n",
      "Epoch 23 num_samples 7400 loss 0.07007705674999093\n",
      "Epoch 23 num_samples 7500 loss 0.13708932261300583\n",
      "Epoch 23 num_samples 7600 loss 0.0796497002191683\n",
      "Epoch 23 num_samples 7700 loss 0.14119104256786888\n",
      "Epoch 23 num_samples 7800 loss 0.050503458629344425\n",
      "Epoch 23 num_samples 7900 loss 0.09135527701543822\n",
      "Epoch 23 num_samples 8000 loss 0.0568783605091316\n",
      "Epoch 23 num_samples 8100 loss 0.07285431121816649\n",
      "Epoch 23 num_samples 8200 loss 0.08705057877589444\n",
      "Epoch 23 num_samples 8300 loss 0.09217176639738846\n",
      "Epoch 23 num_samples 8400 loss 0.07001449777819975\n",
      "Epoch 23 num_samples 8500 loss 0.10051458115324526\n",
      "Epoch 23 num_samples 8600 loss 0.06909508392029426\n",
      "Epoch 23 num_samples 8700 loss 0.08388412568613196\n",
      "Epoch 23 num_samples 8800 loss 0.12598302199941458\n",
      "Epoch 23 num_samples 8900 loss 0.09330385510618136\n",
      "Epoch 23 num_samples 9000 loss 0.08158188648536141\n",
      "Epoch 23 num_samples 9100 loss 0.08406179309734074\n",
      "Epoch 23 num_samples 9200 loss 0.0742657925803861\n",
      "Epoch 23 num_samples 9300 loss 0.08352993692421304\n",
      "Epoch 23 num_samples 9400 loss 0.06295319953708586\n",
      "Epoch 23 num_samples 9500 loss 0.0947746283426996\n",
      "Epoch 23 num_samples 9600 loss 0.06288669285866677\n",
      "Epoch 23 num_samples 9700 loss 0.10300805645940264\n",
      "Epoch 23 num_samples 9800 loss 0.04770158412137435\n",
      "Epoch 23 num_samples 9900 loss 0.14666488810579995\n",
      "Epoch 23 num_samples 10000 loss 0.08617855448672362\n",
      "Epoch 23 num_samples 10100 loss 0.05293153433746052\n",
      "Epoch 23 num_samples 10200 loss 0.1339030619269621\n",
      "Epoch 23 num_samples 10300 loss 0.09471642886680229\n",
      "Epoch 23 num_samples 10400 loss 0.10258701618575769\n",
      "Epoch 23 num_samples 10500 loss 0.06670756683716914\n",
      "Epoch 23 num_samples 10600 loss 0.11696528221705563\n",
      "Epoch 23 num_samples 10700 loss 0.07287553513067135\n",
      "Epoch 23 num_samples 10800 loss 0.12894051090161296\n",
      "Epoch 23 num_samples 10900 loss 0.07078012782932212\n",
      "Epoch 23 num_samples 11000 loss 0.04848325802017822\n",
      "Epoch 23 num_samples 11100 loss 0.08511412046271044\n",
      "Epoch 23 num_samples 11200 loss 0.0726856505537822\n",
      "Epoch 23 num_samples 11300 loss 0.13989214540636824\n",
      "Epoch 23 num_samples 11400 loss 0.122706824262296\n",
      "Epoch 23 num_samples 11500 loss 0.0701418754337255\n",
      "Epoch 23 num_samples 11600 loss 0.06636937061667807\n",
      "Epoch 23 num_samples 11700 loss 0.09910708757205593\n",
      "Epoch 23 num_samples 11800 loss 0.07315419915326855\n",
      "Epoch 23 num_samples 11900 loss 0.07455400317943099\n",
      "Epoch 23 num_samples 12000 loss 0.04857541103276536\n",
      "Epoch 23 num_samples 12100 loss 0.08599912343873711\n",
      "Epoch 23 num_samples 12200 loss 0.11648764692670371\n",
      "Epoch 23 num_samples 12300 loss 0.04985058563245952\n",
      "Epoch 23 num_samples 12400 loss 0.10242589601979674\n",
      "Epoch 23 num_samples 12500 loss 0.08649406550046475\n",
      "Epoch 23 num_samples 12600 loss 0.10140732791760758\n",
      "Epoch 23 num_samples 12700 loss 0.09241044250493174\n",
      "Epoch 23 num_samples 12800 loss 0.13080723291236274\n",
      "Epoch 23 num_samples 12900 loss 0.08392896630885978\n",
      "Epoch 23 num_samples 13000 loss 0.061304912517138946\n",
      "Epoch 23 num_samples 13100 loss 0.14910058057224687\n",
      "Epoch 23 num_samples 13200 loss 0.06561389227696596\n",
      "Epoch 23 num_samples 13300 loss 0.06109796193208469\n",
      "Epoch 23 num_samples 13400 loss 0.040667701347361\n",
      "Epoch 23 num_samples 13500 loss 0.06338833747028913\n",
      "Epoch 23 num_samples 13600 loss 0.10820199602773053\n",
      "Epoch 23 num_samples 13700 loss 0.08274870115447854\n",
      "Epoch 23 num_samples 13800 loss 0.07747727046958432\n",
      "Epoch 23 num_samples 13900 loss 0.04138168297142603\n",
      "Epoch 23 num_samples 14000 loss 0.05611213170944352\n",
      "Epoch 23 num_samples 14100 loss 0.07526330958792446\n",
      "Epoch 23 num_samples 14200 loss 0.05187176403954916\n",
      "Epoch 23 num_samples 14300 loss 0.0927079357157561\n",
      "Epoch 23 num_samples 14400 loss 0.08142842677368323\n",
      "Epoch 23 num_samples 14500 loss 0.08945110298171931\n",
      "Epoch 23 num_samples 14600 loss 0.07124198823421288\n",
      "Epoch 23 num_samples 14700 loss 0.07924532266029001\n",
      "Epoch 23 num_samples 14800 loss 0.059124450419130774\n",
      "Epoch 23 num_samples 14900 loss 0.11783373047444563\n",
      "Epoch 23 num_samples 15000 loss 0.06029885782684875\n",
      "Epoch 23 num_samples 15100 loss 0.08513066826589101\n",
      "Epoch 23 num_samples 15200 loss 0.12600696738855713\n",
      "Epoch 23 num_samples 15300 loss 0.0758338007710739\n",
      "Epoch 23 num_samples 15400 loss 0.05557073827306645\n",
      "Epoch 23 num_samples 15500 loss 0.10541633876504752\n",
      "Epoch 23 num_samples 15600 loss 0.07505402199900363\n",
      "Epoch 23 num_samples 15700 loss 0.05055643221056379\n",
      "Epoch 23 num_samples 15800 loss 0.12614319241591698\n",
      "Epoch 23 num_samples 15900 loss 0.04728172419094669\n",
      "Epoch 23 num_samples 16000 loss 0.10632541790542067\n",
      "Epoch 23 num_samples 16100 loss 0.05951344638842813\n",
      "Epoch 23 num_samples 16200 loss 0.08512520386344256\n",
      "Epoch 23 num_samples 16300 loss 0.11864997173626576\n",
      "Epoch 23 num_samples 16400 loss 0.0961990052132887\n",
      "Epoch 23 num_samples 16500 loss 0.08580830999408716\n",
      "Epoch 23 num_samples 16600 loss 0.10194748446162867\n",
      "Epoch 23 num_samples 16700 loss 0.05481929944499288\n",
      "Epoch 23 num_samples 16800 loss 0.06041474818775225\n",
      "Epoch 23 num_samples 16900 loss 0.07099601713422457\n",
      "Epoch 23 num_samples 17000 loss 0.051488913643042374\n",
      "Epoch 23 num_samples 17100 loss 0.17148501060402097\n",
      "Epoch 23 num_samples 17200 loss 0.08898087145855117\n",
      "Epoch 23 num_samples 17300 loss 0.10774085892924633\n",
      "Epoch 23 num_samples 17400 loss 0.09018652214035237\n",
      "Epoch 23 num_samples 17500 loss 0.08451146896749513\n",
      "Epoch 23 num_samples 17600 loss 0.09456230988633071\n",
      "Epoch 23 num_samples 17700 loss 0.05839013618806381\n",
      "Epoch 23 num_samples 17800 loss 0.10064877276308047\n",
      "Epoch 23 num_samples 17900 loss 0.10488546726195072\n",
      "Epoch 23 num_samples 18000 loss 0.05935389186339702\n",
      "Epoch 23 num_samples 18100 loss 0.08402200985007889\n",
      "Epoch 23 num_samples 18200 loss 0.08863271092936145\n",
      "Epoch 23 num_samples 18300 loss 0.06550860648376981\n",
      "Epoch 23 num_samples 18400 loss 0.12979383012254328\n",
      "Epoch 23 num_samples 18500 loss 0.08213202621349806\n",
      "Epoch 24 num_samples 0 loss 0.06601187952506753\n",
      "Epoch 24 num_samples 100 loss 0.10268316829009919\n",
      "Epoch 24 num_samples 200 loss 0.06259105960298444\n",
      "Epoch 24 num_samples 300 loss 0.06413352042688118\n",
      "Epoch 24 num_samples 400 loss 0.06392571803647469\n",
      "Epoch 24 num_samples 500 loss 0.0804368459623022\n",
      "Epoch 24 num_samples 600 loss 0.10610776458791525\n",
      "Epoch 24 num_samples 700 loss 0.12970017462795524\n",
      "Epoch 24 num_samples 800 loss 0.08593957881998836\n",
      "Epoch 24 num_samples 900 loss 0.08331080261320213\n",
      "Epoch 24 num_samples 1000 loss 0.06955798205756655\n",
      "Epoch 24 num_samples 1100 loss 0.11834858458983884\n",
      "Epoch 24 num_samples 1200 loss 0.07959668082650621\n",
      "Epoch 24 num_samples 1300 loss 0.06346088909009667\n",
      "Epoch 24 num_samples 1400 loss 0.09993976816117016\n",
      "Epoch 24 num_samples 1500 loss 0.1628947211748651\n",
      "Epoch 24 num_samples 1600 loss 0.07295936128002639\n",
      "Epoch 24 num_samples 1700 loss 0.07410794877424358\n",
      "Epoch 24 num_samples 1800 loss 0.06775841000067322\n",
      "Epoch 24 num_samples 1900 loss 0.0717300772766257\n",
      "Epoch 24 num_samples 2000 loss 0.10685212356032114\n",
      "Epoch 24 num_samples 2100 loss 0.05391433323453684\n",
      "Epoch 24 num_samples 2200 loss 0.053675331044896024\n",
      "Epoch 24 num_samples 2300 loss 0.05028942787297488\n",
      "Epoch 24 num_samples 2400 loss 0.06570240079312745\n",
      "Epoch 24 num_samples 2500 loss 0.10842792724607658\n",
      "Epoch 24 num_samples 2600 loss 0.09119953485383808\n",
      "Epoch 24 num_samples 2700 loss 0.09965016218944985\n",
      "Epoch 24 num_samples 2800 loss 0.09750698321707559\n",
      "Epoch 24 num_samples 2900 loss 0.08900117025938421\n",
      "Epoch 24 num_samples 3000 loss 0.06886188571864177\n",
      "Epoch 24 num_samples 3100 loss 0.08985020938805523\n",
      "Epoch 24 num_samples 3200 loss 0.1894442923363481\n",
      "Epoch 24 num_samples 3300 loss 0.08165621909366802\n",
      "Epoch 24 num_samples 3400 loss 0.05728261061115283\n",
      "Epoch 24 num_samples 3500 loss 0.07371673544716728\n",
      "Epoch 24 num_samples 3600 loss 0.04289614348284028\n",
      "Epoch 24 num_samples 3700 loss 0.11249971468236226\n",
      "Epoch 24 num_samples 3800 loss 0.08458412737864257\n",
      "Epoch 24 num_samples 3900 loss 0.08956368504163112\n",
      "Epoch 24 num_samples 4000 loss 0.09092916125008818\n",
      "Epoch 24 num_samples 4100 loss 0.14611220969229036\n",
      "Epoch 24 num_samples 4200 loss 0.0754298561394366\n",
      "Epoch 24 num_samples 4300 loss 0.08885856575661276\n",
      "Epoch 24 num_samples 4400 loss 0.0935761737825191\n",
      "Epoch 24 num_samples 4500 loss 0.11111120503778632\n",
      "Epoch 24 num_samples 4600 loss 0.08450184090632414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 num_samples 4700 loss 0.044459031364184255\n",
      "Epoch 24 num_samples 4800 loss 0.0501969116163225\n",
      "Epoch 24 num_samples 4900 loss 0.05490897841789993\n",
      "Epoch 24 num_samples 5000 loss 0.06370668819226154\n",
      "Epoch 24 num_samples 5100 loss 0.10156197600945392\n",
      "Epoch 24 num_samples 5200 loss 0.04746617817518899\n",
      "Epoch 24 num_samples 5300 loss 0.07200862827783962\n",
      "Epoch 24 num_samples 5400 loss 0.10070040310106872\n",
      "Epoch 24 num_samples 5500 loss 0.05771099301014243\n",
      "Epoch 24 num_samples 5600 loss 0.17005767597089477\n",
      "Epoch 24 num_samples 5700 loss 0.11561870541690436\n",
      "Epoch 24 num_samples 5800 loss 0.10260294588141416\n",
      "Epoch 24 num_samples 5900 loss 0.10972394649597693\n",
      "Epoch 24 num_samples 6000 loss 0.10116570396241052\n",
      "Epoch 24 num_samples 6100 loss 0.06152606538530474\n",
      "Epoch 24 num_samples 6200 loss 0.08542583091698358\n",
      "Epoch 24 num_samples 6300 loss 0.10909450778465322\n",
      "Epoch 24 num_samples 6400 loss 0.06232239813064597\n",
      "Epoch 24 num_samples 6500 loss 0.054395394405541746\n",
      "Epoch 24 num_samples 6600 loss 0.11142348273847957\n",
      "Epoch 24 num_samples 6700 loss 0.04644430159113856\n",
      "Epoch 24 num_samples 6800 loss 0.039241411068516266\n",
      "Epoch 24 num_samples 6900 loss 0.14775362892514096\n",
      "Epoch 24 num_samples 7000 loss 0.1251061017004559\n",
      "Epoch 24 num_samples 7100 loss 0.0628538296320414\n",
      "Epoch 24 num_samples 7200 loss 0.06310992796218959\n",
      "Epoch 24 num_samples 7300 loss 0.0726863046552094\n",
      "Epoch 24 num_samples 7400 loss 0.06435025321656085\n",
      "Epoch 24 num_samples 7500 loss 0.1282296992256655\n",
      "Epoch 24 num_samples 7600 loss 0.07476409693652684\n",
      "Epoch 24 num_samples 7700 loss 0.1326170132047449\n",
      "Epoch 24 num_samples 7800 loss 0.046967859989919675\n",
      "Epoch 24 num_samples 7900 loss 0.08428518702285917\n",
      "Epoch 24 num_samples 8000 loss 0.05252005318120334\n",
      "Epoch 24 num_samples 8100 loss 0.06823806306048137\n",
      "Epoch 24 num_samples 8200 loss 0.08170364852855336\n",
      "Epoch 24 num_samples 8300 loss 0.08637812104549057\n",
      "Epoch 24 num_samples 8400 loss 0.06485226277978438\n",
      "Epoch 24 num_samples 8500 loss 0.09302288417853667\n",
      "Epoch 24 num_samples 8600 loss 0.0647817139583335\n",
      "Epoch 24 num_samples 8700 loss 0.07872678926598313\n",
      "Epoch 24 num_samples 8800 loss 0.11893948808167946\n",
      "Epoch 24 num_samples 8900 loss 0.08631054732787768\n",
      "Epoch 24 num_samples 9000 loss 0.07603844888234254\n",
      "Epoch 24 num_samples 9100 loss 0.07783513116423726\n",
      "Epoch 24 num_samples 9200 loss 0.06851493492816474\n",
      "Epoch 24 num_samples 9300 loss 0.0772112318117083\n",
      "Epoch 24 num_samples 9400 loss 0.05861079651426354\n",
      "Epoch 24 num_samples 9500 loss 0.08700449122011729\n",
      "Epoch 24 num_samples 9600 loss 0.05885252057588374\n",
      "Epoch 24 num_samples 9700 loss 0.09631480576005233\n",
      "Epoch 24 num_samples 9800 loss 0.044257355231158965\n",
      "Epoch 24 num_samples 9900 loss 0.1369622883131373\n",
      "Epoch 24 num_samples 10000 loss 0.08054896870153104\n",
      "Epoch 24 num_samples 10100 loss 0.04979730187078421\n",
      "Epoch 24 num_samples 10200 loss 0.12456556297206463\n",
      "Epoch 24 num_samples 10300 loss 0.08648114607873786\n",
      "Epoch 24 num_samples 10400 loss 0.09680114248045331\n",
      "Epoch 24 num_samples 10500 loss 0.061575624207134104\n",
      "Epoch 24 num_samples 10600 loss 0.1105238586246281\n",
      "Epoch 24 num_samples 10700 loss 0.06723568351540454\n",
      "Epoch 24 num_samples 10800 loss 0.1215982533834527\n",
      "Epoch 24 num_samples 10900 loss 0.065134009974262\n",
      "Epoch 24 num_samples 11000 loss 0.04626151676174391\n",
      "Epoch 24 num_samples 11100 loss 0.07786858561467862\n",
      "Epoch 24 num_samples 11200 loss 0.0673584453666079\n",
      "Epoch 24 num_samples 11300 loss 0.1309558707613803\n",
      "Epoch 24 num_samples 11400 loss 0.11556015244464904\n",
      "Epoch 24 num_samples 11500 loss 0.06484244361276999\n",
      "Epoch 24 num_samples 11600 loss 0.061624725660193065\n",
      "Epoch 24 num_samples 11700 loss 0.0940647499994428\n",
      "Epoch 24 num_samples 11800 loss 0.0678591262142764\n",
      "Epoch 24 num_samples 11900 loss 0.06928167149420313\n",
      "Epoch 24 num_samples 12000 loss 0.04533153582289783\n",
      "Epoch 24 num_samples 12100 loss 0.08153549864750467\n",
      "Epoch 24 num_samples 12200 loss 0.10822740960129576\n",
      "Epoch 24 num_samples 12300 loss 0.04643708976933163\n",
      "Epoch 24 num_samples 12400 loss 0.09637871326682852\n",
      "Epoch 24 num_samples 12500 loss 0.08021527580429101\n",
      "Epoch 24 num_samples 12600 loss 0.095690396830648\n",
      "Epoch 24 num_samples 12700 loss 0.08660615296938318\n",
      "Epoch 24 num_samples 12800 loss 0.12215110161693687\n",
      "Epoch 24 num_samples 12900 loss 0.07753203751684747\n",
      "Epoch 24 num_samples 13000 loss 0.05639218821828978\n",
      "Epoch 24 num_samples 13100 loss 0.14260676466712574\n",
      "Epoch 24 num_samples 13200 loss 0.060783646235295814\n",
      "Epoch 24 num_samples 13300 loss 0.0571798911626826\n",
      "Epoch 24 num_samples 13400 loss 0.036598468282285364\n",
      "Epoch 24 num_samples 13500 loss 0.05819976127542905\n",
      "Epoch 24 num_samples 13600 loss 0.10162688906558079\n",
      "Epoch 24 num_samples 13700 loss 0.07643116461098019\n",
      "Epoch 24 num_samples 13800 loss 0.07278844690883976\n",
      "Epoch 24 num_samples 13900 loss 0.03706577430148828\n",
      "Epoch 24 num_samples 14000 loss 0.052300882727068336\n",
      "Epoch 24 num_samples 14100 loss 0.07008288051847357\n",
      "Epoch 24 num_samples 14200 loss 0.048955549436468446\n",
      "Epoch 24 num_samples 14300 loss 0.08558625598442916\n",
      "Epoch 24 num_samples 14400 loss 0.07575100381801009\n",
      "Epoch 24 num_samples 14500 loss 0.08359518741660185\n",
      "Epoch 24 num_samples 14600 loss 0.06606838887335184\n",
      "Epoch 24 num_samples 14700 loss 0.07308945655322645\n",
      "Epoch 24 num_samples 14800 loss 0.05573864169188889\n",
      "Epoch 24 num_samples 14900 loss 0.10854189244698312\n",
      "Epoch 24 num_samples 15000 loss 0.055643411928455545\n",
      "Epoch 24 num_samples 15100 loss 0.07803352858121246\n",
      "Epoch 24 num_samples 15200 loss 0.11702090849389929\n",
      "Epoch 24 num_samples 15300 loss 0.07015848041438308\n",
      "Epoch 24 num_samples 15400 loss 0.05094511407701454\n",
      "Epoch 24 num_samples 15500 loss 0.09845189312893042\n",
      "Epoch 24 num_samples 15600 loss 0.06951889116470188\n",
      "Epoch 24 num_samples 15700 loss 0.047030462419418974\n",
      "Epoch 24 num_samples 15800 loss 0.11639374904327703\n",
      "Epoch 24 num_samples 15900 loss 0.04448342509511856\n",
      "Epoch 24 num_samples 16000 loss 0.09856364720780053\n",
      "Epoch 24 num_samples 16100 loss 0.0550004910965527\n",
      "Epoch 24 num_samples 16200 loss 0.08024821972210759\n",
      "Epoch 24 num_samples 16300 loss 0.11114107668283657\n",
      "Epoch 24 num_samples 16400 loss 0.0910936692402982\n",
      "Epoch 24 num_samples 16500 loss 0.0784816854482956\n",
      "Epoch 24 num_samples 16600 loss 0.09497312251390662\n",
      "Epoch 24 num_samples 16700 loss 0.05005096742779491\n",
      "Epoch 24 num_samples 16800 loss 0.05614786925784372\n",
      "Epoch 24 num_samples 16900 loss 0.06459655533584656\n",
      "Epoch 24 num_samples 17000 loss 0.04723605996894032\n",
      "Epoch 24 num_samples 17100 loss 0.16255749142530468\n",
      "Epoch 24 num_samples 17200 loss 0.0825010696318011\n",
      "Epoch 24 num_samples 17300 loss 0.10179469496028197\n",
      "Epoch 24 num_samples 17400 loss 0.08171722969733526\n",
      "Epoch 24 num_samples 17500 loss 0.07681987687947493\n",
      "Epoch 24 num_samples 17600 loss 0.08634037869268027\n",
      "Epoch 24 num_samples 17700 loss 0.054134370273031536\n",
      "Epoch 24 num_samples 17800 loss 0.09338446662696123\n",
      "Epoch 24 num_samples 17900 loss 0.09808470425619403\n",
      "Epoch 24 num_samples 18000 loss 0.05599637011001489\n",
      "Epoch 24 num_samples 18100 loss 0.07850368020141206\n",
      "Epoch 24 num_samples 18200 loss 0.08391423680854135\n",
      "Epoch 24 num_samples 18300 loss 0.06158277851853726\n",
      "Epoch 24 num_samples 18400 loss 0.12040153433032204\n",
      "Epoch 24 num_samples 18500 loss 0.07640938785023584\n",
      "Epoch 25 num_samples 0 loss 0.06103434531782368\n",
      "Epoch 25 num_samples 100 loss 0.09605907879744102\n",
      "Epoch 25 num_samples 200 loss 0.05780953074769855\n",
      "Epoch 25 num_samples 300 loss 0.05898625341426416\n",
      "Epoch 25 num_samples 400 loss 0.05992710475101142\n",
      "Epoch 25 num_samples 500 loss 0.07559071746370873\n",
      "Epoch 25 num_samples 600 loss 0.09949847047680951\n",
      "Epoch 25 num_samples 700 loss 0.11954685740046397\n",
      "Epoch 25 num_samples 800 loss 0.07884448116705847\n",
      "Epoch 25 num_samples 900 loss 0.07984490993513721\n",
      "Epoch 25 num_samples 1000 loss 0.06523402163738136\n",
      "Epoch 25 num_samples 1100 loss 0.1108609741153114\n",
      "Epoch 25 num_samples 1200 loss 0.07362432546551409\n",
      "Epoch 25 num_samples 1300 loss 0.06024840553328557\n",
      "Epoch 25 num_samples 1400 loss 0.09321080934888157\n",
      "Epoch 25 num_samples 1500 loss 0.1536322114978949\n",
      "Epoch 25 num_samples 1600 loss 0.06730786994045229\n",
      "Epoch 25 num_samples 1700 loss 0.06822057824271449\n",
      "Epoch 25 num_samples 1800 loss 0.06303131478692506\n",
      "Epoch 25 num_samples 1900 loss 0.06702419243009883\n",
      "Epoch 25 num_samples 2000 loss 0.0983915365014556\n",
      "Epoch 25 num_samples 2100 loss 0.05024979224981072\n",
      "Epoch 25 num_samples 2200 loss 0.04963920910551509\n",
      "Epoch 25 num_samples 2300 loss 0.04548515128043116\n",
      "Epoch 25 num_samples 2400 loss 0.06209834473154835\n",
      "Epoch 25 num_samples 2500 loss 0.0997925436823181\n",
      "Epoch 25 num_samples 2600 loss 0.08697798136991523\n",
      "Epoch 25 num_samples 2700 loss 0.09011946808660745\n",
      "Epoch 25 num_samples 2800 loss 0.09134061851974512\n",
      "Epoch 25 num_samples 2900 loss 0.08324601442611917\n",
      "Epoch 25 num_samples 3000 loss 0.06517581688134194\n",
      "Epoch 25 num_samples 3100 loss 0.08333762526842124\n",
      "Epoch 25 num_samples 3200 loss 0.18004653209426288\n",
      "Epoch 25 num_samples 3300 loss 0.07842694527874966\n",
      "Epoch 25 num_samples 3400 loss 0.0526728719013346\n",
      "Epoch 25 num_samples 3500 loss 0.06735915312542919\n",
      "Epoch 25 num_samples 3600 loss 0.03962051858161852\n",
      "Epoch 25 num_samples 3700 loss 0.10645700436427845\n",
      "Epoch 25 num_samples 3800 loss 0.07826645130906838\n",
      "Epoch 25 num_samples 3900 loss 0.08276798786802068\n",
      "Epoch 25 num_samples 4000 loss 0.08546722235197027\n",
      "Epoch 25 num_samples 4100 loss 0.13604150176976437\n",
      "Epoch 25 num_samples 4200 loss 0.07012811532293606\n",
      "Epoch 25 num_samples 4300 loss 0.08316340413081193\n",
      "Epoch 25 num_samples 4400 loss 0.088281486744221\n",
      "Epoch 25 num_samples 4500 loss 0.1050544512400414\n",
      "Epoch 25 num_samples 4600 loss 0.07648939715650047\n",
      "Epoch 25 num_samples 4700 loss 0.041302126300118036\n",
      "Epoch 25 num_samples 4800 loss 0.04606922123635158\n",
      "Epoch 25 num_samples 4900 loss 0.05087866623800861\n",
      "Epoch 25 num_samples 5000 loss 0.05832639693264608\n",
      "Epoch 25 num_samples 5100 loss 0.09348312394491794\n",
      "Epoch 25 num_samples 5200 loss 0.0439920916694737\n",
      "Epoch 25 num_samples 5300 loss 0.06657342301681504\n",
      "Epoch 25 num_samples 5400 loss 0.0931666638067545\n",
      "Epoch 25 num_samples 5500 loss 0.053183217099982444\n",
      "Epoch 25 num_samples 5600 loss 0.16403388661377\n",
      "Epoch 25 num_samples 5700 loss 0.109972686192944\n",
      "Epoch 25 num_samples 5800 loss 0.09438931490680368\n",
      "Epoch 25 num_samples 5900 loss 0.10196781003591958\n",
      "Epoch 25 num_samples 6000 loss 0.0956459632134001\n",
      "Epoch 25 num_samples 6100 loss 0.0578753591484716\n",
      "Epoch 25 num_samples 6200 loss 0.079141087206056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 num_samples 6300 loss 0.10382719034525134\n",
      "Epoch 25 num_samples 6400 loss 0.05842159297135046\n",
      "Epoch 25 num_samples 6500 loss 0.050560397988256726\n",
      "Epoch 25 num_samples 6600 loss 0.10293700650974003\n",
      "Epoch 25 num_samples 6700 loss 0.04270710700055794\n",
      "Epoch 25 num_samples 6800 loss 0.03679846398572989\n",
      "Epoch 25 num_samples 6900 loss 0.1382928682562153\n",
      "Epoch 25 num_samples 7000 loss 0.11629967404321054\n",
      "Epoch 25 num_samples 7100 loss 0.05914757482270264\n",
      "Epoch 25 num_samples 7200 loss 0.05881759954583215\n",
      "Epoch 25 num_samples 7300 loss 0.06656815205622134\n",
      "Epoch 25 num_samples 7400 loss 0.05895193817216155\n",
      "Epoch 25 num_samples 7500 loss 0.12005127387227857\n",
      "Epoch 25 num_samples 7600 loss 0.07009094387818496\n",
      "Epoch 25 num_samples 7700 loss 0.12384744132699672\n",
      "Epoch 25 num_samples 7800 loss 0.04392114693219225\n",
      "Epoch 25 num_samples 7900 loss 0.07620643168643249\n",
      "Epoch 25 num_samples 8000 loss 0.04866691121553534\n",
      "Epoch 25 num_samples 8100 loss 0.06310882597908513\n",
      "Epoch 25 num_samples 8200 loss 0.0758634837530098\n",
      "Epoch 25 num_samples 8300 loss 0.08089838620173861\n",
      "Epoch 25 num_samples 8400 loss 0.05989907746051438\n",
      "Epoch 25 num_samples 8500 loss 0.08631605210476685\n",
      "Epoch 25 num_samples 8600 loss 0.06131533771337486\n",
      "Epoch 25 num_samples 8700 loss 0.07371042788554628\n",
      "Epoch 25 num_samples 8800 loss 0.1101596560556082\n",
      "Epoch 25 num_samples 8900 loss 0.07943853636310258\n",
      "Epoch 25 num_samples 9000 loss 0.0710145399568136\n",
      "Epoch 25 num_samples 9100 loss 0.07316210303024526\n",
      "Epoch 25 num_samples 9200 loss 0.06349017294652706\n",
      "Epoch 25 num_samples 9300 loss 0.07155761428002137\n",
      "Epoch 25 num_samples 9400 loss 0.05427807274898219\n",
      "Epoch 25 num_samples 9500 loss 0.08049818433940435\n",
      "Epoch 25 num_samples 9600 loss 0.054960949818137796\n",
      "Epoch 25 num_samples 9700 loss 0.09042275711135904\n",
      "Epoch 25 num_samples 9800 loss 0.04134977601281999\n",
      "Epoch 25 num_samples 9900 loss 0.12740294919064563\n",
      "Epoch 25 num_samples 10000 loss 0.07571897992948479\n",
      "Epoch 25 num_samples 10100 loss 0.0469642938283087\n",
      "Epoch 25 num_samples 10200 loss 0.11599977245929258\n",
      "Epoch 25 num_samples 10300 loss 0.07915986381697737\n",
      "Epoch 25 num_samples 10400 loss 0.09232852718248996\n",
      "Epoch 25 num_samples 10500 loss 0.0569738047932688\n",
      "Epoch 25 num_samples 10600 loss 0.10428195004014232\n",
      "Epoch 25 num_samples 10700 loss 0.06209476276421102\n",
      "Epoch 25 num_samples 10800 loss 0.11424768577589027\n",
      "Epoch 25 num_samples 10900 loss 0.05974429904004534\n",
      "Epoch 25 num_samples 11000 loss 0.04357052202222038\n",
      "Epoch 25 num_samples 11100 loss 0.07305341964859925\n",
      "Epoch 25 num_samples 11200 loss 0.06119523949458129\n",
      "Epoch 25 num_samples 11300 loss 0.12427588216550749\n",
      "Epoch 25 num_samples 11400 loss 0.10824558802091858\n",
      "Epoch 25 num_samples 11500 loss 0.062095757714702875\n",
      "Epoch 25 num_samples 11600 loss 0.057103067841120334\n",
      "Epoch 25 num_samples 11700 loss 0.08796077656791262\n",
      "Epoch 25 num_samples 11800 loss 0.06277416932365168\n",
      "Epoch 25 num_samples 11900 loss 0.06384456286909242\n",
      "Epoch 25 num_samples 12000 loss 0.04257831635070314\n",
      "Epoch 25 num_samples 12100 loss 0.07680154772807757\n",
      "Epoch 25 num_samples 12200 loss 0.10109485283275255\n",
      "Epoch 25 num_samples 12300 loss 0.04348752379774129\n",
      "Epoch 25 num_samples 12400 loss 0.09056684129474307\n",
      "Epoch 25 num_samples 12500 loss 0.07522735989101914\n",
      "Epoch 25 num_samples 12600 loss 0.0890970147067938\n",
      "Epoch 25 num_samples 12700 loss 0.08164276870645867\n",
      "Epoch 25 num_samples 12800 loss 0.11352840492284162\n",
      "Epoch 25 num_samples 12900 loss 0.07141013404722156\n",
      "Epoch 25 num_samples 13000 loss 0.05229700704894444\n",
      "Epoch 25 num_samples 13100 loss 0.13527363534100664\n",
      "Epoch 25 num_samples 13200 loss 0.056901646424017426\n",
      "Epoch 25 num_samples 13300 loss 0.053390291831879357\n",
      "Epoch 25 num_samples 13400 loss 0.03396822430520217\n",
      "Epoch 25 num_samples 13500 loss 0.05400130051409249\n",
      "Epoch 25 num_samples 13600 loss 0.09545351627435843\n",
      "Epoch 25 num_samples 13700 loss 0.07021510216980037\n",
      "Epoch 25 num_samples 13800 loss 0.06834485333469108\n",
      "Epoch 25 num_samples 13900 loss 0.033889078834637126\n",
      "Epoch 25 num_samples 14000 loss 0.04954927872651516\n",
      "Epoch 25 num_samples 14100 loss 0.06510684673523816\n",
      "Epoch 25 num_samples 14200 loss 0.046291538639959676\n",
      "Epoch 25 num_samples 14300 loss 0.07915856287782856\n",
      "Epoch 25 num_samples 14400 loss 0.06976933548394322\n",
      "Epoch 25 num_samples 14500 loss 0.07746586500926012\n",
      "Epoch 25 num_samples 14600 loss 0.06201837539830866\n",
      "Epoch 25 num_samples 14700 loss 0.06811855790360523\n",
      "Epoch 25 num_samples 14800 loss 0.05258645047227944\n",
      "Epoch 25 num_samples 14900 loss 0.1000091840818905\n",
      "Epoch 25 num_samples 15000 loss 0.052269174928980464\n",
      "Epoch 25 num_samples 15100 loss 0.07206247590844451\n",
      "Epoch 25 num_samples 15200 loss 0.10892078764203722\n",
      "Epoch 25 num_samples 15300 loss 0.06538308032334929\n",
      "Epoch 25 num_samples 15400 loss 0.04733874957406845\n",
      "Epoch 25 num_samples 15500 loss 0.09299274141374565\n",
      "Epoch 25 num_samples 15600 loss 0.06493795200570307\n",
      "Epoch 25 num_samples 15700 loss 0.043772852168158724\n",
      "Epoch 25 num_samples 15800 loss 0.1085406863190822\n",
      "Epoch 25 num_samples 15900 loss 0.04173972768709813\n",
      "Epoch 25 num_samples 16000 loss 0.08933867940771414\n",
      "Epoch 25 num_samples 16100 loss 0.050768594677063864\n",
      "Epoch 25 num_samples 16200 loss 0.07593616417857592\n",
      "Epoch 25 num_samples 16300 loss 0.10504104461643735\n",
      "Epoch 25 num_samples 16400 loss 0.08618471260167908\n",
      "Epoch 25 num_samples 16500 loss 0.07223970122684369\n",
      "Epoch 25 num_samples 16600 loss 0.08811880800179417\n",
      "Epoch 25 num_samples 16700 loss 0.046340329832964725\n",
      "Epoch 25 num_samples 16800 loss 0.05167179429580337\n",
      "Epoch 25 num_samples 16900 loss 0.059346059938718554\n",
      "Epoch 25 num_samples 17000 loss 0.043640504623988434\n",
      "Epoch 25 num_samples 17100 loss 0.1536464503492769\n",
      "Epoch 25 num_samples 17200 loss 0.07734007185367489\n",
      "Epoch 25 num_samples 17300 loss 0.0949975076354183\n",
      "Epoch 25 num_samples 17400 loss 0.075178399942711\n",
      "Epoch 25 num_samples 17500 loss 0.07058860199239593\n",
      "Epoch 25 num_samples 17600 loss 0.07915367721390582\n",
      "Epoch 25 num_samples 17700 loss 0.05032491681239565\n",
      "Epoch 25 num_samples 17800 loss 0.0861457041900874\n",
      "Epoch 25 num_samples 17900 loss 0.09053919427680959\n",
      "Epoch 25 num_samples 18000 loss 0.0520026958020885\n",
      "Epoch 25 num_samples 18100 loss 0.07335193312472946\n",
      "Epoch 25 num_samples 18200 loss 0.07879463968222514\n",
      "Epoch 25 num_samples 18300 loss 0.058424655435630746\n",
      "Epoch 25 num_samples 18400 loss 0.11132906409250122\n",
      "Epoch 25 num_samples 18500 loss 0.07090420419752874\n",
      "Epoch 26 num_samples 0 loss 0.05598018915150979\n",
      "Epoch 26 num_samples 100 loss 0.09110572314833887\n",
      "Epoch 26 num_samples 200 loss 0.05358195986041687\n",
      "Epoch 26 num_samples 300 loss 0.05466424199278004\n",
      "Epoch 26 num_samples 400 loss 0.056295197894217816\n",
      "Epoch 26 num_samples 500 loss 0.07045441645710064\n",
      "Epoch 26 num_samples 600 loss 0.09345999618828707\n",
      "Epoch 26 num_samples 700 loss 0.10821205949119347\n",
      "Epoch 26 num_samples 800 loss 0.07183917109499598\n",
      "Epoch 26 num_samples 900 loss 0.07629269902905877\n",
      "Epoch 26 num_samples 1000 loss 0.060866779855566815\n",
      "Epoch 26 num_samples 1100 loss 0.10557000177716398\n",
      "Epoch 26 num_samples 1200 loss 0.06921778352861968\n",
      "Epoch 26 num_samples 1300 loss 0.057301956078426454\n",
      "Epoch 26 num_samples 1400 loss 0.08629415649052698\n",
      "Epoch 26 num_samples 1500 loss 0.14531441288573688\n",
      "Epoch 26 num_samples 1600 loss 0.062352684152561864\n",
      "Epoch 26 num_samples 1700 loss 0.06237813257524404\n",
      "Epoch 26 num_samples 1800 loss 0.05860292998503276\n",
      "Epoch 26 num_samples 1900 loss 0.06261882645630548\n",
      "Epoch 26 num_samples 2000 loss 0.09078689747593842\n",
      "Epoch 26 num_samples 2100 loss 0.04673843373286477\n",
      "Epoch 26 num_samples 2200 loss 0.04652435975826555\n",
      "Epoch 26 num_samples 2300 loss 0.04099527103245836\n",
      "Epoch 26 num_samples 2400 loss 0.05796908550604919\n",
      "Epoch 26 num_samples 2500 loss 0.09359008858718987\n",
      "Epoch 26 num_samples 2600 loss 0.08157752750255297\n",
      "Epoch 26 num_samples 2700 loss 0.08320521513213568\n",
      "Epoch 26 num_samples 2800 loss 0.08602347533602515\n",
      "Epoch 26 num_samples 2900 loss 0.07761831163838856\n",
      "Epoch 26 num_samples 3000 loss 0.06108535212224229\n",
      "Epoch 26 num_samples 3100 loss 0.07801836071823962\n",
      "Epoch 26 num_samples 3200 loss 0.17195006316875883\n",
      "Epoch 26 num_samples 3300 loss 0.07369298492547234\n",
      "Epoch 26 num_samples 3400 loss 0.04992358225001347\n",
      "Epoch 26 num_samples 3500 loss 0.0624443097983622\n",
      "Epoch 26 num_samples 3600 loss 0.03653188567452412\n",
      "Epoch 26 num_samples 3700 loss 0.10093026623945031\n",
      "Epoch 26 num_samples 3800 loss 0.07272806013312988\n",
      "Epoch 26 num_samples 3900 loss 0.0769236478151831\n",
      "Epoch 26 num_samples 4000 loss 0.0797658264033738\n",
      "Epoch 26 num_samples 4100 loss 0.12726891766768436\n",
      "Epoch 26 num_samples 4200 loss 0.06568107400527351\n",
      "Epoch 26 num_samples 4300 loss 0.07796046884120188\n",
      "Epoch 26 num_samples 4400 loss 0.0827868717256374\n",
      "Epoch 26 num_samples 4500 loss 0.09694735375335407\n",
      "Epoch 26 num_samples 4600 loss 0.07185555061274405\n",
      "Epoch 26 num_samples 4700 loss 0.03882825812445155\n",
      "Epoch 26 num_samples 4800 loss 0.04237219567060797\n",
      "Epoch 26 num_samples 4900 loss 0.04785699352585193\n",
      "Epoch 26 num_samples 5000 loss 0.054381870143778245\n",
      "Epoch 26 num_samples 5100 loss 0.0859015441723519\n",
      "Epoch 26 num_samples 5200 loss 0.040698206765265324\n",
      "Epoch 26 num_samples 5300 loss 0.06118348834031849\n",
      "Epoch 26 num_samples 5400 loss 0.08594337367573239\n",
      "Epoch 26 num_samples 5500 loss 0.04861269146483026\n",
      "Epoch 26 num_samples 5600 loss 0.16004861185480654\n",
      "Epoch 26 num_samples 5700 loss 0.1037009867429527\n",
      "Epoch 26 num_samples 5800 loss 0.08704525040186234\n",
      "Epoch 26 num_samples 5900 loss 0.09461893666089355\n",
      "Epoch 26 num_samples 6000 loss 0.08915202105619863\n",
      "Epoch 26 num_samples 6100 loss 0.05510334723738427\n",
      "Epoch 26 num_samples 6200 loss 0.07363177306625421\n",
      "Epoch 26 num_samples 6300 loss 0.09805684447871252\n",
      "Epoch 26 num_samples 6400 loss 0.05457795324385099\n",
      "Epoch 26 num_samples 6500 loss 0.04747031899212607\n",
      "Epoch 26 num_samples 6600 loss 0.09586216561977132\n",
      "Epoch 26 num_samples 6700 loss 0.04037367250513672\n",
      "Epoch 26 num_samples 6800 loss 0.034491751720171354\n",
      "Epoch 26 num_samples 6900 loss 0.1282574652453083\n",
      "Epoch 26 num_samples 7000 loss 0.1080765743258607\n",
      "Epoch 26 num_samples 7100 loss 0.05444994261277824\n",
      "Epoch 26 num_samples 7200 loss 0.054886713306736785\n",
      "Epoch 26 num_samples 7300 loss 0.06058097664176801\n",
      "Epoch 26 num_samples 7400 loss 0.05343968083380304\n",
      "Epoch 26 num_samples 7500 loss 0.11294400221888688\n",
      "Epoch 26 num_samples 7600 loss 0.06578999308833844\n",
      "Epoch 26 num_samples 7700 loss 0.11699494533111622\n",
      "Epoch 26 num_samples 7800 loss 0.04139669966258094\n",
      "Epoch 26 num_samples 7900 loss 0.06987526481376134\n",
      "Epoch 26 num_samples 8000 loss 0.045279151163338624\n",
      "Epoch 26 num_samples 8100 loss 0.058310458496978176\n",
      "Epoch 26 num_samples 8200 loss 0.07163688351712535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 num_samples 8300 loss 0.07678055338509333\n",
      "Epoch 26 num_samples 8400 loss 0.05514574865904997\n",
      "Epoch 26 num_samples 8500 loss 0.07946609095499371\n",
      "Epoch 26 num_samples 8600 loss 0.05770901717182388\n",
      "Epoch 26 num_samples 8700 loss 0.06911677304344296\n",
      "Epoch 26 num_samples 8800 loss 0.10421654219091395\n",
      "Epoch 26 num_samples 8900 loss 0.07353643338872277\n",
      "Epoch 26 num_samples 9000 loss 0.06614243616412743\n",
      "Epoch 26 num_samples 9100 loss 0.06839031154390071\n",
      "Epoch 26 num_samples 9200 loss 0.05944067499182529\n",
      "Epoch 26 num_samples 9300 loss 0.06694310529176467\n",
      "Epoch 26 num_samples 9400 loss 0.05069707688229107\n",
      "Epoch 26 num_samples 9500 loss 0.07497645298120631\n",
      "Epoch 26 num_samples 9600 loss 0.05162934743007762\n",
      "Epoch 26 num_samples 9700 loss 0.08471735030661202\n",
      "Epoch 26 num_samples 9800 loss 0.03764206354762179\n",
      "Epoch 26 num_samples 9900 loss 0.11913903929028553\n",
      "Epoch 26 num_samples 10000 loss 0.07088308090632593\n",
      "Epoch 26 num_samples 10100 loss 0.04424793298624911\n",
      "Epoch 26 num_samples 10200 loss 0.10780284745835665\n",
      "Epoch 26 num_samples 10300 loss 0.0734555799472152\n",
      "Epoch 26 num_samples 10400 loss 0.08691542920120465\n",
      "Epoch 26 num_samples 10500 loss 0.05250955994142514\n",
      "Epoch 26 num_samples 10600 loss 0.09838411263210785\n",
      "Epoch 26 num_samples 10700 loss 0.05790288683428559\n",
      "Epoch 26 num_samples 10800 loss 0.1072943681992963\n",
      "Epoch 26 num_samples 10900 loss 0.05552072831369312\n",
      "Epoch 26 num_samples 11000 loss 0.04096957165827758\n",
      "Epoch 26 num_samples 11100 loss 0.06774528830654152\n",
      "Epoch 26 num_samples 11200 loss 0.056651943164463016\n",
      "Epoch 26 num_samples 11300 loss 0.1168907655207461\n",
      "Epoch 26 num_samples 11400 loss 0.10122135900329182\n",
      "Epoch 26 num_samples 11500 loss 0.059518064679192496\n",
      "Epoch 26 num_samples 11600 loss 0.05314936745451639\n",
      "Epoch 26 num_samples 11700 loss 0.08293709181082168\n",
      "Epoch 26 num_samples 11800 loss 0.058149835604313346\n",
      "Epoch 26 num_samples 11900 loss 0.05948620077812723\n",
      "Epoch 26 num_samples 12000 loss 0.03950322559547999\n",
      "Epoch 26 num_samples 12100 loss 0.07217455002965144\n",
      "Epoch 26 num_samples 12200 loss 0.09466380785509115\n",
      "Epoch 26 num_samples 12300 loss 0.04048068444249659\n",
      "Epoch 26 num_samples 12400 loss 0.085624965979081\n",
      "Epoch 26 num_samples 12500 loss 0.07022232643522726\n",
      "Epoch 26 num_samples 12600 loss 0.08465469711448671\n",
      "Epoch 26 num_samples 12700 loss 0.07640922757658714\n",
      "Epoch 26 num_samples 12800 loss 0.10686981608595487\n",
      "Epoch 26 num_samples 12900 loss 0.0655933145096473\n",
      "Epoch 26 num_samples 13000 loss 0.04806976670572933\n",
      "Epoch 26 num_samples 13100 loss 0.12851931775552491\n",
      "Epoch 26 num_samples 13200 loss 0.0528136969425208\n",
      "Epoch 26 num_samples 13300 loss 0.049783109863181886\n",
      "Epoch 26 num_samples 13400 loss 0.03077969965081045\n",
      "Epoch 26 num_samples 13500 loss 0.050225071047706946\n",
      "Epoch 26 num_samples 13600 loss 0.08944940600980043\n",
      "Epoch 26 num_samples 13700 loss 0.06584481734170539\n",
      "Epoch 26 num_samples 13800 loss 0.0641541720677683\n",
      "Epoch 26 num_samples 13900 loss 0.030431038033534565\n",
      "Epoch 26 num_samples 14000 loss 0.04666024155198183\n",
      "Epoch 26 num_samples 14100 loss 0.06103021749002417\n",
      "Epoch 26 num_samples 14200 loss 0.0436880008402809\n",
      "Epoch 26 num_samples 14300 loss 0.07373791105405254\n",
      "Epoch 26 num_samples 14400 loss 0.06527743737259181\n",
      "Epoch 26 num_samples 14500 loss 0.07199645348819997\n",
      "Epoch 26 num_samples 14600 loss 0.05786678706173024\n",
      "Epoch 26 num_samples 14700 loss 0.06401660129212589\n",
      "Epoch 26 num_samples 14800 loss 0.04957979057995346\n",
      "Epoch 26 num_samples 14900 loss 0.09140285417747265\n",
      "Epoch 26 num_samples 15000 loss 0.04915253169406355\n",
      "Epoch 26 num_samples 15100 loss 0.06598772169081552\n",
      "Epoch 26 num_samples 15200 loss 0.10083221637612891\n",
      "Epoch 26 num_samples 15300 loss 0.06080689312920095\n",
      "Epoch 26 num_samples 15400 loss 0.04335040435339521\n",
      "Epoch 26 num_samples 15500 loss 0.08682114630899956\n",
      "Epoch 26 num_samples 15600 loss 0.06064840773440076\n",
      "Epoch 26 num_samples 15700 loss 0.0406506518123779\n",
      "Epoch 26 num_samples 15800 loss 0.10173454376190491\n",
      "Epoch 26 num_samples 15900 loss 0.03903415063277767\n",
      "Epoch 26 num_samples 16000 loss 0.08412540009395542\n",
      "Epoch 26 num_samples 16100 loss 0.047092324274382466\n",
      "Epoch 26 num_samples 16200 loss 0.0709458594489022\n",
      "Epoch 26 num_samples 16300 loss 0.098803684328765\n",
      "Epoch 26 num_samples 16400 loss 0.08143295176462725\n",
      "Epoch 26 num_samples 16500 loss 0.0666659354069301\n",
      "Epoch 26 num_samples 16600 loss 0.08255649910082079\n",
      "Epoch 26 num_samples 16700 loss 0.042385950208747365\n",
      "Epoch 26 num_samples 16800 loss 0.047948360250260384\n",
      "Epoch 26 num_samples 16900 loss 0.05480743211790671\n",
      "Epoch 26 num_samples 17000 loss 0.040317300807484795\n",
      "Epoch 26 num_samples 17100 loss 0.14492755230875096\n",
      "Epoch 26 num_samples 17200 loss 0.07195315168588985\n",
      "Epoch 26 num_samples 17300 loss 0.0894262699336539\n",
      "Epoch 26 num_samples 17400 loss 0.06873849428159948\n",
      "Epoch 26 num_samples 17500 loss 0.06459227770517958\n",
      "Epoch 26 num_samples 17600 loss 0.07214243937982029\n",
      "Epoch 26 num_samples 17700 loss 0.04677826368965123\n",
      "Epoch 26 num_samples 17800 loss 0.07943386745236611\n",
      "Epoch 26 num_samples 17900 loss 0.08457544523247101\n",
      "Epoch 26 num_samples 18000 loss 0.04886266246450388\n",
      "Epoch 26 num_samples 18100 loss 0.06806372782154477\n",
      "Epoch 26 num_samples 18200 loss 0.07411558178942984\n",
      "Epoch 26 num_samples 18300 loss 0.054682047761665124\n",
      "Epoch 26 num_samples 18400 loss 0.10413632724650189\n",
      "Epoch 26 num_samples 18500 loss 0.06642019476846851\n",
      "Epoch 27 num_samples 0 loss 0.05103197969486541\n",
      "Epoch 27 num_samples 100 loss 0.08619778488337372\n",
      "Epoch 27 num_samples 200 loss 0.049938417922703794\n",
      "Epoch 27 num_samples 300 loss 0.04976690562597612\n",
      "Epoch 27 num_samples 400 loss 0.05279825532474154\n",
      "Epoch 27 num_samples 500 loss 0.06673212647930918\n",
      "Epoch 27 num_samples 600 loss 0.08737368243022013\n",
      "Epoch 27 num_samples 700 loss 0.10046330485231289\n",
      "Epoch 27 num_samples 800 loss 0.06638811065978673\n",
      "Epoch 27 num_samples 900 loss 0.07286711760764561\n",
      "Epoch 27 num_samples 1000 loss 0.05716660763746098\n",
      "Epoch 27 num_samples 1100 loss 0.09952471826802788\n",
      "Epoch 27 num_samples 1200 loss 0.06417166520966117\n",
      "Epoch 27 num_samples 1300 loss 0.054869735927610304\n",
      "Epoch 27 num_samples 1400 loss 0.08030394432694381\n",
      "Epoch 27 num_samples 1500 loss 0.13866462348981273\n",
      "Epoch 27 num_samples 1600 loss 0.058231690579559424\n",
      "Epoch 27 num_samples 1700 loss 0.05830989727334773\n",
      "Epoch 27 num_samples 1800 loss 0.05498250926305617\n",
      "Epoch 27 num_samples 1900 loss 0.058877060953630586\n",
      "Epoch 27 num_samples 2000 loss 0.08393124798412999\n",
      "Epoch 27 num_samples 2100 loss 0.043318292677577495\n",
      "Epoch 27 num_samples 2200 loss 0.043569038068658944\n",
      "Epoch 27 num_samples 2300 loss 0.037233215973848016\n",
      "Epoch 27 num_samples 2400 loss 0.05494178482659233\n",
      "Epoch 27 num_samples 2500 loss 0.08661111962931453\n",
      "Epoch 27 num_samples 2600 loss 0.0778658334715872\n",
      "Epoch 27 num_samples 2700 loss 0.07464796025250316\n",
      "Epoch 27 num_samples 2800 loss 0.08090955624477045\n",
      "Epoch 27 num_samples 2900 loss 0.07158889574709713\n",
      "Epoch 27 num_samples 3000 loss 0.05721304262187414\n",
      "Epoch 27 num_samples 3100 loss 0.0713612913356579\n",
      "Epoch 27 num_samples 3200 loss 0.163612722502061\n",
      "Epoch 27 num_samples 3300 loss 0.07054419227516874\n",
      "Epoch 27 num_samples 3400 loss 0.04598380331868654\n",
      "Epoch 27 num_samples 3500 loss 0.057176122849844295\n",
      "Epoch 27 num_samples 3600 loss 0.03403731440791489\n",
      "Epoch 27 num_samples 3700 loss 0.09494256894883585\n",
      "Epoch 27 num_samples 3800 loss 0.06766953174896523\n",
      "Epoch 27 num_samples 3900 loss 0.07140423815525099\n",
      "Epoch 27 num_samples 4000 loss 0.0738582215378038\n",
      "Epoch 27 num_samples 4100 loss 0.11909372314239419\n",
      "Epoch 27 num_samples 4200 loss 0.06079562402949788\n",
      "Epoch 27 num_samples 4300 loss 0.0721424473330048\n",
      "Epoch 27 num_samples 4400 loss 0.07820169118500882\n",
      "Epoch 27 num_samples 4500 loss 0.09011710337632138\n",
      "Epoch 27 num_samples 4600 loss 0.06593291776398243\n",
      "Epoch 27 num_samples 4700 loss 0.03640715192638378\n",
      "Epoch 27 num_samples 4800 loss 0.039576632565710035\n",
      "Epoch 27 num_samples 4900 loss 0.04488612365448675\n",
      "Epoch 27 num_samples 5000 loss 0.04998222090801576\n",
      "Epoch 27 num_samples 5100 loss 0.0799913980650374\n",
      "Epoch 27 num_samples 5200 loss 0.03833381769826596\n",
      "Epoch 27 num_samples 5300 loss 0.05733711458360777\n",
      "Epoch 27 num_samples 5400 loss 0.07937457306760891\n",
      "Epoch 27 num_samples 5500 loss 0.04519870176774842\n",
      "Epoch 27 num_samples 5600 loss 0.1532753810941002\n",
      "Epoch 27 num_samples 5700 loss 0.0979700292640086\n",
      "Epoch 27 num_samples 5800 loss 0.07965031722891121\n",
      "Epoch 27 num_samples 5900 loss 0.08820539034769169\n",
      "Epoch 27 num_samples 6000 loss 0.0822828259540883\n",
      "Epoch 27 num_samples 6100 loss 0.05198010596349988\n",
      "Epoch 27 num_samples 6200 loss 0.06867612639900494\n",
      "Epoch 27 num_samples 6300 loss 0.09238459026836138\n",
      "Epoch 27 num_samples 6400 loss 0.05104805117700867\n",
      "Epoch 27 num_samples 6500 loss 0.04385814712678268\n",
      "Epoch 27 num_samples 6600 loss 0.08941875006804981\n",
      "Epoch 27 num_samples 6700 loss 0.03809169038667546\n",
      "Epoch 27 num_samples 6800 loss 0.03260065708014009\n",
      "Epoch 27 num_samples 6900 loss 0.12014371341674013\n",
      "Epoch 27 num_samples 7000 loss 0.10032037400933407\n",
      "Epoch 27 num_samples 7100 loss 0.050447955404229514\n",
      "Epoch 27 num_samples 7200 loss 0.05114346220686377\n",
      "Epoch 27 num_samples 7300 loss 0.055909465641347855\n",
      "Epoch 27 num_samples 7400 loss 0.04973645881693084\n",
      "Epoch 27 num_samples 7500 loss 0.10565263517894195\n",
      "Epoch 27 num_samples 7600 loss 0.0618586237188917\n",
      "Epoch 27 num_samples 7700 loss 0.11040712213135563\n",
      "Epoch 27 num_samples 7800 loss 0.039140967978225694\n",
      "Epoch 27 num_samples 7900 loss 0.06421718901587425\n",
      "Epoch 27 num_samples 8000 loss 0.04220965716351907\n",
      "Epoch 27 num_samples 8100 loss 0.054434059926414806\n",
      "Epoch 27 num_samples 8200 loss 0.06604594856993068\n",
      "Epoch 27 num_samples 8300 loss 0.07281484488682854\n",
      "Epoch 27 num_samples 8400 loss 0.05107503688220502\n",
      "Epoch 27 num_samples 8500 loss 0.07341011613368352\n",
      "Epoch 27 num_samples 8600 loss 0.054129547952673926\n",
      "Epoch 27 num_samples 8700 loss 0.06437048755553382\n",
      "Epoch 27 num_samples 8800 loss 0.09726616078305461\n",
      "Epoch 27 num_samples 8900 loss 0.06849387646639206\n",
      "Epoch 27 num_samples 9000 loss 0.0614953321912917\n",
      "Epoch 27 num_samples 9100 loss 0.06503623163862032\n",
      "Epoch 27 num_samples 9200 loss 0.055245870719000105\n",
      "Epoch 27 num_samples 9300 loss 0.0622460133026682\n",
      "Epoch 27 num_samples 9400 loss 0.04787696313062145\n",
      "Epoch 27 num_samples 9500 loss 0.06885478947961707\n",
      "Epoch 27 num_samples 9600 loss 0.04831973910744468\n",
      "Epoch 27 num_samples 9700 loss 0.0794948659605431\n",
      "Epoch 27 num_samples 9800 loss 0.035343863622703114\n",
      "Epoch 27 num_samples 9900 loss 0.11169676360820166\n",
      "Epoch 27 num_samples 10000 loss 0.06599633437724234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 num_samples 10100 loss 0.041926805495337775\n",
      "Epoch 27 num_samples 10200 loss 0.10009154377670958\n",
      "Epoch 27 num_samples 10300 loss 0.06757081943879743\n",
      "Epoch 27 num_samples 10400 loss 0.08252919856255068\n",
      "Epoch 27 num_samples 10500 loss 0.04893810027831261\n",
      "Epoch 27 num_samples 10600 loss 0.09330574626321379\n",
      "Epoch 27 num_samples 10700 loss 0.05309471077922692\n",
      "Epoch 27 num_samples 10800 loss 0.10111894830215203\n",
      "Epoch 27 num_samples 10900 loss 0.051206682097632135\n",
      "Epoch 27 num_samples 11000 loss 0.03864733302663304\n",
      "Epoch 27 num_samples 11100 loss 0.06249685337157469\n",
      "Epoch 27 num_samples 11200 loss 0.05243196996640629\n",
      "Epoch 27 num_samples 11300 loss 0.10922920476353934\n",
      "Epoch 27 num_samples 11400 loss 0.09381474391609729\n",
      "Epoch 27 num_samples 11500 loss 0.056341622470062136\n",
      "Epoch 27 num_samples 11600 loss 0.04961324762917691\n",
      "Epoch 27 num_samples 11700 loss 0.07787884333190535\n",
      "Epoch 27 num_samples 11800 loss 0.054229590811622444\n",
      "Epoch 27 num_samples 11900 loss 0.05552187697625785\n",
      "Epoch 27 num_samples 12000 loss 0.03724763961204047\n",
      "Epoch 27 num_samples 12100 loss 0.06807212917050386\n",
      "Epoch 27 num_samples 12200 loss 0.0876613345768678\n",
      "Epoch 27 num_samples 12300 loss 0.03755017379474145\n",
      "Epoch 27 num_samples 12400 loss 0.08043297699597893\n",
      "Epoch 27 num_samples 12500 loss 0.06553291619196011\n",
      "Epoch 27 num_samples 12600 loss 0.08003340011767744\n",
      "Epoch 27 num_samples 12700 loss 0.07148005374373087\n",
      "Epoch 27 num_samples 12800 loss 0.10022602572315115\n",
      "Epoch 27 num_samples 12900 loss 0.06077661438624384\n",
      "Epoch 27 num_samples 13000 loss 0.045354166593298065\n",
      "Epoch 27 num_samples 13100 loss 0.12269719292190953\n",
      "Epoch 27 num_samples 13200 loss 0.049524523357813696\n",
      "Epoch 27 num_samples 13300 loss 0.04584366510253177\n",
      "Epoch 27 num_samples 13400 loss 0.028086510743417822\n",
      "Epoch 27 num_samples 13500 loss 0.04691044107945521\n",
      "Epoch 27 num_samples 13600 loss 0.08545872141066323\n",
      "Epoch 27 num_samples 13700 loss 0.06179304390684808\n",
      "Epoch 27 num_samples 13800 loss 0.05948658578336076\n",
      "Epoch 27 num_samples 13900 loss 0.02762116906378177\n",
      "Epoch 27 num_samples 14000 loss 0.044092688761285144\n",
      "Epoch 27 num_samples 14100 loss 0.05685899469868671\n",
      "Epoch 27 num_samples 14200 loss 0.040356506889111125\n",
      "Epoch 27 num_samples 14300 loss 0.06855958370342596\n",
      "Epoch 27 num_samples 14400 loss 0.06100091008177138\n",
      "Epoch 27 num_samples 14500 loss 0.06781746883476891\n",
      "Epoch 27 num_samples 14600 loss 0.05438292603189956\n",
      "Epoch 27 num_samples 14700 loss 0.05918417573320312\n",
      "Epoch 27 num_samples 14800 loss 0.04637063768475819\n",
      "Epoch 27 num_samples 14900 loss 0.08419520173133474\n",
      "Epoch 27 num_samples 15000 loss 0.046778144394334614\n",
      "Epoch 27 num_samples 15100 loss 0.06151019153471692\n",
      "Epoch 27 num_samples 15200 loss 0.09312711039858453\n",
      "Epoch 27 num_samples 15300 loss 0.057184846388682785\n",
      "Epoch 27 num_samples 15400 loss 0.04016386969890098\n",
      "Epoch 27 num_samples 15500 loss 0.08120841953858667\n",
      "Epoch 27 num_samples 15600 loss 0.05669527411044968\n",
      "Epoch 27 num_samples 15700 loss 0.037810893788064126\n",
      "Epoch 27 num_samples 15800 loss 0.09523791529996344\n",
      "Epoch 27 num_samples 15900 loss 0.03643597057813642\n",
      "Epoch 27 num_samples 16000 loss 0.07859199442378087\n",
      "Epoch 27 num_samples 16100 loss 0.0437133967483717\n",
      "Epoch 27 num_samples 16200 loss 0.06654550466744755\n",
      "Epoch 27 num_samples 16300 loss 0.0941953419518602\n",
      "Epoch 27 num_samples 16400 loss 0.0770556406863863\n",
      "Epoch 27 num_samples 16500 loss 0.0619412333937708\n",
      "Epoch 27 num_samples 16600 loss 0.0770048375413485\n",
      "Epoch 27 num_samples 16700 loss 0.03890935886893056\n",
      "Epoch 27 num_samples 16800 loss 0.04475555437806879\n",
      "Epoch 27 num_samples 16900 loss 0.0516419265796096\n",
      "Epoch 27 num_samples 17000 loss 0.037160023441263984\n",
      "Epoch 27 num_samples 17100 loss 0.1375616258086313\n",
      "Epoch 27 num_samples 17200 loss 0.06748586494207792\n",
      "Epoch 27 num_samples 17300 loss 0.08465989711722555\n",
      "Epoch 27 num_samples 17400 loss 0.06349590891980993\n",
      "Epoch 27 num_samples 17500 loss 0.05919511830108741\n",
      "Epoch 27 num_samples 17600 loss 0.06642210857840887\n",
      "Epoch 27 num_samples 17700 loss 0.04362958960671767\n",
      "Epoch 27 num_samples 17800 loss 0.0731152870952721\n",
      "Epoch 27 num_samples 17900 loss 0.07888201986739608\n",
      "Epoch 27 num_samples 18000 loss 0.04585961583357248\n",
      "Epoch 27 num_samples 18100 loss 0.06346699076201173\n",
      "Epoch 27 num_samples 18200 loss 0.06824189472540622\n",
      "Epoch 27 num_samples 18300 loss 0.050583643572851125\n",
      "Epoch 27 num_samples 18400 loss 0.09679838669069159\n",
      "Epoch 27 num_samples 18500 loss 0.061519767156766776\n",
      "Epoch 28 num_samples 0 loss 0.047376427604895695\n",
      "Epoch 28 num_samples 100 loss 0.08163453537532021\n",
      "Epoch 28 num_samples 200 loss 0.04642536135773454\n",
      "Epoch 28 num_samples 300 loss 0.046399931021386266\n",
      "Epoch 28 num_samples 400 loss 0.04974840094588973\n",
      "Epoch 28 num_samples 500 loss 0.06342581810430221\n",
      "Epoch 28 num_samples 600 loss 0.0823243908069969\n",
      "Epoch 28 num_samples 700 loss 0.09085673731397018\n",
      "Epoch 28 num_samples 800 loss 0.06104578129264627\n",
      "Epoch 28 num_samples 900 loss 0.0694528763731943\n",
      "Epoch 28 num_samples 1000 loss 0.053678081402489586\n",
      "Epoch 28 num_samples 1100 loss 0.09390427330864853\n",
      "Epoch 28 num_samples 1200 loss 0.05987649982786112\n",
      "Epoch 28 num_samples 1300 loss 0.05190245636785407\n",
      "Epoch 28 num_samples 1400 loss 0.07426510546494318\n",
      "Epoch 28 num_samples 1500 loss 0.13073873141302714\n",
      "Epoch 28 num_samples 1600 loss 0.05377750912593372\n",
      "Epoch 28 num_samples 1700 loss 0.053542420665892806\n",
      "Epoch 28 num_samples 1800 loss 0.05147499438044841\n",
      "Epoch 28 num_samples 1900 loss 0.05453671125943535\n",
      "Epoch 28 num_samples 2000 loss 0.07691302709019997\n",
      "Epoch 28 num_samples 2100 loss 0.040312309189608125\n",
      "Epoch 28 num_samples 2200 loss 0.04135805892666559\n",
      "Epoch 28 num_samples 2300 loss 0.03382857463164303\n",
      "Epoch 28 num_samples 2400 loss 0.05143432849508603\n",
      "Epoch 28 num_samples 2500 loss 0.08177322069861155\n",
      "Epoch 28 num_samples 2600 loss 0.07367838592190104\n",
      "Epoch 28 num_samples 2700 loss 0.06879946588733094\n",
      "Epoch 28 num_samples 2800 loss 0.07598182355769587\n",
      "Epoch 28 num_samples 2900 loss 0.06745680029488754\n",
      "Epoch 28 num_samples 3000 loss 0.05348967856012551\n",
      "Epoch 28 num_samples 3100 loss 0.06614864997734206\n",
      "Epoch 28 num_samples 3200 loss 0.15572063087266463\n",
      "Epoch 28 num_samples 3300 loss 0.06708190671044613\n",
      "Epoch 28 num_samples 3400 loss 0.04309063092434708\n",
      "Epoch 28 num_samples 3500 loss 0.05244438207650206\n",
      "Epoch 28 num_samples 3600 loss 0.03218373768583207\n",
      "Epoch 28 num_samples 3700 loss 0.08996537266605945\n",
      "Epoch 28 num_samples 3800 loss 0.06214757552650243\n",
      "Epoch 28 num_samples 3900 loss 0.06584039883835573\n",
      "Epoch 28 num_samples 4000 loss 0.06981306577942807\n",
      "Epoch 28 num_samples 4100 loss 0.112405274251506\n",
      "Epoch 28 num_samples 4200 loss 0.05613981054657947\n",
      "Epoch 28 num_samples 4300 loss 0.06721698207234873\n",
      "Epoch 28 num_samples 4400 loss 0.0728097100781326\n",
      "Epoch 28 num_samples 4500 loss 0.08412467520354962\n",
      "Epoch 28 num_samples 4600 loss 0.06118532771253083\n",
      "Epoch 28 num_samples 4700 loss 0.03436195873190583\n",
      "Epoch 28 num_samples 4800 loss 0.036760946690131906\n",
      "Epoch 28 num_samples 4900 loss 0.04174111427362395\n",
      "Epoch 28 num_samples 5000 loss 0.04693676779446717\n",
      "Epoch 28 num_samples 5100 loss 0.07403388153007305\n",
      "Epoch 28 num_samples 5200 loss 0.035594622127135433\n",
      "Epoch 28 num_samples 5300 loss 0.05346337850156451\n",
      "Epoch 28 num_samples 5400 loss 0.07271532920291485\n",
      "Epoch 28 num_samples 5500 loss 0.04129156568991243\n",
      "Epoch 28 num_samples 5600 loss 0.1487757381890341\n",
      "Epoch 28 num_samples 5700 loss 0.09235672414412066\n",
      "Epoch 28 num_samples 5800 loss 0.07349445230343708\n",
      "Epoch 28 num_samples 5900 loss 0.08314896177802267\n",
      "Epoch 28 num_samples 6000 loss 0.07645950168136192\n",
      "Epoch 28 num_samples 6100 loss 0.048981106448979975\n",
      "Epoch 28 num_samples 6200 loss 0.06407683280657639\n",
      "Epoch 28 num_samples 6300 loss 0.08776351487639936\n",
      "Epoch 28 num_samples 6400 loss 0.04799465407273959\n",
      "Epoch 28 num_samples 6500 loss 0.04120879062953911\n",
      "Epoch 28 num_samples 6600 loss 0.08351923968110658\n",
      "Epoch 28 num_samples 6700 loss 0.035989376238700375\n",
      "Epoch 28 num_samples 6800 loss 0.030361409620477068\n",
      "Epoch 28 num_samples 6900 loss 0.11233730958250188\n",
      "Epoch 28 num_samples 7000 loss 0.0931549690156549\n",
      "Epoch 28 num_samples 7100 loss 0.04535424267351163\n",
      "Epoch 28 num_samples 7200 loss 0.04782504972474795\n",
      "Epoch 28 num_samples 7300 loss 0.05119288783872366\n",
      "Epoch 28 num_samples 7400 loss 0.04628793032653803\n",
      "Epoch 28 num_samples 7500 loss 0.09884667450633834\n",
      "Epoch 28 num_samples 7600 loss 0.05798466576873654\n",
      "Epoch 28 num_samples 7700 loss 0.10364397897612808\n",
      "Epoch 28 num_samples 7800 loss 0.03662126729241532\n",
      "Epoch 28 num_samples 7900 loss 0.059223231981695316\n",
      "Epoch 28 num_samples 8000 loss 0.039072734836883935\n",
      "Epoch 28 num_samples 8100 loss 0.050590754429498605\n",
      "Epoch 28 num_samples 8200 loss 0.06133327385623898\n",
      "Epoch 28 num_samples 8300 loss 0.06864286606741958\n",
      "Epoch 28 num_samples 8400 loss 0.0470201948000401\n",
      "Epoch 28 num_samples 8500 loss 0.06776012615187955\n",
      "Epoch 28 num_samples 8600 loss 0.05172771970961535\n",
      "Epoch 28 num_samples 8700 loss 0.06027319158939158\n",
      "Epoch 28 num_samples 8800 loss 0.09139884959146918\n",
      "Epoch 28 num_samples 8900 loss 0.06405272270849363\n",
      "Epoch 28 num_samples 9000 loss 0.05720965651456528\n",
      "Epoch 28 num_samples 9100 loss 0.06073315737526095\n",
      "Epoch 28 num_samples 9200 loss 0.051825049658043826\n",
      "Epoch 28 num_samples 9300 loss 0.057993635480539395\n",
      "Epoch 28 num_samples 9400 loss 0.04483858290080658\n",
      "Epoch 28 num_samples 9500 loss 0.06320175542367999\n",
      "Epoch 28 num_samples 9600 loss 0.0450881884424345\n",
      "Epoch 28 num_samples 9700 loss 0.07537040480548521\n",
      "Epoch 28 num_samples 9800 loss 0.032882258618312885\n",
      "Epoch 28 num_samples 9900 loss 0.10478833925291361\n",
      "Epoch 28 num_samples 10000 loss 0.061604079017221446\n",
      "Epoch 28 num_samples 10100 loss 0.04007552296577696\n",
      "Epoch 28 num_samples 10200 loss 0.09270545410332641\n",
      "Epoch 28 num_samples 10300 loss 0.06281478718383231\n",
      "Epoch 28 num_samples 10400 loss 0.07732173269171275\n",
      "Epoch 28 num_samples 10500 loss 0.04605740496051478\n",
      "Epoch 28 num_samples 10600 loss 0.08729910208178464\n",
      "Epoch 28 num_samples 10700 loss 0.04899438377893528\n",
      "Epoch 28 num_samples 10800 loss 0.09548634201002358\n",
      "Epoch 28 num_samples 10900 loss 0.047601195015241425\n",
      "Epoch 28 num_samples 11000 loss 0.03619517694068805\n",
      "Epoch 28 num_samples 11100 loss 0.058405021347843554\n",
      "Epoch 28 num_samples 11200 loss 0.04870015050351248\n",
      "Epoch 28 num_samples 11300 loss 0.10279403125475685\n",
      "Epoch 28 num_samples 11400 loss 0.08727065485535906\n",
      "Epoch 28 num_samples 11500 loss 0.05302178429146674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 num_samples 11600 loss 0.046444344420642866\n",
      "Epoch 28 num_samples 11700 loss 0.07272086906611984\n",
      "Epoch 28 num_samples 11800 loss 0.05077116012069502\n",
      "Epoch 28 num_samples 11900 loss 0.05135480017936586\n",
      "Epoch 28 num_samples 12000 loss 0.03528621636483652\n",
      "Epoch 28 num_samples 12100 loss 0.0639248045820293\n",
      "Epoch 28 num_samples 12200 loss 0.08179814848766387\n",
      "Epoch 28 num_samples 12300 loss 0.03556831464215637\n",
      "Epoch 28 num_samples 12400 loss 0.07596165753951518\n",
      "Epoch 28 num_samples 12500 loss 0.06152190343335596\n",
      "Epoch 28 num_samples 12600 loss 0.0753499577586963\n",
      "Epoch 28 num_samples 12700 loss 0.06668783919674377\n",
      "Epoch 28 num_samples 12800 loss 0.0945979177099101\n",
      "Epoch 28 num_samples 12900 loss 0.055483105262928725\n",
      "Epoch 28 num_samples 13000 loss 0.04237208601652364\n",
      "Epoch 28 num_samples 13100 loss 0.11665699676223379\n",
      "Epoch 28 num_samples 13200 loss 0.04581548833852346\n",
      "Epoch 28 num_samples 13300 loss 0.042753234446797246\n",
      "Epoch 28 num_samples 13400 loss 0.025858513661992447\n",
      "Epoch 28 num_samples 13500 loss 0.04372606850555989\n",
      "Epoch 28 num_samples 13600 loss 0.0805092559860184\n",
      "Epoch 28 num_samples 13700 loss 0.05776945945877234\n",
      "Epoch 28 num_samples 13800 loss 0.05536855710417604\n",
      "Epoch 28 num_samples 13900 loss 0.025434937139374645\n",
      "Epoch 28 num_samples 14000 loss 0.0419799013743863\n",
      "Epoch 28 num_samples 14100 loss 0.05365898448073558\n",
      "Epoch 28 num_samples 14200 loss 0.038827476782850055\n",
      "Epoch 28 num_samples 14300 loss 0.06322304704147155\n",
      "Epoch 28 num_samples 14400 loss 0.0576646024061786\n",
      "Epoch 28 num_samples 14500 loss 0.06267316975596776\n",
      "Epoch 28 num_samples 14600 loss 0.05092640767010334\n",
      "Epoch 28 num_samples 14700 loss 0.05598694352979136\n",
      "Epoch 28 num_samples 14800 loss 0.04362257838971545\n",
      "Epoch 28 num_samples 14900 loss 0.07770220691803655\n",
      "Epoch 28 num_samples 15000 loss 0.044013051427164745\n",
      "Epoch 28 num_samples 15100 loss 0.057279023153019464\n",
      "Epoch 28 num_samples 15200 loss 0.08618498912646039\n",
      "Epoch 28 num_samples 15300 loss 0.05396998159492592\n",
      "Epoch 28 num_samples 15400 loss 0.03691142942781592\n",
      "Epoch 28 num_samples 15500 loss 0.07581550559168156\n",
      "Epoch 28 num_samples 15600 loss 0.05355420083690588\n",
      "Epoch 28 num_samples 15700 loss 0.035223497436293875\n",
      "Epoch 28 num_samples 15800 loss 0.0890287747363811\n",
      "Epoch 28 num_samples 15900 loss 0.03437975633321754\n",
      "Epoch 28 num_samples 16000 loss 0.0729807509859542\n",
      "Epoch 28 num_samples 16100 loss 0.04066257346698041\n",
      "Epoch 28 num_samples 16200 loss 0.0622255572380841\n",
      "Epoch 28 num_samples 16300 loss 0.08848744533815955\n",
      "Epoch 28 num_samples 16400 loss 0.07318723387943804\n",
      "Epoch 28 num_samples 16500 loss 0.05845008650529914\n",
      "Epoch 28 num_samples 16600 loss 0.07232637703253765\n",
      "Epoch 28 num_samples 16700 loss 0.03610760045746754\n",
      "Epoch 28 num_samples 16800 loss 0.041960987881829934\n",
      "Epoch 28 num_samples 16900 loss 0.04741310033809461\n",
      "Epoch 28 num_samples 17000 loss 0.035147004810974686\n",
      "Epoch 28 num_samples 17100 loss 0.12980132382926332\n",
      "Epoch 28 num_samples 17200 loss 0.06326955209004426\n",
      "Epoch 28 num_samples 17300 loss 0.07877623015493528\n",
      "Epoch 28 num_samples 17400 loss 0.059318226475006924\n",
      "Epoch 28 num_samples 17500 loss 0.054917976174431296\n",
      "Epoch 28 num_samples 17600 loss 0.06044019758246741\n",
      "Epoch 28 num_samples 17700 loss 0.04037503183494022\n",
      "Epoch 28 num_samples 17800 loss 0.06703100777941659\n",
      "Epoch 28 num_samples 17900 loss 0.0740535601744889\n",
      "Epoch 28 num_samples 18000 loss 0.04358091397824364\n",
      "Epoch 28 num_samples 18100 loss 0.05887016671509793\n",
      "Epoch 28 num_samples 18200 loss 0.06451003665783785\n",
      "Epoch 28 num_samples 18300 loss 0.047863055475101585\n",
      "Epoch 28 num_samples 18400 loss 0.090912733059347\n",
      "Epoch 28 num_samples 18500 loss 0.05830130069670511\n",
      "Epoch 29 num_samples 0 loss 0.0443425639133301\n",
      "Epoch 29 num_samples 100 loss 0.07737829720868203\n",
      "Epoch 29 num_samples 200 loss 0.04347543781726383\n",
      "Epoch 29 num_samples 300 loss 0.043259835564323446\n",
      "Epoch 29 num_samples 400 loss 0.0464345745125723\n",
      "Epoch 29 num_samples 500 loss 0.05987056574558418\n",
      "Epoch 29 num_samples 600 loss 0.07607543717040788\n",
      "Epoch 29 num_samples 700 loss 0.0846182964805452\n",
      "Epoch 29 num_samples 800 loss 0.05653982074555358\n",
      "Epoch 29 num_samples 900 loss 0.06634745234153805\n",
      "Epoch 29 num_samples 1000 loss 0.04999944970826618\n",
      "Epoch 29 num_samples 1100 loss 0.08786370756164871\n",
      "Epoch 29 num_samples 1200 loss 0.055867341350161887\n",
      "Epoch 29 num_samples 1300 loss 0.049731730344348433\n",
      "Epoch 29 num_samples 1400 loss 0.07036549644410905\n",
      "Epoch 29 num_samples 1500 loss 0.12398774593488432\n",
      "Epoch 29 num_samples 1600 loss 0.05077479592449148\n",
      "Epoch 29 num_samples 1700 loss 0.05039833613872623\n",
      "Epoch 29 num_samples 1800 loss 0.047785844018544826\n",
      "Epoch 29 num_samples 1900 loss 0.0516031336544545\n",
      "Epoch 29 num_samples 2000 loss 0.07112072604246626\n",
      "Epoch 29 num_samples 2100 loss 0.03739112804577574\n",
      "Epoch 29 num_samples 2200 loss 0.03838149098823134\n",
      "Epoch 29 num_samples 2300 loss 0.03120442526098792\n",
      "Epoch 29 num_samples 2400 loss 0.04883521607477045\n",
      "Epoch 29 num_samples 2500 loss 0.07562794176006667\n",
      "Epoch 29 num_samples 2600 loss 0.0694750667689498\n",
      "Epoch 29 num_samples 2700 loss 0.06161336058715142\n",
      "Epoch 29 num_samples 2800 loss 0.07168558204542932\n",
      "Epoch 29 num_samples 2900 loss 0.06318418089267044\n",
      "Epoch 29 num_samples 3000 loss 0.050223773734990956\n",
      "Epoch 29 num_samples 3100 loss 0.06123343245591573\n",
      "Epoch 29 num_samples 3200 loss 0.1483057595326515\n",
      "Epoch 29 num_samples 3300 loss 0.06376404004730904\n",
      "Epoch 29 num_samples 3400 loss 0.04075577301199637\n",
      "Epoch 29 num_samples 3500 loss 0.048038917963223016\n",
      "Epoch 29 num_samples 3600 loss 0.02979679556113997\n",
      "Epoch 29 num_samples 3700 loss 0.08505406635366589\n",
      "Epoch 29 num_samples 3800 loss 0.057953376184321254\n",
      "Epoch 29 num_samples 3900 loss 0.06164106648616361\n",
      "Epoch 29 num_samples 4000 loss 0.06493850344155758\n",
      "Epoch 29 num_samples 4100 loss 0.10496420231072028\n",
      "Epoch 29 num_samples 4200 loss 0.053551802490967\n",
      "Epoch 29 num_samples 4300 loss 0.06230783315368696\n",
      "Epoch 29 num_samples 4400 loss 0.06805841736098438\n",
      "Epoch 29 num_samples 4500 loss 0.07888657808158296\n",
      "Epoch 29 num_samples 4600 loss 0.057440653537675954\n",
      "Epoch 29 num_samples 4700 loss 0.03262523425719421\n",
      "Epoch 29 num_samples 4800 loss 0.03416771460450613\n",
      "Epoch 29 num_samples 4900 loss 0.039401202727089545\n",
      "Epoch 29 num_samples 5000 loss 0.043494567277906855\n",
      "Epoch 29 num_samples 5100 loss 0.06908682657107759\n",
      "Epoch 29 num_samples 5200 loss 0.03370082232882022\n",
      "Epoch 29 num_samples 5300 loss 0.04997091880979355\n",
      "Epoch 29 num_samples 5400 loss 0.0676059833846558\n",
      "Epoch 29 num_samples 5500 loss 0.0381193539238427\n",
      "Epoch 29 num_samples 5600 loss 0.1434179513502605\n",
      "Epoch 29 num_samples 5700 loss 0.08768413326139449\n",
      "Epoch 29 num_samples 5800 loss 0.06742306762235115\n",
      "Epoch 29 num_samples 5900 loss 0.07639847047614581\n",
      "Epoch 29 num_samples 6000 loss 0.0705359086858979\n",
      "Epoch 29 num_samples 6100 loss 0.04648235269834155\n",
      "Epoch 29 num_samples 6200 loss 0.06031183782898699\n",
      "Epoch 29 num_samples 6300 loss 0.08328346597910233\n",
      "Epoch 29 num_samples 6400 loss 0.04526320159639645\n",
      "Epoch 29 num_samples 6500 loss 0.03870358667209628\n",
      "Epoch 29 num_samples 6600 loss 0.07845862673268345\n",
      "Epoch 29 num_samples 6700 loss 0.0340344560818898\n",
      "Epoch 29 num_samples 6800 loss 0.028653405087183028\n",
      "Epoch 29 num_samples 6900 loss 0.10551956335522678\n",
      "Epoch 29 num_samples 7000 loss 0.08634924924422807\n",
      "Epoch 29 num_samples 7100 loss 0.041981214658262635\n",
      "Epoch 29 num_samples 7200 loss 0.044483798538373885\n",
      "Epoch 29 num_samples 7300 loss 0.04705365832583427\n",
      "Epoch 29 num_samples 7400 loss 0.04217114029274863\n",
      "Epoch 29 num_samples 7500 loss 0.09316742652814547\n",
      "Epoch 29 num_samples 7600 loss 0.054859836545873814\n",
      "Epoch 29 num_samples 7700 loss 0.0975430600670859\n",
      "Epoch 29 num_samples 7800 loss 0.034450232731817486\n",
      "Epoch 29 num_samples 7900 loss 0.05493112618931471\n",
      "Epoch 29 num_samples 8000 loss 0.03698744249764874\n",
      "Epoch 29 num_samples 8100 loss 0.047291381216730655\n",
      "Epoch 29 num_samples 8200 loss 0.05703858172625427\n",
      "Epoch 29 num_samples 8300 loss 0.06382143651808403\n",
      "Epoch 29 num_samples 8400 loss 0.04365993804803399\n",
      "Epoch 29 num_samples 8500 loss 0.06225996151606702\n",
      "Epoch 29 num_samples 8600 loss 0.04848522716820001\n",
      "Epoch 29 num_samples 8700 loss 0.056380686865396934\n",
      "Epoch 29 num_samples 8800 loss 0.08583971202688429\n",
      "Epoch 29 num_samples 8900 loss 0.06007702645470383\n",
      "Epoch 29 num_samples 9000 loss 0.05389625546112299\n",
      "Epoch 29 num_samples 9100 loss 0.05708593251846069\n",
      "Epoch 29 num_samples 9200 loss 0.048579395538054335\n",
      "Epoch 29 num_samples 9300 loss 0.05473694453242345\n",
      "Epoch 29 num_samples 9400 loss 0.04198446409473153\n",
      "Epoch 29 num_samples 9500 loss 0.05840499186556926\n",
      "Epoch 29 num_samples 9600 loss 0.04250044278896978\n",
      "Epoch 29 num_samples 9700 loss 0.07120859397201096\n",
      "Epoch 29 num_samples 9800 loss 0.031116800949709474\n",
      "Epoch 29 num_samples 9900 loss 0.09907149842781438\n",
      "Epoch 29 num_samples 10000 loss 0.05765593897231656\n",
      "Epoch 29 num_samples 10100 loss 0.03801151351683503\n",
      "Epoch 29 num_samples 10200 loss 0.08501308263750434\n",
      "Epoch 29 num_samples 10300 loss 0.059368277855650915\n",
      "Epoch 29 num_samples 10400 loss 0.07302095122652197\n",
      "Epoch 29 num_samples 10500 loss 0.04308092478307137\n",
      "Epoch 29 num_samples 10600 loss 0.0839929673942891\n",
      "Epoch 29 num_samples 10700 loss 0.045565583077427814\n",
      "Epoch 29 num_samples 10800 loss 0.08938222187179314\n",
      "Epoch 29 num_samples 10900 loss 0.04422611962949451\n",
      "Epoch 29 num_samples 11000 loss 0.034472822554797236\n",
      "Epoch 29 num_samples 11100 loss 0.05502954831986786\n",
      "Epoch 29 num_samples 11200 loss 0.045956853902511405\n",
      "Epoch 29 num_samples 11300 loss 0.09596630266489427\n",
      "Epoch 29 num_samples 11400 loss 0.08096905529056667\n",
      "Epoch 29 num_samples 11500 loss 0.05025748019366123\n",
      "Epoch 29 num_samples 11600 loss 0.04351289056314494\n",
      "Epoch 29 num_samples 11700 loss 0.06890386838015222\n",
      "Epoch 29 num_samples 11800 loss 0.047296183573408694\n",
      "Epoch 29 num_samples 11900 loss 0.047570143291501825\n",
      "Epoch 29 num_samples 12000 loss 0.033173708595855646\n",
      "Epoch 29 num_samples 12100 loss 0.0599291749909037\n",
      "Epoch 29 num_samples 12200 loss 0.07605528031664982\n",
      "Epoch 29 num_samples 12300 loss 0.0329424023274979\n",
      "Epoch 29 num_samples 12400 loss 0.0710606072687931\n",
      "Epoch 29 num_samples 12500 loss 0.058228493591126876\n",
      "Epoch 29 num_samples 12600 loss 0.07174093728931238\n",
      "Epoch 29 num_samples 12700 loss 0.062341240650491646\n",
      "Epoch 29 num_samples 12800 loss 0.09024379339723844\n",
      "Epoch 29 num_samples 12900 loss 0.051593099377442345\n",
      "Epoch 29 num_samples 13000 loss 0.03954482412442938\n",
      "Epoch 29 num_samples 13100 loss 0.11067814721138855\n",
      "Epoch 29 num_samples 13200 loss 0.042946075907673624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 num_samples 13300 loss 0.03958559212906172\n",
      "Epoch 29 num_samples 13400 loss 0.023927258638915334\n",
      "Epoch 29 num_samples 13500 loss 0.04084014221414788\n",
      "Epoch 29 num_samples 13600 loss 0.07658217240458651\n",
      "Epoch 29 num_samples 13700 loss 0.05301066953994092\n",
      "Epoch 29 num_samples 13800 loss 0.052033072171072205\n",
      "Epoch 29 num_samples 13900 loss 0.02322246215472633\n",
      "Epoch 29 num_samples 14000 loss 0.03944990886971667\n",
      "Epoch 29 num_samples 14100 loss 0.05054221716562452\n",
      "Epoch 29 num_samples 14200 loss 0.03670622683102654\n",
      "Epoch 29 num_samples 14300 loss 0.058886813017494946\n",
      "Epoch 29 num_samples 14400 loss 0.05447946128474604\n",
      "Epoch 29 num_samples 14500 loss 0.05871502087423135\n",
      "Epoch 29 num_samples 14600 loss 0.04764745095717909\n",
      "Epoch 29 num_samples 14700 loss 0.05175953487185273\n",
      "Epoch 29 num_samples 14800 loss 0.041105595502518494\n",
      "Epoch 29 num_samples 14900 loss 0.07163287243479291\n",
      "Epoch 29 num_samples 15000 loss 0.04156611165304145\n",
      "Epoch 29 num_samples 15100 loss 0.05336351675947895\n",
      "Epoch 29 num_samples 15200 loss 0.08042511176145303\n",
      "Epoch 29 num_samples 15300 loss 0.05115095478333356\n",
      "Epoch 29 num_samples 15400 loss 0.03432241030315032\n",
      "Epoch 29 num_samples 15500 loss 0.07105478552472685\n",
      "Epoch 29 num_samples 15600 loss 0.050526385220802356\n",
      "Epoch 29 num_samples 15700 loss 0.03269857527990254\n",
      "Epoch 29 num_samples 15800 loss 0.08239697621445842\n",
      "Epoch 29 num_samples 15900 loss 0.032351006816082065\n",
      "Epoch 29 num_samples 16000 loss 0.0683308002491944\n",
      "Epoch 29 num_samples 16100 loss 0.038098052306468\n",
      "Epoch 29 num_samples 16200 loss 0.058512004614986124\n",
      "Epoch 29 num_samples 16300 loss 0.08298391960626067\n",
      "Epoch 29 num_samples 16400 loss 0.06907983116616283\n",
      "Epoch 29 num_samples 16500 loss 0.05500985839126888\n",
      "Epoch 29 num_samples 16600 loss 0.06819985010522536\n",
      "Epoch 29 num_samples 16700 loss 0.033457869900516225\n",
      "Epoch 29 num_samples 16800 loss 0.039225332259774974\n",
      "Epoch 29 num_samples 16900 loss 0.044601062709607356\n",
      "Epoch 29 num_samples 17000 loss 0.03267193902526965\n",
      "Epoch 29 num_samples 17100 loss 0.1232345723257553\n",
      "Epoch 29 num_samples 17200 loss 0.058692722877537254\n",
      "Epoch 29 num_samples 17300 loss 0.07311121054332226\n",
      "Epoch 29 num_samples 17400 loss 0.055617974950320954\n",
      "Epoch 29 num_samples 17500 loss 0.05112130501179767\n",
      "Epoch 29 num_samples 17600 loss 0.05565720757787671\n",
      "Epoch 29 num_samples 17700 loss 0.03767180095185098\n",
      "Epoch 29 num_samples 17800 loss 0.06138001856728719\n",
      "Epoch 29 num_samples 17900 loss 0.07047200283207936\n",
      "Epoch 29 num_samples 18000 loss 0.04155207195230663\n",
      "Epoch 29 num_samples 18100 loss 0.05508591703174777\n",
      "Epoch 29 num_samples 18200 loss 0.060805187471121104\n",
      "Epoch 29 num_samples 18300 loss 0.045133893370686934\n",
      "Epoch 29 num_samples 18400 loss 0.08527639345466347\n",
      "Epoch 29 num_samples 18500 loss 0.05440774302302853\n",
      "Epoch 30 num_samples 0 loss 0.04129542031085109\n",
      "Epoch 30 num_samples 100 loss 0.07359678490187246\n",
      "Epoch 30 num_samples 200 loss 0.040938739841014475\n",
      "Epoch 30 num_samples 300 loss 0.040697472769361254\n",
      "Epoch 30 num_samples 400 loss 0.04338863792104559\n",
      "Epoch 30 num_samples 500 loss 0.056278326001997225\n",
      "Epoch 30 num_samples 600 loss 0.07184133452725751\n",
      "Epoch 30 num_samples 700 loss 0.07752622014420371\n",
      "Epoch 30 num_samples 800 loss 0.0528506271516163\n",
      "Epoch 30 num_samples 900 loss 0.06372782483245441\n",
      "Epoch 30 num_samples 1000 loss 0.04679256835736928\n",
      "Epoch 30 num_samples 1100 loss 0.08276289523080894\n",
      "Epoch 30 num_samples 1200 loss 0.0521498115832782\n",
      "Epoch 30 num_samples 1300 loss 0.04701563322238686\n",
      "Epoch 30 num_samples 1400 loss 0.06628583159446054\n",
      "Epoch 30 num_samples 1500 loss 0.11623933493034042\n",
      "Epoch 30 num_samples 1600 loss 0.047699492545590375\n",
      "Epoch 30 num_samples 1700 loss 0.04719337020109121\n",
      "Epoch 30 num_samples 1800 loss 0.04537204327186288\n",
      "Epoch 30 num_samples 1900 loss 0.048961257026952865\n",
      "Epoch 30 num_samples 2000 loss 0.06637905905878004\n",
      "Epoch 30 num_samples 2100 loss 0.03513904971749732\n",
      "Epoch 30 num_samples 2200 loss 0.036454395803978634\n",
      "Epoch 30 num_samples 2300 loss 0.027970962880516516\n",
      "Epoch 30 num_samples 2400 loss 0.04575313222891663\n",
      "Epoch 30 num_samples 2500 loss 0.07024199067673587\n",
      "Epoch 30 num_samples 2600 loss 0.0658641304470717\n",
      "Epoch 30 num_samples 2700 loss 0.05601282586054665\n",
      "Epoch 30 num_samples 2800 loss 0.0677254446429906\n",
      "Epoch 30 num_samples 2900 loss 0.059325024137644865\n",
      "Epoch 30 num_samples 3000 loss 0.04714521611698671\n",
      "Epoch 30 num_samples 3100 loss 0.05644295823989665\n",
      "Epoch 30 num_samples 3200 loss 0.14082498032657273\n",
      "Epoch 30 num_samples 3300 loss 0.06054309229313187\n",
      "Epoch 30 num_samples 3400 loss 0.03870997518331721\n",
      "Epoch 30 num_samples 3500 loss 0.04442616372036591\n",
      "Epoch 30 num_samples 3600 loss 0.02779288685969033\n",
      "Epoch 30 num_samples 3700 loss 0.08079622608336397\n",
      "Epoch 30 num_samples 3800 loss 0.053651252895644\n",
      "Epoch 30 num_samples 3900 loss 0.05712207428458632\n",
      "Epoch 30 num_samples 4000 loss 0.061014242223476886\n",
      "Epoch 30 num_samples 4100 loss 0.09919562736317822\n",
      "Epoch 30 num_samples 4200 loss 0.049985956384638645\n",
      "Epoch 30 num_samples 4300 loss 0.057199867285204854\n",
      "Epoch 30 num_samples 4400 loss 0.06441662745582623\n",
      "Epoch 30 num_samples 4500 loss 0.07296115797691238\n",
      "Epoch 30 num_samples 4600 loss 0.052828851623825425\n",
      "Epoch 30 num_samples 4700 loss 0.030940650298031214\n",
      "Epoch 30 num_samples 4800 loss 0.0321681861476375\n",
      "Epoch 30 num_samples 4900 loss 0.03674836872361679\n",
      "Epoch 30 num_samples 5000 loss 0.040189554365058486\n",
      "Epoch 30 num_samples 5100 loss 0.06477222628152829\n",
      "Epoch 30 num_samples 5200 loss 0.03175483123934572\n",
      "Epoch 30 num_samples 5300 loss 0.04654803621211119\n",
      "Epoch 30 num_samples 5400 loss 0.06268300897617309\n",
      "Epoch 30 num_samples 5500 loss 0.035441055775048594\n",
      "Epoch 30 num_samples 5600 loss 0.13835032782999673\n",
      "Epoch 30 num_samples 5700 loss 0.08275317842247068\n",
      "Epoch 30 num_samples 5800 loss 0.0625011300665014\n",
      "Epoch 30 num_samples 5900 loss 0.07077050697936939\n",
      "Epoch 30 num_samples 6000 loss 0.06553908807268627\n",
      "Epoch 30 num_samples 6100 loss 0.04405940186639748\n",
      "Epoch 30 num_samples 6200 loss 0.05638579634053463\n",
      "Epoch 30 num_samples 6300 loss 0.07889067393072445\n",
      "Epoch 30 num_samples 6400 loss 0.042594183967582584\n",
      "Epoch 30 num_samples 6500 loss 0.03651667893777062\n",
      "Epoch 30 num_samples 6600 loss 0.07402607168485413\n",
      "Epoch 30 num_samples 6700 loss 0.03242893309798104\n",
      "Epoch 30 num_samples 6800 loss 0.026806371020497818\n",
      "Epoch 30 num_samples 6900 loss 0.09948669193116384\n",
      "Epoch 30 num_samples 7000 loss 0.08054217592777109\n",
      "Epoch 30 num_samples 7100 loss 0.037810482016607624\n",
      "Epoch 30 num_samples 7200 loss 0.042253244055832855\n",
      "Epoch 30 num_samples 7300 loss 0.04353903668242024\n",
      "Epoch 30 num_samples 7400 loss 0.039493673105355884\n",
      "Epoch 30 num_samples 7500 loss 0.08726947351278164\n",
      "Epoch 30 num_samples 7600 loss 0.05066977168928102\n",
      "Epoch 30 num_samples 7700 loss 0.09206777856163091\n",
      "Epoch 30 num_samples 7800 loss 0.032698707992114995\n",
      "Epoch 30 num_samples 7900 loss 0.0513097798439331\n",
      "Epoch 30 num_samples 8000 loss 0.034351840568540064\n",
      "Epoch 30 num_samples 8100 loss 0.044387735818502076\n",
      "Epoch 30 num_samples 8200 loss 0.05302961852386184\n",
      "Epoch 30 num_samples 8300 loss 0.06026343719623165\n",
      "Epoch 30 num_samples 8400 loss 0.040912541490687133\n",
      "Epoch 30 num_samples 8500 loss 0.05877500610433303\n",
      "Epoch 30 num_samples 8600 loss 0.045974858707865156\n",
      "Epoch 30 num_samples 8700 loss 0.05326246958307337\n",
      "Epoch 30 num_samples 8800 loss 0.08032052406053737\n",
      "Epoch 30 num_samples 8900 loss 0.05636749273199841\n",
      "Epoch 30 num_samples 9000 loss 0.050890806549197504\n",
      "Epoch 30 num_samples 9100 loss 0.053640555329705644\n",
      "Epoch 30 num_samples 9200 loss 0.0459045594285454\n",
      "Epoch 30 num_samples 9300 loss 0.05134814628981062\n",
      "Epoch 30 num_samples 9400 loss 0.03949521229320275\n",
      "Epoch 30 num_samples 9500 loss 0.05457751211020307\n",
      "Epoch 30 num_samples 9600 loss 0.03985217319618704\n",
      "Epoch 30 num_samples 9700 loss 0.06726609493401896\n",
      "Epoch 30 num_samples 9800 loss 0.028990146196379296\n",
      "Epoch 30 num_samples 9900 loss 0.0939631112215528\n",
      "Epoch 30 num_samples 10000 loss 0.0539858443582709\n",
      "Epoch 30 num_samples 10100 loss 0.03586975678450224\n",
      "Epoch 30 num_samples 10200 loss 0.07820703306516417\n",
      "Epoch 30 num_samples 10300 loss 0.05478757736611962\n",
      "Epoch 30 num_samples 10400 loss 0.06817543710838195\n",
      "Epoch 30 num_samples 10500 loss 0.04047096366513295\n",
      "Epoch 30 num_samples 10600 loss 0.07842255538046722\n",
      "Epoch 30 num_samples 10700 loss 0.042384122035718806\n",
      "Epoch 30 num_samples 10800 loss 0.08456564710052573\n",
      "Epoch 30 num_samples 10900 loss 0.041189704457565715\n",
      "Epoch 30 num_samples 11000 loss 0.03275917329302029\n",
      "Epoch 30 num_samples 11100 loss 0.051068927034525105\n",
      "Epoch 30 num_samples 11200 loss 0.04255674030163201\n",
      "Epoch 30 num_samples 11300 loss 0.09037472599921656\n",
      "Epoch 30 num_samples 11400 loss 0.0751201418713562\n",
      "Epoch 30 num_samples 11500 loss 0.047043539822527965\n",
      "Epoch 30 num_samples 11600 loss 0.041214825328136424\n",
      "Epoch 30 num_samples 11700 loss 0.06449867508534415\n",
      "Epoch 30 num_samples 11800 loss 0.04414015996110656\n",
      "Epoch 30 num_samples 11900 loss 0.04461860065936055\n",
      "Epoch 30 num_samples 12000 loss 0.031228157009306617\n",
      "Epoch 30 num_samples 12100 loss 0.056042234560050794\n",
      "Epoch 30 num_samples 12200 loss 0.07052124544904113\n",
      "Epoch 30 num_samples 12300 loss 0.030999759732259772\n",
      "Epoch 30 num_samples 12400 loss 0.06704690277304735\n",
      "Epoch 30 num_samples 12500 loss 0.054684182815296085\n",
      "Epoch 30 num_samples 12600 loss 0.06693130926113933\n",
      "Epoch 30 num_samples 12700 loss 0.05878209035967798\n",
      "Epoch 30 num_samples 12800 loss 0.08566679915363469\n",
      "Epoch 30 num_samples 12900 loss 0.04761757702260743\n",
      "Epoch 30 num_samples 13000 loss 0.036911569144096455\n",
      "Epoch 30 num_samples 13100 loss 0.10527468960711599\n",
      "Epoch 30 num_samples 13200 loss 0.03970683269454992\n",
      "Epoch 30 num_samples 13300 loss 0.03736222514810802\n",
      "Epoch 30 num_samples 13400 loss 0.022351151656971147\n",
      "Epoch 30 num_samples 13500 loss 0.03828784983862812\n",
      "Epoch 30 num_samples 13600 loss 0.071799673813101\n",
      "Epoch 30 num_samples 13700 loss 0.04942312101127197\n",
      "Epoch 30 num_samples 13800 loss 0.04879253452384424\n",
      "Epoch 30 num_samples 13900 loss 0.021513457623723795\n",
      "Epoch 30 num_samples 14000 loss 0.03728933374073198\n",
      "Epoch 30 num_samples 14100 loss 0.04745011418091735\n",
      "Epoch 30 num_samples 14200 loss 0.03486709469686031\n",
      "Epoch 30 num_samples 14300 loss 0.05506613747968564\n",
      "Epoch 30 num_samples 14400 loss 0.050868682561673824\n",
      "Epoch 30 num_samples 14500 loss 0.05495955966030074\n",
      "Epoch 30 num_samples 14600 loss 0.04470985632626863\n",
      "Epoch 30 num_samples 14700 loss 0.04856568984413048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 num_samples 14800 loss 0.03922088330779818\n",
      "Epoch 30 num_samples 14900 loss 0.06648622931726816\n",
      "Epoch 30 num_samples 15000 loss 0.03964076306235429\n",
      "Epoch 30 num_samples 15100 loss 0.04967663274324689\n",
      "Epoch 30 num_samples 15200 loss 0.07397450898888146\n",
      "Epoch 30 num_samples 15300 loss 0.04831788556924812\n",
      "Epoch 30 num_samples 15400 loss 0.03211137109015785\n",
      "Epoch 30 num_samples 15500 loss 0.06676593305103933\n",
      "Epoch 30 num_samples 15600 loss 0.04777623993844278\n",
      "Epoch 30 num_samples 15700 loss 0.030765213806733933\n",
      "Epoch 30 num_samples 15800 loss 0.07714724519373545\n",
      "Epoch 30 num_samples 15900 loss 0.030549946641221702\n",
      "Epoch 30 num_samples 16000 loss 0.06377457197044746\n",
      "Epoch 30 num_samples 16100 loss 0.03580675087169319\n",
      "Epoch 30 num_samples 16200 loss 0.05554085895499693\n",
      "Epoch 30 num_samples 16300 loss 0.07859470557694634\n",
      "Epoch 30 num_samples 16400 loss 0.06503367724789606\n",
      "Epoch 30 num_samples 16500 loss 0.051913088305129244\n",
      "Epoch 30 num_samples 16600 loss 0.0645581483306653\n",
      "Epoch 30 num_samples 16700 loss 0.03115624260259512\n",
      "Epoch 30 num_samples 16800 loss 0.03672736397901933\n",
      "Epoch 30 num_samples 16900 loss 0.04149802104503004\n",
      "Epoch 30 num_samples 17000 loss 0.030548050098415942\n",
      "Epoch 30 num_samples 17100 loss 0.1158439307941942\n",
      "Epoch 30 num_samples 17200 loss 0.05536560455733621\n",
      "Epoch 30 num_samples 17300 loss 0.06826484015752012\n",
      "Epoch 30 num_samples 17400 loss 0.05199474553003748\n",
      "Epoch 30 num_samples 17500 loss 0.04717316213899889\n",
      "Epoch 30 num_samples 17600 loss 0.05136931533786897\n",
      "Epoch 30 num_samples 17700 loss 0.03544873591211584\n",
      "Epoch 30 num_samples 17800 loss 0.056276737644768884\n",
      "Epoch 30 num_samples 17900 loss 0.06710371843702304\n",
      "Epoch 30 num_samples 18000 loss 0.03912817511963658\n",
      "Epoch 30 num_samples 18100 loss 0.05135943276428678\n",
      "Epoch 30 num_samples 18200 loss 0.05655537088329514\n",
      "Epoch 30 num_samples 18300 loss 0.041677267420520324\n",
      "Epoch 30 num_samples 18400 loss 0.08057385965466174\n",
      "Epoch 30 num_samples 18500 loss 0.051198229733935584\n",
      "Epoch 31 num_samples 0 loss 0.03857934689515552\n",
      "Epoch 31 num_samples 100 loss 0.06902972446273244\n",
      "Epoch 31 num_samples 200 loss 0.03846571270681249\n",
      "Epoch 31 num_samples 300 loss 0.0377158693432603\n",
      "Epoch 31 num_samples 400 loss 0.04078574731675728\n",
      "Epoch 31 num_samples 500 loss 0.05343866327343947\n",
      "Epoch 31 num_samples 600 loss 0.0672869022015712\n",
      "Epoch 31 num_samples 700 loss 0.07215576672150777\n",
      "Epoch 31 num_samples 800 loss 0.049187092548491414\n",
      "Epoch 31 num_samples 900 loss 0.060610833029668125\n",
      "Epoch 31 num_samples 1000 loss 0.04363278232840098\n",
      "Epoch 31 num_samples 1100 loss 0.07815921227438792\n",
      "Epoch 31 num_samples 1200 loss 0.04840508860362333\n",
      "Epoch 31 num_samples 1300 loss 0.04509750058256467\n",
      "Epoch 31 num_samples 1400 loss 0.061734577768060905\n",
      "Epoch 31 num_samples 1500 loss 0.1093025211535189\n",
      "Epoch 31 num_samples 1600 loss 0.04439351511093545\n",
      "Epoch 31 num_samples 1700 loss 0.0431392578018462\n",
      "Epoch 31 num_samples 1800 loss 0.042323460120551236\n",
      "Epoch 31 num_samples 1900 loss 0.04638987083724128\n",
      "Epoch 31 num_samples 2000 loss 0.061530424775591314\n",
      "Epoch 31 num_samples 2100 loss 0.03248599165905614\n",
      "Epoch 31 num_samples 2200 loss 0.03441368859557426\n",
      "Epoch 31 num_samples 2300 loss 0.026214469834865937\n",
      "Epoch 31 num_samples 2400 loss 0.043125889454125585\n",
      "Epoch 31 num_samples 2500 loss 0.06570678576939645\n",
      "Epoch 31 num_samples 2600 loss 0.06193691650893011\n",
      "Epoch 31 num_samples 2700 loss 0.05150500967493418\n",
      "Epoch 31 num_samples 2800 loss 0.06386008016232723\n",
      "Epoch 31 num_samples 2900 loss 0.05670221207897118\n",
      "Epoch 31 num_samples 3000 loss 0.04467971127856272\n",
      "Epoch 31 num_samples 3100 loss 0.051956190994965026\n",
      "Epoch 31 num_samples 3200 loss 0.13317997771332063\n",
      "Epoch 31 num_samples 3300 loss 0.05803110259530187\n",
      "Epoch 31 num_samples 3400 loss 0.03656256388122442\n",
      "Epoch 31 num_samples 3500 loss 0.04099790289026453\n",
      "Epoch 31 num_samples 3600 loss 0.02625306495660035\n",
      "Epoch 31 num_samples 3700 loss 0.07629827303949233\n",
      "Epoch 31 num_samples 3800 loss 0.050591504326227776\n",
      "Epoch 31 num_samples 3900 loss 0.054051177335044616\n",
      "Epoch 31 num_samples 4000 loss 0.05817992061563665\n",
      "Epoch 31 num_samples 4100 loss 0.09220082326007492\n",
      "Epoch 31 num_samples 4200 loss 0.04678111976416255\n",
      "Epoch 31 num_samples 4300 loss 0.053434002213521604\n",
      "Epoch 31 num_samples 4400 loss 0.0598087961694948\n",
      "Epoch 31 num_samples 4500 loss 0.0685252798583833\n",
      "Epoch 31 num_samples 4600 loss 0.049854148614792246\n",
      "Epoch 31 num_samples 4700 loss 0.029415688224194686\n",
      "Epoch 31 num_samples 4800 loss 0.03023483222325039\n",
      "Epoch 31 num_samples 4900 loss 0.0347202744200089\n",
      "Epoch 31 num_samples 5000 loss 0.03768267556055313\n",
      "Epoch 31 num_samples 5100 loss 0.06103312624328909\n",
      "Epoch 31 num_samples 5200 loss 0.030105034176198097\n",
      "Epoch 31 num_samples 5300 loss 0.04361233622127662\n",
      "Epoch 31 num_samples 5400 loss 0.05828582949518252\n",
      "Epoch 31 num_samples 5500 loss 0.0328564021023902\n",
      "Epoch 31 num_samples 5600 loss 0.13391945643241593\n",
      "Epoch 31 num_samples 5700 loss 0.07767397265975434\n",
      "Epoch 31 num_samples 5800 loss 0.05760446699489662\n",
      "Epoch 31 num_samples 5900 loss 0.06567877435125358\n",
      "Epoch 31 num_samples 6000 loss 0.06024476102963322\n",
      "Epoch 31 num_samples 6100 loss 0.041620719097372375\n",
      "Epoch 31 num_samples 6200 loss 0.05322013708223455\n",
      "Epoch 31 num_samples 6300 loss 0.07508998109098766\n",
      "Epoch 31 num_samples 6400 loss 0.04037592902804798\n",
      "Epoch 31 num_samples 6500 loss 0.03412424834944226\n",
      "Epoch 31 num_samples 6600 loss 0.06965702732465327\n",
      "Epoch 31 num_samples 6700 loss 0.03068955017739574\n",
      "Epoch 31 num_samples 6800 loss 0.025602435528220377\n",
      "Epoch 31 num_samples 6900 loss 0.09364121696309251\n",
      "Epoch 31 num_samples 7000 loss 0.0741328783388892\n",
      "Epoch 31 num_samples 7100 loss 0.0359870686204324\n",
      "Epoch 31 num_samples 7200 loss 0.04033284703278686\n",
      "Epoch 31 num_samples 7300 loss 0.040529454468810525\n",
      "Epoch 31 num_samples 7400 loss 0.03628569470958279\n",
      "Epoch 31 num_samples 7500 loss 0.08186213328439028\n",
      "Epoch 31 num_samples 7600 loss 0.0477327217010936\n",
      "Epoch 31 num_samples 7700 loss 0.08714982641874958\n",
      "Epoch 31 num_samples 7800 loss 0.031302777545697796\n",
      "Epoch 31 num_samples 7900 loss 0.0476634485073589\n",
      "Epoch 31 num_samples 8000 loss 0.03282581311110313\n",
      "Epoch 31 num_samples 8100 loss 0.04258079184943878\n",
      "Epoch 31 num_samples 8200 loss 0.04979019907947047\n",
      "Epoch 31 num_samples 8300 loss 0.05650085031131936\n",
      "Epoch 31 num_samples 8400 loss 0.037944844058695595\n",
      "Epoch 31 num_samples 8500 loss 0.05367490554787116\n",
      "Epoch 31 num_samples 8600 loss 0.043501605106817325\n",
      "Epoch 31 num_samples 8700 loss 0.05001173059049342\n",
      "Epoch 31 num_samples 8800 loss 0.07484683185558688\n",
      "Epoch 31 num_samples 8900 loss 0.05317134352172759\n",
      "Epoch 31 num_samples 9000 loss 0.04746926948020708\n",
      "Epoch 31 num_samples 9100 loss 0.04971874660513583\n",
      "Epoch 31 num_samples 9200 loss 0.0433172446679462\n",
      "Epoch 31 num_samples 9300 loss 0.04749986277736534\n",
      "Epoch 31 num_samples 9400 loss 0.03734596884125271\n",
      "Epoch 31 num_samples 9500 loss 0.050838234854453074\n",
      "Epoch 31 num_samples 9600 loss 0.03751614083061585\n",
      "Epoch 31 num_samples 9700 loss 0.06441460592846988\n",
      "Epoch 31 num_samples 9800 loss 0.027173233146291654\n",
      "Epoch 31 num_samples 9900 loss 0.08904006776006206\n",
      "Epoch 31 num_samples 10000 loss 0.050304705079494735\n",
      "Epoch 31 num_samples 10100 loss 0.03442306941299076\n",
      "Epoch 31 num_samples 10200 loss 0.07225860550040948\n",
      "Epoch 31 num_samples 10300 loss 0.05099606659022245\n",
      "Epoch 31 num_samples 10400 loss 0.06508902149941018\n",
      "Epoch 31 num_samples 10500 loss 0.03756542562793167\n",
      "Epoch 31 num_samples 10600 loss 0.07462799175491756\n",
      "Epoch 31 num_samples 10700 loss 0.03954864919178327\n",
      "Epoch 31 num_samples 10800 loss 0.07922303993310338\n",
      "Epoch 31 num_samples 10900 loss 0.038539831806836296\n",
      "Epoch 31 num_samples 11000 loss 0.03091704894644125\n",
      "Epoch 31 num_samples 11100 loss 0.04741120900495666\n",
      "Epoch 31 num_samples 11200 loss 0.039764803278176324\n",
      "Epoch 31 num_samples 11300 loss 0.08408654541900848\n",
      "Epoch 31 num_samples 11400 loss 0.06783860678107026\n",
      "Epoch 31 num_samples 11500 loss 0.04431662205700841\n",
      "Epoch 31 num_samples 11600 loss 0.039134845250937314\n",
      "Epoch 31 num_samples 11700 loss 0.061945618065810296\n",
      "Epoch 31 num_samples 11800 loss 0.04160788126173797\n",
      "Epoch 31 num_samples 11900 loss 0.041665167413897294\n",
      "Epoch 31 num_samples 12000 loss 0.029424210321114884\n",
      "Epoch 31 num_samples 12100 loss 0.052253520669423646\n",
      "Epoch 31 num_samples 12200 loss 0.06581868524186335\n",
      "Epoch 31 num_samples 12300 loss 0.02957553134880264\n",
      "Epoch 31 num_samples 12400 loss 0.06318350923586175\n",
      "Epoch 31 num_samples 12500 loss 0.051478514324292526\n",
      "Epoch 31 num_samples 12600 loss 0.0631556674212701\n",
      "Epoch 31 num_samples 12700 loss 0.05429009110817178\n",
      "Epoch 31 num_samples 12800 loss 0.0813299040690739\n",
      "Epoch 31 num_samples 12900 loss 0.04435321269493222\n",
      "Epoch 31 num_samples 13000 loss 0.034928362247037915\n",
      "Epoch 31 num_samples 13100 loss 0.09984333221185093\n",
      "Epoch 31 num_samples 13200 loss 0.03675273202498909\n",
      "Epoch 31 num_samples 13300 loss 0.035027408776449456\n",
      "Epoch 31 num_samples 13400 loss 0.020838094478823423\n",
      "Epoch 31 num_samples 13500 loss 0.03610314291354749\n",
      "Epoch 31 num_samples 13600 loss 0.0682789943024916\n",
      "Epoch 31 num_samples 13700 loss 0.04609675198026144\n",
      "Epoch 31 num_samples 13800 loss 0.0452570905704513\n",
      "Epoch 31 num_samples 13900 loss 0.019877624655043412\n",
      "Epoch 31 num_samples 14000 loss 0.034838411000847475\n",
      "Epoch 31 num_samples 14100 loss 0.04456590705405896\n",
      "Epoch 31 num_samples 14200 loss 0.03262615363273648\n",
      "Epoch 31 num_samples 14300 loss 0.05125216765904714\n",
      "Epoch 31 num_samples 14400 loss 0.04848542196017788\n",
      "Epoch 31 num_samples 14500 loss 0.05145782883809963\n",
      "Epoch 31 num_samples 14600 loss 0.04208116518140583\n",
      "Epoch 31 num_samples 14700 loss 0.04582659640749658\n",
      "Epoch 31 num_samples 14800 loss 0.03675509325914532\n",
      "Epoch 31 num_samples 14900 loss 0.061920292477470947\n",
      "Epoch 31 num_samples 15000 loss 0.03747949422491661\n",
      "Epoch 31 num_samples 15100 loss 0.04626142335998695\n",
      "Epoch 31 num_samples 15200 loss 0.06846492412250223\n",
      "Epoch 31 num_samples 15300 loss 0.045179165435978455\n",
      "Epoch 31 num_samples 15400 loss 0.029656592218532462\n",
      "Epoch 31 num_samples 15500 loss 0.06186651978588751\n",
      "Epoch 31 num_samples 15600 loss 0.04535264704508523\n",
      "Epoch 31 num_samples 15700 loss 0.029065233366679825\n",
      "Epoch 31 num_samples 15800 loss 0.07245637946799682\n",
      "Epoch 31 num_samples 15900 loss 0.02850791748738045\n",
      "Epoch 31 num_samples 16000 loss 0.060066116199337626\n",
      "Epoch 31 num_samples 16100 loss 0.033592658051614974\n",
      "Epoch 31 num_samples 16200 loss 0.05197249677429129\n",
      "Epoch 31 num_samples 16300 loss 0.07370402557958648\n",
      "Epoch 31 num_samples 16400 loss 0.061715586393631845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 num_samples 16500 loss 0.049419130677776986\n",
      "Epoch 31 num_samples 16600 loss 0.06049169410717234\n",
      "Epoch 31 num_samples 16700 loss 0.02915220977746447\n",
      "Epoch 31 num_samples 16800 loss 0.034452565131080165\n",
      "Epoch 31 num_samples 16900 loss 0.03928477522725522\n",
      "Epoch 31 num_samples 17000 loss 0.028620411663953203\n",
      "Epoch 31 num_samples 17100 loss 0.1090317887667398\n",
      "Epoch 31 num_samples 17200 loss 0.051317107505875995\n",
      "Epoch 31 num_samples 17300 loss 0.06394129976676222\n",
      "Epoch 31 num_samples 17400 loss 0.048729582090848655\n",
      "Epoch 31 num_samples 17500 loss 0.0438228487676585\n",
      "Epoch 31 num_samples 17600 loss 0.04848459126686356\n",
      "Epoch 31 num_samples 17700 loss 0.03390294395767609\n",
      "Epoch 31 num_samples 17800 loss 0.05174481958734981\n",
      "Epoch 31 num_samples 17900 loss 0.06348048973280487\n",
      "Epoch 31 num_samples 18000 loss 0.03720855918333912\n",
      "Epoch 31 num_samples 18100 loss 0.04809176489086233\n",
      "Epoch 31 num_samples 18200 loss 0.05262340915862571\n",
      "Epoch 31 num_samples 18300 loss 0.039301452313806905\n",
      "Epoch 31 num_samples 18400 loss 0.07598191227994792\n",
      "Epoch 31 num_samples 18500 loss 0.048310134991322605\n",
      "Epoch 32 num_samples 0 loss 0.0356768638546658\n",
      "Epoch 32 num_samples 100 loss 0.06528101356743825\n",
      "Epoch 32 num_samples 200 loss 0.03632652505100854\n",
      "Epoch 32 num_samples 300 loss 0.035668139907682674\n",
      "Epoch 32 num_samples 400 loss 0.03837343756236521\n",
      "Epoch 32 num_samples 500 loss 0.05095974145739945\n",
      "Epoch 32 num_samples 600 loss 0.06335192861074945\n",
      "Epoch 32 num_samples 700 loss 0.06685105631856818\n",
      "Epoch 32 num_samples 800 loss 0.04616860292080848\n",
      "Epoch 32 num_samples 900 loss 0.05805788777518944\n",
      "Epoch 32 num_samples 1000 loss 0.041110229602322586\n",
      "Epoch 32 num_samples 1100 loss 0.07363980261910742\n",
      "Epoch 32 num_samples 1200 loss 0.045149179646717226\n",
      "Epoch 32 num_samples 1300 loss 0.04285643587100643\n",
      "Epoch 32 num_samples 1400 loss 0.05843337874970371\n",
      "Epoch 32 num_samples 1500 loss 0.10301361603530843\n",
      "Epoch 32 num_samples 1600 loss 0.041850845067249585\n",
      "Epoch 32 num_samples 1700 loss 0.04055467031040243\n",
      "Epoch 32 num_samples 1800 loss 0.04009899030632675\n",
      "Epoch 32 num_samples 1900 loss 0.04377724146822425\n",
      "Epoch 32 num_samples 2000 loss 0.05734471943966864\n",
      "Epoch 32 num_samples 2100 loss 0.03057699886879853\n",
      "Epoch 32 num_samples 2200 loss 0.032681124453782705\n",
      "Epoch 32 num_samples 2300 loss 0.024033297627166897\n",
      "Epoch 32 num_samples 2400 loss 0.04063576452471475\n",
      "Epoch 32 num_samples 2500 loss 0.06086986388905984\n",
      "Epoch 32 num_samples 2600 loss 0.058550348441948064\n",
      "Epoch 32 num_samples 2700 loss 0.04755571308174735\n",
      "Epoch 32 num_samples 2800 loss 0.06058619469620719\n",
      "Epoch 32 num_samples 2900 loss 0.05295949170534184\n",
      "Epoch 32 num_samples 3000 loss 0.04225078695471259\n",
      "Epoch 32 num_samples 3100 loss 0.048816060932358595\n",
      "Epoch 32 num_samples 3200 loss 0.1266832235335304\n",
      "Epoch 32 num_samples 3300 loss 0.05458525284682622\n",
      "Epoch 32 num_samples 3400 loss 0.03495260360141844\n",
      "Epoch 32 num_samples 3500 loss 0.03761552405663529\n",
      "Epoch 32 num_samples 3600 loss 0.02451432079065974\n",
      "Epoch 32 num_samples 3700 loss 0.07181652220325456\n",
      "Epoch 32 num_samples 3800 loss 0.04691167248264671\n",
      "Epoch 32 num_samples 3900 loss 0.05070652162395036\n",
      "Epoch 32 num_samples 4000 loss 0.05481211333078407\n",
      "Epoch 32 num_samples 4100 loss 0.0865766116375751\n",
      "Epoch 32 num_samples 4200 loss 0.04441286801941929\n",
      "Epoch 32 num_samples 4300 loss 0.05002662871778208\n",
      "Epoch 32 num_samples 4400 loss 0.05641095931037622\n",
      "Epoch 32 num_samples 4500 loss 0.06398083142937186\n",
      "Epoch 32 num_samples 4600 loss 0.04735530549900597\n",
      "Epoch 32 num_samples 4700 loss 0.028199025413985827\n",
      "Epoch 32 num_samples 4800 loss 0.028278566595657768\n",
      "Epoch 32 num_samples 4900 loss 0.03285681651064892\n",
      "Epoch 32 num_samples 5000 loss 0.03506986613140783\n",
      "Epoch 32 num_samples 5100 loss 0.057601460537076384\n",
      "Epoch 32 num_samples 5200 loss 0.028275598835015694\n",
      "Epoch 32 num_samples 5300 loss 0.040433608891531386\n",
      "Epoch 32 num_samples 5400 loss 0.05426446337022581\n",
      "Epoch 32 num_samples 5500 loss 0.030733167768576704\n",
      "Epoch 32 num_samples 5600 loss 0.12924779334919284\n",
      "Epoch 32 num_samples 5700 loss 0.07342247010260915\n",
      "Epoch 32 num_samples 5800 loss 0.05348035473869934\n",
      "Epoch 32 num_samples 5900 loss 0.0610999759794009\n",
      "Epoch 32 num_samples 6000 loss 0.05565164105295176\n",
      "Epoch 32 num_samples 6100 loss 0.03981051602726876\n",
      "Epoch 32 num_samples 6200 loss 0.050009338982269363\n",
      "Epoch 32 num_samples 6300 loss 0.07089312508193948\n",
      "Epoch 32 num_samples 6400 loss 0.037952593590500065\n",
      "Epoch 32 num_samples 6500 loss 0.03252342047231748\n",
      "Epoch 32 num_samples 6600 loss 0.06582278703691583\n",
      "Epoch 32 num_samples 6700 loss 0.029230990247705303\n",
      "Epoch 32 num_samples 6800 loss 0.023933968369314784\n",
      "Epoch 32 num_samples 6900 loss 0.08862531128669617\n",
      "Epoch 32 num_samples 7000 loss 0.06894086656432538\n",
      "Epoch 32 num_samples 7100 loss 0.03318601080931667\n",
      "Epoch 32 num_samples 7200 loss 0.03785350636962887\n",
      "Epoch 32 num_samples 7300 loss 0.03766771659912844\n",
      "Epoch 32 num_samples 7400 loss 0.034248128994938606\n",
      "Epoch 32 num_samples 7500 loss 0.07757950188790941\n",
      "Epoch 32 num_samples 7600 loss 0.04490064572781314\n",
      "Epoch 32 num_samples 7700 loss 0.08201405505594661\n",
      "Epoch 32 num_samples 7800 loss 0.02975530456020305\n",
      "Epoch 32 num_samples 7900 loss 0.04505255925832584\n",
      "Epoch 32 num_samples 8000 loss 0.030514327084471028\n",
      "Epoch 32 num_samples 8100 loss 0.03954514591460333\n",
      "Epoch 32 num_samples 8200 loss 0.046350708533619625\n",
      "Epoch 32 num_samples 8300 loss 0.051944758833101984\n",
      "Epoch 32 num_samples 8400 loss 0.03564490085185216\n",
      "Epoch 32 num_samples 8500 loss 0.05043196204780518\n",
      "Epoch 32 num_samples 8600 loss 0.0411962191298701\n",
      "Epoch 32 num_samples 8700 loss 0.04709272598972289\n",
      "Epoch 32 num_samples 8800 loss 0.06995147887462631\n",
      "Epoch 32 num_samples 8900 loss 0.050322435353453994\n",
      "Epoch 32 num_samples 9000 loss 0.04408694821839601\n",
      "Epoch 32 num_samples 9100 loss 0.04717868983939864\n",
      "Epoch 32 num_samples 9200 loss 0.04073920361990484\n",
      "Epoch 32 num_samples 9300 loss 0.044898058611534356\n",
      "Epoch 32 num_samples 9400 loss 0.03541054149376941\n",
      "Epoch 32 num_samples 9500 loss 0.046936618109917366\n",
      "Epoch 32 num_samples 9600 loss 0.03578728301543716\n",
      "Epoch 32 num_samples 9700 loss 0.0611426554555479\n",
      "Epoch 32 num_samples 9800 loss 0.025630068800664096\n",
      "Epoch 32 num_samples 9900 loss 0.08514135825347648\n",
      "Epoch 32 num_samples 10000 loss 0.0466797751655128\n",
      "Epoch 32 num_samples 10100 loss 0.03258087451456771\n",
      "Epoch 32 num_samples 10200 loss 0.06668578298959918\n",
      "Epoch 32 num_samples 10300 loss 0.04778331587720345\n",
      "Epoch 32 num_samples 10400 loss 0.060976787399357635\n",
      "Epoch 32 num_samples 10500 loss 0.03587808131615759\n",
      "Epoch 32 num_samples 10600 loss 0.07100317545318297\n",
      "Epoch 32 num_samples 10700 loss 0.03726922751232498\n",
      "Epoch 32 num_samples 10800 loss 0.0742140509443794\n",
      "Epoch 32 num_samples 10900 loss 0.03623837224365321\n",
      "Epoch 32 num_samples 11000 loss 0.029310692888569693\n",
      "Epoch 32 num_samples 11100 loss 0.04431180644922403\n",
      "Epoch 32 num_samples 11200 loss 0.037578463840422224\n",
      "Epoch 32 num_samples 11300 loss 0.07942603262468877\n",
      "Epoch 32 num_samples 11400 loss 0.06274342986065241\n",
      "Epoch 32 num_samples 11500 loss 0.04197534701093311\n",
      "Epoch 32 num_samples 11600 loss 0.03720551374723184\n",
      "Epoch 32 num_samples 11700 loss 0.05789674015113332\n",
      "Epoch 32 num_samples 11800 loss 0.03893441988792918\n",
      "Epoch 32 num_samples 11900 loss 0.039059366824370854\n",
      "Epoch 32 num_samples 12000 loss 0.02779752291220464\n",
      "Epoch 32 num_samples 12100 loss 0.04876061094696546\n",
      "Epoch 32 num_samples 12200 loss 0.06177446763883731\n",
      "Epoch 32 num_samples 12300 loss 0.02759886497989452\n",
      "Epoch 32 num_samples 12400 loss 0.05981002975797232\n",
      "Epoch 32 num_samples 12500 loss 0.048333685287016044\n",
      "Epoch 32 num_samples 12600 loss 0.06014530923486288\n",
      "Epoch 32 num_samples 12700 loss 0.05036890418854251\n",
      "Epoch 32 num_samples 12800 loss 0.0781437028680077\n",
      "Epoch 32 num_samples 12900 loss 0.04155878685874798\n",
      "Epoch 32 num_samples 13000 loss 0.03293188159301923\n",
      "Epoch 32 num_samples 13100 loss 0.09471193971264157\n",
      "Epoch 32 num_samples 13200 loss 0.03428062139684637\n",
      "Epoch 32 num_samples 13300 loss 0.03294256878037504\n",
      "Epoch 32 num_samples 13400 loss 0.019655979679074304\n",
      "Epoch 32 num_samples 13500 loss 0.033769420683787306\n",
      "Epoch 32 num_samples 13600 loss 0.06413028672309239\n",
      "Epoch 32 num_samples 13700 loss 0.043058946680297056\n",
      "Epoch 32 num_samples 13800 loss 0.04283096596347721\n",
      "Epoch 32 num_samples 13900 loss 0.018318029864787096\n",
      "Epoch 32 num_samples 14000 loss 0.03243595032787501\n",
      "Epoch 32 num_samples 14100 loss 0.04205916851804039\n",
      "Epoch 32 num_samples 14200 loss 0.030926105901979816\n",
      "Epoch 32 num_samples 14300 loss 0.04825663411308548\n",
      "Epoch 32 num_samples 14400 loss 0.045603351773889786\n",
      "Epoch 32 num_samples 14500 loss 0.04904325324864033\n",
      "Epoch 32 num_samples 14600 loss 0.0398014461122962\n",
      "Epoch 32 num_samples 14700 loss 0.043593951265867015\n",
      "Epoch 32 num_samples 14800 loss 0.03476430321109965\n",
      "Epoch 32 num_samples 14900 loss 0.05784573272543603\n",
      "Epoch 32 num_samples 15000 loss 0.03568991623443709\n",
      "Epoch 32 num_samples 15100 loss 0.043382699466268354\n",
      "Epoch 32 num_samples 15200 loss 0.06293134846469049\n",
      "Epoch 32 num_samples 15300 loss 0.04269891468927027\n",
      "Epoch 32 num_samples 15400 loss 0.02800060932816433\n",
      "Epoch 32 num_samples 15500 loss 0.05795088246141544\n",
      "Epoch 32 num_samples 15600 loss 0.042928199765254076\n",
      "Epoch 32 num_samples 15700 loss 0.0276462489356408\n",
      "Epoch 32 num_samples 15800 loss 0.06746813931595587\n",
      "Epoch 32 num_samples 15900 loss 0.027077823172410767\n",
      "Epoch 32 num_samples 16000 loss 0.05651692151453586\n",
      "Epoch 32 num_samples 16100 loss 0.03175920503504165\n",
      "Epoch 32 num_samples 16200 loss 0.04874181345008955\n",
      "Epoch 32 num_samples 16300 loss 0.06939190400183254\n",
      "Epoch 32 num_samples 16400 loss 0.058225028237837886\n",
      "Epoch 32 num_samples 16500 loss 0.046782713440031466\n",
      "Epoch 32 num_samples 16600 loss 0.05722930779443775\n",
      "Epoch 32 num_samples 16700 loss 0.027537490998034934\n",
      "Epoch 32 num_samples 16800 loss 0.032215980556776574\n",
      "Epoch 32 num_samples 16900 loss 0.0370106356503714\n",
      "Epoch 32 num_samples 17000 loss 0.026962641457597903\n",
      "Epoch 32 num_samples 17100 loss 0.10274959961155897\n",
      "Epoch 32 num_samples 17200 loss 0.04886492810577264\n",
      "Epoch 32 num_samples 17300 loss 0.05997829876418219\n",
      "Epoch 32 num_samples 17400 loss 0.04506863733430622\n",
      "Epoch 32 num_samples 17500 loss 0.04126363605632313\n",
      "Epoch 32 num_samples 17600 loss 0.045029419996466\n",
      "Epoch 32 num_samples 17700 loss 0.031720469343523634\n",
      "Epoch 32 num_samples 17800 loss 0.04772283305012442\n",
      "Epoch 32 num_samples 17900 loss 0.06039392033825556\n",
      "Epoch 32 num_samples 18000 loss 0.03513921607073761\n",
      "Epoch 32 num_samples 18100 loss 0.0450835976216464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 num_samples 18200 loss 0.0498077079218966\n",
      "Epoch 32 num_samples 18300 loss 0.03683682818859011\n",
      "Epoch 32 num_samples 18400 loss 0.07135906987705569\n",
      "Epoch 32 num_samples 18500 loss 0.045838059725740975\n",
      "Epoch 33 num_samples 0 loss 0.03347390536827779\n",
      "Epoch 33 num_samples 100 loss 0.061584069193446445\n",
      "Epoch 33 num_samples 200 loss 0.03463702633005768\n",
      "Epoch 33 num_samples 300 loss 0.03360095347147192\n",
      "Epoch 33 num_samples 400 loss 0.03646316837878076\n",
      "Epoch 33 num_samples 500 loss 0.0482930198932245\n",
      "Epoch 33 num_samples 600 loss 0.060085984013855606\n",
      "Epoch 33 num_samples 700 loss 0.062436387898479814\n",
      "Epoch 33 num_samples 800 loss 0.043463698042095794\n",
      "Epoch 33 num_samples 900 loss 0.0551560877733899\n",
      "Epoch 33 num_samples 1000 loss 0.03866787214795441\n",
      "Epoch 33 num_samples 1100 loss 0.06959840083162203\n",
      "Epoch 33 num_samples 1200 loss 0.04198106005285251\n",
      "Epoch 33 num_samples 1300 loss 0.040620274666231776\n",
      "Epoch 33 num_samples 1400 loss 0.05422847200673089\n",
      "Epoch 33 num_samples 1500 loss 0.09603866222708334\n",
      "Epoch 33 num_samples 1600 loss 0.038912727483655235\n",
      "Epoch 33 num_samples 1700 loss 0.038078952064239766\n",
      "Epoch 33 num_samples 1800 loss 0.03772084952140664\n",
      "Epoch 33 num_samples 1900 loss 0.04179315395135494\n",
      "Epoch 33 num_samples 2000 loss 0.05322758193612431\n",
      "Epoch 33 num_samples 2100 loss 0.02862234690120446\n",
      "Epoch 33 num_samples 2200 loss 0.0309884238126945\n",
      "Epoch 33 num_samples 2300 loss 0.022601897019478158\n",
      "Epoch 33 num_samples 2400 loss 0.038261912356420506\n",
      "Epoch 33 num_samples 2500 loss 0.05649246392297335\n",
      "Epoch 33 num_samples 2600 loss 0.0550788881354636\n",
      "Epoch 33 num_samples 2700 loss 0.04338035090224734\n",
      "Epoch 33 num_samples 2800 loss 0.056944926666685484\n",
      "Epoch 33 num_samples 2900 loss 0.05000284275770636\n",
      "Epoch 33 num_samples 3000 loss 0.039380290893875985\n",
      "Epoch 33 num_samples 3100 loss 0.044980173352831124\n",
      "Epoch 33 num_samples 3200 loss 0.12000945417153275\n",
      "Epoch 33 num_samples 3300 loss 0.052194694677354284\n",
      "Epoch 33 num_samples 3400 loss 0.033141464915915526\n",
      "Epoch 33 num_samples 3500 loss 0.03557858313650462\n",
      "Epoch 33 num_samples 3600 loss 0.023332378382148806\n",
      "Epoch 33 num_samples 3700 loss 0.06729673667124006\n",
      "Epoch 33 num_samples 3800 loss 0.04387997347819162\n",
      "Epoch 33 num_samples 3900 loss 0.04748134787367228\n",
      "Epoch 33 num_samples 4000 loss 0.051729211247818485\n",
      "Epoch 33 num_samples 4100 loss 0.08207382750996298\n",
      "Epoch 33 num_samples 4200 loss 0.04126182710600158\n",
      "Epoch 33 num_samples 4300 loss 0.047024339810687474\n",
      "Epoch 33 num_samples 4400 loss 0.05288303759883575\n",
      "Epoch 33 num_samples 4500 loss 0.06034251365124612\n",
      "Epoch 33 num_samples 4600 loss 0.04439110362852901\n",
      "Epoch 33 num_samples 4700 loss 0.02640479643758514\n",
      "Epoch 33 num_samples 4800 loss 0.026773818783327064\n",
      "Epoch 33 num_samples 4900 loss 0.03101582340642382\n",
      "Epoch 33 num_samples 5000 loss 0.03274670308264922\n",
      "Epoch 33 num_samples 5100 loss 0.05425781631165282\n",
      "Epoch 33 num_samples 5200 loss 0.026745166527570703\n",
      "Epoch 33 num_samples 5300 loss 0.03848924130790429\n",
      "Epoch 33 num_samples 5400 loss 0.050973387136967085\n",
      "Epoch 33 num_samples 5500 loss 0.028739718919990588\n",
      "Epoch 33 num_samples 5600 loss 0.12437596771833885\n",
      "Epoch 33 num_samples 5700 loss 0.06911509561957824\n",
      "Epoch 33 num_samples 5800 loss 0.04981124041381107\n",
      "Epoch 33 num_samples 5900 loss 0.05754638061436504\n",
      "Epoch 33 num_samples 6000 loss 0.05126287337371342\n",
      "Epoch 33 num_samples 6100 loss 0.03762324320336163\n",
      "Epoch 33 num_samples 6200 loss 0.046889966947166135\n",
      "Epoch 33 num_samples 6300 loss 0.06716278467563332\n",
      "Epoch 33 num_samples 6400 loss 0.03590317152970588\n",
      "Epoch 33 num_samples 6500 loss 0.0306715365868775\n",
      "Epoch 33 num_samples 6600 loss 0.06209471322201054\n",
      "Epoch 33 num_samples 6700 loss 0.02807517497757499\n",
      "Epoch 33 num_samples 6800 loss 0.022696141288345194\n",
      "Epoch 33 num_samples 6900 loss 0.08370413738099886\n",
      "Epoch 33 num_samples 7000 loss 0.06416852329965052\n",
      "Epoch 33 num_samples 7100 loss 0.031028186986934294\n",
      "Epoch 33 num_samples 7200 loss 0.03619827806795992\n",
      "Epoch 33 num_samples 7300 loss 0.035610425585841016\n",
      "Epoch 33 num_samples 7400 loss 0.03199995774375414\n",
      "Epoch 33 num_samples 7500 loss 0.07299211693439654\n",
      "Epoch 33 num_samples 7600 loss 0.04182429092777925\n",
      "Epoch 33 num_samples 7700 loss 0.07715452888021138\n",
      "Epoch 33 num_samples 7800 loss 0.028365688850241214\n",
      "Epoch 33 num_samples 7900 loss 0.042256100018137725\n",
      "Epoch 33 num_samples 8000 loss 0.028870839968861212\n",
      "Epoch 33 num_samples 8100 loss 0.03755136340023782\n",
      "Epoch 33 num_samples 8200 loss 0.04358646499187893\n",
      "Epoch 33 num_samples 8300 loss 0.049034514107545724\n",
      "Epoch 33 num_samples 8400 loss 0.033446290320447186\n",
      "Epoch 33 num_samples 8500 loss 0.046446204954597906\n",
      "Epoch 33 num_samples 8600 loss 0.03918282474443133\n",
      "Epoch 33 num_samples 8700 loss 0.04428711726443316\n",
      "Epoch 33 num_samples 8800 loss 0.06548865082717986\n",
      "Epoch 33 num_samples 8900 loss 0.04764239229981402\n",
      "Epoch 33 num_samples 9000 loss 0.0416351604828931\n",
      "Epoch 33 num_samples 9100 loss 0.044012420031606964\n",
      "Epoch 33 num_samples 9200 loss 0.038647114780240646\n",
      "Epoch 33 num_samples 9300 loss 0.04293789404346044\n",
      "Epoch 33 num_samples 9400 loss 0.033089397477761136\n",
      "Epoch 33 num_samples 9500 loss 0.043768953111721805\n",
      "Epoch 33 num_samples 9600 loss 0.03386227464599178\n",
      "Epoch 33 num_samples 9700 loss 0.05825311682461916\n",
      "Epoch 33 num_samples 9800 loss 0.02435265168835864\n",
      "Epoch 33 num_samples 9900 loss 0.08022561757426985\n",
      "Epoch 33 num_samples 10000 loss 0.043450517887029604\n",
      "Epoch 33 num_samples 10100 loss 0.031019825266385075\n",
      "Epoch 33 num_samples 10200 loss 0.06118364910234339\n",
      "Epoch 33 num_samples 10300 loss 0.0438086739421144\n",
      "Epoch 33 num_samples 10400 loss 0.05797884320078916\n",
      "Epoch 33 num_samples 10500 loss 0.033684891150275224\n",
      "Epoch 33 num_samples 10600 loss 0.06679559579763367\n",
      "Epoch 33 num_samples 10700 loss 0.03563754710713132\n",
      "Epoch 33 num_samples 10800 loss 0.06932462584118362\n",
      "Epoch 33 num_samples 10900 loss 0.0343244847546785\n",
      "Epoch 33 num_samples 11000 loss 0.027946196565550398\n",
      "Epoch 33 num_samples 11100 loss 0.041652779256623446\n",
      "Epoch 33 num_samples 11200 loss 0.03512153550024326\n",
      "Epoch 33 num_samples 11300 loss 0.0738489101879401\n",
      "Epoch 33 num_samples 11400 loss 0.057434587049109975\n",
      "Epoch 33 num_samples 11500 loss 0.03971024508927119\n",
      "Epoch 33 num_samples 11600 loss 0.03501641532706077\n",
      "Epoch 33 num_samples 11700 loss 0.054497134737338034\n",
      "Epoch 33 num_samples 11800 loss 0.03655277456247433\n",
      "Epoch 33 num_samples 11900 loss 0.03657113440736481\n",
      "Epoch 33 num_samples 12000 loss 0.0262204600475659\n",
      "Epoch 33 num_samples 12100 loss 0.04547842533340046\n",
      "Epoch 33 num_samples 12200 loss 0.057550925940762755\n",
      "Epoch 33 num_samples 12300 loss 0.02619418260334505\n",
      "Epoch 33 num_samples 12400 loss 0.056182084104050484\n",
      "Epoch 33 num_samples 12500 loss 0.04526708132715081\n",
      "Epoch 33 num_samples 12600 loss 0.05656215081511624\n",
      "Epoch 33 num_samples 12700 loss 0.04722303310993247\n",
      "Epoch 33 num_samples 12800 loss 0.0743869188562216\n",
      "Epoch 33 num_samples 12900 loss 0.0389788429851342\n",
      "Epoch 33 num_samples 13000 loss 0.0311480732766103\n",
      "Epoch 33 num_samples 13100 loss 0.08926301747979608\n",
      "Epoch 33 num_samples 13200 loss 0.0315874115958534\n",
      "Epoch 33 num_samples 13300 loss 0.031063537945576796\n",
      "Epoch 33 num_samples 13400 loss 0.018259757463079854\n",
      "Epoch 33 num_samples 13500 loss 0.03177320259397873\n",
      "Epoch 33 num_samples 13600 loss 0.06083035721434303\n",
      "Epoch 33 num_samples 13700 loss 0.040540742191078255\n",
      "Epoch 33 num_samples 13800 loss 0.04054549257201247\n",
      "Epoch 33 num_samples 13900 loss 0.016979812817716048\n",
      "Epoch 33 num_samples 14000 loss 0.030473054032527754\n",
      "Epoch 33 num_samples 14100 loss 0.03945395499611815\n",
      "Epoch 33 num_samples 14200 loss 0.028881088858369014\n",
      "Epoch 33 num_samples 14300 loss 0.045091019446452024\n",
      "Epoch 33 num_samples 14400 loss 0.04290095235346711\n",
      "Epoch 33 num_samples 14500 loss 0.046584033546534676\n",
      "Epoch 33 num_samples 14600 loss 0.03728291182691478\n",
      "Epoch 33 num_samples 14700 loss 0.041054756210758846\n",
      "Epoch 33 num_samples 14800 loss 0.03299464648271833\n",
      "Epoch 33 num_samples 14900 loss 0.05415751174363091\n",
      "Epoch 33 num_samples 15000 loss 0.03378641324141261\n",
      "Epoch 33 num_samples 15100 loss 0.04063010323237027\n",
      "Epoch 33 num_samples 15200 loss 0.058183820683008716\n",
      "Epoch 33 num_samples 15300 loss 0.04031033613913605\n",
      "Epoch 33 num_samples 15400 loss 0.02641683402473287\n",
      "Epoch 33 num_samples 15500 loss 0.05383623403335773\n",
      "Epoch 33 num_samples 15600 loss 0.04058689699306127\n",
      "Epoch 33 num_samples 15700 loss 0.025966931925939397\n",
      "Epoch 33 num_samples 15800 loss 0.06328473771339378\n",
      "Epoch 33 num_samples 15900 loss 0.025732679717722452\n",
      "Epoch 33 num_samples 16000 loss 0.05363258211654953\n",
      "Epoch 33 num_samples 16100 loss 0.029546524433395716\n",
      "Epoch 33 num_samples 16200 loss 0.04584022107869721\n",
      "Epoch 33 num_samples 16300 loss 0.06457326556817924\n",
      "Epoch 33 num_samples 16400 loss 0.05507503520547667\n",
      "Epoch 33 num_samples 16500 loss 0.04465703671923554\n",
      "Epoch 33 num_samples 16600 loss 0.05367800034482958\n",
      "Epoch 33 num_samples 16700 loss 0.025995369144395042\n",
      "Epoch 33 num_samples 16800 loss 0.03030084684764415\n",
      "Epoch 33 num_samples 16900 loss 0.03490202692183943\n",
      "Epoch 33 num_samples 17000 loss 0.025359007883141098\n",
      "Epoch 33 num_samples 17100 loss 0.09750530876153657\n",
      "Epoch 33 num_samples 17200 loss 0.045791164066021836\n",
      "Epoch 33 num_samples 17300 loss 0.05649293679614585\n",
      "Epoch 33 num_samples 17400 loss 0.04238837637271902\n",
      "Epoch 33 num_samples 17500 loss 0.03860333061510913\n",
      "Epoch 33 num_samples 17600 loss 0.04234617744989661\n",
      "Epoch 33 num_samples 17700 loss 0.03022221304634649\n",
      "Epoch 33 num_samples 17800 loss 0.04396848025511748\n",
      "Epoch 33 num_samples 17900 loss 0.05686402792785805\n",
      "Epoch 33 num_samples 18000 loss 0.03334939565402218\n",
      "Epoch 33 num_samples 18100 loss 0.0426472263809362\n",
      "Epoch 33 num_samples 18200 loss 0.04650971408724601\n",
      "Epoch 33 num_samples 18300 loss 0.034778510927859524\n",
      "Epoch 33 num_samples 18400 loss 0.06755754954600468\n",
      "Epoch 33 num_samples 18500 loss 0.04330294746249006\n",
      "Epoch 34 num_samples 0 loss 0.03153661437864604\n",
      "Epoch 34 num_samples 100 loss 0.05772253042861324\n",
      "Epoch 34 num_samples 200 loss 0.03295000852672391\n",
      "Epoch 34 num_samples 300 loss 0.0319294645602396\n",
      "Epoch 34 num_samples 400 loss 0.034465366292658145\n",
      "Epoch 34 num_samples 500 loss 0.04576827020323617\n",
      "Epoch 34 num_samples 600 loss 0.05716913864999367\n",
      "Epoch 34 num_samples 700 loss 0.05826377790869187\n",
      "Epoch 34 num_samples 800 loss 0.04029891066606241\n",
      "Epoch 34 num_samples 900 loss 0.05286828852016094\n",
      "Epoch 34 num_samples 1000 loss 0.036546088729015665\n",
      "Epoch 34 num_samples 1100 loss 0.06597479347772198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 num_samples 1200 loss 0.039007797570265665\n",
      "Epoch 34 num_samples 1300 loss 0.039111531037478005\n",
      "Epoch 34 num_samples 1400 loss 0.05086258067959639\n",
      "Epoch 34 num_samples 1500 loss 0.09015521438502493\n",
      "Epoch 34 num_samples 1600 loss 0.03657774821479733\n",
      "Epoch 34 num_samples 1700 loss 0.03551920761588624\n",
      "Epoch 34 num_samples 1800 loss 0.03575925396972665\n",
      "Epoch 34 num_samples 1900 loss 0.039545499328455386\n",
      "Epoch 34 num_samples 2000 loss 0.05042399758523663\n",
      "Epoch 34 num_samples 2100 loss 0.026990718083639825\n",
      "Epoch 34 num_samples 2200 loss 0.029428530834785627\n",
      "Epoch 34 num_samples 2300 loss 0.02088439754716387\n",
      "Epoch 34 num_samples 2400 loss 0.03593532322034395\n",
      "Epoch 34 num_samples 2500 loss 0.05279745119707766\n",
      "Epoch 34 num_samples 2600 loss 0.052623772590835394\n",
      "Epoch 34 num_samples 2700 loss 0.04042684361477651\n",
      "Epoch 34 num_samples 2800 loss 0.053808888551373446\n",
      "Epoch 34 num_samples 2900 loss 0.04742191747751938\n",
      "Epoch 34 num_samples 3000 loss 0.037661949893274545\n",
      "Epoch 34 num_samples 3100 loss 0.042102697520478044\n",
      "Epoch 34 num_samples 3200 loss 0.11375941231169115\n",
      "Epoch 34 num_samples 3300 loss 0.04934112849698793\n",
      "Epoch 34 num_samples 3400 loss 0.03108495886079077\n",
      "Epoch 34 num_samples 3500 loss 0.03353415076037547\n",
      "Epoch 34 num_samples 3600 loss 0.021995291032085404\n",
      "Epoch 34 num_samples 3700 loss 0.06427313347532586\n",
      "Epoch 34 num_samples 3800 loss 0.040817380526120044\n",
      "Epoch 34 num_samples 3900 loss 0.04472275080877956\n",
      "Epoch 34 num_samples 4000 loss 0.049448601779966884\n",
      "Epoch 34 num_samples 4100 loss 0.07722875192446382\n",
      "Epoch 34 num_samples 4200 loss 0.03925462103563971\n",
      "Epoch 34 num_samples 4300 loss 0.043516076339984326\n",
      "Epoch 34 num_samples 4400 loss 0.05003797770100654\n",
      "Epoch 34 num_samples 4500 loss 0.05681854209697848\n",
      "Epoch 34 num_samples 4600 loss 0.04208830579717337\n",
      "Epoch 34 num_samples 4700 loss 0.02540202743093048\n",
      "Epoch 34 num_samples 4800 loss 0.025166866876123472\n",
      "Epoch 34 num_samples 4900 loss 0.02930244335503182\n",
      "Epoch 34 num_samples 5000 loss 0.03105044288469329\n",
      "Epoch 34 num_samples 5100 loss 0.05124816535085521\n",
      "Epoch 34 num_samples 5200 loss 0.025300154553419652\n",
      "Epoch 34 num_samples 5300 loss 0.03593026004500713\n",
      "Epoch 34 num_samples 5400 loss 0.04756078822642044\n",
      "Epoch 34 num_samples 5500 loss 0.02696797985170237\n",
      "Epoch 34 num_samples 5600 loss 0.12000169920805105\n",
      "Epoch 34 num_samples 5700 loss 0.06463551984245584\n",
      "Epoch 34 num_samples 5800 loss 0.04611973886816406\n",
      "Epoch 34 num_samples 5900 loss 0.05316681742502143\n",
      "Epoch 34 num_samples 6000 loss 0.047222739462766554\n",
      "Epoch 34 num_samples 6100 loss 0.035845525193977344\n",
      "Epoch 34 num_samples 6200 loss 0.04481933495316122\n",
      "Epoch 34 num_samples 6300 loss 0.06365554314063203\n",
      "Epoch 34 num_samples 6400 loss 0.0334732778187596\n",
      "Epoch 34 num_samples 6500 loss 0.02884889620058714\n",
      "Epoch 34 num_samples 6600 loss 0.05861395299650624\n",
      "Epoch 34 num_samples 6700 loss 0.02713797938956337\n",
      "Epoch 34 num_samples 6800 loss 0.020936235654039827\n",
      "Epoch 34 num_samples 6900 loss 0.07900585403809764\n",
      "Epoch 34 num_samples 7000 loss 0.059401094966260164\n",
      "Epoch 34 num_samples 7100 loss 0.02924025947872247\n",
      "Epoch 34 num_samples 7200 loss 0.03445119780082832\n",
      "Epoch 34 num_samples 7300 loss 0.03346452855230449\n",
      "Epoch 34 num_samples 7400 loss 0.029861967246727558\n",
      "Epoch 34 num_samples 7500 loss 0.06886758965293736\n",
      "Epoch 34 num_samples 7600 loss 0.03981217319900999\n",
      "Epoch 34 num_samples 7700 loss 0.07300694891413181\n",
      "Epoch 34 num_samples 7800 loss 0.027142172718338572\n",
      "Epoch 34 num_samples 7900 loss 0.03955988059628134\n",
      "Epoch 34 num_samples 8000 loss 0.027204095453456416\n",
      "Epoch 34 num_samples 8100 loss 0.035417156348649934\n",
      "Epoch 34 num_samples 8200 loss 0.04124422308743681\n",
      "Epoch 34 num_samples 8300 loss 0.04550459835549965\n",
      "Epoch 34 num_samples 8400 loss 0.03148299110999641\n",
      "Epoch 34 num_samples 8500 loss 0.04343737276209444\n",
      "Epoch 34 num_samples 8600 loss 0.037232567103478754\n",
      "Epoch 34 num_samples 8700 loss 0.0418442594713424\n",
      "Epoch 34 num_samples 8800 loss 0.06115758821360942\n",
      "Epoch 34 num_samples 8900 loss 0.045460175210558784\n",
      "Epoch 34 num_samples 9000 loss 0.0383439177850786\n",
      "Epoch 34 num_samples 9100 loss 0.041390955065436275\n",
      "Epoch 34 num_samples 9200 loss 0.03687969792111772\n",
      "Epoch 34 num_samples 9300 loss 0.040070316878727086\n",
      "Epoch 34 num_samples 9400 loss 0.03159833695123679\n",
      "Epoch 34 num_samples 9500 loss 0.040532399668435595\n",
      "Epoch 34 num_samples 9600 loss 0.03207990850266073\n",
      "Epoch 34 num_samples 9700 loss 0.05558819787091908\n",
      "Epoch 34 num_samples 9800 loss 0.02300155081919621\n",
      "Epoch 34 num_samples 9900 loss 0.07699016093626794\n",
      "Epoch 34 num_samples 10000 loss 0.04074416045547959\n",
      "Epoch 34 num_samples 10100 loss 0.029576609905306035\n",
      "Epoch 34 num_samples 10200 loss 0.056220205567997256\n",
      "Epoch 34 num_samples 10300 loss 0.04099534994457382\n",
      "Epoch 34 num_samples 10400 loss 0.05509093835346854\n",
      "Epoch 34 num_samples 10500 loss 0.03177802641309117\n",
      "Epoch 34 num_samples 10600 loss 0.06280730365623906\n",
      "Epoch 34 num_samples 10700 loss 0.03358357325639191\n",
      "Epoch 34 num_samples 10800 loss 0.06433198320029881\n",
      "Epoch 34 num_samples 10900 loss 0.032254223279714715\n",
      "Epoch 34 num_samples 11000 loss 0.026549169560395346\n",
      "Epoch 34 num_samples 11100 loss 0.03928628513750146\n",
      "Epoch 34 num_samples 11200 loss 0.03298949217633548\n",
      "Epoch 34 num_samples 11300 loss 0.06896799064353451\n",
      "Epoch 34 num_samples 11400 loss 0.05252361267966288\n",
      "Epoch 34 num_samples 11500 loss 0.03705926427890657\n",
      "Epoch 34 num_samples 11600 loss 0.03355840262201847\n",
      "Epoch 34 num_samples 11700 loss 0.051695491010639125\n",
      "Epoch 34 num_samples 11800 loss 0.034563722555423795\n",
      "Epoch 34 num_samples 11900 loss 0.03408091581471636\n",
      "Epoch 34 num_samples 12000 loss 0.024974794893607707\n",
      "Epoch 34 num_samples 12100 loss 0.04230913803694403\n",
      "Epoch 34 num_samples 12200 loss 0.05387548710570081\n",
      "Epoch 34 num_samples 12300 loss 0.024815533913196547\n",
      "Epoch 34 num_samples 12400 loss 0.05340353946225976\n",
      "Epoch 34 num_samples 12500 loss 0.04282777778120162\n",
      "Epoch 34 num_samples 12600 loss 0.053850985859906324\n",
      "Epoch 34 num_samples 12700 loss 0.044156969504223556\n",
      "Epoch 34 num_samples 12800 loss 0.07098724556986913\n",
      "Epoch 34 num_samples 12900 loss 0.036350856098859165\n",
      "Epoch 34 num_samples 13000 loss 0.029446163361333114\n",
      "Epoch 34 num_samples 13100 loss 0.08432669079536137\n",
      "Epoch 34 num_samples 13200 loss 0.02990690633010824\n",
      "Epoch 34 num_samples 13300 loss 0.02900560949283646\n",
      "Epoch 34 num_samples 13400 loss 0.017194593485783\n",
      "Epoch 34 num_samples 13500 loss 0.030154476106658813\n",
      "Epoch 34 num_samples 13600 loss 0.05728088240578796\n",
      "Epoch 34 num_samples 13700 loss 0.038076411255955865\n",
      "Epoch 34 num_samples 13800 loss 0.037801934631350106\n",
      "Epoch 34 num_samples 13900 loss 0.015866432750351975\n",
      "Epoch 34 num_samples 14000 loss 0.0288688661733155\n",
      "Epoch 34 num_samples 14100 loss 0.03704776161963432\n",
      "Epoch 34 num_samples 14200 loss 0.027624862774573215\n",
      "Epoch 34 num_samples 14300 loss 0.042390420736609646\n",
      "Epoch 34 num_samples 14400 loss 0.040073630026914275\n",
      "Epoch 34 num_samples 14500 loss 0.04427293587933896\n",
      "Epoch 34 num_samples 14600 loss 0.03502059044320674\n",
      "Epoch 34 num_samples 14700 loss 0.038588012775851374\n",
      "Epoch 34 num_samples 14800 loss 0.031415712495621424\n",
      "Epoch 34 num_samples 14900 loss 0.05108700233112257\n",
      "Epoch 34 num_samples 15000 loss 0.032241663455990395\n",
      "Epoch 34 num_samples 15100 loss 0.03802416745240704\n",
      "Epoch 34 num_samples 15200 loss 0.05410110673501478\n",
      "Epoch 34 num_samples 15300 loss 0.038362533899192225\n",
      "Epoch 34 num_samples 15400 loss 0.024931222396140963\n",
      "Epoch 34 num_samples 15500 loss 0.050221811438260794\n",
      "Epoch 34 num_samples 15600 loss 0.03875662486392526\n",
      "Epoch 34 num_samples 15700 loss 0.024690350957643888\n",
      "Epoch 34 num_samples 15800 loss 0.05852460823621516\n",
      "Epoch 34 num_samples 15900 loss 0.024339051711007795\n",
      "Epoch 34 num_samples 16000 loss 0.05030308760311149\n",
      "Epoch 34 num_samples 16100 loss 0.027856161453219404\n",
      "Epoch 34 num_samples 16200 loss 0.043311671050580855\n",
      "Epoch 34 num_samples 16300 loss 0.060842438293950155\n",
      "Epoch 34 num_samples 16400 loss 0.052496714990972144\n",
      "Epoch 34 num_samples 16500 loss 0.04201883675486287\n",
      "Epoch 34 num_samples 16600 loss 0.05065313794569993\n",
      "Epoch 34 num_samples 16700 loss 0.024495652590314235\n",
      "Epoch 34 num_samples 16800 loss 0.028543427682135268\n",
      "Epoch 34 num_samples 16900 loss 0.032526335562070144\n",
      "Epoch 34 num_samples 17000 loss 0.0237576903959502\n",
      "Epoch 34 num_samples 17100 loss 0.09086360162189745\n",
      "Epoch 34 num_samples 17200 loss 0.04334594095512166\n",
      "Epoch 34 num_samples 17300 loss 0.052682671739267946\n",
      "Epoch 34 num_samples 17400 loss 0.03965224725396436\n",
      "Epoch 34 num_samples 17500 loss 0.03622918144402039\n",
      "Epoch 34 num_samples 17600 loss 0.03975550275152052\n",
      "Epoch 34 num_samples 17700 loss 0.028650192162939028\n",
      "Epoch 34 num_samples 17800 loss 0.040509506064582326\n",
      "Epoch 34 num_samples 17900 loss 0.054609187258069694\n",
      "Epoch 34 num_samples 18000 loss 0.03170291717615941\n",
      "Epoch 34 num_samples 18100 loss 0.04009153014264255\n",
      "Epoch 34 num_samples 18200 loss 0.04390658717063575\n",
      "Epoch 34 num_samples 18300 loss 0.03252914972834441\n",
      "Epoch 34 num_samples 18400 loss 0.06390387996356475\n",
      "Epoch 34 num_samples 18500 loss 0.04104101270128578\n",
      "Epoch 35 num_samples 0 loss 0.02972156022763236\n",
      "Epoch 35 num_samples 100 loss 0.05464002025263395\n",
      "Epoch 35 num_samples 200 loss 0.031203727861262978\n",
      "Epoch 35 num_samples 300 loss 0.029584531342750943\n",
      "Epoch 35 num_samples 400 loss 0.0326602898998529\n",
      "Epoch 35 num_samples 500 loss 0.04324702987303789\n",
      "Epoch 35 num_samples 600 loss 0.054543963787368345\n",
      "Epoch 35 num_samples 700 loss 0.05539632273370593\n",
      "Epoch 35 num_samples 800 loss 0.03792625499183187\n",
      "Epoch 35 num_samples 900 loss 0.05020502744442812\n",
      "Epoch 35 num_samples 1000 loss 0.03453169154427185\n",
      "Epoch 35 num_samples 1100 loss 0.06232651408104202\n",
      "Epoch 35 num_samples 1200 loss 0.0365034927370867\n",
      "Epoch 35 num_samples 1300 loss 0.037105841019923924\n",
      "Epoch 35 num_samples 1400 loss 0.047521672616989\n",
      "Epoch 35 num_samples 1500 loss 0.08394912097417878\n",
      "Epoch 35 num_samples 1600 loss 0.03470488656724305\n",
      "Epoch 35 num_samples 1700 loss 0.03360977456713979\n",
      "Epoch 35 num_samples 1800 loss 0.03382430286151127\n",
      "Epoch 35 num_samples 1900 loss 0.03738366519753539\n",
      "Epoch 35 num_samples 2000 loss 0.04682266636083236\n",
      "Epoch 35 num_samples 2100 loss 0.025299373598328144\n",
      "Epoch 35 num_samples 2200 loss 0.027829910718702545\n",
      "Epoch 35 num_samples 2300 loss 0.019601046725381512\n",
      "Epoch 35 num_samples 2400 loss 0.03416043877640105\n",
      "Epoch 35 num_samples 2500 loss 0.04896196462308058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 num_samples 2600 loss 0.04957216073946103\n",
      "Epoch 35 num_samples 2700 loss 0.03727437194097962\n",
      "Epoch 35 num_samples 2800 loss 0.0507229361105173\n",
      "Epoch 35 num_samples 2900 loss 0.04464369774933753\n",
      "Epoch 35 num_samples 3000 loss 0.03580066459250515\n",
      "Epoch 35 num_samples 3100 loss 0.038869913868818315\n",
      "Epoch 35 num_samples 3200 loss 0.1080424132388777\n",
      "Epoch 35 num_samples 3300 loss 0.04679709408182441\n",
      "Epoch 35 num_samples 3400 loss 0.029367834990099845\n",
      "Epoch 35 num_samples 3500 loss 0.03134791707835032\n",
      "Epoch 35 num_samples 3600 loss 0.02050155874489814\n",
      "Epoch 35 num_samples 3700 loss 0.06089637410487932\n",
      "Epoch 35 num_samples 3800 loss 0.03802910623859929\n",
      "Epoch 35 num_samples 3900 loss 0.042062578650906506\n",
      "Epoch 35 num_samples 4000 loss 0.04628488197953782\n",
      "Epoch 35 num_samples 4100 loss 0.0729153253797554\n",
      "Epoch 35 num_samples 4200 loss 0.03686407746293467\n",
      "Epoch 35 num_samples 4300 loss 0.04077240994914368\n",
      "Epoch 35 num_samples 4400 loss 0.04778780594104112\n",
      "Epoch 35 num_samples 4500 loss 0.05378145992183258\n",
      "Epoch 35 num_samples 4600 loss 0.03978021085074243\n",
      "Epoch 35 num_samples 4700 loss 0.023903238167046547\n",
      "Epoch 35 num_samples 4800 loss 0.023920635854435855\n",
      "Epoch 35 num_samples 4900 loss 0.027859368567382616\n",
      "Epoch 35 num_samples 5000 loss 0.029003285922072557\n",
      "Epoch 35 num_samples 5100 loss 0.04876337620772169\n",
      "Epoch 35 num_samples 5200 loss 0.02407515464599965\n",
      "Epoch 35 num_samples 5300 loss 0.03397039365353813\n",
      "Epoch 35 num_samples 5400 loss 0.04459295933186274\n",
      "Epoch 35 num_samples 5500 loss 0.025492008107381232\n",
      "Epoch 35 num_samples 5600 loss 0.1150154479801228\n",
      "Epoch 35 num_samples 5700 loss 0.0604919243258802\n",
      "Epoch 35 num_samples 5800 loss 0.04276248367250317\n",
      "Epoch 35 num_samples 5900 loss 0.04951721321200065\n",
      "Epoch 35 num_samples 6000 loss 0.04383212020524613\n",
      "Epoch 35 num_samples 6100 loss 0.033412989245000045\n",
      "Epoch 35 num_samples 6200 loss 0.04232505184333256\n",
      "Epoch 35 num_samples 6300 loss 0.05940904397633805\n",
      "Epoch 35 num_samples 6400 loss 0.03161755716951005\n",
      "Epoch 35 num_samples 6500 loss 0.027490348841771838\n",
      "Epoch 35 num_samples 6600 loss 0.05573137269168656\n",
      "Epoch 35 num_samples 6700 loss 0.025897802551630905\n",
      "Epoch 35 num_samples 6800 loss 0.019962779318307377\n",
      "Epoch 35 num_samples 6900 loss 0.07580385990130854\n",
      "Epoch 35 num_samples 7000 loss 0.0554991065332082\n",
      "Epoch 35 num_samples 7100 loss 0.02741926132100593\n",
      "Epoch 35 num_samples 7200 loss 0.032754525133891724\n",
      "Epoch 35 num_samples 7300 loss 0.03171509262947143\n",
      "Epoch 35 num_samples 7400 loss 0.028078077536367766\n",
      "Epoch 35 num_samples 7500 loss 0.06520648577411287\n",
      "Epoch 35 num_samples 7600 loss 0.037050363691064306\n",
      "Epoch 35 num_samples 7700 loss 0.06832985251470554\n",
      "Epoch 35 num_samples 7800 loss 0.02634533361791613\n",
      "Epoch 35 num_samples 7900 loss 0.03729293294060205\n",
      "Epoch 35 num_samples 8000 loss 0.025698642845437325\n",
      "Epoch 35 num_samples 8100 loss 0.03332713860132523\n",
      "Epoch 35 num_samples 8200 loss 0.03875959176252091\n",
      "Epoch 35 num_samples 8300 loss 0.04255905228354804\n",
      "Epoch 35 num_samples 8400 loss 0.029515757514999578\n",
      "Epoch 35 num_samples 8500 loss 0.04035827332931828\n",
      "Epoch 35 num_samples 8600 loss 0.03552869178593999\n",
      "Epoch 35 num_samples 8700 loss 0.03893745063064585\n",
      "Epoch 35 num_samples 8800 loss 0.05793492903396131\n",
      "Epoch 35 num_samples 8900 loss 0.04299023972246232\n",
      "Epoch 35 num_samples 9000 loss 0.03562980716795403\n",
      "Epoch 35 num_samples 9100 loss 0.03936716749449653\n",
      "Epoch 35 num_samples 9200 loss 0.034415164829496275\n",
      "Epoch 35 num_samples 9300 loss 0.0378122231840543\n",
      "Epoch 35 num_samples 9400 loss 0.030136727536127825\n",
      "Epoch 35 num_samples 9500 loss 0.03820381532666987\n",
      "Epoch 35 num_samples 9600 loss 0.03044281025941337\n",
      "Epoch 35 num_samples 9700 loss 0.05315172723992636\n",
      "Epoch 35 num_samples 9800 loss 0.02161237829883148\n",
      "Epoch 35 num_samples 9900 loss 0.07313331050524827\n",
      "Epoch 35 num_samples 10000 loss 0.03785681441946614\n",
      "Epoch 35 num_samples 10100 loss 0.027915138072571444\n",
      "Epoch 35 num_samples 10200 loss 0.05221963448266814\n",
      "Epoch 35 num_samples 10300 loss 0.037852086590169275\n",
      "Epoch 35 num_samples 10400 loss 0.05224294053877251\n",
      "Epoch 35 num_samples 10500 loss 0.030317725598866755\n",
      "Epoch 35 num_samples 10600 loss 0.059051994904355976\n",
      "Epoch 35 num_samples 10700 loss 0.03165607208421048\n",
      "Epoch 35 num_samples 10800 loss 0.05941307155383823\n",
      "Epoch 35 num_samples 10900 loss 0.03076022324208182\n",
      "Epoch 35 num_samples 11000 loss 0.02542307616747296\n",
      "Epoch 35 num_samples 11100 loss 0.03669946298493889\n",
      "Epoch 35 num_samples 11200 loss 0.03088994321076806\n",
      "Epoch 35 num_samples 11300 loss 0.06435554071674889\n",
      "Epoch 35 num_samples 11400 loss 0.04727540028975888\n",
      "Epoch 35 num_samples 11500 loss 0.035191502725573656\n",
      "Epoch 35 num_samples 11600 loss 0.031666190537721094\n",
      "Epoch 35 num_samples 11700 loss 0.04902477279364535\n",
      "Epoch 35 num_samples 11800 loss 0.032807371212477204\n",
      "Epoch 35 num_samples 11900 loss 0.03199412063248275\n",
      "Epoch 35 num_samples 12000 loss 0.02390456994920967\n",
      "Epoch 35 num_samples 12100 loss 0.03913645498436514\n",
      "Epoch 35 num_samples 12200 loss 0.050440298832843136\n",
      "Epoch 35 num_samples 12300 loss 0.023543459760620937\n",
      "Epoch 35 num_samples 12400 loss 0.05016555638464443\n",
      "Epoch 35 num_samples 12500 loss 0.04035304752743924\n",
      "Epoch 35 num_samples 12600 loss 0.05056167457230732\n",
      "Epoch 35 num_samples 12700 loss 0.0418876730989697\n",
      "Epoch 35 num_samples 12800 loss 0.06745401184023488\n",
      "Epoch 35 num_samples 12900 loss 0.03429501550393443\n",
      "Epoch 35 num_samples 13000 loss 0.027879021156158194\n",
      "Epoch 35 num_samples 13100 loss 0.07942181442172032\n",
      "Epoch 35 num_samples 13200 loss 0.02770517015496112\n",
      "Epoch 35 num_samples 13300 loss 0.027390293886222015\n",
      "Epoch 35 num_samples 13400 loss 0.016300675309905338\n",
      "Epoch 35 num_samples 13500 loss 0.02855609485947871\n",
      "Epoch 35 num_samples 13600 loss 0.05407845109439001\n",
      "Epoch 35 num_samples 13700 loss 0.03564436893953239\n",
      "Epoch 35 num_samples 13800 loss 0.035865982755122996\n",
      "Epoch 35 num_samples 13900 loss 0.01478607423095234\n",
      "Epoch 35 num_samples 14000 loss 0.027170769703983227\n",
      "Epoch 35 num_samples 14100 loss 0.03521871304838015\n",
      "Epoch 35 num_samples 14200 loss 0.02599485827828441\n",
      "Epoch 35 num_samples 14300 loss 0.04034189325611013\n",
      "Epoch 35 num_samples 14400 loss 0.038021693254269164\n",
      "Epoch 35 num_samples 14500 loss 0.04222310896613998\n",
      "Epoch 35 num_samples 14600 loss 0.03348662068301582\n",
      "Epoch 35 num_samples 14700 loss 0.036558614461042666\n",
      "Epoch 35 num_samples 14800 loss 0.030043759233711668\n",
      "Epoch 35 num_samples 14900 loss 0.047676515373159985\n",
      "Epoch 35 num_samples 15000 loss 0.030575233211873134\n",
      "Epoch 35 num_samples 15100 loss 0.03623076972343176\n",
      "Epoch 35 num_samples 15200 loss 0.05014448765288666\n",
      "Epoch 35 num_samples 15300 loss 0.03661138697460833\n",
      "Epoch 35 num_samples 15400 loss 0.023424019026520977\n",
      "Epoch 35 num_samples 15500 loss 0.04717995695674851\n",
      "Epoch 35 num_samples 15600 loss 0.03689446041168152\n",
      "Epoch 35 num_samples 15700 loss 0.02350329281595706\n",
      "Epoch 35 num_samples 15800 loss 0.05541239746091039\n",
      "Epoch 35 num_samples 15900 loss 0.023224784691470077\n",
      "Epoch 35 num_samples 16000 loss 0.04777122821494213\n",
      "Epoch 35 num_samples 16100 loss 0.02649952044306785\n",
      "Epoch 35 num_samples 16200 loss 0.04070802941510701\n",
      "Epoch 35 num_samples 16300 loss 0.057056335762957995\n",
      "Epoch 35 num_samples 16400 loss 0.049592008339447116\n",
      "Epoch 35 num_samples 16500 loss 0.03983735894549931\n",
      "Epoch 35 num_samples 16600 loss 0.04806909585842137\n",
      "Epoch 35 num_samples 16700 loss 0.0232871686160451\n",
      "Epoch 35 num_samples 16800 loss 0.026927963739426984\n",
      "Epoch 35 num_samples 16900 loss 0.03068124957216554\n",
      "Epoch 35 num_samples 17000 loss 0.02247753852881675\n",
      "Epoch 35 num_samples 17100 loss 0.08558951616928008\n",
      "Epoch 35 num_samples 17200 loss 0.04094653051865691\n",
      "Epoch 35 num_samples 17300 loss 0.04974342364375567\n",
      "Epoch 35 num_samples 17400 loss 0.037132847089246385\n",
      "Epoch 35 num_samples 17500 loss 0.034475891439785813\n",
      "Epoch 35 num_samples 17600 loss 0.037402513998595684\n",
      "Epoch 35 num_samples 17700 loss 0.027474505535004762\n",
      "Epoch 35 num_samples 17800 loss 0.037339807297262995\n",
      "Epoch 35 num_samples 17900 loss 0.05173324103404692\n",
      "Epoch 35 num_samples 18000 loss 0.03043875232091804\n",
      "Epoch 35 num_samples 18100 loss 0.037810229645058244\n",
      "Epoch 35 num_samples 18200 loss 0.04157950172566862\n",
      "Epoch 35 num_samples 18300 loss 0.030888757297429733\n",
      "Epoch 35 num_samples 18400 loss 0.06099525316684299\n",
      "Epoch 35 num_samples 18500 loss 0.03879162883121556\n",
      "Epoch 36 num_samples 0 loss 0.027886175586212293\n",
      "Epoch 36 num_samples 100 loss 0.05151142370395949\n",
      "Epoch 36 num_samples 200 loss 0.029503399223047275\n",
      "Epoch 36 num_samples 300 loss 0.027888299321447752\n",
      "Epoch 36 num_samples 400 loss 0.030864268376776548\n",
      "Epoch 36 num_samples 500 loss 0.041936221648534604\n",
      "Epoch 36 num_samples 600 loss 0.05154559284156589\n",
      "Epoch 36 num_samples 700 loss 0.05190169558675675\n",
      "Epoch 36 num_samples 800 loss 0.03566056504169647\n",
      "Epoch 36 num_samples 900 loss 0.04788357036129062\n",
      "Epoch 36 num_samples 1000 loss 0.03262056609666866\n",
      "Epoch 36 num_samples 1100 loss 0.059249169894055174\n",
      "Epoch 36 num_samples 1200 loss 0.03413992578626134\n",
      "Epoch 36 num_samples 1300 loss 0.03567462157561351\n",
      "Epoch 36 num_samples 1400 loss 0.04475903028208683\n",
      "Epoch 36 num_samples 1500 loss 0.0783863195262552\n",
      "Epoch 36 num_samples 1600 loss 0.032628491973772135\n",
      "Epoch 36 num_samples 1700 loss 0.03135582231625428\n",
      "Epoch 36 num_samples 1800 loss 0.03187130145600759\n",
      "Epoch 36 num_samples 1900 loss 0.03547573533078304\n",
      "Epoch 36 num_samples 2000 loss 0.04427285425269116\n",
      "Epoch 36 num_samples 2100 loss 0.023673660930056347\n",
      "Epoch 36 num_samples 2200 loss 0.026272261403080793\n",
      "Epoch 36 num_samples 2300 loss 0.018211574801910234\n",
      "Epoch 36 num_samples 2400 loss 0.03201842675259492\n",
      "Epoch 36 num_samples 2500 loss 0.04597025449110943\n",
      "Epoch 36 num_samples 2600 loss 0.04716316538264323\n",
      "Epoch 36 num_samples 2700 loss 0.03460774756005796\n",
      "Epoch 36 num_samples 2800 loss 0.0482315803065304\n",
      "Epoch 36 num_samples 2900 loss 0.04256886952940318\n",
      "Epoch 36 num_samples 3000 loss 0.03444042286630176\n",
      "Epoch 36 num_samples 3100 loss 0.03659480718381185\n",
      "Epoch 36 num_samples 3200 loss 0.10231987268389023\n",
      "Epoch 36 num_samples 3300 loss 0.04412180059022816\n",
      "Epoch 36 num_samples 3400 loss 0.027983963196619836\n",
      "Epoch 36 num_samples 3500 loss 0.02988564581807638\n",
      "Epoch 36 num_samples 3600 loss 0.01944131870886192\n",
      "Epoch 36 num_samples 3700 loss 0.05716768849572551\n",
      "Epoch 36 num_samples 3800 loss 0.036082440725630514\n",
      "Epoch 36 num_samples 3900 loss 0.03996847548633467\n",
      "Epoch 36 num_samples 4000 loss 0.044185909102027576\n",
      "Epoch 36 num_samples 4100 loss 0.0682980610972621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 num_samples 4200 loss 0.034719223872367484\n",
      "Epoch 36 num_samples 4300 loss 0.03870784419233314\n",
      "Epoch 36 num_samples 4400 loss 0.04493967618426206\n",
      "Epoch 36 num_samples 4500 loss 0.05032812530719711\n",
      "Epoch 36 num_samples 4600 loss 0.03810695083745121\n",
      "Epoch 36 num_samples 4700 loss 0.02263399618391456\n",
      "Epoch 36 num_samples 4800 loss 0.02278510090526215\n",
      "Epoch 36 num_samples 4900 loss 0.026372896108046592\n",
      "Epoch 36 num_samples 5000 loss 0.027498752196436067\n",
      "Epoch 36 num_samples 5100 loss 0.046326844944932964\n",
      "Epoch 36 num_samples 5200 loss 0.022648632487144257\n",
      "Epoch 36 num_samples 5300 loss 0.03180826522692658\n",
      "Epoch 36 num_samples 5400 loss 0.04227457493365279\n",
      "Epoch 36 num_samples 5500 loss 0.024026725351117335\n",
      "Epoch 36 num_samples 5600 loss 0.11090844997957593\n",
      "Epoch 36 num_samples 5700 loss 0.057036859210684056\n",
      "Epoch 36 num_samples 5800 loss 0.03973547452147597\n",
      "Epoch 36 num_samples 5900 loss 0.04690166017272686\n",
      "Epoch 36 num_samples 6000 loss 0.04099686351228586\n",
      "Epoch 36 num_samples 6100 loss 0.03180800969345357\n",
      "Epoch 36 num_samples 6200 loss 0.03961255854757061\n",
      "Epoch 36 num_samples 6300 loss 0.05625172447886499\n",
      "Epoch 36 num_samples 6400 loss 0.030107699083489994\n",
      "Epoch 36 num_samples 6500 loss 0.026132461274169967\n",
      "Epoch 36 num_samples 6600 loss 0.05269460176779792\n",
      "Epoch 36 num_samples 6700 loss 0.02491074978505166\n",
      "Epoch 36 num_samples 6800 loss 0.0187414632537838\n",
      "Epoch 36 num_samples 6900 loss 0.07179851066687108\n",
      "Epoch 36 num_samples 7000 loss 0.05229813906829408\n",
      "Epoch 36 num_samples 7100 loss 0.02569726605301857\n",
      "Epoch 36 num_samples 7200 loss 0.03130428249534109\n",
      "Epoch 36 num_samples 7300 loss 0.02989913540791692\n",
      "Epoch 36 num_samples 7400 loss 0.02616623258575574\n",
      "Epoch 36 num_samples 7500 loss 0.062017395732482924\n",
      "Epoch 36 num_samples 7600 loss 0.035077032348748365\n",
      "Epoch 36 num_samples 7700 loss 0.06493899623349077\n",
      "Epoch 36 num_samples 7800 loss 0.025097122135646268\n",
      "Epoch 36 num_samples 7900 loss 0.03522651786104736\n",
      "Epoch 36 num_samples 8000 loss 0.024451885101243357\n",
      "Epoch 36 num_samples 8100 loss 0.03179884344301284\n",
      "Epoch 36 num_samples 8200 loss 0.03662399108649435\n",
      "Epoch 36 num_samples 8300 loss 0.04006558433669698\n",
      "Epoch 36 num_samples 8400 loss 0.027733231582100906\n",
      "Epoch 36 num_samples 8500 loss 0.038168509391197\n",
      "Epoch 36 num_samples 8600 loss 0.03417396184956728\n",
      "Epoch 36 num_samples 8700 loss 0.03689376925496448\n",
      "Epoch 36 num_samples 8800 loss 0.05364465036398935\n",
      "Epoch 36 num_samples 8900 loss 0.04079236385455687\n",
      "Epoch 36 num_samples 9000 loss 0.033271110073594325\n",
      "Epoch 36 num_samples 9100 loss 0.03663580691681267\n",
      "Epoch 36 num_samples 9200 loss 0.032716703659873884\n",
      "Epoch 36 num_samples 9300 loss 0.03573967205506441\n",
      "Epoch 36 num_samples 9400 loss 0.028642282745397502\n",
      "Epoch 36 num_samples 9500 loss 0.03545157233113699\n",
      "Epoch 36 num_samples 9600 loss 0.028666922317810473\n",
      "Epoch 36 num_samples 9700 loss 0.05100631352790348\n",
      "Epoch 36 num_samples 9800 loss 0.020408530942216875\n",
      "Epoch 36 num_samples 9900 loss 0.06916988863190678\n",
      "Epoch 36 num_samples 10000 loss 0.03512952062972058\n",
      "Epoch 36 num_samples 10100 loss 0.02662197142051709\n",
      "Epoch 36 num_samples 10200 loss 0.048117758012765854\n",
      "Epoch 36 num_samples 10300 loss 0.035474332854806695\n",
      "Epoch 36 num_samples 10400 loss 0.04954375006599077\n",
      "Epoch 36 num_samples 10500 loss 0.028390576544308176\n",
      "Epoch 36 num_samples 10600 loss 0.056060148364626416\n",
      "Epoch 36 num_samples 10700 loss 0.029999215120146475\n",
      "Epoch 36 num_samples 10800 loss 0.05497117954232624\n",
      "Epoch 36 num_samples 10900 loss 0.028975141648456194\n",
      "Epoch 36 num_samples 11000 loss 0.024020042695712018\n",
      "Epoch 36 num_samples 11100 loss 0.034916536585991996\n",
      "Epoch 36 num_samples 11200 loss 0.029524901052600833\n",
      "Epoch 36 num_samples 11300 loss 0.0600392992755642\n",
      "Epoch 36 num_samples 11400 loss 0.04360889258910051\n",
      "Epoch 36 num_samples 11500 loss 0.033098694251583294\n",
      "Epoch 36 num_samples 11600 loss 0.030095645074965413\n",
      "Epoch 36 num_samples 11700 loss 0.046239680753298165\n",
      "Epoch 36 num_samples 11800 loss 0.0311012102611083\n",
      "Epoch 36 num_samples 11900 loss 0.03024961431194809\n",
      "Epoch 36 num_samples 12000 loss 0.022798271910600812\n",
      "Epoch 36 num_samples 12100 loss 0.03677464450562172\n",
      "Epoch 36 num_samples 12200 loss 0.047420505573395395\n",
      "Epoch 36 num_samples 12300 loss 0.022409045937441155\n",
      "Epoch 36 num_samples 12400 loss 0.04708358838210763\n",
      "Epoch 36 num_samples 12500 loss 0.03837905312514491\n",
      "Epoch 36 num_samples 12600 loss 0.04800218516489096\n",
      "Epoch 36 num_samples 12700 loss 0.039196687739471915\n",
      "Epoch 36 num_samples 12800 loss 0.06431415021618342\n",
      "Epoch 36 num_samples 12900 loss 0.032482715829579484\n",
      "Epoch 36 num_samples 13000 loss 0.026684013447448224\n",
      "Epoch 36 num_samples 13100 loss 0.07464241850755621\n",
      "Epoch 36 num_samples 13200 loss 0.025726056148587112\n",
      "Epoch 36 num_samples 13300 loss 0.02593777327077259\n",
      "Epoch 36 num_samples 13400 loss 0.015406627156525101\n",
      "Epoch 36 num_samples 13500 loss 0.027052922168615642\n",
      "Epoch 36 num_samples 13600 loss 0.05113815443212772\n",
      "Epoch 36 num_samples 13700 loss 0.034181804395673095\n",
      "Epoch 36 num_samples 13800 loss 0.03386180929478646\n",
      "Epoch 36 num_samples 13900 loss 0.013816535002329957\n",
      "Epoch 36 num_samples 14000 loss 0.025614086779078685\n",
      "Epoch 36 num_samples 14100 loss 0.03322500805231466\n",
      "Epoch 36 num_samples 14200 loss 0.024791418364548515\n",
      "Epoch 36 num_samples 14300 loss 0.03800376489129682\n",
      "Epoch 36 num_samples 14400 loss 0.03606583961890502\n",
      "Epoch 36 num_samples 14500 loss 0.03999109091554105\n",
      "Epoch 36 num_samples 14600 loss 0.03192181888652841\n",
      "Epoch 36 num_samples 14700 loss 0.03460142977915346\n",
      "Epoch 36 num_samples 14800 loss 0.02866829763403164\n",
      "Epoch 36 num_samples 14900 loss 0.04452119227087588\n",
      "Epoch 36 num_samples 15000 loss 0.028779161440107625\n",
      "Epoch 36 num_samples 15100 loss 0.03420654221576531\n",
      "Epoch 36 num_samples 15200 loss 0.045973252763790065\n",
      "Epoch 36 num_samples 15300 loss 0.03458111164699066\n",
      "Epoch 36 num_samples 15400 loss 0.022137259861247986\n",
      "Epoch 36 num_samples 15500 loss 0.04415989819849784\n",
      "Epoch 36 num_samples 15600 loss 0.03493815062256958\n",
      "Epoch 36 num_samples 15700 loss 0.02244468152610021\n",
      "Epoch 36 num_samples 15800 loss 0.05178544093924994\n",
      "Epoch 36 num_samples 15900 loss 0.022053663784676304\n",
      "Epoch 36 num_samples 16000 loss 0.04523040289291842\n",
      "Epoch 36 num_samples 16100 loss 0.024965890711522453\n",
      "Epoch 36 num_samples 16200 loss 0.03883758710262909\n",
      "Epoch 36 num_samples 16300 loss 0.05405144772416081\n",
      "Epoch 36 num_samples 16400 loss 0.0470912859232085\n",
      "Epoch 36 num_samples 16500 loss 0.03818216079484924\n",
      "Epoch 36 num_samples 16600 loss 0.04540466788362834\n",
      "Epoch 36 num_samples 16700 loss 0.022321804856926645\n",
      "Epoch 36 num_samples 16800 loss 0.02534067053483523\n",
      "Epoch 36 num_samples 16900 loss 0.028958451532562178\n",
      "Epoch 36 num_samples 17000 loss 0.02136868554699473\n",
      "Epoch 36 num_samples 17100 loss 0.08009009936189665\n",
      "Epoch 36 num_samples 17200 loss 0.038698291069095656\n",
      "Epoch 36 num_samples 17300 loss 0.04665030644154171\n",
      "Epoch 36 num_samples 17400 loss 0.03518578049596768\n",
      "Epoch 36 num_samples 17500 loss 0.03257413611830981\n",
      "Epoch 36 num_samples 17600 loss 0.03518746368437868\n",
      "Epoch 36 num_samples 17700 loss 0.02588325488363763\n",
      "Epoch 36 num_samples 17800 loss 0.03453578099292759\n",
      "Epoch 36 num_samples 17900 loss 0.049167048812954556\n",
      "Epoch 36 num_samples 18000 loss 0.028863157930368824\n",
      "Epoch 36 num_samples 18100 loss 0.0356777233108153\n",
      "Epoch 36 num_samples 18200 loss 0.039031751041098926\n",
      "Epoch 36 num_samples 18300 loss 0.029152554415445633\n",
      "Epoch 36 num_samples 18400 loss 0.05769374741011861\n",
      "Epoch 36 num_samples 18500 loss 0.03731602192625308\n",
      "Epoch 37 num_samples 0 loss 0.026532642289246566\n",
      "Epoch 37 num_samples 100 loss 0.04861922809877463\n",
      "Epoch 37 num_samples 200 loss 0.028133245852806812\n",
      "Epoch 37 num_samples 300 loss 0.026410599033072888\n",
      "Epoch 37 num_samples 400 loss 0.02933738867796678\n",
      "Epoch 37 num_samples 500 loss 0.03956082704884757\n",
      "Epoch 37 num_samples 600 loss 0.04903910562396179\n",
      "Epoch 37 num_samples 700 loss 0.049454007117248844\n",
      "Epoch 37 num_samples 800 loss 0.033753869247504786\n",
      "Epoch 37 num_samples 900 loss 0.04617049282049347\n",
      "Epoch 37 num_samples 1000 loss 0.030907453354703823\n",
      "Epoch 37 num_samples 1100 loss 0.0554382096537577\n",
      "Epoch 37 num_samples 1200 loss 0.032134490049482205\n",
      "Epoch 37 num_samples 1300 loss 0.03381082360970656\n",
      "Epoch 37 num_samples 1400 loss 0.0421984478961288\n",
      "Epoch 37 num_samples 1500 loss 0.07312576651170545\n",
      "Epoch 37 num_samples 1600 loss 0.03121799405225592\n",
      "Epoch 37 num_samples 1700 loss 0.030052268568946668\n",
      "Epoch 37 num_samples 1800 loss 0.03016394911020044\n",
      "Epoch 37 num_samples 1900 loss 0.033669037136740236\n",
      "Epoch 37 num_samples 2000 loss 0.041972806507773824\n",
      "Epoch 37 num_samples 2100 loss 0.022573271652489825\n",
      "Epoch 37 num_samples 2200 loss 0.024911690453170782\n",
      "Epoch 37 num_samples 2300 loss 0.017202147172499946\n",
      "Epoch 37 num_samples 2400 loss 0.03055868789824084\n",
      "Epoch 37 num_samples 2500 loss 0.04275923418041013\n",
      "Epoch 37 num_samples 2600 loss 0.04468057538182642\n",
      "Epoch 37 num_samples 2700 loss 0.03205000610747142\n",
      "Epoch 37 num_samples 2800 loss 0.04559078422064231\n",
      "Epoch 37 num_samples 2900 loss 0.04030358022085271\n",
      "Epoch 37 num_samples 3000 loss 0.03290114001973374\n",
      "Epoch 37 num_samples 3100 loss 0.03384334198332643\n",
      "Epoch 37 num_samples 3200 loss 0.09647872419739055\n",
      "Epoch 37 num_samples 3300 loss 0.04224033548910024\n",
      "Epoch 37 num_samples 3400 loss 0.026635906765913923\n",
      "Epoch 37 num_samples 3500 loss 0.02804759414887411\n",
      "Epoch 37 num_samples 3600 loss 0.018585859504484062\n",
      "Epoch 37 num_samples 3700 loss 0.054748024981805955\n",
      "Epoch 37 num_samples 3800 loss 0.03390903708939442\n",
      "Epoch 37 num_samples 3900 loss 0.03761037780265423\n",
      "Epoch 37 num_samples 4000 loss 0.042204089365805844\n",
      "Epoch 37 num_samples 4100 loss 0.06458089595873398\n",
      "Epoch 37 num_samples 4200 loss 0.03289228395075682\n",
      "Epoch 37 num_samples 4300 loss 0.036316173270650086\n",
      "Epoch 37 num_samples 4400 loss 0.04275150520146846\n",
      "Epoch 37 num_samples 4500 loss 0.0479527509914162\n",
      "Epoch 37 num_samples 4600 loss 0.0357209524397894\n",
      "Epoch 37 num_samples 4700 loss 0.021762850640021973\n",
      "Epoch 37 num_samples 4800 loss 0.021639014367837182\n",
      "Epoch 37 num_samples 4900 loss 0.025088160909175598\n",
      "Epoch 37 num_samples 5000 loss 0.025717740155506076\n",
      "Epoch 37 num_samples 5100 loss 0.04377823870174816\n",
      "Epoch 37 num_samples 5200 loss 0.021810329046062994\n",
      "Epoch 37 num_samples 5300 loss 0.030423170897768675\n",
      "Epoch 37 num_samples 5400 loss 0.03954123904872086\n",
      "Epoch 37 num_samples 5500 loss 0.022716572481554273\n",
      "Epoch 37 num_samples 5600 loss 0.10655531110903292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 num_samples 5700 loss 0.05219447410819036\n",
      "Epoch 37 num_samples 5800 loss 0.03724942734196164\n",
      "Epoch 37 num_samples 5900 loss 0.043473767646258335\n",
      "Epoch 37 num_samples 6000 loss 0.03817315142016343\n",
      "Epoch 37 num_samples 6100 loss 0.030223422479280657\n",
      "Epoch 37 num_samples 6200 loss 0.037359944308964374\n",
      "Epoch 37 num_samples 6300 loss 0.05269623183898694\n",
      "Epoch 37 num_samples 6400 loss 0.028398980675762697\n",
      "Epoch 37 num_samples 6500 loss 0.025010158412179413\n",
      "Epoch 37 num_samples 6600 loss 0.0501696408724809\n",
      "Epoch 37 num_samples 6700 loss 0.023816987191804025\n",
      "Epoch 37 num_samples 6800 loss 0.017715651353306765\n",
      "Epoch 37 num_samples 6900 loss 0.06779702046547077\n",
      "Epoch 37 num_samples 7000 loss 0.048791376978948656\n",
      "Epoch 37 num_samples 7100 loss 0.023866115514974213\n",
      "Epoch 37 num_samples 7200 loss 0.02971996129411571\n",
      "Epoch 37 num_samples 7300 loss 0.028293644780141906\n",
      "Epoch 37 num_samples 7400 loss 0.02493269715248597\n",
      "Epoch 37 num_samples 7500 loss 0.05875925498709999\n",
      "Epoch 37 num_samples 7600 loss 0.03357486607109526\n",
      "Epoch 37 num_samples 7700 loss 0.061041991692198566\n",
      "Epoch 37 num_samples 7800 loss 0.024170991967223755\n",
      "Epoch 37 num_samples 7900 loss 0.03341037317570213\n",
      "Epoch 37 num_samples 8000 loss 0.023067029221061058\n",
      "Epoch 37 num_samples 8100 loss 0.02993973813686971\n",
      "Epoch 37 num_samples 8200 loss 0.03468778848312351\n",
      "Epoch 37 num_samples 8300 loss 0.037543982296403794\n",
      "Epoch 37 num_samples 8400 loss 0.025960556480995933\n",
      "Epoch 37 num_samples 8500 loss 0.035834060483062986\n",
      "Epoch 37 num_samples 8600 loss 0.032390343147692936\n",
      "Epoch 37 num_samples 8700 loss 0.03511206180981654\n",
      "Epoch 37 num_samples 8800 loss 0.05007300804609364\n",
      "Epoch 37 num_samples 8900 loss 0.03910239797948755\n",
      "Epoch 37 num_samples 9000 loss 0.03136026351693337\n",
      "Epoch 37 num_samples 9100 loss 0.0346740410233735\n",
      "Epoch 37 num_samples 9200 loss 0.03110787989455588\n",
      "Epoch 37 num_samples 9300 loss 0.033611714595364675\n",
      "Epoch 37 num_samples 9400 loss 0.027221039339387534\n",
      "Epoch 37 num_samples 9500 loss 0.032916160049452976\n",
      "Epoch 37 num_samples 9600 loss 0.027351986096472755\n",
      "Epoch 37 num_samples 9700 loss 0.04900960917537503\n",
      "Epoch 37 num_samples 9800 loss 0.019423353236860844\n",
      "Epoch 37 num_samples 9900 loss 0.06631515490611892\n",
      "Epoch 37 num_samples 10000 loss 0.03290251306817202\n",
      "Epoch 37 num_samples 10100 loss 0.025605475600226583\n",
      "Epoch 37 num_samples 10200 loss 0.044979315938431214\n",
      "Epoch 37 num_samples 10300 loss 0.03315879914036087\n",
      "Epoch 37 num_samples 10400 loss 0.046701142388994456\n",
      "Epoch 37 num_samples 10500 loss 0.027036326344192937\n",
      "Epoch 37 num_samples 10600 loss 0.052992243953913505\n",
      "Epoch 37 num_samples 10700 loss 0.028525247295345696\n",
      "Epoch 37 num_samples 10800 loss 0.051186636912091785\n",
      "Epoch 37 num_samples 10900 loss 0.027169248668228372\n",
      "Epoch 37 num_samples 11000 loss 0.022949297238939445\n",
      "Epoch 37 num_samples 11100 loss 0.03294264494272285\n",
      "Epoch 37 num_samples 11200 loss 0.02762212974333529\n",
      "Epoch 37 num_samples 11300 loss 0.05609146980629245\n",
      "Epoch 37 num_samples 11400 loss 0.04009675722109964\n",
      "Epoch 37 num_samples 11500 loss 0.03167631045285534\n",
      "Epoch 37 num_samples 11600 loss 0.02880963343331563\n",
      "Epoch 37 num_samples 11700 loss 0.04408123776730699\n",
      "Epoch 37 num_samples 11800 loss 0.029459157943668574\n",
      "Epoch 37 num_samples 11900 loss 0.02814800572532948\n",
      "Epoch 37 num_samples 12000 loss 0.021788931188510312\n",
      "Epoch 37 num_samples 12100 loss 0.03372038171006762\n",
      "Epoch 37 num_samples 12200 loss 0.04491828350758473\n",
      "Epoch 37 num_samples 12300 loss 0.021026100055271328\n",
      "Epoch 37 num_samples 12400 loss 0.0449399428993985\n",
      "Epoch 37 num_samples 12500 loss 0.03579799580145297\n",
      "Epoch 37 num_samples 12600 loss 0.04528554007421914\n",
      "Epoch 37 num_samples 12700 loss 0.03682092205422987\n",
      "Epoch 37 num_samples 12800 loss 0.06166173853673032\n",
      "Epoch 37 num_samples 12900 loss 0.03042500507238859\n",
      "Epoch 37 num_samples 13000 loss 0.024981767595183117\n",
      "Epoch 37 num_samples 13100 loss 0.06999870398965995\n",
      "Epoch 37 num_samples 13200 loss 0.02401391004972605\n",
      "Epoch 37 num_samples 13300 loss 0.02471122709583096\n",
      "Epoch 37 num_samples 13400 loss 0.014642490158294138\n",
      "Epoch 37 num_samples 13500 loss 0.025790750530190372\n",
      "Epoch 37 num_samples 13600 loss 0.04896998018296468\n",
      "Epoch 37 num_samples 13700 loss 0.03209277491441005\n",
      "Epoch 37 num_samples 13800 loss 0.03176497292336248\n",
      "Epoch 37 num_samples 13900 loss 0.013103628831189363\n",
      "Epoch 37 num_samples 14000 loss 0.024129796490794008\n",
      "Epoch 37 num_samples 14100 loss 0.03165324776686036\n",
      "Epoch 37 num_samples 14200 loss 0.023343559154790902\n",
      "Epoch 37 num_samples 14300 loss 0.03590485428028099\n",
      "Epoch 37 num_samples 14400 loss 0.03426941934060783\n",
      "Epoch 37 num_samples 14500 loss 0.03808031230077515\n",
      "Epoch 37 num_samples 14600 loss 0.030088354453956606\n",
      "Epoch 37 num_samples 14700 loss 0.032916562339699945\n",
      "Epoch 37 num_samples 14800 loss 0.027151938137700803\n",
      "Epoch 37 num_samples 14900 loss 0.04234742229689074\n",
      "Epoch 37 num_samples 15000 loss 0.027288471613153387\n",
      "Epoch 37 num_samples 15100 loss 0.032709209662926474\n",
      "Epoch 37 num_samples 15200 loss 0.04303206095034312\n",
      "Epoch 37 num_samples 15300 loss 0.033316667626392855\n",
      "Epoch 37 num_samples 15400 loss 0.02099192491801224\n",
      "Epoch 37 num_samples 15500 loss 0.04136420415836099\n",
      "Epoch 37 num_samples 15600 loss 0.033373905779766\n",
      "Epoch 37 num_samples 15700 loss 0.02129856736671578\n",
      "Epoch 37 num_samples 15800 loss 0.04892443447694354\n",
      "Epoch 37 num_samples 15900 loss 0.020940964070205768\n",
      "Epoch 37 num_samples 16000 loss 0.043233542041025454\n",
      "Epoch 37 num_samples 16100 loss 0.02378116429199344\n",
      "Epoch 37 num_samples 16200 loss 0.03641740465741581\n",
      "Epoch 37 num_samples 16300 loss 0.05085364790714934\n",
      "Epoch 37 num_samples 16400 loss 0.04423538356803232\n",
      "Epoch 37 num_samples 16500 loss 0.03611522772748623\n",
      "Epoch 37 num_samples 16600 loss 0.04298172833152032\n",
      "Epoch 37 num_samples 16700 loss 0.021130748937528157\n",
      "Epoch 37 num_samples 16800 loss 0.023832887762435206\n",
      "Epoch 37 num_samples 16900 loss 0.027165959929381884\n",
      "Epoch 37 num_samples 17000 loss 0.020182269421531892\n",
      "Epoch 37 num_samples 17100 loss 0.07479313456012977\n",
      "Epoch 37 num_samples 17200 loss 0.03669146924276266\n",
      "Epoch 37 num_samples 17300 loss 0.04376724807504886\n",
      "Epoch 37 num_samples 17400 loss 0.033254761093867324\n",
      "Epoch 37 num_samples 17500 loss 0.03094838861801297\n",
      "Epoch 37 num_samples 17600 loss 0.03313757968944657\n",
      "Epoch 37 num_samples 17700 loss 0.024666766206531566\n",
      "Epoch 37 num_samples 17800 loss 0.03190885007728353\n",
      "Epoch 37 num_samples 17900 loss 0.047215197560788055\n",
      "Epoch 37 num_samples 18000 loss 0.02757220167444867\n",
      "Epoch 37 num_samples 18100 loss 0.03342083623436382\n",
      "Epoch 37 num_samples 18200 loss 0.03642031148729174\n",
      "Epoch 37 num_samples 18300 loss 0.027551314926921942\n",
      "Epoch 37 num_samples 18400 loss 0.0544717485091166\n",
      "Epoch 37 num_samples 18500 loss 0.03549747159826647\n",
      "Epoch 38 num_samples 0 loss 0.02539652025000814\n",
      "Epoch 38 num_samples 100 loss 0.046107102855805875\n",
      "Epoch 38 num_samples 200 loss 0.02687882421226448\n",
      "Epoch 38 num_samples 300 loss 0.024954640395182644\n",
      "Epoch 38 num_samples 400 loss 0.02790928267690689\n",
      "Epoch 38 num_samples 500 loss 0.038523267707974894\n",
      "Epoch 38 num_samples 600 loss 0.04693404453324621\n",
      "Epoch 38 num_samples 700 loss 0.04658152104948779\n",
      "Epoch 38 num_samples 800 loss 0.03176438049614399\n",
      "Epoch 38 num_samples 900 loss 0.04431342877869211\n",
      "Epoch 38 num_samples 1000 loss 0.029573649308994462\n",
      "Epoch 38 num_samples 1100 loss 0.05308643211513051\n",
      "Epoch 38 num_samples 1200 loss 0.03031593642327902\n",
      "Epoch 38 num_samples 1300 loss 0.032374623608122086\n",
      "Epoch 38 num_samples 1400 loss 0.03974621634944164\n",
      "Epoch 38 num_samples 1500 loss 0.06775326343888124\n",
      "Epoch 38 num_samples 1600 loss 0.02965065971709615\n",
      "Epoch 38 num_samples 1700 loss 0.028620821402062954\n",
      "Epoch 38 num_samples 1800 loss 0.028778290105271234\n",
      "Epoch 38 num_samples 1900 loss 0.03233932756391496\n",
      "Epoch 38 num_samples 2000 loss 0.0397189707517988\n",
      "Epoch 38 num_samples 2100 loss 0.02176839144250229\n",
      "Epoch 38 num_samples 2200 loss 0.02358426544877891\n",
      "Epoch 38 num_samples 2300 loss 0.01618662615371093\n",
      "Epoch 38 num_samples 2400 loss 0.028871337663276857\n",
      "Epoch 38 num_samples 2500 loss 0.040344023171220836\n",
      "Epoch 38 num_samples 2600 loss 0.04223586166947482\n",
      "Epoch 38 num_samples 2700 loss 0.03011408867951409\n",
      "Epoch 38 num_samples 2800 loss 0.04332559395756224\n",
      "Epoch 38 num_samples 2900 loss 0.03796661496612178\n",
      "Epoch 38 num_samples 3000 loss 0.03140410238108319\n",
      "Epoch 38 num_samples 3100 loss 0.032012794810482\n",
      "Epoch 38 num_samples 3200 loss 0.09126263634370378\n",
      "Epoch 38 num_samples 3300 loss 0.03914523988176843\n",
      "Epoch 38 num_samples 3400 loss 0.025056300583511035\n",
      "Epoch 38 num_samples 3500 loss 0.02651642104949544\n",
      "Epoch 38 num_samples 3600 loss 0.017619119312238044\n",
      "Epoch 38 num_samples 3700 loss 0.0513992863972839\n",
      "Epoch 38 num_samples 3800 loss 0.03193699260258878\n",
      "Epoch 38 num_samples 3900 loss 0.03585141780163402\n",
      "Epoch 38 num_samples 4000 loss 0.040277730638337034\n",
      "Epoch 38 num_samples 4100 loss 0.061006691054195\n",
      "Epoch 38 num_samples 4200 loss 0.03120304020142826\n",
      "Epoch 38 num_samples 4300 loss 0.034206229781549295\n",
      "Epoch 38 num_samples 4400 loss 0.04065719058227179\n",
      "Epoch 38 num_samples 4500 loss 0.04520464587832147\n",
      "Epoch 38 num_samples 4600 loss 0.03407424774285824\n",
      "Epoch 38 num_samples 4700 loss 0.02077679405518452\n",
      "Epoch 38 num_samples 4800 loss 0.02039380023970429\n",
      "Epoch 38 num_samples 4900 loss 0.023957064531391004\n",
      "Epoch 38 num_samples 5000 loss 0.024447933708886743\n",
      "Epoch 38 num_samples 5100 loss 0.041806188695406886\n",
      "Epoch 38 num_samples 5200 loss 0.0205344524913923\n",
      "Epoch 38 num_samples 5300 loss 0.028607193465131714\n",
      "Epoch 38 num_samples 5400 loss 0.037427106813220395\n",
      "Epoch 38 num_samples 5500 loss 0.02159791773618066\n",
      "Epoch 38 num_samples 5600 loss 0.10245023533770375\n",
      "Epoch 38 num_samples 5700 loss 0.04862926799907196\n",
      "Epoch 38 num_samples 5800 loss 0.034713058016355304\n",
      "Epoch 38 num_samples 5900 loss 0.040913832322246095\n",
      "Epoch 38 num_samples 6000 loss 0.03534178847905275\n",
      "Epoch 38 num_samples 6100 loss 0.028772467587785833\n",
      "Epoch 38 num_samples 6200 loss 0.03577190435869869\n",
      "Epoch 38 num_samples 6300 loss 0.050659702771590445\n",
      "Epoch 38 num_samples 6400 loss 0.02676755445096294\n",
      "Epoch 38 num_samples 6500 loss 0.02403530524928048\n",
      "Epoch 38 num_samples 6600 loss 0.0475537714784061\n",
      "Epoch 38 num_samples 6700 loss 0.022931304101365662\n",
      "Epoch 38 num_samples 6800 loss 0.016729264619652157\n",
      "Epoch 38 num_samples 6900 loss 0.06441809851093125\n",
      "Epoch 38 num_samples 7000 loss 0.0456820479483904\n",
      "Epoch 38 num_samples 7100 loss 0.02319181453068588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 num_samples 7200 loss 0.028669691716940067\n",
      "Epoch 38 num_samples 7300 loss 0.02699948822353484\n",
      "Epoch 38 num_samples 7400 loss 0.023297106619853705\n",
      "Epoch 38 num_samples 7500 loss 0.05596364613641013\n",
      "Epoch 38 num_samples 7600 loss 0.03180061601061059\n",
      "Epoch 38 num_samples 7700 loss 0.05716336495519881\n",
      "Epoch 38 num_samples 7800 loss 0.023356243416779138\n",
      "Epoch 38 num_samples 7900 loss 0.031367648167905215\n",
      "Epoch 38 num_samples 8000 loss 0.022087119257891245\n",
      "Epoch 38 num_samples 8100 loss 0.028709629340568876\n",
      "Epoch 38 num_samples 8200 loss 0.03296832959137315\n",
      "Epoch 38 num_samples 8300 loss 0.03461885926331548\n",
      "Epoch 38 num_samples 8400 loss 0.02461209882186073\n",
      "Epoch 38 num_samples 8500 loss 0.033661010598380205\n",
      "Epoch 38 num_samples 8600 loss 0.0313620299294189\n",
      "Epoch 38 num_samples 8700 loss 0.03330350291996348\n",
      "Epoch 38 num_samples 8800 loss 0.0466678577755415\n",
      "Epoch 38 num_samples 8900 loss 0.03732447227980091\n",
      "Epoch 38 num_samples 9000 loss 0.029397525560394176\n",
      "Epoch 38 num_samples 9100 loss 0.03266012913777788\n",
      "Epoch 38 num_samples 9200 loss 0.02988942844171377\n",
      "Epoch 38 num_samples 9300 loss 0.03170930066950797\n",
      "Epoch 38 num_samples 9400 loss 0.02581225324349158\n",
      "Epoch 38 num_samples 9500 loss 0.03084276122876241\n",
      "Epoch 38 num_samples 9600 loss 0.026058669037747246\n",
      "Epoch 38 num_samples 9700 loss 0.04691762052701577\n",
      "Epoch 38 num_samples 9800 loss 0.01842368721731872\n",
      "Epoch 38 num_samples 9900 loss 0.06337301494523138\n",
      "Epoch 38 num_samples 10000 loss 0.030670800244908383\n",
      "Epoch 38 num_samples 10100 loss 0.02404720333620314\n",
      "Epoch 38 num_samples 10200 loss 0.04211310572751758\n",
      "Epoch 38 num_samples 10300 loss 0.03123081647950554\n",
      "Epoch 38 num_samples 10400 loss 0.04395882073856359\n",
      "Epoch 38 num_samples 10500 loss 0.02559183009501038\n",
      "Epoch 38 num_samples 10600 loss 0.04941018376256252\n",
      "Epoch 38 num_samples 10700 loss 0.026992174939716184\n",
      "Epoch 38 num_samples 10800 loss 0.04700645366023173\n",
      "Epoch 38 num_samples 10900 loss 0.025818440270221333\n",
      "Epoch 38 num_samples 11000 loss 0.022037819849696508\n",
      "Epoch 38 num_samples 11100 loss 0.0310686978753988\n",
      "Epoch 38 num_samples 11200 loss 0.026336115611949425\n",
      "Epoch 38 num_samples 11300 loss 0.05225200686028909\n",
      "Epoch 38 num_samples 11400 loss 0.037252744532747906\n",
      "Epoch 38 num_samples 11500 loss 0.030166339389692643\n",
      "Epoch 38 num_samples 11600 loss 0.027401733932830793\n",
      "Epoch 38 num_samples 11700 loss 0.04147356523839857\n",
      "Epoch 38 num_samples 11800 loss 0.027921083532463763\n",
      "Epoch 38 num_samples 11900 loss 0.026508433590609882\n",
      "Epoch 38 num_samples 12000 loss 0.020878229221046905\n",
      "Epoch 38 num_samples 12100 loss 0.03186776830087073\n",
      "Epoch 38 num_samples 12200 loss 0.04216447854716525\n",
      "Epoch 38 num_samples 12300 loss 0.020531788341849887\n",
      "Epoch 38 num_samples 12400 loss 0.04279120589814296\n",
      "Epoch 38 num_samples 12500 loss 0.034112382256238555\n",
      "Epoch 38 num_samples 12600 loss 0.04267134647652072\n",
      "Epoch 38 num_samples 12700 loss 0.03498360898635856\n",
      "Epoch 38 num_samples 12800 loss 0.05868008839856258\n",
      "Epoch 38 num_samples 12900 loss 0.028638994476354488\n",
      "Epoch 38 num_samples 13000 loss 0.02403494585201763\n",
      "Epoch 38 num_samples 13100 loss 0.06611137825175667\n",
      "Epoch 38 num_samples 13200 loss 0.02218873582641507\n",
      "Epoch 38 num_samples 13300 loss 0.02366293493764805\n",
      "Epoch 38 num_samples 13400 loss 0.014094988369770124\n",
      "Epoch 38 num_samples 13500 loss 0.024330521663213842\n",
      "Epoch 38 num_samples 13600 loss 0.04609487245250555\n",
      "Epoch 38 num_samples 13700 loss 0.030200575858439303\n",
      "Epoch 38 num_samples 13800 loss 0.030129092439054168\n",
      "Epoch 38 num_samples 13900 loss 0.012398136971488845\n",
      "Epoch 38 num_samples 14000 loss 0.022852968950680383\n",
      "Epoch 38 num_samples 14100 loss 0.029756766239036985\n",
      "Epoch 38 num_samples 14200 loss 0.022447595060845232\n",
      "Epoch 38 num_samples 14300 loss 0.03431442990742657\n",
      "Epoch 38 num_samples 14400 loss 0.03259001479505415\n",
      "Epoch 38 num_samples 14500 loss 0.0361580757890816\n",
      "Epoch 38 num_samples 14600 loss 0.028890956397709465\n",
      "Epoch 38 num_samples 14700 loss 0.03134051978403029\n",
      "Epoch 38 num_samples 14800 loss 0.026418937530345875\n",
      "Epoch 38 num_samples 14900 loss 0.03962763377301063\n",
      "Epoch 38 num_samples 15000 loss 0.02599585130088016\n",
      "Epoch 38 num_samples 15100 loss 0.03093348969633956\n",
      "Epoch 38 num_samples 15200 loss 0.039607593901434986\n",
      "Epoch 38 num_samples 15300 loss 0.03163741274971813\n",
      "Epoch 38 num_samples 15400 loss 0.020118383266205707\n",
      "Epoch 38 num_samples 15500 loss 0.03922900344406614\n",
      "Epoch 38 num_samples 15600 loss 0.03179294224912345\n",
      "Epoch 38 num_samples 15700 loss 0.02036265125608918\n",
      "Epoch 38 num_samples 15800 loss 0.04570140477375737\n",
      "Epoch 38 num_samples 15900 loss 0.020276970132345015\n",
      "Epoch 38 num_samples 16000 loss 0.041274881427934854\n",
      "Epoch 38 num_samples 16100 loss 0.02240462385455054\n",
      "Epoch 38 num_samples 16200 loss 0.03487148461048973\n",
      "Epoch 38 num_samples 16300 loss 0.04784018578147526\n",
      "Epoch 38 num_samples 16400 loss 0.04207294771091446\n",
      "Epoch 38 num_samples 16500 loss 0.03440239444934774\n",
      "Epoch 38 num_samples 16600 loss 0.04053166731376969\n",
      "Epoch 38 num_samples 16700 loss 0.020263420968065944\n",
      "Epoch 38 num_samples 16800 loss 0.022636089665122122\n",
      "Epoch 38 num_samples 16900 loss 0.02564863546091546\n",
      "Epoch 38 num_samples 17000 loss 0.019129017761896443\n",
      "Epoch 38 num_samples 17100 loss 0.07012462735424424\n",
      "Epoch 38 num_samples 17200 loss 0.03468053295245685\n",
      "Epoch 38 num_samples 17300 loss 0.04119806753904876\n",
      "Epoch 38 num_samples 17400 loss 0.0315266472624307\n",
      "Epoch 38 num_samples 17500 loss 0.029196519605137198\n",
      "Epoch 38 num_samples 17600 loss 0.03135552477734497\n",
      "Epoch 38 num_samples 17700 loss 0.023562222885200202\n",
      "Epoch 38 num_samples 17800 loss 0.029799759406190392\n",
      "Epoch 38 num_samples 17900 loss 0.04445960691636901\n",
      "Epoch 38 num_samples 18000 loss 0.02635732216822065\n",
      "Epoch 38 num_samples 18100 loss 0.031647982469958945\n",
      "Epoch 38 num_samples 18200 loss 0.03447810930845303\n",
      "Epoch 38 num_samples 18300 loss 0.026056484869185884\n",
      "Epoch 38 num_samples 18400 loss 0.05143801781114861\n",
      "Epoch 38 num_samples 18500 loss 0.033904639821602287\n",
      "Epoch 39 num_samples 0 loss 0.02385753164057477\n",
      "Epoch 39 num_samples 100 loss 0.04348033519324006\n",
      "Epoch 39 num_samples 200 loss 0.025659956647650903\n",
      "Epoch 39 num_samples 300 loss 0.02358240758413592\n",
      "Epoch 39 num_samples 400 loss 0.026505290718377466\n",
      "Epoch 39 num_samples 500 loss 0.03662935764146291\n",
      "Epoch 39 num_samples 600 loss 0.044780268797324004\n",
      "Epoch 39 num_samples 700 loss 0.04463468197133943\n",
      "Epoch 39 num_samples 800 loss 0.029844708166022728\n",
      "Epoch 39 num_samples 900 loss 0.04244504880141777\n",
      "Epoch 39 num_samples 1000 loss 0.027915001635388945\n",
      "Epoch 39 num_samples 1100 loss 0.050245269847275065\n",
      "Epoch 39 num_samples 1200 loss 0.028767947165268613\n",
      "Epoch 39 num_samples 1300 loss 0.03085062821047434\n",
      "Epoch 39 num_samples 1400 loss 0.03796606315770277\n",
      "Epoch 39 num_samples 1500 loss 0.0627764167666954\n",
      "Epoch 39 num_samples 1600 loss 0.028231217740318025\n",
      "Epoch 39 num_samples 1700 loss 0.027038707722073327\n",
      "Epoch 39 num_samples 1800 loss 0.027102735808666702\n",
      "Epoch 39 num_samples 1900 loss 0.030544326291324735\n",
      "Epoch 39 num_samples 2000 loss 0.03766834428596638\n",
      "Epoch 39 num_samples 2100 loss 0.020476786027695173\n",
      "Epoch 39 num_samples 2200 loss 0.022619581984687814\n",
      "Epoch 39 num_samples 2300 loss 0.01548158466316349\n",
      "Epoch 39 num_samples 2400 loss 0.02711636408856149\n",
      "Epoch 39 num_samples 2500 loss 0.03816198757530547\n",
      "Epoch 39 num_samples 2600 loss 0.04018779392650432\n",
      "Epoch 39 num_samples 2700 loss 0.027979227404504328\n",
      "Epoch 39 num_samples 2800 loss 0.04121995954863318\n",
      "Epoch 39 num_samples 2900 loss 0.036240512623326636\n",
      "Epoch 39 num_samples 3000 loss 0.02997384825068374\n",
      "Epoch 39 num_samples 3100 loss 0.02980334157564455\n",
      "Epoch 39 num_samples 3200 loss 0.08548105833152533\n",
      "Epoch 39 num_samples 3300 loss 0.03674410047379744\n",
      "Epoch 39 num_samples 3400 loss 0.024051748139347105\n",
      "Epoch 39 num_samples 3500 loss 0.025015502923459013\n",
      "Epoch 39 num_samples 3600 loss 0.016770440078961068\n",
      "Epoch 39 num_samples 3700 loss 0.048820419012409265\n",
      "Epoch 39 num_samples 3800 loss 0.030000209643083604\n",
      "Epoch 39 num_samples 3900 loss 0.033854788416342395\n",
      "Epoch 39 num_samples 4000 loss 0.03829363429946557\n",
      "Epoch 39 num_samples 4100 loss 0.05766315839548973\n",
      "Epoch 39 num_samples 4200 loss 0.029609926604136295\n",
      "Epoch 39 num_samples 4300 loss 0.03236152827139652\n",
      "Epoch 39 num_samples 4400 loss 0.03874854955265829\n",
      "Epoch 39 num_samples 4500 loss 0.042756795829856066\n",
      "Epoch 39 num_samples 4600 loss 0.03259319038715814\n",
      "Epoch 39 num_samples 4700 loss 0.019663401676470748\n",
      "Epoch 39 num_samples 4800 loss 0.019391549318392952\n",
      "Epoch 39 num_samples 4900 loss 0.022897723244748754\n",
      "Epoch 39 num_samples 5000 loss 0.023245422055853327\n",
      "Epoch 39 num_samples 5100 loss 0.03963238421700278\n",
      "Epoch 39 num_samples 5200 loss 0.019703783602969673\n",
      "Epoch 39 num_samples 5300 loss 0.02748807253620612\n",
      "Epoch 39 num_samples 5400 loss 0.03572929980745592\n",
      "Epoch 39 num_samples 5500 loss 0.020489646243691907\n",
      "Epoch 39 num_samples 5600 loss 0.09848105110585209\n",
      "Epoch 39 num_samples 5700 loss 0.045050570846135084\n",
      "Epoch 39 num_samples 5800 loss 0.032798473613524066\n",
      "Epoch 39 num_samples 5900 loss 0.03860414817518243\n",
      "Epoch 39 num_samples 6000 loss 0.03312665882868676\n",
      "Epoch 39 num_samples 6100 loss 0.027230531391612404\n",
      "Epoch 39 num_samples 6200 loss 0.03347482539643042\n",
      "Epoch 39 num_samples 6300 loss 0.04720329576632104\n",
      "Epoch 39 num_samples 6400 loss 0.025421991769843225\n",
      "Epoch 39 num_samples 6500 loss 0.022784732462327217\n",
      "Epoch 39 num_samples 6600 loss 0.04524332808100996\n",
      "Epoch 39 num_samples 6700 loss 0.02206549385894154\n",
      "Epoch 39 num_samples 6800 loss 0.015783456614495737\n",
      "Epoch 39 num_samples 6900 loss 0.06151087789847432\n",
      "Epoch 39 num_samples 7000 loss 0.04297854245220079\n",
      "Epoch 39 num_samples 7100 loss 0.02165352370807997\n",
      "Epoch 39 num_samples 7200 loss 0.027468944220636716\n",
      "Epoch 39 num_samples 7300 loss 0.025626536129118183\n",
      "Epoch 39 num_samples 7400 loss 0.022047654379436746\n",
      "Epoch 39 num_samples 7500 loss 0.05283735426975214\n",
      "Epoch 39 num_samples 7600 loss 0.03040830259753537\n",
      "Epoch 39 num_samples 7700 loss 0.053762907319827795\n",
      "Epoch 39 num_samples 7800 loss 0.02232259183491809\n",
      "Epoch 39 num_samples 7900 loss 0.029719209686955798\n",
      "Epoch 39 num_samples 8000 loss 0.021218621975926034\n",
      "Epoch 39 num_samples 8100 loss 0.027200704227493558\n",
      "Epoch 39 num_samples 8200 loss 0.03107836150328023\n",
      "Epoch 39 num_samples 8300 loss 0.03279654095223096\n",
      "Epoch 39 num_samples 8400 loss 0.02308025666603227\n",
      "Epoch 39 num_samples 8500 loss 0.0317271648205522\n",
      "Epoch 39 num_samples 8600 loss 0.029699668831152968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 num_samples 8700 loss 0.03146115949281916\n",
      "Epoch 39 num_samples 8800 loss 0.043391994460227575\n",
      "Epoch 39 num_samples 8900 loss 0.03556699603060642\n",
      "Epoch 39 num_samples 9000 loss 0.027731598099819586\n",
      "Epoch 39 num_samples 9100 loss 0.0308517043015857\n",
      "Epoch 39 num_samples 9200 loss 0.028617995476991735\n",
      "Epoch 39 num_samples 9300 loss 0.029913328326958536\n",
      "Epoch 39 num_samples 9400 loss 0.024639054831319472\n",
      "Epoch 39 num_samples 9500 loss 0.029512133902019577\n",
      "Epoch 39 num_samples 9600 loss 0.024766441819358952\n",
      "Epoch 39 num_samples 9700 loss 0.04482676631255507\n",
      "Epoch 39 num_samples 9800 loss 0.017736414551364245\n",
      "Epoch 39 num_samples 9900 loss 0.06037179902158586\n",
      "Epoch 39 num_samples 10000 loss 0.029362352048676862\n",
      "Epoch 39 num_samples 10100 loss 0.023250197194489994\n",
      "Epoch 39 num_samples 10200 loss 0.03925540732531164\n",
      "Epoch 39 num_samples 10300 loss 0.02948209853793861\n",
      "Epoch 39 num_samples 10400 loss 0.04181433340719067\n",
      "Epoch 39 num_samples 10500 loss 0.02428383857213685\n",
      "Epoch 39 num_samples 10600 loss 0.046557500860265194\n",
      "Epoch 39 num_samples 10700 loss 0.02580057944632969\n",
      "Epoch 39 num_samples 10800 loss 0.04359941010727473\n",
      "Epoch 39 num_samples 10900 loss 0.024558604796882683\n",
      "Epoch 39 num_samples 11000 loss 0.02105062064061762\n",
      "Epoch 39 num_samples 11100 loss 0.029441022596660687\n",
      "Epoch 39 num_samples 11200 loss 0.024865750744424542\n",
      "Epoch 39 num_samples 11300 loss 0.048947506953873926\n",
      "Epoch 39 num_samples 11400 loss 0.034399635548433595\n",
      "Epoch 39 num_samples 11500 loss 0.0288568724660019\n",
      "Epoch 39 num_samples 11600 loss 0.02594027005498781\n",
      "Epoch 39 num_samples 11700 loss 0.039789440115982184\n",
      "Epoch 39 num_samples 11800 loss 0.026586719357132287\n",
      "Epoch 39 num_samples 11900 loss 0.025002399309335593\n",
      "Epoch 39 num_samples 12000 loss 0.019813140210840956\n",
      "Epoch 39 num_samples 12100 loss 0.029640371802825038\n",
      "Epoch 39 num_samples 12200 loss 0.03959691866119242\n",
      "Epoch 39 num_samples 12300 loss 0.019388378447828546\n",
      "Epoch 39 num_samples 12400 loss 0.0402537308432042\n",
      "Epoch 39 num_samples 12500 loss 0.03247817118684157\n",
      "Epoch 39 num_samples 12600 loss 0.0409624910041687\n",
      "Epoch 39 num_samples 12700 loss 0.03307298393986891\n",
      "Epoch 39 num_samples 12800 loss 0.056112030205485566\n",
      "Epoch 39 num_samples 12900 loss 0.026870599579410116\n",
      "Epoch 39 num_samples 13000 loss 0.022698270345809866\n",
      "Epoch 39 num_samples 13100 loss 0.06154644338883161\n",
      "Epoch 39 num_samples 13200 loss 0.02072997701019482\n",
      "Epoch 39 num_samples 13300 loss 0.022201930835249746\n",
      "Epoch 39 num_samples 13400 loss 0.013319533740832947\n",
      "Epoch 39 num_samples 13500 loss 0.02324778708947539\n",
      "Epoch 39 num_samples 13600 loss 0.04377546632457338\n",
      "Epoch 39 num_samples 13700 loss 0.028985115766837075\n",
      "Epoch 39 num_samples 13800 loss 0.028593833242749965\n",
      "Epoch 39 num_samples 13900 loss 0.01177188061796819\n",
      "Epoch 39 num_samples 14000 loss 0.02159459845847989\n",
      "Epoch 39 num_samples 14100 loss 0.028235837689449993\n",
      "Epoch 39 num_samples 14200 loss 0.02119058993009192\n",
      "Epoch 39 num_samples 14300 loss 0.032073054484081195\n",
      "Epoch 39 num_samples 14400 loss 0.031181336616677487\n",
      "Epoch 39 num_samples 14500 loss 0.03485396781351341\n",
      "Epoch 39 num_samples 14600 loss 0.02734502753926256\n",
      "Epoch 39 num_samples 14700 loss 0.029682824989075533\n",
      "Epoch 39 num_samples 14800 loss 0.025216079322268544\n",
      "Epoch 39 num_samples 14900 loss 0.03759132782247888\n",
      "Epoch 39 num_samples 15000 loss 0.024609482345594454\n",
      "Epoch 39 num_samples 15100 loss 0.029412332829416517\n",
      "Epoch 39 num_samples 15200 loss 0.0372013112821151\n",
      "Epoch 39 num_samples 15300 loss 0.03022148782284842\n",
      "Epoch 39 num_samples 15400 loss 0.0190848972240158\n",
      "Epoch 39 num_samples 15500 loss 0.03686894572488795\n",
      "Epoch 39 num_samples 15600 loss 0.030117239960398157\n",
      "Epoch 39 num_samples 15700 loss 0.01960635880871822\n",
      "Epoch 39 num_samples 15800 loss 0.04297243529159089\n",
      "Epoch 39 num_samples 15900 loss 0.01940977100407021\n",
      "Epoch 39 num_samples 16000 loss 0.039017956619233116\n",
      "Epoch 39 num_samples 16100 loss 0.021410004285332396\n",
      "Epoch 39 num_samples 16200 loss 0.032963515195576415\n",
      "Epoch 39 num_samples 16300 loss 0.0453528028752268\n",
      "Epoch 39 num_samples 16400 loss 0.039994585313262804\n",
      "Epoch 39 num_samples 16500 loss 0.033164490039929426\n",
      "Epoch 39 num_samples 16600 loss 0.03841717014782747\n",
      "Epoch 39 num_samples 16700 loss 0.019417884544105934\n",
      "Epoch 39 num_samples 16800 loss 0.021295009728845092\n",
      "Epoch 39 num_samples 16900 loss 0.0243034944712249\n",
      "Epoch 39 num_samples 17000 loss 0.018213343089584607\n",
      "Epoch 39 num_samples 17100 loss 0.06528485171992349\n",
      "Epoch 39 num_samples 17200 loss 0.03309423478654248\n",
      "Epoch 39 num_samples 17300 loss 0.03895632231585458\n",
      "Epoch 39 num_samples 17400 loss 0.03017759227995871\n",
      "Epoch 39 num_samples 17500 loss 0.02780020223764536\n",
      "Epoch 39 num_samples 17600 loss 0.02952544672418379\n",
      "Epoch 39 num_samples 17700 loss 0.02247233171589153\n",
      "Epoch 39 num_samples 17800 loss 0.027786152071191995\n",
      "Epoch 39 num_samples 17900 loss 0.04247511579812988\n",
      "Epoch 39 num_samples 18000 loss 0.025053680251961995\n",
      "Epoch 39 num_samples 18100 loss 0.030024544884555353\n",
      "Epoch 39 num_samples 18200 loss 0.032318787525916014\n",
      "Epoch 39 num_samples 18300 loss 0.02446098126558356\n",
      "Epoch 39 num_samples 18400 loss 0.048764990174392675\n",
      "Epoch 39 num_samples 18500 loss 0.03225064242958512\n",
      "Epoch 40 num_samples 0 loss 0.022791912076244657\n",
      "Epoch 40 num_samples 100 loss 0.04140601978992901\n",
      "Epoch 40 num_samples 200 loss 0.024530759698274184\n",
      "Epoch 40 num_samples 300 loss 0.02215737143893854\n",
      "Epoch 40 num_samples 400 loss 0.025189080183223442\n",
      "Epoch 40 num_samples 500 loss 0.03527520983333958\n",
      "Epoch 40 num_samples 600 loss 0.04279101823943672\n",
      "Epoch 40 num_samples 700 loss 0.04223461206081556\n",
      "Epoch 40 num_samples 800 loss 0.028053552097380904\n",
      "Epoch 40 num_samples 900 loss 0.040819357944788456\n",
      "Epoch 40 num_samples 1000 loss 0.02665970094789134\n",
      "Epoch 40 num_samples 1100 loss 0.047517433545028714\n",
      "Epoch 40 num_samples 1200 loss 0.027099778054585903\n",
      "Epoch 40 num_samples 1300 loss 0.02955841148262236\n",
      "Epoch 40 num_samples 1400 loss 0.03534547030722004\n",
      "Epoch 40 num_samples 1500 loss 0.058241364338452256\n",
      "Epoch 40 num_samples 1600 loss 0.026960801275308473\n",
      "Epoch 40 num_samples 1700 loss 0.025709185554135674\n",
      "Epoch 40 num_samples 1800 loss 0.025719279482102415\n",
      "Epoch 40 num_samples 1900 loss 0.029435478957164047\n",
      "Epoch 40 num_samples 2000 loss 0.036221010923839794\n",
      "Epoch 40 num_samples 2100 loss 0.019517893434396204\n",
      "Epoch 40 num_samples 2200 loss 0.021464747764072544\n",
      "Epoch 40 num_samples 2300 loss 0.014515954032006916\n",
      "Epoch 40 num_samples 2400 loss 0.025795746847779605\n",
      "Epoch 40 num_samples 2500 loss 0.03595246494843079\n",
      "Epoch 40 num_samples 2600 loss 0.038307169167791366\n",
      "Epoch 40 num_samples 2700 loss 0.02637758832496565\n",
      "Epoch 40 num_samples 2800 loss 0.038976040256522265\n",
      "Epoch 40 num_samples 2900 loss 0.03432434308566156\n",
      "Epoch 40 num_samples 3000 loss 0.02894562425443029\n",
      "Epoch 40 num_samples 3100 loss 0.028364765157088082\n",
      "Epoch 40 num_samples 3200 loss 0.08008166638411959\n",
      "Epoch 40 num_samples 3300 loss 0.034283562401550984\n",
      "Epoch 40 num_samples 3400 loss 0.022946195806668394\n",
      "Epoch 40 num_samples 3500 loss 0.02385851851289132\n",
      "Epoch 40 num_samples 3600 loss 0.015966055435724984\n",
      "Epoch 40 num_samples 3700 loss 0.04618276098558348\n",
      "Epoch 40 num_samples 3800 loss 0.028240581579047488\n",
      "Epoch 40 num_samples 3900 loss 0.03238201894847952\n",
      "Epoch 40 num_samples 4000 loss 0.03604949370435073\n",
      "Epoch 40 num_samples 4100 loss 0.054337048664622606\n",
      "Epoch 40 num_samples 4200 loss 0.028504462945488182\n",
      "Epoch 40 num_samples 4300 loss 0.030929599295233805\n",
      "Epoch 40 num_samples 4400 loss 0.0364331076780174\n",
      "Epoch 40 num_samples 4500 loss 0.04090081676645166\n",
      "Epoch 40 num_samples 4600 loss 0.031209860763038375\n",
      "Epoch 40 num_samples 4700 loss 0.018823330752172934\n",
      "Epoch 40 num_samples 4800 loss 0.01839759192948212\n",
      "Epoch 40 num_samples 4900 loss 0.022106655308101884\n",
      "Epoch 40 num_samples 5000 loss 0.02209389301994892\n",
      "Epoch 40 num_samples 5100 loss 0.03798432385101549\n",
      "Epoch 40 num_samples 5200 loss 0.01911609505281061\n",
      "Epoch 40 num_samples 5300 loss 0.02597247803727679\n",
      "Epoch 40 num_samples 5400 loss 0.03347678371575064\n",
      "Epoch 40 num_samples 5500 loss 0.019540096904766137\n",
      "Epoch 40 num_samples 5600 loss 0.09385734181735826\n",
      "Epoch 40 num_samples 5700 loss 0.04099608315688782\n",
      "Epoch 40 num_samples 5800 loss 0.031106362554256046\n",
      "Epoch 40 num_samples 5900 loss 0.0364525974587232\n",
      "Epoch 40 num_samples 6000 loss 0.03089207911249281\n",
      "Epoch 40 num_samples 6100 loss 0.025847572006619343\n",
      "Epoch 40 num_samples 6200 loss 0.03172194454901956\n",
      "Epoch 40 num_samples 6300 loss 0.04471055200444878\n",
      "Epoch 40 num_samples 6400 loss 0.02407397189328807\n",
      "Epoch 40 num_samples 6500 loss 0.021780578728802204\n",
      "Epoch 40 num_samples 6600 loss 0.04323982704502491\n",
      "Epoch 40 num_samples 6700 loss 0.02117136416068699\n",
      "Epoch 40 num_samples 6800 loss 0.015226081131368726\n",
      "Epoch 40 num_samples 6900 loss 0.058572253191969036\n",
      "Epoch 40 num_samples 7000 loss 0.04010649494510346\n",
      "Epoch 40 num_samples 7100 loss 0.020505312704209938\n",
      "Epoch 40 num_samples 7200 loss 0.026247386355821033\n",
      "Epoch 40 num_samples 7300 loss 0.024610887776351332\n",
      "Epoch 40 num_samples 7400 loss 0.02101089552160212\n",
      "Epoch 40 num_samples 7500 loss 0.05033637742650436\n",
      "Epoch 40 num_samples 7600 loss 0.028740125366215254\n",
      "Epoch 40 num_samples 7700 loss 0.05097481151443086\n",
      "Epoch 40 num_samples 7800 loss 0.02138994912221615\n",
      "Epoch 40 num_samples 7900 loss 0.028132669768246167\n",
      "Epoch 40 num_samples 8000 loss 0.02008819075196408\n",
      "Epoch 40 num_samples 8100 loss 0.025890013430398442\n",
      "Epoch 40 num_samples 8200 loss 0.029763353549356796\n",
      "Epoch 40 num_samples 8300 loss 0.03026638782147735\n",
      "Epoch 40 num_samples 8400 loss 0.02186143330311863\n",
      "Epoch 40 num_samples 8500 loss 0.03014814593364276\n",
      "Epoch 40 num_samples 8600 loss 0.028608882596511617\n",
      "Epoch 40 num_samples 8700 loss 0.02993371107907574\n",
      "Epoch 40 num_samples 8800 loss 0.0401340126028046\n",
      "Epoch 40 num_samples 8900 loss 0.03387600051868076\n",
      "Epoch 40 num_samples 9000 loss 0.026252415296222624\n",
      "Epoch 40 num_samples 9100 loss 0.029322246338032862\n",
      "Epoch 40 num_samples 9200 loss 0.02707180310321779\n",
      "Epoch 40 num_samples 9300 loss 0.028533566458019913\n",
      "Epoch 40 num_samples 9400 loss 0.02349494910305488\n",
      "Epoch 40 num_samples 9500 loss 0.027312532044596986\n",
      "Epoch 40 num_samples 9600 loss 0.023834284539535552\n",
      "Epoch 40 num_samples 9700 loss 0.0429167194894115\n",
      "Epoch 40 num_samples 9800 loss 0.016959984870480435\n",
      "Epoch 40 num_samples 9900 loss 0.057610000395416694\n",
      "Epoch 40 num_samples 10000 loss 0.027377802603787936\n",
      "Epoch 40 num_samples 10100 loss 0.022173562264797737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 num_samples 10200 loss 0.03716053702790556\n",
      "Epoch 40 num_samples 10300 loss 0.02813561417228529\n",
      "Epoch 40 num_samples 10400 loss 0.03930777222792348\n",
      "Epoch 40 num_samples 10500 loss 0.02317934451421369\n",
      "Epoch 40 num_samples 10600 loss 0.04367260640133685\n",
      "Epoch 40 num_samples 10700 loss 0.024483936393527302\n",
      "Epoch 40 num_samples 10800 loss 0.04033119838172656\n",
      "Epoch 40 num_samples 10900 loss 0.023256156279508965\n",
      "Epoch 40 num_samples 11000 loss 0.02021557228004064\n",
      "Epoch 40 num_samples 11100 loss 0.02771256861181053\n",
      "Epoch 40 num_samples 11200 loss 0.023655999470412522\n",
      "Epoch 40 num_samples 11300 loss 0.04583014733862636\n",
      "Epoch 40 num_samples 11400 loss 0.031918322587780025\n",
      "Epoch 40 num_samples 11500 loss 0.027516477152711202\n",
      "Epoch 40 num_samples 11600 loss 0.024744340046839005\n",
      "Epoch 40 num_samples 11700 loss 0.03791568395645945\n",
      "Epoch 40 num_samples 11800 loss 0.02540353991192526\n",
      "Epoch 40 num_samples 11900 loss 0.023492181887974004\n",
      "Epoch 40 num_samples 12000 loss 0.018884363944929976\n",
      "Epoch 40 num_samples 12100 loss 0.02753067712189448\n",
      "Epoch 40 num_samples 12200 loss 0.03750429764576128\n",
      "Epoch 40 num_samples 12300 loss 0.01851455835272903\n",
      "Epoch 40 num_samples 12400 loss 0.038019182797960946\n",
      "Epoch 40 num_samples 12500 loss 0.03101377031829312\n",
      "Epoch 40 num_samples 12600 loss 0.03858798838393033\n",
      "Epoch 40 num_samples 12700 loss 0.03130804923249539\n",
      "Epoch 40 num_samples 12800 loss 0.05344961188367345\n",
      "Epoch 40 num_samples 12900 loss 0.025599113813503962\n",
      "Epoch 40 num_samples 13000 loss 0.021615006565341332\n",
      "Epoch 40 num_samples 13100 loss 0.057921226892324214\n",
      "Epoch 40 num_samples 13200 loss 0.01952117007852105\n",
      "Epoch 40 num_samples 13300 loss 0.021336620516320123\n",
      "Epoch 40 num_samples 13400 loss 0.012810413175601236\n",
      "Epoch 40 num_samples 13500 loss 0.022130744392583526\n",
      "Epoch 40 num_samples 13600 loss 0.04147141549233778\n",
      "Epoch 40 num_samples 13700 loss 0.027426311721267888\n",
      "Epoch 40 num_samples 13800 loss 0.02690799444990531\n",
      "Epoch 40 num_samples 13900 loss 0.011168935720930544\n",
      "Epoch 40 num_samples 14000 loss 0.02037675114133167\n",
      "Epoch 40 num_samples 14100 loss 0.026584233725063782\n",
      "Epoch 40 num_samples 14200 loss 0.020259454609019255\n",
      "Epoch 40 num_samples 14300 loss 0.030646639760299486\n",
      "Epoch 40 num_samples 14400 loss 0.029735874945581456\n",
      "Epoch 40 num_samples 14500 loss 0.03324212392181419\n",
      "Epoch 40 num_samples 14600 loss 0.026054824153763246\n",
      "Epoch 40 num_samples 14700 loss 0.02806287044925038\n",
      "Epoch 40 num_samples 14800 loss 0.024247463927289156\n",
      "Epoch 40 num_samples 14900 loss 0.03558470940597758\n",
      "Epoch 40 num_samples 15000 loss 0.023521164894670585\n",
      "Epoch 40 num_samples 15100 loss 0.028079903799121782\n",
      "Epoch 40 num_samples 15200 loss 0.03468234630406599\n",
      "Epoch 40 num_samples 15300 loss 0.028943270387037017\n",
      "Epoch 40 num_samples 15400 loss 0.01823606901569405\n",
      "Epoch 40 num_samples 15500 loss 0.03485553969247858\n",
      "Epoch 40 num_samples 15600 loss 0.028884578506509093\n",
      "Epoch 40 num_samples 15700 loss 0.018823479147081306\n",
      "Epoch 40 num_samples 15800 loss 0.040958383912989636\n",
      "Epoch 40 num_samples 15900 loss 0.01861279006139823\n",
      "Epoch 40 num_samples 16000 loss 0.03748773040613036\n",
      "Epoch 40 num_samples 16100 loss 0.020338015228064586\n",
      "Epoch 40 num_samples 16200 loss 0.03137316551220624\n",
      "Epoch 40 num_samples 16300 loss 0.0426693300319746\n",
      "Epoch 40 num_samples 16400 loss 0.037910073681396116\n",
      "Epoch 40 num_samples 16500 loss 0.031667725313372135\n",
      "Epoch 40 num_samples 16600 loss 0.03645924644528842\n",
      "Epoch 40 num_samples 16700 loss 0.01850859404144116\n",
      "Epoch 40 num_samples 16800 loss 0.0203104066503889\n",
      "Epoch 40 num_samples 16900 loss 0.023035150674478\n",
      "Epoch 40 num_samples 17000 loss 0.01725556914514342\n",
      "Epoch 40 num_samples 17100 loss 0.06091899457125754\n",
      "Epoch 40 num_samples 17200 loss 0.03165205748923823\n",
      "Epoch 40 num_samples 17300 loss 0.03683429762780257\n",
      "Epoch 40 num_samples 17400 loss 0.02824591111821106\n",
      "Epoch 40 num_samples 17500 loss 0.026643937678627452\n",
      "Epoch 40 num_samples 17600 loss 0.027965285075946523\n",
      "Epoch 40 num_samples 17700 loss 0.021347314549985973\n",
      "Epoch 40 num_samples 17800 loss 0.026194166194718402\n",
      "Epoch 40 num_samples 17900 loss 0.04027198543173193\n",
      "Epoch 40 num_samples 18000 loss 0.02401051821797241\n",
      "Epoch 40 num_samples 18100 loss 0.028521616646148343\n",
      "Epoch 40 num_samples 18200 loss 0.03091877388518893\n",
      "Epoch 40 num_samples 18300 loss 0.023706549237140474\n",
      "Epoch 40 num_samples 18400 loss 0.04633870868790812\n",
      "Epoch 40 num_samples 18500 loss 0.030636068342257787\n",
      "Epoch 41 num_samples 0 loss 0.021703002459056833\n",
      "Epoch 41 num_samples 100 loss 0.03974634217892307\n",
      "Epoch 41 num_samples 200 loss 0.023350697683588995\n",
      "Epoch 41 num_samples 300 loss 0.021174002729724462\n",
      "Epoch 41 num_samples 400 loss 0.024022752288124435\n",
      "Epoch 41 num_samples 500 loss 0.033435243321948534\n",
      "Epoch 41 num_samples 600 loss 0.04145775933394344\n",
      "Epoch 41 num_samples 700 loss 0.04048929315404223\n",
      "Epoch 41 num_samples 800 loss 0.02676207934518347\n",
      "Epoch 41 num_samples 900 loss 0.039338845457006714\n",
      "Epoch 41 num_samples 1000 loss 0.025296939631219307\n",
      "Epoch 41 num_samples 1100 loss 0.04517514019065466\n",
      "Epoch 41 num_samples 1200 loss 0.02581368505793337\n",
      "Epoch 41 num_samples 1300 loss 0.028133046755069984\n",
      "Epoch 41 num_samples 1400 loss 0.03365319869110006\n",
      "Epoch 41 num_samples 1500 loss 0.05411003781939422\n",
      "Epoch 41 num_samples 1600 loss 0.02571627231172897\n",
      "Epoch 41 num_samples 1700 loss 0.024578050136462432\n",
      "Epoch 41 num_samples 1800 loss 0.024607345198423846\n",
      "Epoch 41 num_samples 1900 loss 0.028223702852225287\n",
      "Epoch 41 num_samples 2000 loss 0.034228423698258285\n",
      "Epoch 41 num_samples 2100 loss 0.018656927251437614\n",
      "Epoch 41 num_samples 2200 loss 0.02056977455319555\n",
      "Epoch 41 num_samples 2300 loss 0.013731263789384109\n",
      "Epoch 41 num_samples 2400 loss 0.024547995134359693\n",
      "Epoch 41 num_samples 2500 loss 0.03408816161774987\n",
      "Epoch 41 num_samples 2600 loss 0.036219610206570135\n",
      "Epoch 41 num_samples 2700 loss 0.024955377001924996\n",
      "Epoch 41 num_samples 2800 loss 0.03703370105566332\n",
      "Epoch 41 num_samples 2900 loss 0.032574495010615226\n",
      "Epoch 41 num_samples 3000 loss 0.02775981982797436\n",
      "Epoch 41 num_samples 3100 loss 0.026752606423347126\n",
      "Epoch 41 num_samples 3200 loss 0.07559521233682581\n",
      "Epoch 41 num_samples 3300 loss 0.03242650556735746\n",
      "Epoch 41 num_samples 3400 loss 0.02186549614038147\n",
      "Epoch 41 num_samples 3500 loss 0.022580937929524206\n",
      "Epoch 41 num_samples 3600 loss 0.015156305022345105\n",
      "Epoch 41 num_samples 3700 loss 0.04411826743609093\n",
      "Epoch 41 num_samples 3800 loss 0.026878940581131293\n",
      "Epoch 41 num_samples 3900 loss 0.030792073292115026\n",
      "Epoch 41 num_samples 4000 loss 0.03414124657388504\n",
      "Epoch 41 num_samples 4100 loss 0.05128022650056042\n",
      "Epoch 41 num_samples 4200 loss 0.02697296553171507\n",
      "Epoch 41 num_samples 4300 loss 0.028893485555028242\n",
      "Epoch 41 num_samples 4400 loss 0.0349804594095984\n",
      "Epoch 41 num_samples 4500 loss 0.03865056825465278\n",
      "Epoch 41 num_samples 4600 loss 0.029656532337975775\n",
      "Epoch 41 num_samples 4700 loss 0.017957768887609048\n",
      "Epoch 41 num_samples 4800 loss 0.017453962453533665\n",
      "Epoch 41 num_samples 4900 loss 0.021242665350690543\n",
      "Epoch 41 num_samples 5000 loss 0.02119676245341762\n",
      "Epoch 41 num_samples 5100 loss 0.03609391746353838\n",
      "Epoch 41 num_samples 5200 loss 0.018091537891696312\n",
      "Epoch 41 num_samples 5300 loss 0.024928196201675704\n",
      "Epoch 41 num_samples 5400 loss 0.03208155645110063\n",
      "Epoch 41 num_samples 5500 loss 0.01869738687781514\n",
      "Epoch 41 num_samples 5600 loss 0.08982901673612843\n",
      "Epoch 41 num_samples 5700 loss 0.038166868032885576\n",
      "Epoch 41 num_samples 5800 loss 0.02923404664860568\n",
      "Epoch 41 num_samples 5900 loss 0.03445133922684717\n",
      "Epoch 41 num_samples 6000 loss 0.028985233521611416\n",
      "Epoch 41 num_samples 6100 loss 0.02452668396383918\n",
      "Epoch 41 num_samples 6200 loss 0.030236483546340488\n",
      "Epoch 41 num_samples 6300 loss 0.042568507127090205\n",
      "Epoch 41 num_samples 6400 loss 0.022783005266472377\n",
      "Epoch 41 num_samples 6500 loss 0.020639035760099088\n",
      "Epoch 41 num_samples 6600 loss 0.04108966697452706\n",
      "Epoch 41 num_samples 6700 loss 0.02048168355725569\n",
      "Epoch 41 num_samples 6800 loss 0.01445051660056809\n",
      "Epoch 41 num_samples 6900 loss 0.05579175681407486\n",
      "Epoch 41 num_samples 7000 loss 0.03801163829529003\n",
      "Epoch 41 num_samples 7100 loss 0.019711314225198496\n",
      "Epoch 41 num_samples 7200 loss 0.02535371832919278\n",
      "Epoch 41 num_samples 7300 loss 0.023490826104623833\n",
      "Epoch 41 num_samples 7400 loss 0.019886633958753938\n",
      "Epoch 41 num_samples 7500 loss 0.04815054582977002\n",
      "Epoch 41 num_samples 7600 loss 0.027627884850754517\n",
      "Epoch 41 num_samples 7700 loss 0.04795920595395162\n",
      "Epoch 41 num_samples 7800 loss 0.020720105679956687\n",
      "Epoch 41 num_samples 7900 loss 0.026697092505758312\n",
      "Epoch 41 num_samples 8000 loss 0.01921277290081425\n",
      "Epoch 41 num_samples 8100 loss 0.024939855381546278\n",
      "Epoch 41 num_samples 8200 loss 0.02831569304347342\n",
      "Epoch 41 num_samples 8300 loss 0.02843253772087566\n",
      "Epoch 41 num_samples 8400 loss 0.020633158063389306\n",
      "Epoch 41 num_samples 8500 loss 0.028530552995903707\n",
      "Epoch 41 num_samples 8600 loss 0.027097600019253435\n",
      "Epoch 41 num_samples 8700 loss 0.028157868920666504\n",
      "Epoch 41 num_samples 8800 loss 0.03765722434797539\n",
      "Epoch 41 num_samples 8900 loss 0.032347036751237714\n",
      "Epoch 41 num_samples 9000 loss 0.02495855794529276\n",
      "Epoch 41 num_samples 9100 loss 0.027572196607354257\n",
      "Epoch 41 num_samples 9200 loss 0.02610262356518302\n",
      "Epoch 41 num_samples 9300 loss 0.026772426292940108\n",
      "Epoch 41 num_samples 9400 loss 0.022613268795280816\n",
      "Epoch 41 num_samples 9500 loss 0.025791542637301264\n",
      "Epoch 41 num_samples 9600 loss 0.022527092584826925\n",
      "Epoch 41 num_samples 9700 loss 0.04141276557308513\n",
      "Epoch 41 num_samples 9800 loss 0.016140765294873457\n",
      "Epoch 41 num_samples 9900 loss 0.055030802851636966\n",
      "Epoch 41 num_samples 10000 loss 0.0260752789876973\n",
      "Epoch 41 num_samples 10100 loss 0.021210427178233324\n",
      "Epoch 41 num_samples 10200 loss 0.034981872119796156\n",
      "Epoch 41 num_samples 10300 loss 0.02668413928363073\n",
      "Epoch 41 num_samples 10400 loss 0.037332133610489066\n",
      "Epoch 41 num_samples 10500 loss 0.02218811922541073\n",
      "Epoch 41 num_samples 10600 loss 0.041144099668092696\n",
      "Epoch 41 num_samples 10700 loss 0.02373802928637765\n",
      "Epoch 41 num_samples 10800 loss 0.03725614633615911\n",
      "Epoch 41 num_samples 10900 loss 0.022122183711984444\n",
      "Epoch 41 num_samples 11000 loss 0.019329794476186248\n",
      "Epoch 41 num_samples 11100 loss 0.02648098958204586\n",
      "Epoch 41 num_samples 11200 loss 0.022435252906958997\n",
      "Epoch 41 num_samples 11300 loss 0.04270470899733384\n",
      "Epoch 41 num_samples 11400 loss 0.029651617642515563\n",
      "Epoch 41 num_samples 11500 loss 0.026038842622675383\n",
      "Epoch 41 num_samples 11600 loss 0.023571469901357292\n",
      "Epoch 41 num_samples 11700 loss 0.03632028517275845\n",
      "Epoch 41 num_samples 11800 loss 0.024215737247985283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 num_samples 11900 loss 0.022385818321266803\n",
      "Epoch 41 num_samples 12000 loss 0.01803382616198435\n",
      "Epoch 41 num_samples 12100 loss 0.025580529618877534\n",
      "Epoch 41 num_samples 12200 loss 0.03569224577223174\n",
      "Epoch 41 num_samples 12300 loss 0.017750900632031847\n",
      "Epoch 41 num_samples 12400 loss 0.036198069918471104\n",
      "Epoch 41 num_samples 12500 loss 0.029393269482679455\n",
      "Epoch 41 num_samples 12600 loss 0.03685345451903992\n",
      "Epoch 41 num_samples 12700 loss 0.029810790382852104\n",
      "Epoch 41 num_samples 12800 loss 0.050886029429455505\n",
      "Epoch 41 num_samples 12900 loss 0.02430754991721697\n",
      "Epoch 41 num_samples 13000 loss 0.02081986612542191\n",
      "Epoch 41 num_samples 13100 loss 0.05386270969685025\n",
      "Epoch 41 num_samples 13200 loss 0.018377773600518944\n",
      "Epoch 41 num_samples 13300 loss 0.020254313125131103\n",
      "Epoch 41 num_samples 13400 loss 0.012126476250530658\n",
      "Epoch 41 num_samples 13500 loss 0.020868658973108425\n",
      "Epoch 41 num_samples 13600 loss 0.039528185185184646\n",
      "Epoch 41 num_samples 13700 loss 0.02614659443582912\n",
      "Epoch 41 num_samples 13800 loss 0.025263893112727392\n",
      "Epoch 41 num_samples 13900 loss 0.010565308527842125\n",
      "Epoch 41 num_samples 14000 loss 0.019494758556753207\n",
      "Epoch 41 num_samples 14100 loss 0.02546666266457006\n",
      "Epoch 41 num_samples 14200 loss 0.019515745241930508\n",
      "Epoch 41 num_samples 14300 loss 0.02918813741377865\n",
      "Epoch 41 num_samples 14400 loss 0.028319361689381744\n",
      "Epoch 41 num_samples 14500 loss 0.03177521341236624\n",
      "Epoch 41 num_samples 14600 loss 0.024890942478595843\n",
      "Epoch 41 num_samples 14700 loss 0.026693786551596214\n",
      "Epoch 41 num_samples 14800 loss 0.023272315232159856\n",
      "Epoch 41 num_samples 14900 loss 0.03347420275633012\n",
      "Epoch 41 num_samples 15000 loss 0.02244228910266789\n",
      "Epoch 41 num_samples 15100 loss 0.026639478825189515\n",
      "Epoch 41 num_samples 15200 loss 0.032558745591596834\n",
      "Epoch 41 num_samples 15300 loss 0.02780297341535449\n",
      "Epoch 41 num_samples 15400 loss 0.017444063602164453\n",
      "Epoch 41 num_samples 15500 loss 0.03279955316172574\n",
      "Epoch 41 num_samples 15600 loss 0.027716641856060632\n",
      "Epoch 41 num_samples 15700 loss 0.01803156251159949\n",
      "Epoch 41 num_samples 15800 loss 0.03823106415242665\n",
      "Epoch 41 num_samples 15900 loss 0.017992628906897557\n",
      "Epoch 41 num_samples 16000 loss 0.03572579499144442\n",
      "Epoch 41 num_samples 16100 loss 0.0192281370721393\n",
      "Epoch 41 num_samples 16200 loss 0.029887673135278466\n",
      "Epoch 41 num_samples 16300 loss 0.040315858191216095\n",
      "Epoch 41 num_samples 16400 loss 0.036229158221597856\n",
      "Epoch 41 num_samples 16500 loss 0.030474512402441558\n",
      "Epoch 41 num_samples 16600 loss 0.03480997309340998\n",
      "Epoch 41 num_samples 16700 loss 0.017651600907447995\n",
      "Epoch 41 num_samples 16800 loss 0.019270399988985287\n",
      "Epoch 41 num_samples 16900 loss 0.021933726081728645\n",
      "Epoch 41 num_samples 17000 loss 0.016375760199871615\n",
      "Epoch 41 num_samples 17100 loss 0.05706941525320323\n",
      "Epoch 41 num_samples 17200 loss 0.03031561477108432\n",
      "Epoch 41 num_samples 17300 loss 0.0348858983209397\n",
      "Epoch 41 num_samples 17400 loss 0.026909572929191196\n",
      "Epoch 41 num_samples 17500 loss 0.025399437529887235\n",
      "Epoch 41 num_samples 17600 loss 0.02627832870439249\n",
      "Epoch 41 num_samples 17700 loss 0.02037903264126022\n",
      "Epoch 41 num_samples 17800 loss 0.024582318932070323\n",
      "Epoch 41 num_samples 17900 loss 0.0383300033433898\n",
      "Epoch 41 num_samples 18000 loss 0.0229247097321846\n",
      "Epoch 41 num_samples 18100 loss 0.026671069763926997\n",
      "Epoch 41 num_samples 18200 loss 0.02924813665719456\n",
      "Epoch 41 num_samples 18300 loss 0.022168931263570738\n",
      "Epoch 41 num_samples 18400 loss 0.04422958316915843\n",
      "Epoch 41 num_samples 18500 loss 0.029280664283320136\n",
      "Epoch 42 num_samples 0 loss 0.020465675025719828\n",
      "Epoch 42 num_samples 100 loss 0.037611091902949444\n",
      "Epoch 42 num_samples 200 loss 0.022507891861701924\n",
      "Epoch 42 num_samples 300 loss 0.02005709723809181\n",
      "Epoch 42 num_samples 400 loss 0.022782351543086055\n",
      "Epoch 42 num_samples 500 loss 0.03231120432581255\n",
      "Epoch 42 num_samples 600 loss 0.03906035334519965\n",
      "Epoch 42 num_samples 700 loss 0.03894264569607929\n",
      "Epoch 42 num_samples 800 loss 0.02534668813735006\n",
      "Epoch 42 num_samples 900 loss 0.03774283727818833\n",
      "Epoch 42 num_samples 1000 loss 0.024152821927795595\n",
      "Epoch 42 num_samples 1100 loss 0.042655711731463555\n",
      "Epoch 42 num_samples 1200 loss 0.02451843516561804\n",
      "Epoch 42 num_samples 1300 loss 0.026976065318129742\n",
      "Epoch 42 num_samples 1400 loss 0.03214990171653961\n",
      "Epoch 42 num_samples 1500 loss 0.05047111309777681\n",
      "Epoch 42 num_samples 1600 loss 0.024692787418921214\n",
      "Epoch 42 num_samples 1700 loss 0.023421124306764903\n",
      "Epoch 42 num_samples 1800 loss 0.02336183710498111\n",
      "Epoch 42 num_samples 1900 loss 0.026878363789581094\n",
      "Epoch 42 num_samples 2000 loss 0.03271929629190707\n",
      "Epoch 42 num_samples 2100 loss 0.017743945604253714\n",
      "Epoch 42 num_samples 2200 loss 0.01954883429693565\n",
      "Epoch 42 num_samples 2300 loss 0.0131112551192673\n",
      "Epoch 42 num_samples 2400 loss 0.023367876790009276\n",
      "Epoch 42 num_samples 2500 loss 0.03224711149054791\n",
      "Epoch 42 num_samples 2600 loss 0.03436410432325793\n",
      "Epoch 42 num_samples 2700 loss 0.02353690830502143\n",
      "Epoch 42 num_samples 2800 loss 0.035454724223942385\n",
      "Epoch 42 num_samples 2900 loss 0.031105931605878327\n",
      "Epoch 42 num_samples 3000 loss 0.026183317968439913\n",
      "Epoch 42 num_samples 3100 loss 0.025085659984217693\n",
      "Epoch 42 num_samples 3200 loss 0.07033443638406152\n",
      "Epoch 42 num_samples 3300 loss 0.03035373356125711\n",
      "Epoch 42 num_samples 3400 loss 0.020875934638180996\n",
      "Epoch 42 num_samples 3500 loss 0.02146057981240595\n",
      "Epoch 42 num_samples 3600 loss 0.014452316762132156\n",
      "Epoch 42 num_samples 3700 loss 0.041753719335969997\n",
      "Epoch 42 num_samples 3800 loss 0.02547569854742633\n",
      "Epoch 42 num_samples 3900 loss 0.029258943461698276\n",
      "Epoch 42 num_samples 4000 loss 0.0328326328453708\n",
      "Epoch 42 num_samples 4100 loss 0.04881345262236237\n",
      "Epoch 42 num_samples 4200 loss 0.02572649528312551\n",
      "Epoch 42 num_samples 4300 loss 0.027479576481004093\n",
      "Epoch 42 num_samples 4400 loss 0.03328334029421148\n",
      "Epoch 42 num_samples 4500 loss 0.03677808100267808\n",
      "Epoch 42 num_samples 4600 loss 0.02837849237274002\n",
      "Epoch 42 num_samples 4700 loss 0.017272052174294963\n",
      "Epoch 42 num_samples 4800 loss 0.016546228866317344\n",
      "Epoch 42 num_samples 4900 loss 0.020253854130232587\n",
      "Epoch 42 num_samples 5000 loss 0.0201042594349505\n",
      "Epoch 42 num_samples 5100 loss 0.03453026152466296\n",
      "Epoch 42 num_samples 5200 loss 0.01736309700579285\n",
      "Epoch 42 num_samples 5300 loss 0.02382277564259116\n",
      "Epoch 42 num_samples 5400 loss 0.030690258516910554\n",
      "Epoch 42 num_samples 5500 loss 0.017874713095429304\n",
      "Epoch 42 num_samples 5600 loss 0.08622786045263436\n",
      "Epoch 42 num_samples 5700 loss 0.03531698703041632\n",
      "Epoch 42 num_samples 5800 loss 0.027772484422089315\n",
      "Epoch 42 num_samples 5900 loss 0.03259350965026915\n",
      "Epoch 42 num_samples 6000 loss 0.027132372262220105\n",
      "Epoch 42 num_samples 6100 loss 0.023173150661440003\n",
      "Epoch 42 num_samples 6200 loss 0.028693360167186634\n",
      "Epoch 42 num_samples 6300 loss 0.039883559949273305\n",
      "Epoch 42 num_samples 6400 loss 0.021645845443737818\n",
      "Epoch 42 num_samples 6500 loss 0.019797450497117116\n",
      "Epoch 42 num_samples 6600 loss 0.03961698796379515\n",
      "Epoch 42 num_samples 6700 loss 0.019589118333129915\n",
      "Epoch 42 num_samples 6800 loss 0.013702150691510121\n",
      "Epoch 42 num_samples 6900 loss 0.053291751060227203\n",
      "Epoch 42 num_samples 7000 loss 0.03588851374975437\n",
      "Epoch 42 num_samples 7100 loss 0.018444872279664445\n",
      "Epoch 42 num_samples 7200 loss 0.024375558697273685\n",
      "Epoch 42 num_samples 7300 loss 0.022588768679647434\n",
      "Epoch 42 num_samples 7400 loss 0.01899149359350858\n",
      "Epoch 42 num_samples 7500 loss 0.04568304174600888\n",
      "Epoch 42 num_samples 7600 loss 0.026138091900706567\n",
      "Epoch 42 num_samples 7700 loss 0.045194400861908575\n",
      "Epoch 42 num_samples 7800 loss 0.019887339140228787\n",
      "Epoch 42 num_samples 7900 loss 0.02547524624544222\n",
      "Epoch 42 num_samples 8000 loss 0.018329189114653362\n",
      "Epoch 42 num_samples 8100 loss 0.023769741754546932\n",
      "Epoch 42 num_samples 8200 loss 0.02709144010224724\n",
      "Epoch 42 num_samples 8300 loss 0.02652124652086008\n",
      "Epoch 42 num_samples 8400 loss 0.019536727190921407\n",
      "Epoch 42 num_samples 8500 loss 0.027204766574489208\n",
      "Epoch 42 num_samples 8600 loss 0.025939340639106776\n",
      "Epoch 42 num_samples 8700 loss 0.026954472017278946\n",
      "Epoch 42 num_samples 8800 loss 0.03449172134664465\n",
      "Epoch 42 num_samples 8900 loss 0.030977063198084832\n",
      "Epoch 42 num_samples 9000 loss 0.023792571120483455\n",
      "Epoch 42 num_samples 9100 loss 0.02610584815532906\n",
      "Epoch 42 num_samples 9200 loss 0.024807192599124388\n",
      "Epoch 42 num_samples 9300 loss 0.025646295774762004\n",
      "Epoch 42 num_samples 9400 loss 0.021583878498335825\n",
      "Epoch 42 num_samples 9500 loss 0.024354899655817788\n",
      "Epoch 42 num_samples 9600 loss 0.021700977848684938\n",
      "Epoch 42 num_samples 9700 loss 0.039897554543078126\n",
      "Epoch 42 num_samples 9800 loss 0.015460709571361399\n",
      "Epoch 42 num_samples 9900 loss 0.05236534153807302\n",
      "Epoch 42 num_samples 10000 loss 0.024797425520030173\n",
      "Epoch 42 num_samples 10100 loss 0.020318945485784244\n",
      "Epoch 42 num_samples 10200 loss 0.03326998962961562\n",
      "Epoch 42 num_samples 10300 loss 0.02533548493576454\n",
      "Epoch 42 num_samples 10400 loss 0.035371138775463364\n",
      "Epoch 42 num_samples 10500 loss 0.021149531018374353\n",
      "Epoch 42 num_samples 10600 loss 0.03858199708736085\n",
      "Epoch 42 num_samples 10700 loss 0.022616629111265017\n",
      "Epoch 42 num_samples 10800 loss 0.034699222571006424\n",
      "Epoch 42 num_samples 10900 loss 0.021165316884714392\n",
      "Epoch 42 num_samples 11000 loss 0.018650821725694187\n",
      "Epoch 42 num_samples 11100 loss 0.02524981019218491\n",
      "Epoch 42 num_samples 11200 loss 0.021379451816477504\n",
      "Epoch 42 num_samples 11300 loss 0.04055834670379048\n",
      "Epoch 42 num_samples 11400 loss 0.028439201462138807\n",
      "Epoch 42 num_samples 11500 loss 0.02507342307448428\n",
      "Epoch 42 num_samples 11600 loss 0.022547495230700244\n",
      "Epoch 42 num_samples 11700 loss 0.0343167000378194\n",
      "Epoch 42 num_samples 11800 loss 0.023058504314562845\n",
      "Epoch 42 num_samples 11900 loss 0.02114724624458836\n",
      "Epoch 42 num_samples 12000 loss 0.017181734320585035\n",
      "Epoch 42 num_samples 12100 loss 0.023980954152943372\n",
      "Epoch 42 num_samples 12200 loss 0.03363880862205532\n",
      "Epoch 42 num_samples 12300 loss 0.017003958785745475\n",
      "Epoch 42 num_samples 12400 loss 0.03438552779913795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 num_samples 12500 loss 0.028198815881115315\n",
      "Epoch 42 num_samples 12600 loss 0.034844143610998544\n",
      "Epoch 42 num_samples 12700 loss 0.02829342455030151\n",
      "Epoch 42 num_samples 12800 loss 0.04827477722656534\n",
      "Epoch 42 num_samples 12900 loss 0.023267363342034685\n",
      "Epoch 42 num_samples 13000 loss 0.019817501610905234\n",
      "Epoch 42 num_samples 13100 loss 0.050001214609605465\n",
      "Epoch 42 num_samples 13200 loss 0.017319698172729582\n",
      "Epoch 42 num_samples 13300 loss 0.019253426376610153\n",
      "Epoch 42 num_samples 13400 loss 0.011786015796741071\n",
      "Epoch 42 num_samples 13500 loss 0.019851781017955417\n",
      "Epoch 42 num_samples 13600 loss 0.037376496556632464\n",
      "Epoch 42 num_samples 13700 loss 0.02507742700284594\n",
      "Epoch 42 num_samples 13800 loss 0.024072813653891547\n",
      "Epoch 42 num_samples 13900 loss 0.010149740850223847\n",
      "Epoch 42 num_samples 14000 loss 0.01858971984655517\n",
      "Epoch 42 num_samples 14100 loss 0.024113040375754437\n",
      "Epoch 42 num_samples 14200 loss 0.018611607070783496\n",
      "Epoch 42 num_samples 14300 loss 0.027582814943992683\n",
      "Epoch 42 num_samples 14400 loss 0.027267572275050188\n",
      "Epoch 42 num_samples 14500 loss 0.030412374095064497\n",
      "Epoch 42 num_samples 14600 loss 0.023856762243765237\n",
      "Epoch 42 num_samples 14700 loss 0.025477135103778678\n",
      "Epoch 42 num_samples 14800 loss 0.02241263898716162\n",
      "Epoch 42 num_samples 14900 loss 0.031697314385071236\n",
      "Epoch 42 num_samples 15000 loss 0.021488739859887366\n",
      "Epoch 42 num_samples 15100 loss 0.025519741795365754\n",
      "Epoch 42 num_samples 15200 loss 0.030665297019268793\n",
      "Epoch 42 num_samples 15300 loss 0.02681905715798487\n",
      "Epoch 42 num_samples 15400 loss 0.01668971987361639\n",
      "Epoch 42 num_samples 15500 loss 0.03087248783173137\n",
      "Epoch 42 num_samples 15600 loss 0.026688825849170397\n",
      "Epoch 42 num_samples 15700 loss 0.017349544168520983\n",
      "Epoch 42 num_samples 15800 loss 0.036119426097470875\n",
      "Epoch 42 num_samples 15900 loss 0.01720925724383461\n",
      "Epoch 42 num_samples 16000 loss 0.034011950276289935\n",
      "Epoch 42 num_samples 16100 loss 0.01833313055427593\n",
      "Epoch 42 num_samples 16200 loss 0.02845308504587859\n",
      "Epoch 42 num_samples 16300 loss 0.038126896937561064\n",
      "Epoch 42 num_samples 16400 loss 0.03453304971451769\n",
      "Epoch 42 num_samples 16500 loss 0.029235402359755934\n",
      "Epoch 42 num_samples 16600 loss 0.03286223491169123\n",
      "Epoch 42 num_samples 16700 loss 0.01698392033389877\n",
      "Epoch 42 num_samples 16800 loss 0.018293388267501248\n",
      "Epoch 42 num_samples 16900 loss 0.0208444080560802\n",
      "Epoch 42 num_samples 17000 loss 0.015645965240524265\n",
      "Epoch 42 num_samples 17100 loss 0.05302632164669291\n",
      "Epoch 42 num_samples 17200 loss 0.02887658402385562\n",
      "Epoch 42 num_samples 17300 loss 0.03307905587662744\n",
      "Epoch 42 num_samples 17400 loss 0.025684282519915048\n",
      "Epoch 42 num_samples 17500 loss 0.024312492815134777\n",
      "Epoch 42 num_samples 17600 loss 0.025146055349912835\n",
      "Epoch 42 num_samples 17700 loss 0.019537848674426806\n",
      "Epoch 42 num_samples 17800 loss 0.023136977826313247\n",
      "Epoch 42 num_samples 17900 loss 0.036182060300906684\n",
      "Epoch 42 num_samples 18000 loss 0.02200368828469048\n",
      "Epoch 42 num_samples 18100 loss 0.025552520896684312\n",
      "Epoch 42 num_samples 18200 loss 0.02782825656090334\n",
      "Epoch 42 num_samples 18300 loss 0.02115941581210402\n",
      "Epoch 42 num_samples 18400 loss 0.041788005647226\n",
      "Epoch 42 num_samples 18500 loss 0.027766235895470913\n",
      "Epoch 43 num_samples 0 loss 0.019672735400709122\n",
      "Epoch 43 num_samples 100 loss 0.0356791044301004\n",
      "Epoch 43 num_samples 200 loss 0.021450808712028886\n",
      "Epoch 43 num_samples 300 loss 0.018953002792737757\n",
      "Epoch 43 num_samples 400 loss 0.021956118206204845\n",
      "Epoch 43 num_samples 500 loss 0.031104426271284503\n",
      "Epoch 43 num_samples 600 loss 0.03776915676524702\n",
      "Epoch 43 num_samples 700 loss 0.03699153775038552\n",
      "Epoch 43 num_samples 800 loss 0.02392857801661147\n",
      "Epoch 43 num_samples 900 loss 0.036181942009556434\n",
      "Epoch 43 num_samples 1000 loss 0.023183888273925212\n",
      "Epoch 43 num_samples 1100 loss 0.041041173266147944\n",
      "Epoch 43 num_samples 1200 loss 0.023437723374452508\n",
      "Epoch 43 num_samples 1300 loss 0.02618427277395462\n",
      "Epoch 43 num_samples 1400 loss 0.03044420630494696\n",
      "Epoch 43 num_samples 1500 loss 0.04681896028466347\n",
      "Epoch 43 num_samples 1600 loss 0.02354777238046176\n",
      "Epoch 43 num_samples 1700 loss 0.022326794616202766\n",
      "Epoch 43 num_samples 1800 loss 0.02247374123391988\n",
      "Epoch 43 num_samples 1900 loss 0.025860280267557753\n",
      "Epoch 43 num_samples 2000 loss 0.031100661966725004\n",
      "Epoch 43 num_samples 2100 loss 0.017011547993255667\n",
      "Epoch 43 num_samples 2200 loss 0.018691297221131064\n",
      "Epoch 43 num_samples 2300 loss 0.01237746847852119\n",
      "Epoch 43 num_samples 2400 loss 0.022270883376392582\n",
      "Epoch 43 num_samples 2500 loss 0.03063885343735551\n",
      "Epoch 43 num_samples 2600 loss 0.03255268453770824\n",
      "Epoch 43 num_samples 2700 loss 0.02225514988490217\n",
      "Epoch 43 num_samples 2800 loss 0.03391940373766349\n",
      "Epoch 43 num_samples 2900 loss 0.02953787992100797\n",
      "Epoch 43 num_samples 3000 loss 0.025037465551014684\n",
      "Epoch 43 num_samples 3100 loss 0.0240554970939485\n",
      "Epoch 43 num_samples 3200 loss 0.06549593762110463\n",
      "Epoch 43 num_samples 3300 loss 0.02926338936788241\n",
      "Epoch 43 num_samples 3400 loss 0.019990051749743748\n",
      "Epoch 43 num_samples 3500 loss 0.020538157661185434\n",
      "Epoch 43 num_samples 3600 loss 0.01385103844747589\n",
      "Epoch 43 num_samples 3700 loss 0.03969999310179559\n",
      "Epoch 43 num_samples 3800 loss 0.0240552339700678\n",
      "Epoch 43 num_samples 3900 loss 0.02769826081673029\n",
      "Epoch 43 num_samples 4000 loss 0.03140841745435575\n",
      "Epoch 43 num_samples 4100 loss 0.04617764718985442\n",
      "Epoch 43 num_samples 4200 loss 0.02460219276240392\n",
      "Epoch 43 num_samples 4300 loss 0.025909239019600447\n",
      "Epoch 43 num_samples 4400 loss 0.03138708119589492\n",
      "Epoch 43 num_samples 4500 loss 0.0353866511846602\n",
      "Epoch 43 num_samples 4600 loss 0.027139658738214608\n",
      "Epoch 43 num_samples 4700 loss 0.016469704616599416\n",
      "Epoch 43 num_samples 4800 loss 0.015881393216472604\n",
      "Epoch 43 num_samples 4900 loss 0.01955860580890082\n",
      "Epoch 43 num_samples 5000 loss 0.01919593860374102\n",
      "Epoch 43 num_samples 5100 loss 0.033126584422395015\n",
      "Epoch 43 num_samples 5200 loss 0.016619124963080524\n",
      "Epoch 43 num_samples 5300 loss 0.022947727252456734\n",
      "Epoch 43 num_samples 5400 loss 0.029316140166302383\n",
      "Epoch 43 num_samples 5500 loss 0.017072340324250406\n",
      "Epoch 43 num_samples 5600 loss 0.08191801410312825\n",
      "Epoch 43 num_samples 5700 loss 0.03293079829467942\n",
      "Epoch 43 num_samples 5800 loss 0.026259049934191803\n",
      "Epoch 43 num_samples 5900 loss 0.030606768182655158\n",
      "Epoch 43 num_samples 6000 loss 0.025371136943077844\n",
      "Epoch 43 num_samples 6100 loss 0.022139651499866537\n",
      "Epoch 43 num_samples 6200 loss 0.027232093563775206\n",
      "Epoch 43 num_samples 6300 loss 0.0374361359972485\n",
      "Epoch 43 num_samples 6400 loss 0.02071111675150961\n",
      "Epoch 43 num_samples 6500 loss 0.01885836005494601\n",
      "Epoch 43 num_samples 6600 loss 0.03761045846848498\n",
      "Epoch 43 num_samples 6700 loss 0.018908265158026197\n",
      "Epoch 43 num_samples 6800 loss 0.013148721285817446\n",
      "Epoch 43 num_samples 6900 loss 0.05086919621692352\n",
      "Epoch 43 num_samples 7000 loss 0.033813469445191854\n",
      "Epoch 43 num_samples 7100 loss 0.01774123544225675\n",
      "Epoch 43 num_samples 7200 loss 0.023366884894852814\n",
      "Epoch 43 num_samples 7300 loss 0.021626372563092734\n",
      "Epoch 43 num_samples 7400 loss 0.018091771174688732\n",
      "Epoch 43 num_samples 7500 loss 0.04335314778170338\n",
      "Epoch 43 num_samples 7600 loss 0.025074444519236308\n",
      "Epoch 43 num_samples 7700 loss 0.04250699081423688\n",
      "Epoch 43 num_samples 7800 loss 0.01924679078258152\n",
      "Epoch 43 num_samples 7900 loss 0.024330458276697185\n",
      "Epoch 43 num_samples 8000 loss 0.017592555022879108\n",
      "Epoch 43 num_samples 8100 loss 0.022797722665585423\n",
      "Epoch 43 num_samples 8200 loss 0.026002778461168427\n",
      "Epoch 43 num_samples 8300 loss 0.02514582803040453\n",
      "Epoch 43 num_samples 8400 loss 0.018638711842560853\n",
      "Epoch 43 num_samples 8500 loss 0.02598678316873377\n",
      "Epoch 43 num_samples 8600 loss 0.024806220561004153\n",
      "Epoch 43 num_samples 8700 loss 0.02546754216784489\n",
      "Epoch 43 num_samples 8800 loss 0.032465406414641955\n",
      "Epoch 43 num_samples 8900 loss 0.029528627122793808\n",
      "Epoch 43 num_samples 9000 loss 0.022871497383645502\n",
      "Epoch 43 num_samples 9100 loss 0.02493612153417506\n",
      "Epoch 43 num_samples 9200 loss 0.024022177285377228\n",
      "Epoch 43 num_samples 9300 loss 0.024374804106153763\n",
      "Epoch 43 num_samples 9400 loss 0.020793946494653524\n",
      "Epoch 43 num_samples 9500 loss 0.023051989221524447\n",
      "Epoch 43 num_samples 9600 loss 0.02072440369220645\n",
      "Epoch 43 num_samples 9700 loss 0.038219546572854826\n",
      "Epoch 43 num_samples 9800 loss 0.014764861521646737\n",
      "Epoch 43 num_samples 9900 loss 0.050052382731544956\n",
      "Epoch 43 num_samples 10000 loss 0.023614215260416228\n",
      "Epoch 43 num_samples 10100 loss 0.01937913715170787\n",
      "Epoch 43 num_samples 10200 loss 0.03170707853568142\n",
      "Epoch 43 num_samples 10300 loss 0.024326511194761192\n",
      "Epoch 43 num_samples 10400 loss 0.03351053602140945\n",
      "Epoch 43 num_samples 10500 loss 0.020333269785353308\n",
      "Epoch 43 num_samples 10600 loss 0.036416821688917876\n",
      "Epoch 43 num_samples 10700 loss 0.021839663105643132\n",
      "Epoch 43 num_samples 10800 loss 0.032538092524800735\n",
      "Epoch 43 num_samples 10900 loss 0.020243902562281955\n",
      "Epoch 43 num_samples 11000 loss 0.0177785828641067\n",
      "Epoch 43 num_samples 11100 loss 0.02405433005872112\n",
      "Epoch 43 num_samples 11200 loss 0.020470185115381224\n",
      "Epoch 43 num_samples 11300 loss 0.03800075207620928\n",
      "Epoch 43 num_samples 11400 loss 0.026325502314557533\n",
      "Epoch 43 num_samples 11500 loss 0.02382028786683823\n",
      "Epoch 43 num_samples 11600 loss 0.0214631148868505\n",
      "Epoch 43 num_samples 11700 loss 0.03291256607322269\n",
      "Epoch 43 num_samples 11800 loss 0.022077315453217547\n",
      "Epoch 43 num_samples 11900 loss 0.020128855743579366\n",
      "Epoch 43 num_samples 12000 loss 0.016421450262636014\n",
      "Epoch 43 num_samples 12100 loss 0.02236805454061127\n",
      "Epoch 43 num_samples 12200 loss 0.03184728073533581\n",
      "Epoch 43 num_samples 12300 loss 0.016496721701642465\n",
      "Epoch 43 num_samples 12400 loss 0.03276750791789371\n",
      "Epoch 43 num_samples 12500 loss 0.02687573381835993\n",
      "Epoch 43 num_samples 12600 loss 0.0333347815399308\n",
      "Epoch 43 num_samples 12700 loss 0.026893079712887874\n",
      "Epoch 43 num_samples 12800 loss 0.045863505650258374\n",
      "Epoch 43 num_samples 12900 loss 0.022177017087449506\n",
      "Epoch 43 num_samples 13000 loss 0.018852786988005618\n",
      "Epoch 43 num_samples 13100 loss 0.04657061954086668\n",
      "Epoch 43 num_samples 13200 loss 0.01619469625033527\n",
      "Epoch 43 num_samples 13300 loss 0.018336487751022073\n",
      "Epoch 43 num_samples 13400 loss 0.011285962951956026\n",
      "Epoch 43 num_samples 13500 loss 0.018888229258897205\n",
      "Epoch 43 num_samples 13600 loss 0.03548257472168317\n",
      "Epoch 43 num_samples 13700 loss 0.023855554010035328\n",
      "Epoch 43 num_samples 13800 loss 0.022851168153380837\n",
      "Epoch 43 num_samples 13900 loss 0.00966725368892799\n",
      "Epoch 43 num_samples 14000 loss 0.017786157441703004\n",
      "Epoch 43 num_samples 14100 loss 0.022893589273255816\n",
      "Epoch 43 num_samples 14200 loss 0.017819222264046707\n",
      "Epoch 43 num_samples 14300 loss 0.026264100539348426\n",
      "Epoch 43 num_samples 14400 loss 0.025868000822858513\n",
      "Epoch 43 num_samples 14500 loss 0.0291407751223863\n",
      "Epoch 43 num_samples 14600 loss 0.02280024979212125\n",
      "Epoch 43 num_samples 14700 loss 0.02432798795930621\n",
      "Epoch 43 num_samples 14800 loss 0.021592567537453426\n",
      "Epoch 43 num_samples 14900 loss 0.02993465400698634\n",
      "Epoch 43 num_samples 15000 loss 0.02055952941899505\n",
      "Epoch 43 num_samples 15100 loss 0.02433467131466465\n",
      "Epoch 43 num_samples 15200 loss 0.029225983055605708\n",
      "Epoch 43 num_samples 15300 loss 0.02572482934688745\n",
      "Epoch 43 num_samples 15400 loss 0.015975859938919437\n",
      "Epoch 43 num_samples 15500 loss 0.02901417026066201\n",
      "Epoch 43 num_samples 15600 loss 0.02539576759943409\n",
      "Epoch 43 num_samples 15700 loss 0.016603955070500234\n",
      "Epoch 43 num_samples 15800 loss 0.034318429963546046\n",
      "Epoch 43 num_samples 15900 loss 0.01661965143794714\n",
      "Epoch 43 num_samples 16000 loss 0.032803435501526826\n",
      "Epoch 43 num_samples 16100 loss 0.017592550519659744\n",
      "Epoch 43 num_samples 16200 loss 0.02731479675355608\n",
      "Epoch 43 num_samples 16300 loss 0.03614438187873132\n",
      "Epoch 43 num_samples 16400 loss 0.033073958696212484\n",
      "Epoch 43 num_samples 16500 loss 0.02794286447679396\n",
      "Epoch 43 num_samples 16600 loss 0.03156420386578921\n",
      "Epoch 43 num_samples 16700 loss 0.016247387401210327\n",
      "Epoch 43 num_samples 16800 loss 0.017342285566741823\n",
      "Epoch 43 num_samples 16900 loss 0.019897186587425987\n",
      "Epoch 43 num_samples 17000 loss 0.014966697500662601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 num_samples 17100 loss 0.04982996736293961\n",
      "Epoch 43 num_samples 17200 loss 0.027646857110838034\n",
      "Epoch 43 num_samples 17300 loss 0.03130075439057701\n",
      "Epoch 43 num_samples 17400 loss 0.024586075192536114\n",
      "Epoch 43 num_samples 17500 loss 0.02309388993972039\n",
      "Epoch 43 num_samples 17600 loss 0.023810283993189008\n",
      "Epoch 43 num_samples 17700 loss 0.01846482251629972\n",
      "Epoch 43 num_samples 17800 loss 0.021830226496635855\n",
      "Epoch 43 num_samples 17900 loss 0.0345403673832052\n",
      "Epoch 43 num_samples 18000 loss 0.021161048440596325\n",
      "Epoch 43 num_samples 18100 loss 0.024219246201495757\n",
      "Epoch 43 num_samples 18200 loss 0.026236906238624867\n",
      "Epoch 43 num_samples 18300 loss 0.01994918790119583\n",
      "Epoch 43 num_samples 18400 loss 0.04007221521452323\n",
      "Epoch 43 num_samples 18500 loss 0.026472971058017918\n",
      "Epoch 44 num_samples 0 loss 0.018540645839111726\n",
      "Epoch 44 num_samples 100 loss 0.03416326948216161\n",
      "Epoch 44 num_samples 200 loss 0.02056954596565787\n",
      "Epoch 44 num_samples 300 loss 0.018075408541100013\n",
      "Epoch 44 num_samples 400 loss 0.020778209999148256\n",
      "Epoch 44 num_samples 500 loss 0.030066362380343027\n",
      "Epoch 44 num_samples 600 loss 0.035999942958668665\n",
      "Epoch 44 num_samples 700 loss 0.035767629179754415\n",
      "Epoch 44 num_samples 800 loss 0.02273331604749539\n",
      "Epoch 44 num_samples 900 loss 0.03489788633670963\n",
      "Epoch 44 num_samples 1000 loss 0.022013923330029606\n",
      "Epoch 44 num_samples 1100 loss 0.03871933440363076\n",
      "Epoch 44 num_samples 1200 loss 0.02235866126214405\n",
      "Epoch 44 num_samples 1300 loss 0.024894020438340457\n",
      "Epoch 44 num_samples 1400 loss 0.02907172959943102\n",
      "Epoch 44 num_samples 1500 loss 0.043488117980539906\n",
      "Epoch 44 num_samples 1600 loss 0.022589118322428076\n",
      "Epoch 44 num_samples 1700 loss 0.02145843564496158\n",
      "Epoch 44 num_samples 1800 loss 0.02143062550055665\n",
      "Epoch 44 num_samples 1900 loss 0.024794237019566477\n",
      "Epoch 44 num_samples 2000 loss 0.029753221519184993\n",
      "Epoch 44 num_samples 2100 loss 0.016175446992385947\n",
      "Epoch 44 num_samples 2200 loss 0.017761208713033914\n",
      "Epoch 44 num_samples 2300 loss 0.0118882285240509\n",
      "Epoch 44 num_samples 2400 loss 0.021032823013285948\n",
      "Epoch 44 num_samples 2500 loss 0.029182488043953302\n",
      "Epoch 44 num_samples 2600 loss 0.03105284954838548\n",
      "Epoch 44 num_samples 2700 loss 0.021199368639559398\n",
      "Epoch 44 num_samples 2800 loss 0.032495834684073396\n",
      "Epoch 44 num_samples 2900 loss 0.02802916252197309\n",
      "Epoch 44 num_samples 3000 loss 0.02380592823139115\n",
      "Epoch 44 num_samples 3100 loss 0.022773782469944458\n",
      "Epoch 44 num_samples 3200 loss 0.06140992914561285\n",
      "Epoch 44 num_samples 3300 loss 0.02742235680794905\n",
      "Epoch 44 num_samples 3400 loss 0.019126437330027824\n",
      "Epoch 44 num_samples 3500 loss 0.019533870556264973\n",
      "Epoch 44 num_samples 3600 loss 0.013321856416065534\n",
      "Epoch 44 num_samples 3700 loss 0.037828412752749896\n",
      "Epoch 44 num_samples 3800 loss 0.02267383426099271\n",
      "Epoch 44 num_samples 3900 loss 0.026285302502691784\n",
      "Epoch 44 num_samples 4000 loss 0.029737948868879947\n",
      "Epoch 44 num_samples 4100 loss 0.043688761251314066\n",
      "Epoch 44 num_samples 4200 loss 0.023760594110922347\n",
      "Epoch 44 num_samples 4300 loss 0.024629429345791137\n",
      "Epoch 44 num_samples 4400 loss 0.02990535002987495\n",
      "Epoch 44 num_samples 4500 loss 0.03376675629141567\n",
      "Epoch 44 num_samples 4600 loss 0.0258757968381543\n",
      "Epoch 44 num_samples 4700 loss 0.01565399936047739\n",
      "Epoch 44 num_samples 4800 loss 0.015311459866638177\n",
      "Epoch 44 num_samples 4900 loss 0.018871755567033306\n",
      "Epoch 44 num_samples 5000 loss 0.018172369806008584\n",
      "Epoch 44 num_samples 5100 loss 0.03176215356594115\n",
      "Epoch 44 num_samples 5200 loss 0.016097153052141135\n",
      "Epoch 44 num_samples 5300 loss 0.02177260319363819\n",
      "Epoch 44 num_samples 5400 loss 0.02785396987575006\n",
      "Epoch 44 num_samples 5500 loss 0.01646758510991706\n",
      "Epoch 44 num_samples 5600 loss 0.07852454130900752\n",
      "Epoch 44 num_samples 5700 loss 0.02995888258521057\n",
      "Epoch 44 num_samples 5800 loss 0.024667670930897802\n",
      "Epoch 44 num_samples 5900 loss 0.02960761616579579\n",
      "Epoch 44 num_samples 6000 loss 0.024492031575157634\n",
      "Epoch 44 num_samples 6100 loss 0.02103266363091825\n",
      "Epoch 44 num_samples 6200 loss 0.025830035388602603\n",
      "Epoch 44 num_samples 6300 loss 0.036116329147542814\n",
      "Epoch 44 num_samples 6400 loss 0.01973605317485983\n",
      "Epoch 44 num_samples 6500 loss 0.018070813771121994\n",
      "Epoch 44 num_samples 6600 loss 0.036109142851821534\n",
      "Epoch 44 num_samples 6700 loss 0.0181070409010217\n",
      "Epoch 44 num_samples 6800 loss 0.012758920992246743\n",
      "Epoch 44 num_samples 6900 loss 0.048902041857629905\n",
      "Epoch 44 num_samples 7000 loss 0.03195705031137295\n",
      "Epoch 44 num_samples 7100 loss 0.01666724655649039\n",
      "Epoch 44 num_samples 7200 loss 0.02225107861371997\n",
      "Epoch 44 num_samples 7300 loss 0.020949138073432273\n",
      "Epoch 44 num_samples 7400 loss 0.01733624704685104\n",
      "Epoch 44 num_samples 7500 loss 0.0414151328267951\n",
      "Epoch 44 num_samples 7600 loss 0.023876461675176285\n",
      "Epoch 44 num_samples 7700 loss 0.04025029724790431\n",
      "Epoch 44 num_samples 7800 loss 0.018584386552026114\n",
      "Epoch 44 num_samples 7900 loss 0.023074691818262424\n",
      "Epoch 44 num_samples 8000 loss 0.016720012850353384\n",
      "Epoch 44 num_samples 8100 loss 0.021653952226841397\n",
      "Epoch 44 num_samples 8200 loss 0.024856670367955046\n",
      "Epoch 44 num_samples 8300 loss 0.023547643230611495\n",
      "Epoch 44 num_samples 8400 loss 0.017748824684797028\n",
      "Epoch 44 num_samples 8500 loss 0.02487953479009692\n",
      "Epoch 44 num_samples 8600 loss 0.02388139359901956\n",
      "Epoch 44 num_samples 8700 loss 0.0245448540238834\n",
      "Epoch 44 num_samples 8800 loss 0.02985029945775161\n",
      "Epoch 44 num_samples 8900 loss 0.028206285142070353\n",
      "Epoch 44 num_samples 9000 loss 0.021906158041451924\n",
      "Epoch 44 num_samples 9100 loss 0.023887138529633322\n",
      "Epoch 44 num_samples 9200 loss 0.022820098164673137\n",
      "Epoch 44 num_samples 9300 loss 0.02326762483657995\n",
      "Epoch 44 num_samples 9400 loss 0.019895304267750314\n",
      "Epoch 44 num_samples 9500 loss 0.02161758955245116\n",
      "Epoch 44 num_samples 9600 loss 0.019836056485112316\n",
      "Epoch 44 num_samples 9700 loss 0.03674145340015349\n",
      "Epoch 44 num_samples 9800 loss 0.014127184371278063\n",
      "Epoch 44 num_samples 9900 loss 0.04747735619552385\n",
      "Epoch 44 num_samples 10000 loss 0.02220152399566771\n",
      "Epoch 44 num_samples 10100 loss 0.018602509805051053\n",
      "Epoch 44 num_samples 10200 loss 0.03011106878626565\n",
      "Epoch 44 num_samples 10300 loss 0.023255003340221462\n",
      "Epoch 44 num_samples 10400 loss 0.031855475315071685\n",
      "Epoch 44 num_samples 10500 loss 0.019367434633347117\n",
      "Epoch 44 num_samples 10600 loss 0.03411787738057339\n",
      "Epoch 44 num_samples 10700 loss 0.020801084513991742\n",
      "Epoch 44 num_samples 10800 loss 0.030360429925677317\n",
      "Epoch 44 num_samples 10900 loss 0.019336795996157643\n",
      "Epoch 44 num_samples 11000 loss 0.01727061092619798\n",
      "Epoch 44 num_samples 11100 loss 0.022966062108531977\n",
      "Epoch 44 num_samples 11200 loss 0.019412990460909683\n",
      "Epoch 44 num_samples 11300 loss 0.036003208207902614\n",
      "Epoch 44 num_samples 11400 loss 0.024757419902972845\n",
      "Epoch 44 num_samples 11500 loss 0.023144337428618655\n",
      "Epoch 44 num_samples 11600 loss 0.020586039280864582\n",
      "Epoch 44 num_samples 11700 loss 0.03127090269873561\n",
      "Epoch 44 num_samples 11800 loss 0.02093152866100937\n",
      "Epoch 44 num_samples 11900 loss 0.019200418254376975\n",
      "Epoch 44 num_samples 12000 loss 0.01570367796730267\n",
      "Epoch 44 num_samples 12100 loss 0.021037034289331277\n",
      "Epoch 44 num_samples 12200 loss 0.030263210620485318\n",
      "Epoch 44 num_samples 12300 loss 0.015787629081951363\n",
      "Epoch 44 num_samples 12400 loss 0.031353115875279586\n",
      "Epoch 44 num_samples 12500 loss 0.025744541229589687\n",
      "Epoch 44 num_samples 12600 loss 0.0317896038744207\n",
      "Epoch 44 num_samples 12700 loss 0.02557620709500257\n",
      "Epoch 44 num_samples 12800 loss 0.04354962878901464\n",
      "Epoch 44 num_samples 12900 loss 0.02097279333125268\n",
      "Epoch 44 num_samples 13000 loss 0.018127246378267067\n",
      "Epoch 44 num_samples 13100 loss 0.04322103362752723\n",
      "Epoch 44 num_samples 13200 loss 0.0154820753307166\n",
      "Epoch 44 num_samples 13300 loss 0.01748228640452007\n",
      "Epoch 44 num_samples 13400 loss 0.01084225016728657\n",
      "Epoch 44 num_samples 13500 loss 0.018008253078759848\n",
      "Epoch 44 num_samples 13600 loss 0.03352405355508827\n",
      "Epoch 44 num_samples 13700 loss 0.02263327056832016\n",
      "Epoch 44 num_samples 13800 loss 0.021542678399070127\n",
      "Epoch 44 num_samples 13900 loss 0.009169963788092405\n",
      "Epoch 44 num_samples 14000 loss 0.016889138514765846\n",
      "Epoch 44 num_samples 14100 loss 0.021645265732139055\n",
      "Epoch 44 num_samples 14200 loss 0.017195713451892095\n",
      "Epoch 44 num_samples 14300 loss 0.025049182523335208\n",
      "Epoch 44 num_samples 14400 loss 0.025037578230512652\n",
      "Epoch 44 num_samples 14500 loss 0.02783175413792846\n",
      "Epoch 44 num_samples 14600 loss 0.021844157143175558\n",
      "Epoch 44 num_samples 14700 loss 0.023268647383579193\n",
      "Epoch 44 num_samples 14800 loss 0.02064975544699026\n",
      "Epoch 44 num_samples 14900 loss 0.028440962258822852\n",
      "Epoch 44 num_samples 15000 loss 0.01974902228544599\n",
      "Epoch 44 num_samples 15100 loss 0.023303560687615663\n",
      "Epoch 44 num_samples 15200 loss 0.02745466783560518\n",
      "Epoch 44 num_samples 15300 loss 0.02493336644718171\n",
      "Epoch 44 num_samples 15400 loss 0.015283608598860498\n",
      "Epoch 44 num_samples 15500 loss 0.02731835957061533\n",
      "Epoch 44 num_samples 15600 loss 0.02473399388123186\n",
      "Epoch 44 num_samples 15700 loss 0.015983269359523586\n",
      "Epoch 44 num_samples 15800 loss 0.032397427563642237\n",
      "Epoch 44 num_samples 15900 loss 0.01597039208290073\n",
      "Epoch 44 num_samples 16000 loss 0.03148960670157947\n",
      "Epoch 44 num_samples 16100 loss 0.01670211076561974\n",
      "Epoch 44 num_samples 16200 loss 0.025857165330976043\n",
      "Epoch 44 num_samples 16300 loss 0.034161099859523335\n",
      "Epoch 44 num_samples 16400 loss 0.03173107896427652\n",
      "Epoch 44 num_samples 16500 loss 0.026648361221040383\n",
      "Epoch 44 num_samples 16600 loss 0.029862920105923476\n",
      "Epoch 44 num_samples 16700 loss 0.01549541587484967\n",
      "Epoch 44 num_samples 16800 loss 0.016521763584200502\n",
      "Epoch 44 num_samples 16900 loss 0.018979146020823144\n",
      "Epoch 44 num_samples 17000 loss 0.014294318937350985\n",
      "Epoch 44 num_samples 17100 loss 0.0470226706407696\n",
      "Epoch 44 num_samples 17200 loss 0.026279158263616695\n",
      "Epoch 44 num_samples 17300 loss 0.02971767931531761\n",
      "Epoch 44 num_samples 17400 loss 0.023264620431151174\n",
      "Epoch 44 num_samples 17500 loss 0.02226433619348698\n",
      "Epoch 44 num_samples 17600 loss 0.022699169446055843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 num_samples 17700 loss 0.01764923437187622\n",
      "Epoch 44 num_samples 17800 loss 0.020654004502724456\n",
      "Epoch 44 num_samples 17900 loss 0.032731735714805914\n",
      "Epoch 44 num_samples 18000 loss 0.020247126515446592\n",
      "Epoch 44 num_samples 18100 loss 0.023243191477071892\n",
      "Epoch 44 num_samples 18200 loss 0.025136912293599992\n",
      "Epoch 44 num_samples 18300 loss 0.019084940025245592\n",
      "Epoch 44 num_samples 18400 loss 0.03810260697387879\n",
      "Epoch 44 num_samples 18500 loss 0.024986145955851413\n",
      "Epoch 45 num_samples 0 loss 0.017730944124615244\n",
      "Epoch 45 num_samples 100 loss 0.03255413865692039\n",
      "Epoch 45 num_samples 200 loss 0.020011146887126133\n",
      "Epoch 45 num_samples 300 loss 0.01729264148088564\n",
      "Epoch 45 num_samples 400 loss 0.01993938917147601\n",
      "Epoch 45 num_samples 500 loss 0.028713537815186464\n",
      "Epoch 45 num_samples 600 loss 0.03444445224390582\n",
      "Epoch 45 num_samples 700 loss 0.03412046977092596\n",
      "Epoch 45 num_samples 800 loss 0.021616695615362433\n",
      "Epoch 45 num_samples 900 loss 0.03372017093494009\n",
      "Epoch 45 num_samples 1000 loss 0.021093604671635898\n",
      "Epoch 45 num_samples 1100 loss 0.0374500095196412\n",
      "Epoch 45 num_samples 1200 loss 0.02131802284346345\n",
      "Epoch 45 num_samples 1300 loss 0.023879114946274947\n",
      "Epoch 45 num_samples 1400 loss 0.02768927985415938\n",
      "Epoch 45 num_samples 1500 loss 0.0400693563705041\n",
      "Epoch 45 num_samples 1600 loss 0.021763500948026326\n",
      "Epoch 45 num_samples 1700 loss 0.02045269597792245\n",
      "Epoch 45 num_samples 1800 loss 0.02065849525955644\n",
      "Epoch 45 num_samples 1900 loss 0.023711269068645454\n",
      "Epoch 45 num_samples 2000 loss 0.02837971121681697\n",
      "Epoch 45 num_samples 2100 loss 0.015527668646325588\n",
      "Epoch 45 num_samples 2200 loss 0.017015793975040633\n",
      "Epoch 45 num_samples 2300 loss 0.01126966238015227\n",
      "Epoch 45 num_samples 2400 loss 0.020189011021498664\n",
      "Epoch 45 num_samples 2500 loss 0.027901089536609146\n",
      "Epoch 45 num_samples 2600 loss 0.02972499697994316\n",
      "Epoch 45 num_samples 2700 loss 0.020165318176530972\n",
      "Epoch 45 num_samples 2800 loss 0.03078968323230777\n",
      "Epoch 45 num_samples 2900 loss 0.02685925263411271\n",
      "Epoch 45 num_samples 3000 loss 0.022854384350138535\n",
      "Epoch 45 num_samples 3100 loss 0.02152819396886022\n",
      "Epoch 45 num_samples 3200 loss 0.05739269967176672\n",
      "Epoch 45 num_samples 3300 loss 0.025853741848730506\n",
      "Epoch 45 num_samples 3400 loss 0.01823715126510073\n",
      "Epoch 45 num_samples 3500 loss 0.01886564586961874\n",
      "Epoch 45 num_samples 3600 loss 0.012789378734373944\n",
      "Epoch 45 num_samples 3700 loss 0.03590801810266729\n",
      "Epoch 45 num_samples 3800 loss 0.021641459391383195\n",
      "Epoch 45 num_samples 3900 loss 0.024881184189245707\n",
      "Epoch 45 num_samples 4000 loss 0.028834510628330996\n",
      "Epoch 45 num_samples 4100 loss 0.04143339890866859\n",
      "Epoch 45 num_samples 4200 loss 0.022716146996073584\n",
      "Epoch 45 num_samples 4300 loss 0.02328382585126456\n",
      "Epoch 45 num_samples 4400 loss 0.028631326605849824\n",
      "Epoch 45 num_samples 4500 loss 0.031952111948434656\n",
      "Epoch 45 num_samples 4600 loss 0.02480264693679424\n",
      "Epoch 45 num_samples 4700 loss 0.01512076637540527\n",
      "Epoch 45 num_samples 4800 loss 0.014578216637120854\n",
      "Epoch 45 num_samples 4900 loss 0.018079216643231973\n",
      "Epoch 45 num_samples 5000 loss 0.017442162969370536\n",
      "Epoch 45 num_samples 5100 loss 0.030480959474415696\n",
      "Epoch 45 num_samples 5200 loss 0.015276516260824425\n",
      "Epoch 45 num_samples 5300 loss 0.020886763449948928\n",
      "Epoch 45 num_samples 5400 loss 0.02713328508542341\n",
      "Epoch 45 num_samples 5500 loss 0.01560889859039523\n",
      "Epoch 45 num_samples 5600 loss 0.07520107776058693\n",
      "Epoch 45 num_samples 5700 loss 0.028174611977938514\n",
      "Epoch 45 num_samples 5800 loss 0.023263136746448854\n",
      "Epoch 45 num_samples 5900 loss 0.027978191182873705\n",
      "Epoch 45 num_samples 6000 loss 0.023142190016371553\n",
      "Epoch 45 num_samples 6100 loss 0.02004944544317225\n",
      "Epoch 45 num_samples 6200 loss 0.024621205615170047\n",
      "Epoch 45 num_samples 6300 loss 0.033893415639794075\n",
      "Epoch 45 num_samples 6400 loss 0.018741483964848683\n",
      "Epoch 45 num_samples 6500 loss 0.017200244470203362\n",
      "Epoch 45 num_samples 6600 loss 0.034842281594317494\n",
      "Epoch 45 num_samples 6700 loss 0.01744901777160803\n",
      "Epoch 45 num_samples 6800 loss 0.012050200508211196\n",
      "Epoch 45 num_samples 6900 loss 0.046666495899303495\n",
      "Epoch 45 num_samples 7000 loss 0.030307197320564118\n",
      "Epoch 45 num_samples 7100 loss 0.016167082304935514\n",
      "Epoch 45 num_samples 7200 loss 0.021524131863551395\n",
      "Epoch 45 num_samples 7300 loss 0.019979531917585346\n",
      "Epoch 45 num_samples 7400 loss 0.01650563915577076\n",
      "Epoch 45 num_samples 7500 loss 0.03939515280894879\n",
      "Epoch 45 num_samples 7600 loss 0.022943306479998746\n",
      "Epoch 45 num_samples 7700 loss 0.037711323861226644\n",
      "Epoch 45 num_samples 7800 loss 0.017931599807833057\n",
      "Epoch 45 num_samples 7900 loss 0.022072034417465757\n",
      "Epoch 45 num_samples 8000 loss 0.016076554103873767\n",
      "Epoch 45 num_samples 8100 loss 0.020790987750588682\n",
      "Epoch 45 num_samples 8200 loss 0.023823646460933202\n",
      "Epoch 45 num_samples 8300 loss 0.022205431444186692\n",
      "Epoch 45 num_samples 8400 loss 0.0168094251992252\n",
      "Epoch 45 num_samples 8500 loss 0.02338683364612601\n",
      "Epoch 45 num_samples 8600 loss 0.02289632489658068\n",
      "Epoch 45 num_samples 8700 loss 0.02326595553205444\n",
      "Epoch 45 num_samples 8800 loss 0.02803761044425625\n",
      "Epoch 45 num_samples 8900 loss 0.027400905617832105\n",
      "Epoch 45 num_samples 9000 loss 0.02106409948931319\n",
      "Epoch 45 num_samples 9100 loss 0.02264627928639326\n",
      "Epoch 45 num_samples 9200 loss 0.02217496200807424\n",
      "Epoch 45 num_samples 9300 loss 0.022312697409210748\n",
      "Epoch 45 num_samples 9400 loss 0.01917560503011528\n",
      "Epoch 45 num_samples 9500 loss 0.020738177796013276\n",
      "Epoch 45 num_samples 9600 loss 0.019147418642245905\n",
      "Epoch 45 num_samples 9700 loss 0.035273217603918355\n",
      "Epoch 45 num_samples 9800 loss 0.013544306453542397\n",
      "Epoch 45 num_samples 9900 loss 0.045503885110133396\n",
      "Epoch 45 num_samples 10000 loss 0.02124414155686905\n",
      "Epoch 45 num_samples 10100 loss 0.017847147239634525\n",
      "Epoch 45 num_samples 10200 loss 0.0284468809744883\n",
      "Epoch 45 num_samples 10300 loss 0.022171590233403062\n",
      "Epoch 45 num_samples 10400 loss 0.030358279038737855\n",
      "Epoch 45 num_samples 10500 loss 0.01853344057178801\n",
      "Epoch 45 num_samples 10600 loss 0.03224946468370884\n",
      "Epoch 45 num_samples 10700 loss 0.01997568674777738\n",
      "Epoch 45 num_samples 10800 loss 0.028641434243220472\n",
      "Epoch 45 num_samples 10900 loss 0.018477515239745432\n",
      "Epoch 45 num_samples 11000 loss 0.016635481702939985\n",
      "Epoch 45 num_samples 11100 loss 0.02189319572407758\n",
      "Epoch 45 num_samples 11200 loss 0.018595672204533273\n",
      "Epoch 45 num_samples 11300 loss 0.03383918886877929\n",
      "Epoch 45 num_samples 11400 loss 0.023345454922722636\n",
      "Epoch 45 num_samples 11500 loss 0.021928317352524828\n",
      "Epoch 45 num_samples 11600 loss 0.019654710727551344\n",
      "Epoch 45 num_samples 11700 loss 0.029934726399626913\n",
      "Epoch 45 num_samples 11800 loss 0.020042345879662377\n",
      "Epoch 45 num_samples 11900 loss 0.018221923419968353\n",
      "Epoch 45 num_samples 12000 loss 0.015059370837738865\n",
      "Epoch 45 num_samples 12100 loss 0.019882558271290467\n",
      "Epoch 45 num_samples 12200 loss 0.028855434918324603\n",
      "Epoch 45 num_samples 12300 loss 0.015371716287416128\n",
      "Epoch 45 num_samples 12400 loss 0.029817993319015024\n",
      "Epoch 45 num_samples 12500 loss 0.024622652587430852\n",
      "Epoch 45 num_samples 12600 loss 0.03025458362020291\n",
      "Epoch 45 num_samples 12700 loss 0.024370688896481543\n",
      "Epoch 45 num_samples 12800 loss 0.04100062471161037\n",
      "Epoch 45 num_samples 12900 loss 0.020094021743439407\n",
      "Epoch 45 num_samples 13000 loss 0.017420857409246898\n",
      "Epoch 45 num_samples 13100 loss 0.04010602627420925\n",
      "Epoch 45 num_samples 13200 loss 0.014586926450070849\n",
      "Epoch 45 num_samples 13300 loss 0.016666193229859808\n",
      "Epoch 45 num_samples 13400 loss 0.010448884853999321\n",
      "Epoch 45 num_samples 13500 loss 0.017306250797055774\n",
      "Epoch 45 num_samples 13600 loss 0.03215375976938445\n",
      "Epoch 45 num_samples 13700 loss 0.02177728059324488\n",
      "Epoch 45 num_samples 13800 loss 0.020560151126508875\n",
      "Epoch 45 num_samples 13900 loss 0.008752258485634476\n",
      "Epoch 45 num_samples 14000 loss 0.016064449334999203\n",
      "Epoch 45 num_samples 14100 loss 0.02050658044796272\n",
      "Epoch 45 num_samples 14200 loss 0.016353921836869442\n",
      "Epoch 45 num_samples 14300 loss 0.02409074388827432\n",
      "Epoch 45 num_samples 14400 loss 0.02402355304583808\n",
      "Epoch 45 num_samples 14500 loss 0.026766410233501885\n",
      "Epoch 45 num_samples 14600 loss 0.020953947012334134\n",
      "Epoch 45 num_samples 14700 loss 0.022147322240427324\n",
      "Epoch 45 num_samples 14800 loss 0.019977011073812393\n",
      "Epoch 45 num_samples 14900 loss 0.0270139534095426\n",
      "Epoch 45 num_samples 15000 loss 0.01890569645505167\n",
      "Epoch 45 num_samples 15100 loss 0.022260278751250376\n",
      "Epoch 45 num_samples 15200 loss 0.026034653915127572\n",
      "Epoch 45 num_samples 15300 loss 0.023835413425592165\n",
      "Epoch 45 num_samples 15400 loss 0.01463245972547209\n",
      "Epoch 45 num_samples 15500 loss 0.02604260751803698\n",
      "Epoch 45 num_samples 15600 loss 0.023480250903465328\n",
      "Epoch 45 num_samples 15700 loss 0.01530365809255829\n",
      "Epoch 45 num_samples 15800 loss 0.03063511559309118\n",
      "Epoch 45 num_samples 15900 loss 0.015506185402143229\n",
      "Epoch 45 num_samples 16000 loss 0.030318140794088774\n",
      "Epoch 45 num_samples 16100 loss 0.01606500530396603\n",
      "Epoch 45 num_samples 16200 loss 0.02492071440979343\n",
      "Epoch 45 num_samples 16300 loss 0.03263888141942825\n",
      "Epoch 45 num_samples 16400 loss 0.03047459931326322\n",
      "Epoch 45 num_samples 16500 loss 0.02557212094208648\n",
      "Epoch 45 num_samples 16600 loss 0.028436628772349343\n",
      "Epoch 45 num_samples 16700 loss 0.014922070752385512\n",
      "Epoch 45 num_samples 16800 loss 0.0158346109362418\n",
      "Epoch 45 num_samples 16900 loss 0.018077080673566406\n",
      "Epoch 45 num_samples 17000 loss 0.013581361406995658\n",
      "Epoch 45 num_samples 17100 loss 0.044011636718491544\n",
      "Epoch 45 num_samples 17200 loss 0.02517640378082457\n",
      "Epoch 45 num_samples 17300 loss 0.028233550364402272\n",
      "Epoch 45 num_samples 17400 loss 0.02230315953139364\n",
      "Epoch 45 num_samples 17500 loss 0.02137268843990703\n",
      "Epoch 45 num_samples 17600 loss 0.021623055551515842\n",
      "Epoch 45 num_samples 17700 loss 0.016995167947579843\n",
      "Epoch 45 num_samples 17800 loss 0.019749785467808506\n",
      "Epoch 45 num_samples 17900 loss 0.031134172719687526\n",
      "Epoch 45 num_samples 18000 loss 0.019453830021962118\n",
      "Epoch 45 num_samples 18100 loss 0.022216771735959068\n",
      "Epoch 45 num_samples 18200 loss 0.02394646143063885\n",
      "Epoch 45 num_samples 18300 loss 0.018040124754482495\n",
      "Epoch 45 num_samples 18400 loss 0.036444882480576216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 num_samples 18500 loss 0.02397637238715511\n",
      "Epoch 46 num_samples 0 loss 0.01709346700387817\n",
      "Epoch 46 num_samples 100 loss 0.031018153919366433\n",
      "Epoch 46 num_samples 200 loss 0.01924106267549486\n",
      "Epoch 46 num_samples 300 loss 0.016464897500866077\n",
      "Epoch 46 num_samples 400 loss 0.019130408997350003\n",
      "Epoch 46 num_samples 500 loss 0.027882398080329888\n",
      "Epoch 46 num_samples 600 loss 0.032945547010722054\n",
      "Epoch 46 num_samples 700 loss 0.032742853731748685\n",
      "Epoch 46 num_samples 800 loss 0.02073487670996052\n",
      "Epoch 46 num_samples 900 loss 0.03238336212890523\n",
      "Epoch 46 num_samples 1000 loss 0.020078396643433073\n",
      "Epoch 46 num_samples 1100 loss 0.035694359964570016\n",
      "Epoch 46 num_samples 1200 loss 0.02050077685401313\n",
      "Epoch 46 num_samples 1300 loss 0.022992172991283165\n",
      "Epoch 46 num_samples 1400 loss 0.02649299758215535\n",
      "Epoch 46 num_samples 1500 loss 0.037559088280295604\n",
      "Epoch 46 num_samples 1600 loss 0.020803656485812737\n",
      "Epoch 46 num_samples 1700 loss 0.01960821894717087\n",
      "Epoch 46 num_samples 1800 loss 0.01988499618958734\n",
      "Epoch 46 num_samples 1900 loss 0.022871153094603986\n",
      "Epoch 46 num_samples 2000 loss 0.027222500858323128\n",
      "Epoch 46 num_samples 2100 loss 0.0148094167290447\n",
      "Epoch 46 num_samples 2200 loss 0.016238448902571267\n",
      "Epoch 46 num_samples 2300 loss 0.010892732311249426\n",
      "Epoch 46 num_samples 2400 loss 0.01929414219941665\n",
      "Epoch 46 num_samples 2500 loss 0.026502472809646883\n",
      "Epoch 46 num_samples 2600 loss 0.028286262234309963\n",
      "Epoch 46 num_samples 2700 loss 0.01917338697513087\n",
      "Epoch 46 num_samples 2800 loss 0.029362547310500312\n",
      "Epoch 46 num_samples 2900 loss 0.025721144475187224\n",
      "Epoch 46 num_samples 3000 loss 0.021717242500313087\n",
      "Epoch 46 num_samples 3100 loss 0.02057632289896982\n",
      "Epoch 46 num_samples 3200 loss 0.0529278555881808\n",
      "Epoch 46 num_samples 3300 loss 0.024549691077796226\n",
      "Epoch 46 num_samples 3400 loss 0.017477685134320197\n",
      "Epoch 46 num_samples 3500 loss 0.017996839552994356\n",
      "Epoch 46 num_samples 3600 loss 0.012324723173707107\n",
      "Epoch 46 num_samples 3700 loss 0.034222854215132464\n",
      "Epoch 46 num_samples 3800 loss 0.020571494049643927\n",
      "Epoch 46 num_samples 3900 loss 0.02374988355186713\n",
      "Epoch 46 num_samples 4000 loss 0.027372679041370883\n",
      "Epoch 46 num_samples 4100 loss 0.03927990729816182\n",
      "Epoch 46 num_samples 4200 loss 0.021798188177392572\n",
      "Epoch 46 num_samples 4300 loss 0.02207202866573107\n",
      "Epoch 46 num_samples 4400 loss 0.027122429261265443\n",
      "Epoch 46 num_samples 4500 loss 0.030650889847738304\n",
      "Epoch 46 num_samples 4600 loss 0.0238317082575314\n",
      "Epoch 46 num_samples 4700 loss 0.01428133085936689\n",
      "Epoch 46 num_samples 4800 loss 0.014041192583143087\n",
      "Epoch 46 num_samples 4900 loss 0.017485308062803417\n",
      "Epoch 46 num_samples 5000 loss 0.016721631507259985\n",
      "Epoch 46 num_samples 5100 loss 0.02933641261026688\n",
      "Epoch 46 num_samples 5200 loss 0.014644598294001127\n",
      "Epoch 46 num_samples 5300 loss 0.01994421181451631\n",
      "Epoch 46 num_samples 5400 loss 0.026145853236854734\n",
      "Epoch 46 num_samples 5500 loss 0.015066534308048184\n",
      "Epoch 46 num_samples 5600 loss 0.07137157279544935\n",
      "Epoch 46 num_samples 5700 loss 0.02621347984585953\n",
      "Epoch 46 num_samples 5800 loss 0.022106631722623896\n",
      "Epoch 46 num_samples 5900 loss 0.02685412723579164\n",
      "Epoch 46 num_samples 6000 loss 0.022095598337259985\n",
      "Epoch 46 num_samples 6100 loss 0.019207539389200404\n",
      "Epoch 46 num_samples 6200 loss 0.023413908264044624\n",
      "Epoch 46 num_samples 6300 loss 0.032705437947055854\n",
      "Epoch 46 num_samples 6400 loss 0.017828728732245114\n",
      "Epoch 46 num_samples 6500 loss 0.016374940385298294\n",
      "Epoch 46 num_samples 6600 loss 0.03342564636791647\n",
      "Epoch 46 num_samples 6700 loss 0.01688443661325467\n",
      "Epoch 46 num_samples 6800 loss 0.011587868738790244\n",
      "Epoch 46 num_samples 6900 loss 0.044858518245834936\n",
      "Epoch 46 num_samples 7000 loss 0.028644843786774968\n",
      "Epoch 46 num_samples 7100 loss 0.01524623882634006\n",
      "Epoch 46 num_samples 7200 loss 0.0207706330494312\n",
      "Epoch 46 num_samples 7300 loss 0.01927768917458364\n",
      "Epoch 46 num_samples 7400 loss 0.015757005239102166\n",
      "Epoch 46 num_samples 7500 loss 0.03764165592655749\n",
      "Epoch 46 num_samples 7600 loss 0.021991917792962248\n",
      "Epoch 46 num_samples 7700 loss 0.03585606007445597\n",
      "Epoch 46 num_samples 7800 loss 0.017197990962311813\n",
      "Epoch 46 num_samples 7900 loss 0.02135192141232668\n",
      "Epoch 46 num_samples 8000 loss 0.015384121851337772\n",
      "Epoch 46 num_samples 8100 loss 0.020044093867027282\n",
      "Epoch 46 num_samples 8200 loss 0.02264919527119112\n",
      "Epoch 46 num_samples 8300 loss 0.021096967606907366\n",
      "Epoch 46 num_samples 8400 loss 0.016072136371912907\n",
      "Epoch 46 num_samples 8500 loss 0.0225647633334619\n",
      "Epoch 46 num_samples 8600 loss 0.02189477830626444\n",
      "Epoch 46 num_samples 8700 loss 0.02215469487269732\n",
      "Epoch 46 num_samples 8800 loss 0.026311450186966158\n",
      "Epoch 46 num_samples 8900 loss 0.026200663817080496\n",
      "Epoch 46 num_samples 9000 loss 0.020198812288847304\n",
      "Epoch 46 num_samples 9100 loss 0.02177062164168296\n",
      "Epoch 46 num_samples 9200 loss 0.02117105156654596\n",
      "Epoch 46 num_samples 9300 loss 0.02140104097503082\n",
      "Epoch 46 num_samples 9400 loss 0.018290387595956293\n",
      "Epoch 46 num_samples 9500 loss 0.019771423058600763\n",
      "Epoch 46 num_samples 9600 loss 0.01841820826776025\n",
      "Epoch 46 num_samples 9700 loss 0.033719885778014505\n",
      "Epoch 46 num_samples 9800 loss 0.01297909859627807\n",
      "Epoch 46 num_samples 9900 loss 0.04332651118322916\n",
      "Epoch 46 num_samples 10000 loss 0.02020333105653842\n",
      "Epoch 46 num_samples 10100 loss 0.01717596593313894\n",
      "Epoch 46 num_samples 10200 loss 0.02701764554141923\n",
      "Epoch 46 num_samples 10300 loss 0.021270579052587647\n",
      "Epoch 46 num_samples 10400 loss 0.0289727445434748\n",
      "Epoch 46 num_samples 10500 loss 0.017837153999447707\n",
      "Epoch 46 num_samples 10600 loss 0.030406281530365155\n",
      "Epoch 46 num_samples 10700 loss 0.0192219650733904\n",
      "Epoch 46 num_samples 10800 loss 0.026780365122440242\n",
      "Epoch 46 num_samples 10900 loss 0.01777760487861524\n",
      "Epoch 46 num_samples 11000 loss 0.016044343246773916\n",
      "Epoch 46 num_samples 11100 loss 0.02102733507990365\n",
      "Epoch 46 num_samples 11200 loss 0.017692462707531907\n",
      "Epoch 46 num_samples 11300 loss 0.03217697336200117\n",
      "Epoch 46 num_samples 11400 loss 0.02229176461577688\n",
      "Epoch 46 num_samples 11500 loss 0.020979507445211983\n",
      "Epoch 46 num_samples 11600 loss 0.018775764456699182\n",
      "Epoch 46 num_samples 11700 loss 0.028641145456056588\n",
      "Epoch 46 num_samples 11800 loss 0.019054014513370677\n",
      "Epoch 46 num_samples 11900 loss 0.01744532990339592\n",
      "Epoch 46 num_samples 12000 loss 0.014480416946552437\n",
      "Epoch 46 num_samples 12100 loss 0.018764838267639444\n",
      "Epoch 46 num_samples 12200 loss 0.0273828062896861\n",
      "Epoch 46 num_samples 12300 loss 0.01469982156452574\n",
      "Epoch 46 num_samples 12400 loss 0.028224291966517524\n",
      "Epoch 46 num_samples 12500 loss 0.023666200014254478\n",
      "Epoch 46 num_samples 12600 loss 0.029013629948955923\n",
      "Epoch 46 num_samples 12700 loss 0.023282190807963236\n",
      "Epoch 46 num_samples 12800 loss 0.03915847510762176\n",
      "Epoch 46 num_samples 12900 loss 0.019243948775905188\n",
      "Epoch 46 num_samples 13000 loss 0.016575475262547948\n",
      "Epoch 46 num_samples 13100 loss 0.03709925585945825\n",
      "Epoch 46 num_samples 13200 loss 0.013896034561004982\n",
      "Epoch 46 num_samples 13300 loss 0.015883676114793254\n",
      "Epoch 46 num_samples 13400 loss 0.010017175253849882\n",
      "Epoch 46 num_samples 13500 loss 0.01645117859208224\n",
      "Epoch 46 num_samples 13600 loss 0.030311097695833147\n",
      "Epoch 46 num_samples 13700 loss 0.021100394812589567\n",
      "Epoch 46 num_samples 13800 loss 0.019673366221500465\n",
      "Epoch 46 num_samples 13900 loss 0.008346021755226626\n",
      "Epoch 46 num_samples 14000 loss 0.015288526180437585\n",
      "Epoch 46 num_samples 14100 loss 0.01952765440196056\n",
      "Epoch 46 num_samples 14200 loss 0.0157924792057835\n",
      "Epoch 46 num_samples 14300 loss 0.02311340903748124\n",
      "Epoch 46 num_samples 14400 loss 0.023082906311230875\n",
      "Epoch 46 num_samples 14500 loss 0.025784304265323313\n",
      "Epoch 46 num_samples 14600 loss 0.020075318288855355\n",
      "Epoch 46 num_samples 14700 loss 0.021181612961619932\n",
      "Epoch 46 num_samples 14800 loss 0.01927436430185934\n",
      "Epoch 46 num_samples 14900 loss 0.025616412780589543\n",
      "Epoch 46 num_samples 15000 loss 0.01816659411441578\n",
      "Epoch 46 num_samples 15100 loss 0.02140824342137936\n",
      "Epoch 46 num_samples 15200 loss 0.024747816203683798\n",
      "Epoch 46 num_samples 15300 loss 0.02297552188928745\n",
      "Epoch 46 num_samples 15400 loss 0.014074651574433843\n",
      "Epoch 46 num_samples 15500 loss 0.02473024905958505\n",
      "Epoch 46 num_samples 15600 loss 0.022699884163377555\n",
      "Epoch 46 num_samples 15700 loss 0.01482804002449453\n",
      "Epoch 46 num_samples 15800 loss 0.029185400802873778\n",
      "Epoch 46 num_samples 15900 loss 0.014914534084104114\n",
      "Epoch 46 num_samples 16000 loss 0.029028107557400377\n",
      "Epoch 46 num_samples 16100 loss 0.01539622975456648\n",
      "Epoch 46 num_samples 16200 loss 0.023824336112088708\n",
      "Epoch 46 num_samples 16300 loss 0.03093684985716018\n",
      "Epoch 46 num_samples 16400 loss 0.02920892226044449\n",
      "Epoch 46 num_samples 16500 loss 0.024496659263158742\n",
      "Epoch 46 num_samples 16600 loss 0.027128220767941018\n",
      "Epoch 46 num_samples 16700 loss 0.014363001466089152\n",
      "Epoch 46 num_samples 16800 loss 0.015120396913256508\n",
      "Epoch 46 num_samples 16900 loss 0.017309299362045557\n",
      "Epoch 46 num_samples 17000 loss 0.013080464593972219\n",
      "Epoch 46 num_samples 17100 loss 0.04136197245942538\n",
      "Epoch 46 num_samples 17200 loss 0.02419138848031199\n",
      "Epoch 46 num_samples 17300 loss 0.02708450572354076\n",
      "Epoch 46 num_samples 17400 loss 0.021583795189672673\n",
      "Epoch 46 num_samples 17500 loss 0.0205642149967326\n",
      "Epoch 46 num_samples 17600 loss 0.020684458562862548\n",
      "Epoch 46 num_samples 17700 loss 0.016155659307344274\n",
      "Epoch 46 num_samples 17800 loss 0.018725218832426668\n",
      "Epoch 46 num_samples 17900 loss 0.02962680360048678\n",
      "Epoch 46 num_samples 18000 loss 0.018672815794580137\n",
      "Epoch 46 num_samples 18100 loss 0.021218887785263894\n",
      "Epoch 46 num_samples 18200 loss 0.022857142340839208\n",
      "Epoch 46 num_samples 18300 loss 0.017224631243686308\n",
      "Epoch 46 num_samples 18400 loss 0.0347530847695521\n",
      "Epoch 46 num_samples 18500 loss 0.022924111999733425\n",
      "Epoch 47 num_samples 0 loss 0.016166118540439662\n",
      "Epoch 47 num_samples 100 loss 0.02954926360970343\n",
      "Epoch 47 num_samples 200 loss 0.018403393901504646\n",
      "Epoch 47 num_samples 300 loss 0.0158829158424898\n",
      "Epoch 47 num_samples 400 loss 0.01822036147144631\n",
      "Epoch 47 num_samples 500 loss 0.02683983601770652\n",
      "Epoch 47 num_samples 600 loss 0.031205516091594467\n",
      "Epoch 47 num_samples 700 loss 0.03137114889437221\n",
      "Epoch 47 num_samples 800 loss 0.019769989064831343\n",
      "Epoch 47 num_samples 900 loss 0.03137829664719028\n",
      "Epoch 47 num_samples 1000 loss 0.01919320930893694\n",
      "Epoch 47 num_samples 1100 loss 0.0341789526328001\n",
      "Epoch 47 num_samples 1200 loss 0.01953891520234087\n",
      "Epoch 47 num_samples 1300 loss 0.02205638271719554\n",
      "Epoch 47 num_samples 1400 loss 0.025194712596020175\n",
      "Epoch 47 num_samples 1500 loss 0.03533317706899299\n",
      "Epoch 47 num_samples 1600 loss 0.020134920312152013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 num_samples 1700 loss 0.018867370532113098\n",
      "Epoch 47 num_samples 1800 loss 0.018998031454060857\n",
      "Epoch 47 num_samples 1900 loss 0.021992634707594157\n",
      "Epoch 47 num_samples 2000 loss 0.02603089665972888\n",
      "Epoch 47 num_samples 2100 loss 0.014116851175694738\n",
      "Epoch 47 num_samples 2200 loss 0.015566867997695957\n",
      "Epoch 47 num_samples 2300 loss 0.010433853243440656\n",
      "Epoch 47 num_samples 2400 loss 0.018522180071403573\n",
      "Epoch 47 num_samples 2500 loss 0.025128269224717958\n",
      "Epoch 47 num_samples 2600 loss 0.026946249455810305\n",
      "Epoch 47 num_samples 2700 loss 0.018291591601407177\n",
      "Epoch 47 num_samples 2800 loss 0.02808706825143749\n",
      "Epoch 47 num_samples 2900 loss 0.02459282503619633\n",
      "Epoch 47 num_samples 3000 loss 0.0210209918444092\n",
      "Epoch 47 num_samples 3100 loss 0.019770336601339623\n",
      "Epoch 47 num_samples 3200 loss 0.04951257537865484\n",
      "Epoch 47 num_samples 3300 loss 0.023359738178532458\n",
      "Epoch 47 num_samples 3400 loss 0.01676114795077814\n",
      "Epoch 47 num_samples 3500 loss 0.017266339863724233\n",
      "Epoch 47 num_samples 3600 loss 0.01176930070553202\n",
      "Epoch 47 num_samples 3700 loss 0.0327666373098803\n",
      "Epoch 47 num_samples 3800 loss 0.019624004102560363\n",
      "Epoch 47 num_samples 3900 loss 0.02246413274108254\n",
      "Epoch 47 num_samples 4000 loss 0.026360469813442148\n",
      "Epoch 47 num_samples 4100 loss 0.03729282461585889\n",
      "Epoch 47 num_samples 4200 loss 0.020890386437028494\n",
      "Epoch 47 num_samples 4300 loss 0.020878387490277657\n",
      "Epoch 47 num_samples 4400 loss 0.026121309308672527\n",
      "Epoch 47 num_samples 4500 loss 0.029354518869576855\n",
      "Epoch 47 num_samples 4600 loss 0.022658843523692053\n",
      "Epoch 47 num_samples 4700 loss 0.013874573903260787\n",
      "Epoch 47 num_samples 4800 loss 0.013538555495952882\n",
      "Epoch 47 num_samples 4900 loss 0.016783856341028358\n",
      "Epoch 47 num_samples 5000 loss 0.01595471328415725\n",
      "Epoch 47 num_samples 5100 loss 0.028137226151845312\n",
      "Epoch 47 num_samples 5200 loss 0.01407928096598275\n",
      "Epoch 47 num_samples 5300 loss 0.01921243866628432\n",
      "Epoch 47 num_samples 5400 loss 0.025009599795498594\n",
      "Epoch 47 num_samples 5500 loss 0.014433129520233678\n",
      "Epoch 47 num_samples 5600 loss 0.06814498358892904\n",
      "Epoch 47 num_samples 5700 loss 0.024299403831010896\n",
      "Epoch 47 num_samples 5800 loss 0.021055683658082556\n",
      "Epoch 47 num_samples 5900 loss 0.025528546818735797\n",
      "Epoch 47 num_samples 6000 loss 0.02105384392945914\n",
      "Epoch 47 num_samples 6100 loss 0.018343662109992595\n",
      "Epoch 47 num_samples 6200 loss 0.022453818045454807\n",
      "Epoch 47 num_samples 6300 loss 0.030928560266021296\n",
      "Epoch 47 num_samples 6400 loss 0.017007870556311738\n",
      "Epoch 47 num_samples 6500 loss 0.01559176211849726\n",
      "Epoch 47 num_samples 6600 loss 0.032165550009015165\n",
      "Epoch 47 num_samples 6700 loss 0.016354911310573608\n",
      "Epoch 47 num_samples 6800 loss 0.011174932934340232\n",
      "Epoch 47 num_samples 6900 loss 0.042971866648071025\n",
      "Epoch 47 num_samples 7000 loss 0.027426294167683638\n",
      "Epoch 47 num_samples 7100 loss 0.01463864533378826\n",
      "Epoch 47 num_samples 7200 loss 0.019891230791375388\n",
      "Epoch 47 num_samples 7300 loss 0.01854412153216702\n",
      "Epoch 47 num_samples 7400 loss 0.015001574453492972\n",
      "Epoch 47 num_samples 7500 loss 0.03602375892101826\n",
      "Epoch 47 num_samples 7600 loss 0.021172027305017913\n",
      "Epoch 47 num_samples 7700 loss 0.03403859452678565\n",
      "Epoch 47 num_samples 7800 loss 0.01664654198617379\n",
      "Epoch 47 num_samples 7900 loss 0.020420002847291438\n",
      "Epoch 47 num_samples 8000 loss 0.014849371381303454\n",
      "Epoch 47 num_samples 8100 loss 0.019228434466756473\n",
      "Epoch 47 num_samples 8200 loss 0.021962543897988098\n",
      "Epoch 47 num_samples 8300 loss 0.020120832792820974\n",
      "Epoch 47 num_samples 8400 loss 0.015328424547338444\n",
      "Epoch 47 num_samples 8500 loss 0.021503830499813387\n",
      "Epoch 47 num_samples 8600 loss 0.021109454506017093\n",
      "Epoch 47 num_samples 8700 loss 0.021194904504149584\n",
      "Epoch 47 num_samples 8800 loss 0.02479518247669306\n",
      "Epoch 47 num_samples 8900 loss 0.025309128765882812\n",
      "Epoch 47 num_samples 9000 loss 0.019519547187883353\n",
      "Epoch 47 num_samples 9100 loss 0.020779894363728138\n",
      "Epoch 47 num_samples 9200 loss 0.020501730737348352\n",
      "Epoch 47 num_samples 9300 loss 0.0206378442776413\n",
      "Epoch 47 num_samples 9400 loss 0.01750382130305979\n",
      "Epoch 47 num_samples 9500 loss 0.01882702761666475\n",
      "Epoch 47 num_samples 9600 loss 0.01760246005671001\n",
      "Epoch 47 num_samples 9700 loss 0.0324009295117527\n",
      "Epoch 47 num_samples 9800 loss 0.012455482501998833\n",
      "Epoch 47 num_samples 9900 loss 0.0412323402359492\n",
      "Epoch 47 num_samples 10000 loss 0.019342036120109672\n",
      "Epoch 47 num_samples 10100 loss 0.016531431432638244\n",
      "Epoch 47 num_samples 10200 loss 0.026002008810776682\n",
      "Epoch 47 num_samples 10300 loss 0.020207319533861106\n",
      "Epoch 47 num_samples 10400 loss 0.027623289362911353\n",
      "Epoch 47 num_samples 10500 loss 0.017144104128387103\n",
      "Epoch 47 num_samples 10600 loss 0.028622029476684078\n",
      "Epoch 47 num_samples 10700 loss 0.01852056547244523\n",
      "Epoch 47 num_samples 10800 loss 0.025393505866551633\n",
      "Epoch 47 num_samples 10900 loss 0.017054538556234764\n",
      "Epoch 47 num_samples 11000 loss 0.01536446324841698\n",
      "Epoch 47 num_samples 11100 loss 0.020286420966083515\n",
      "Epoch 47 num_samples 11200 loss 0.017017468888115842\n",
      "Epoch 47 num_samples 11300 loss 0.03040286179423887\n",
      "Epoch 47 num_samples 11400 loss 0.021164752673826333\n",
      "Epoch 47 num_samples 11500 loss 0.020037167940393938\n",
      "Epoch 47 num_samples 11600 loss 0.01813260120118573\n",
      "Epoch 47 num_samples 11700 loss 0.02740291759228625\n",
      "Epoch 47 num_samples 11800 loss 0.018429019232294876\n",
      "Epoch 47 num_samples 11900 loss 0.016741071257398304\n",
      "Epoch 47 num_samples 12000 loss 0.013851979396875345\n",
      "Epoch 47 num_samples 12100 loss 0.017625894792434822\n",
      "Epoch 47 num_samples 12200 loss 0.026232865970963457\n",
      "Epoch 47 num_samples 12300 loss 0.014314023203886538\n",
      "Epoch 47 num_samples 12400 loss 0.027244085298227222\n",
      "Epoch 47 num_samples 12500 loss 0.022721813891178524\n",
      "Epoch 47 num_samples 12600 loss 0.027715403561231047\n",
      "Epoch 47 num_samples 12700 loss 0.022220594539603313\n",
      "Epoch 47 num_samples 12800 loss 0.03741040150936528\n",
      "Epoch 47 num_samples 12900 loss 0.018502259589081495\n",
      "Epoch 47 num_samples 13000 loss 0.01584566099001558\n",
      "Epoch 47 num_samples 13100 loss 0.03453345270282869\n",
      "Epoch 47 num_samples 13200 loss 0.013252316664936417\n",
      "Epoch 47 num_samples 13300 loss 0.015306864263652489\n",
      "Epoch 47 num_samples 13400 loss 0.009650057243948115\n",
      "Epoch 47 num_samples 13500 loss 0.015842113490438504\n",
      "Epoch 47 num_samples 13600 loss 0.02910857267445574\n",
      "Epoch 47 num_samples 13700 loss 0.020035002721634297\n",
      "Epoch 47 num_samples 13800 loss 0.018746664994927983\n",
      "Epoch 47 num_samples 13900 loss 0.007987254491208646\n",
      "Epoch 47 num_samples 14000 loss 0.014744561997086968\n",
      "Epoch 47 num_samples 14100 loss 0.018794310105485098\n",
      "Epoch 47 num_samples 14200 loss 0.015206913633299552\n",
      "Epoch 47 num_samples 14300 loss 0.022272540400944885\n",
      "Epoch 47 num_samples 14400 loss 0.022019349619009847\n",
      "Epoch 47 num_samples 14500 loss 0.02489345138939238\n",
      "Epoch 47 num_samples 14600 loss 0.019283570474597802\n",
      "Epoch 47 num_samples 14700 loss 0.02036342776885469\n",
      "Epoch 47 num_samples 14800 loss 0.01847652674209165\n",
      "Epoch 47 num_samples 14900 loss 0.02435826879369141\n",
      "Epoch 47 num_samples 15000 loss 0.017390573860091\n",
      "Epoch 47 num_samples 15100 loss 0.0204935076208321\n",
      "Epoch 47 num_samples 15200 loss 0.023390913440467846\n",
      "Epoch 47 num_samples 15300 loss 0.022163381397867478\n",
      "Epoch 47 num_samples 15400 loss 0.013537793004410182\n",
      "Epoch 47 num_samples 15500 loss 0.023394837218230026\n",
      "Epoch 47 num_samples 15600 loss 0.021987702145274485\n",
      "Epoch 47 num_samples 15700 loss 0.014225619064363332\n",
      "Epoch 47 num_samples 15800 loss 0.027645411093700608\n",
      "Epoch 47 num_samples 15900 loss 0.014345709988508069\n",
      "Epoch 47 num_samples 16000 loss 0.028051976217082792\n",
      "Epoch 47 num_samples 16100 loss 0.014763530395234956\n",
      "Epoch 47 num_samples 16200 loss 0.022727856670045447\n",
      "Epoch 47 num_samples 16300 loss 0.029425789683367308\n",
      "Epoch 47 num_samples 16400 loss 0.02802826627777801\n",
      "Epoch 47 num_samples 16500 loss 0.023635664526494488\n",
      "Epoch 47 num_samples 16600 loss 0.025869813320903413\n",
      "Epoch 47 num_samples 16700 loss 0.013675667414127912\n",
      "Epoch 47 num_samples 16800 loss 0.014371375669787783\n",
      "Epoch 47 num_samples 16900 loss 0.016669657978991118\n",
      "Epoch 47 num_samples 17000 loss 0.012493498542742234\n",
      "Epoch 47 num_samples 17100 loss 0.03907909315794026\n",
      "Epoch 47 num_samples 17200 loss 0.023116340364529125\n",
      "Epoch 47 num_samples 17300 loss 0.025687641745495534\n",
      "Epoch 47 num_samples 17400 loss 0.020575269142694256\n",
      "Epoch 47 num_samples 17500 loss 0.019795932293092133\n",
      "Epoch 47 num_samples 17600 loss 0.019739522105893546\n",
      "Epoch 47 num_samples 17700 loss 0.015470730848896825\n",
      "Epoch 47 num_samples 17800 loss 0.017809498366896798\n",
      "Epoch 47 num_samples 17900 loss 0.02817915246164807\n",
      "Epoch 47 num_samples 18000 loss 0.01791346042554051\n",
      "Epoch 47 num_samples 18100 loss 0.02039113895894797\n",
      "Epoch 47 num_samples 18200 loss 0.02178160584488976\n",
      "Epoch 47 num_samples 18300 loss 0.016421456302438155\n",
      "Epoch 47 num_samples 18400 loss 0.03305973865041105\n",
      "Epoch 47 num_samples 18500 loss 0.0220267532213024\n",
      "Epoch 48 num_samples 0 loss 0.015537111377631781\n",
      "Epoch 48 num_samples 100 loss 0.02828128245195269\n",
      "Epoch 48 num_samples 200 loss 0.017734404222551025\n",
      "Epoch 48 num_samples 300 loss 0.015143482454276838\n",
      "Epoch 48 num_samples 400 loss 0.01765801853399692\n",
      "Epoch 48 num_samples 500 loss 0.025901317040093633\n",
      "Epoch 48 num_samples 600 loss 0.030171230387356904\n",
      "Epoch 48 num_samples 700 loss 0.030124242065494748\n",
      "Epoch 48 num_samples 800 loss 0.018786913305731047\n",
      "Epoch 48 num_samples 900 loss 0.03015848495376835\n",
      "Epoch 48 num_samples 1000 loss 0.018388314564629266\n",
      "Epoch 48 num_samples 1100 loss 0.03291078233178546\n",
      "Epoch 48 num_samples 1200 loss 0.018726494425808912\n",
      "Epoch 48 num_samples 1300 loss 0.02125358117201104\n",
      "Epoch 48 num_samples 1400 loss 0.024168227886941385\n",
      "Epoch 48 num_samples 1500 loss 0.03322894324427357\n",
      "Epoch 48 num_samples 1600 loss 0.019073971342804585\n",
      "Epoch 48 num_samples 1700 loss 0.01811567177976916\n",
      "Epoch 48 num_samples 1800 loss 0.018215064658475926\n",
      "Epoch 48 num_samples 1900 loss 0.0210751564786735\n",
      "Epoch 48 num_samples 2000 loss 0.02505403967709177\n",
      "Epoch 48 num_samples 2100 loss 0.013510716795196187\n",
      "Epoch 48 num_samples 2200 loss 0.014946143533291661\n",
      "Epoch 48 num_samples 2300 loss 0.01004786854487251\n",
      "Epoch 48 num_samples 2400 loss 0.017721333774362764\n",
      "Epoch 48 num_samples 2500 loss 0.024199331860795547\n",
      "Epoch 48 num_samples 2600 loss 0.025784776476597653\n",
      "Epoch 48 num_samples 2700 loss 0.017629042776180652\n",
      "Epoch 48 num_samples 2800 loss 0.027039227408370375\n",
      "Epoch 48 num_samples 2900 loss 0.02360234012563025\n",
      "Epoch 48 num_samples 3000 loss 0.020063837940401372\n",
      "Epoch 48 num_samples 3100 loss 0.018788044477567326\n",
      "Epoch 48 num_samples 3200 loss 0.04583493219366728\n",
      "Epoch 48 num_samples 3300 loss 0.022261915408953198\n",
      "Epoch 48 num_samples 3400 loss 0.01614833568678812\n",
      "Epoch 48 num_samples 3500 loss 0.016585431558859755\n",
      "Epoch 48 num_samples 3600 loss 0.011400449463486227\n",
      "Epoch 48 num_samples 3700 loss 0.03139392199399138\n",
      "Epoch 48 num_samples 3800 loss 0.018625550046873808\n",
      "Epoch 48 num_samples 3900 loss 0.021654587728478537\n",
      "Epoch 48 num_samples 4000 loss 0.0250978161558305\n",
      "Epoch 48 num_samples 4100 loss 0.03536631831959635\n",
      "Epoch 48 num_samples 4200 loss 0.02011104161918312\n",
      "Epoch 48 num_samples 4300 loss 0.019999806181889606\n",
      "Epoch 48 num_samples 4400 loss 0.024587286547683523\n",
      "Epoch 48 num_samples 4500 loss 0.027983341743442365\n",
      "Epoch 48 num_samples 4600 loss 0.02181183145292426\n",
      "Epoch 48 num_samples 4700 loss 0.013354160737117522\n",
      "Epoch 48 num_samples 4800 loss 0.013033700520238573\n",
      "Epoch 48 num_samples 4900 loss 0.01621654131743194\n",
      "Epoch 48 num_samples 5000 loss 0.015240848299896885\n",
      "Epoch 48 num_samples 5100 loss 0.026987057123236888\n",
      "Epoch 48 num_samples 5200 loss 0.013571923033240845\n",
      "Epoch 48 num_samples 5300 loss 0.01840580202904552\n",
      "Epoch 48 num_samples 5400 loss 0.023944539053907154\n",
      "Epoch 48 num_samples 5500 loss 0.013837655686088954\n",
      "Epoch 48 num_samples 5600 loss 0.0651546125807998\n",
      "Epoch 48 num_samples 5700 loss 0.023158884110424396\n",
      "Epoch 48 num_samples 5800 loss 0.020030818965074398\n",
      "Epoch 48 num_samples 5900 loss 0.02449089306084999\n",
      "Epoch 48 num_samples 6000 loss 0.02022745349814606\n",
      "Epoch 48 num_samples 6100 loss 0.017733447775588863\n",
      "Epoch 48 num_samples 6200 loss 0.021574472540648922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 num_samples 6300 loss 0.029428354242038015\n",
      "Epoch 48 num_samples 6400 loss 0.016301206104720765\n",
      "Epoch 48 num_samples 6500 loss 0.014940055575803824\n",
      "Epoch 48 num_samples 6600 loss 0.0310858644628283\n",
      "Epoch 48 num_samples 6700 loss 0.015763138893580657\n",
      "Epoch 48 num_samples 6800 loss 0.010671666408995376\n",
      "Epoch 48 num_samples 6900 loss 0.04135797462963218\n",
      "Epoch 48 num_samples 7000 loss 0.02622057816964049\n",
      "Epoch 48 num_samples 7100 loss 0.013920334317777852\n",
      "Epoch 48 num_samples 7200 loss 0.01918378195260801\n",
      "Epoch 48 num_samples 7300 loss 0.01792584241110646\n",
      "Epoch 48 num_samples 7400 loss 0.014519126379816555\n",
      "Epoch 48 num_samples 7500 loss 0.03446723461738277\n",
      "Epoch 48 num_samples 7600 loss 0.020387647638783868\n",
      "Epoch 48 num_samples 7700 loss 0.032273202904685244\n",
      "Epoch 48 num_samples 7800 loss 0.01604090739630248\n",
      "Epoch 48 num_samples 7900 loss 0.019596375157173173\n",
      "Epoch 48 num_samples 8000 loss 0.014141974055234586\n",
      "Epoch 48 num_samples 8100 loss 0.018308059873741844\n",
      "Epoch 48 num_samples 8200 loss 0.021045843877376402\n",
      "Epoch 48 num_samples 8300 loss 0.018901095602706933\n",
      "Epoch 48 num_samples 8400 loss 0.014670977035719308\n",
      "Epoch 48 num_samples 8500 loss 0.020636245178353316\n",
      "Epoch 48 num_samples 8600 loss 0.020325561119111227\n",
      "Epoch 48 num_samples 8700 loss 0.020418925456431807\n",
      "Epoch 48 num_samples 8800 loss 0.023127272755105604\n",
      "Epoch 48 num_samples 8900 loss 0.02426294341036991\n",
      "Epoch 48 num_samples 9000 loss 0.018754054824456468\n",
      "Epoch 48 num_samples 9100 loss 0.020100532742461395\n",
      "Epoch 48 num_samples 9200 loss 0.019721975563982665\n",
      "Epoch 48 num_samples 9300 loss 0.019664825080065076\n",
      "Epoch 48 num_samples 9400 loss 0.016880578461308665\n",
      "Epoch 48 num_samples 9500 loss 0.01790015014711027\n",
      "Epoch 48 num_samples 9600 loss 0.01701302364044111\n",
      "Epoch 48 num_samples 9700 loss 0.0309796746033437\n",
      "Epoch 48 num_samples 9800 loss 0.012015427315667475\n",
      "Epoch 48 num_samples 9900 loss 0.03951219075500286\n",
      "Epoch 48 num_samples 10000 loss 0.018405882007594153\n",
      "Epoch 48 num_samples 10100 loss 0.015834347981320995\n",
      "Epoch 48 num_samples 10200 loss 0.024770098996269523\n",
      "Epoch 48 num_samples 10300 loss 0.01931602219683499\n",
      "Epoch 48 num_samples 10400 loss 0.026372491103312898\n",
      "Epoch 48 num_samples 10500 loss 0.01648394658795257\n",
      "Epoch 48 num_samples 10600 loss 0.027092049020222653\n",
      "Epoch 48 num_samples 10700 loss 0.017957243045012276\n",
      "Epoch 48 num_samples 10800 loss 0.024208291915789205\n",
      "Epoch 48 num_samples 10900 loss 0.016292141769771184\n",
      "Epoch 48 num_samples 11000 loss 0.014880766214228172\n",
      "Epoch 48 num_samples 11100 loss 0.019371612931075647\n",
      "Epoch 48 num_samples 11200 loss 0.016263217795960273\n",
      "Epoch 48 num_samples 11300 loss 0.028970113392545772\n",
      "Epoch 48 num_samples 11400 loss 0.020148444106172784\n",
      "Epoch 48 num_samples 11500 loss 0.019093660239462348\n",
      "Epoch 48 num_samples 11600 loss 0.017175849786099852\n",
      "Epoch 48 num_samples 11700 loss 0.026287450778496285\n",
      "Epoch 48 num_samples 11800 loss 0.017521569363610257\n",
      "Epoch 48 num_samples 11900 loss 0.0160040978802838\n",
      "Epoch 48 num_samples 12000 loss 0.013319577355457279\n",
      "Epoch 48 num_samples 12100 loss 0.016583919078268797\n",
      "Epoch 48 num_samples 12200 loss 0.02491687119280767\n",
      "Epoch 48 num_samples 12300 loss 0.01381833947001986\n",
      "Epoch 48 num_samples 12400 loss 0.025936083957190853\n",
      "Epoch 48 num_samples 12500 loss 0.021821376929100512\n",
      "Epoch 48 num_samples 12600 loss 0.026470076620548944\n",
      "Epoch 48 num_samples 12700 loss 0.02139744722072315\n",
      "Epoch 48 num_samples 12800 loss 0.03580664727366569\n",
      "Epoch 48 num_samples 12900 loss 0.01775617851978179\n",
      "Epoch 48 num_samples 13000 loss 0.015290446186236045\n",
      "Epoch 48 num_samples 13100 loss 0.03229711487453457\n",
      "Epoch 48 num_samples 13200 loss 0.012502320930906266\n",
      "Epoch 48 num_samples 13300 loss 0.014671510584673903\n",
      "Epoch 48 num_samples 13400 loss 0.009298318517974495\n",
      "Epoch 48 num_samples 13500 loss 0.015111130918441962\n",
      "Epoch 48 num_samples 13600 loss 0.027605683818906906\n",
      "Epoch 48 num_samples 13700 loss 0.019217407915379715\n",
      "Epoch 48 num_samples 13800 loss 0.01792377296837831\n",
      "Epoch 48 num_samples 13900 loss 0.007678820802660547\n",
      "Epoch 48 num_samples 14000 loss 0.014000153296052727\n",
      "Epoch 48 num_samples 14100 loss 0.01792983124916412\n",
      "Epoch 48 num_samples 14200 loss 0.014617536867636316\n",
      "Epoch 48 num_samples 14300 loss 0.02126813872236555\n",
      "Epoch 48 num_samples 14400 loss 0.02120758807461431\n",
      "Epoch 48 num_samples 14500 loss 0.023987497903719762\n",
      "Epoch 48 num_samples 14600 loss 0.01850953342917482\n",
      "Epoch 48 num_samples 14700 loss 0.019467129051658847\n",
      "Epoch 48 num_samples 14800 loss 0.017767529109633754\n",
      "Epoch 48 num_samples 14900 loss 0.02342422741589583\n",
      "Epoch 48 num_samples 15000 loss 0.01686240571967002\n",
      "Epoch 48 num_samples 15100 loss 0.01976770197765741\n",
      "Epoch 48 num_samples 15200 loss 0.022299592147722\n",
      "Epoch 48 num_samples 15300 loss 0.021352208625436027\n",
      "Epoch 48 num_samples 15400 loss 0.013043875604592043\n",
      "Epoch 48 num_samples 15500 loss 0.02231397943068231\n",
      "Epoch 48 num_samples 15600 loss 0.02103642956619917\n",
      "Epoch 48 num_samples 15700 loss 0.013655387257682339\n",
      "Epoch 48 num_samples 15800 loss 0.026173407849476926\n",
      "Epoch 48 num_samples 15900 loss 0.013797159518127761\n",
      "Epoch 48 num_samples 16000 loss 0.02681770077021933\n",
      "Epoch 48 num_samples 16100 loss 0.014165876995583368\n",
      "Epoch 48 num_samples 16200 loss 0.021950981204349577\n",
      "Epoch 48 num_samples 16300 loss 0.02805006049478838\n",
      "Epoch 48 num_samples 16400 loss 0.02683451078585196\n",
      "Epoch 48 num_samples 16500 loss 0.022788257973708585\n",
      "Epoch 48 num_samples 16600 loss 0.02472154795980637\n",
      "Epoch 48 num_samples 16700 loss 0.013203859420607738\n",
      "Epoch 48 num_samples 16800 loss 0.013834714922424128\n",
      "Epoch 48 num_samples 16900 loss 0.015978100895695745\n",
      "Epoch 48 num_samples 17000 loss 0.012070528091638723\n",
      "Epoch 48 num_samples 17100 loss 0.037035168424363905\n",
      "Epoch 48 num_samples 17200 loss 0.022100434878202072\n",
      "Epoch 48 num_samples 17300 loss 0.024531682932857977\n",
      "Epoch 48 num_samples 17400 loss 0.019800995456840616\n",
      "Epoch 48 num_samples 17500 loss 0.019106530593815688\n",
      "Epoch 48 num_samples 17600 loss 0.018935496110797166\n",
      "Epoch 48 num_samples 17700 loss 0.014829535081264923\n",
      "Epoch 48 num_samples 17800 loss 0.01700046831270627\n",
      "Epoch 48 num_samples 17900 loss 0.027013943173572866\n",
      "Epoch 48 num_samples 18000 loss 0.01730533070288953\n",
      "Epoch 48 num_samples 18100 loss 0.01949911570368371\n",
      "Epoch 48 num_samples 18200 loss 0.020842772494186253\n",
      "Epoch 48 num_samples 18300 loss 0.015655375579683453\n",
      "Epoch 48 num_samples 18400 loss 0.031516812607942736\n",
      "Epoch 48 num_samples 18500 loss 0.02109089506970249\n",
      "Epoch 49 num_samples 0 loss 0.014872234506803098\n",
      "Epoch 49 num_samples 100 loss 0.02702383107179844\n",
      "Epoch 49 num_samples 200 loss 0.017161467146409315\n",
      "Epoch 49 num_samples 300 loss 0.014625056998465356\n",
      "Epoch 49 num_samples 400 loss 0.0169622095904379\n",
      "Epoch 49 num_samples 500 loss 0.0250227044596439\n",
      "Epoch 49 num_samples 600 loss 0.028967985854592464\n",
      "Epoch 49 num_samples 700 loss 0.02894625733669108\n",
      "Epoch 49 num_samples 800 loss 0.018034117512361385\n",
      "Epoch 49 num_samples 900 loss 0.029012879034221877\n",
      "Epoch 49 num_samples 1000 loss 0.017601737884379246\n",
      "Epoch 49 num_samples 1100 loss 0.03145673865619947\n",
      "Epoch 49 num_samples 1200 loss 0.018014429887293043\n",
      "Epoch 49 num_samples 1300 loss 0.020497863847821405\n",
      "Epoch 49 num_samples 1400 loss 0.02302732299461917\n",
      "Epoch 49 num_samples 1500 loss 0.03114301337235839\n",
      "Epoch 49 num_samples 1600 loss 0.018357166755205583\n",
      "Epoch 49 num_samples 1700 loss 0.01743260672087961\n",
      "Epoch 49 num_samples 1800 loss 0.017543311413024718\n",
      "Epoch 49 num_samples 1900 loss 0.020274893161751188\n",
      "Epoch 49 num_samples 2000 loss 0.02405275186335982\n",
      "Epoch 49 num_samples 2100 loss 0.012982678403828355\n",
      "Epoch 49 num_samples 2200 loss 0.014313897868682025\n",
      "Epoch 49 num_samples 2300 loss 0.009605218140690607\n",
      "Epoch 49 num_samples 2400 loss 0.01693717954919581\n",
      "Epoch 49 num_samples 2500 loss 0.023203775320526036\n",
      "Epoch 49 num_samples 2600 loss 0.02457014625348388\n",
      "Epoch 49 num_samples 2700 loss 0.016794854423307144\n",
      "Epoch 49 num_samples 2800 loss 0.025965815419449038\n",
      "Epoch 49 num_samples 2900 loss 0.022683253761579713\n",
      "Epoch 49 num_samples 3000 loss 0.019100272318829374\n",
      "Epoch 49 num_samples 3100 loss 0.01792173877769756\n",
      "Epoch 49 num_samples 3200 loss 0.04318042908344048\n",
      "Epoch 49 num_samples 3300 loss 0.02132367042418408\n",
      "Epoch 49 num_samples 3400 loss 0.015525779356822018\n",
      "Epoch 49 num_samples 3500 loss 0.01602900213202619\n",
      "Epoch 49 num_samples 3600 loss 0.010925358105623086\n",
      "Epoch 49 num_samples 3700 loss 0.02984824716325921\n",
      "Epoch 49 num_samples 3800 loss 0.017809179234843077\n",
      "Epoch 49 num_samples 3900 loss 0.020520477473118758\n",
      "Epoch 49 num_samples 4000 loss 0.024164491807300025\n",
      "Epoch 49 num_samples 4100 loss 0.03348981713867107\n",
      "Epoch 49 num_samples 4200 loss 0.019227410555925584\n",
      "Epoch 49 num_samples 4300 loss 0.019061934398539523\n",
      "Epoch 49 num_samples 4400 loss 0.023483005543410006\n",
      "Epoch 49 num_samples 4500 loss 0.02689350424904729\n",
      "Epoch 49 num_samples 4600 loss 0.020999632411897028\n",
      "Epoch 49 num_samples 4700 loss 0.012883790132358009\n",
      "Epoch 49 num_samples 4800 loss 0.01240561198637212\n",
      "Epoch 49 num_samples 4900 loss 0.01566701344634052\n",
      "Epoch 49 num_samples 5000 loss 0.014657176700082885\n",
      "Epoch 49 num_samples 5100 loss 0.02603388589685719\n",
      "Epoch 49 num_samples 5200 loss 0.012974855208249276\n",
      "Epoch 49 num_samples 5300 loss 0.017645260532519035\n",
      "Epoch 49 num_samples 5400 loss 0.023212170602781735\n",
      "Epoch 49 num_samples 5500 loss 0.01331803062134978\n",
      "Epoch 49 num_samples 5600 loss 0.06209991099265265\n",
      "Epoch 49 num_samples 5700 loss 0.021745942929272274\n",
      "Epoch 49 num_samples 5800 loss 0.019199203616551273\n",
      "Epoch 49 num_samples 5900 loss 0.02353619405877903\n",
      "Epoch 49 num_samples 6000 loss 0.01932302560048863\n",
      "Epoch 49 num_samples 6100 loss 0.017000844343606995\n",
      "Epoch 49 num_samples 6200 loss 0.020832722329155187\n",
      "Epoch 49 num_samples 6300 loss 0.028088116971294475\n",
      "Epoch 49 num_samples 6400 loss 0.015544742459619072\n",
      "Epoch 49 num_samples 6500 loss 0.014342817936263543\n",
      "Epoch 49 num_samples 6600 loss 0.030031009622477404\n",
      "Epoch 49 num_samples 6700 loss 0.015099782703842473\n",
      "Epoch 49 num_samples 6800 loss 0.010303081551807343\n",
      "Epoch 49 num_samples 6900 loss 0.03973966705336311\n",
      "Epoch 49 num_samples 7000 loss 0.02491433564646314\n",
      "Epoch 49 num_samples 7100 loss 0.013562479783204356\n",
      "Epoch 49 num_samples 7200 loss 0.01851433324886048\n",
      "Epoch 49 num_samples 7300 loss 0.01727895292822292\n",
      "Epoch 49 num_samples 7400 loss 0.013760130966559227\n",
      "Epoch 49 num_samples 7500 loss 0.032884546406251755\n",
      "Epoch 49 num_samples 7600 loss 0.019464485060143807\n",
      "Epoch 49 num_samples 7700 loss 0.030603049010788384\n",
      "Epoch 49 num_samples 7800 loss 0.015524985713027706\n",
      "Epoch 49 num_samples 7900 loss 0.018811530266659653\n",
      "Epoch 49 num_samples 8000 loss 0.013547895897774482\n",
      "Epoch 49 num_samples 8100 loss 0.017774839701923607\n",
      "Epoch 49 num_samples 8200 loss 0.020284635277537943\n",
      "Epoch 49 num_samples 8300 loss 0.01818856342139895\n",
      "Epoch 49 num_samples 8400 loss 0.014029118752774638\n",
      "Epoch 49 num_samples 8500 loss 0.01970384340502603\n",
      "Epoch 49 num_samples 8600 loss 0.019477582223104653\n",
      "Epoch 49 num_samples 8700 loss 0.019499133554016907\n",
      "Epoch 49 num_samples 8800 loss 0.02198735637081239\n",
      "Epoch 49 num_samples 8900 loss 0.023302236415755826\n",
      "Epoch 49 num_samples 9000 loss 0.018109340470757327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 num_samples 9100 loss 0.01921706995961996\n",
      "Epoch 49 num_samples 9200 loss 0.019009974837745733\n",
      "Epoch 49 num_samples 9300 loss 0.018970832660967843\n",
      "Epoch 49 num_samples 9400 loss 0.01622314742623735\n",
      "Epoch 49 num_samples 9500 loss 0.017402827102478688\n",
      "Epoch 49 num_samples 9600 loss 0.016414687362202054\n",
      "Epoch 49 num_samples 9700 loss 0.029782309055761555\n",
      "Epoch 49 num_samples 9800 loss 0.011479250766394604\n",
      "Epoch 49 num_samples 9900 loss 0.03765745911923935\n",
      "Epoch 49 num_samples 10000 loss 0.017561269287538345\n",
      "Epoch 49 num_samples 10100 loss 0.015220064235567494\n",
      "Epoch 49 num_samples 10200 loss 0.02374782555057087\n",
      "Epoch 49 num_samples 10300 loss 0.018461138616751683\n",
      "Epoch 49 num_samples 10400 loss 0.025312361155549558\n",
      "Epoch 49 num_samples 10500 loss 0.01588669171280293\n",
      "Epoch 49 num_samples 10600 loss 0.025637603818880975\n",
      "Epoch 49 num_samples 10700 loss 0.017138642284112233\n",
      "Epoch 49 num_samples 10800 loss 0.022858358196471248\n",
      "Epoch 49 num_samples 10900 loss 0.015667248269408497\n",
      "Epoch 49 num_samples 11000 loss 0.014359296334769532\n",
      "Epoch 49 num_samples 11100 loss 0.01859962228348466\n",
      "Epoch 49 num_samples 11200 loss 0.015559877082288304\n",
      "Epoch 49 num_samples 11300 loss 0.02756683064200048\n",
      "Epoch 49 num_samples 11400 loss 0.01907354304671348\n",
      "Epoch 49 num_samples 11500 loss 0.01834011022840116\n",
      "Epoch 49 num_samples 11600 loss 0.016564974132937702\n",
      "Epoch 49 num_samples 11700 loss 0.025099724037876213\n",
      "Epoch 49 num_samples 11800 loss 0.01691850252970773\n",
      "Epoch 49 num_samples 11900 loss 0.015475865510017115\n",
      "Epoch 49 num_samples 12000 loss 0.012825078261743976\n",
      "Epoch 49 num_samples 12100 loss 0.015704254952260042\n",
      "Epoch 49 num_samples 12200 loss 0.023888865393154057\n",
      "Epoch 49 num_samples 12300 loss 0.013380434658898583\n",
      "Epoch 49 num_samples 12400 loss 0.024848378862985118\n",
      "Epoch 49 num_samples 12500 loss 0.020670064134081758\n",
      "Epoch 49 num_samples 12600 loss 0.025558766300207827\n",
      "Epoch 49 num_samples 12700 loss 0.0205693859933974\n",
      "Epoch 49 num_samples 12800 loss 0.03391006920006745\n",
      "Epoch 49 num_samples 12900 loss 0.017024818662845453\n",
      "Epoch 49 num_samples 13000 loss 0.014768328708884566\n",
      "Epoch 49 num_samples 13100 loss 0.0303344940502408\n",
      "Epoch 49 num_samples 13200 loss 0.012038424735165382\n",
      "Epoch 49 num_samples 13300 loss 0.013970372180500689\n",
      "Epoch 49 num_samples 13400 loss 0.009065575192075194\n",
      "Epoch 49 num_samples 13500 loss 0.014538934479886715\n",
      "Epoch 49 num_samples 13600 loss 0.026472765941718795\n",
      "Epoch 49 num_samples 13700 loss 0.018495044123278164\n",
      "Epoch 49 num_samples 13800 loss 0.017170544895501277\n",
      "Epoch 49 num_samples 13900 loss 0.007371459922948692\n",
      "Epoch 49 num_samples 14000 loss 0.013516519622700875\n",
      "Epoch 49 num_samples 14100 loss 0.017204922467784375\n",
      "Epoch 49 num_samples 14200 loss 0.01406866681526719\n",
      "Epoch 49 num_samples 14300 loss 0.020318317307492246\n",
      "Epoch 49 num_samples 14400 loss 0.02032409090075298\n",
      "Epoch 49 num_samples 14500 loss 0.023093583992168532\n",
      "Epoch 49 num_samples 14600 loss 0.01783491841625939\n",
      "Epoch 49 num_samples 14700 loss 0.018675864317180855\n",
      "Epoch 49 num_samples 14800 loss 0.01718030283284218\n",
      "Epoch 49 num_samples 14900 loss 0.02234830439010033\n",
      "Epoch 49 num_samples 15000 loss 0.01626318746443793\n",
      "Epoch 49 num_samples 15100 loss 0.019086171143388134\n",
      "Epoch 49 num_samples 15200 loss 0.021420575277830273\n",
      "Epoch 49 num_samples 15300 loss 0.020595382069303253\n",
      "Epoch 49 num_samples 15400 loss 0.012507427961804627\n",
      "Epoch 49 num_samples 15500 loss 0.021283223580624205\n",
      "Epoch 49 num_samples 15600 loss 0.02012974008536081\n",
      "Epoch 49 num_samples 15700 loss 0.013121852233837527\n",
      "Epoch 49 num_samples 15800 loss 0.025078770085443\n",
      "Epoch 49 num_samples 15900 loss 0.013354845266230375\n",
      "Epoch 49 num_samples 16000 loss 0.026066101104270253\n",
      "Epoch 49 num_samples 16100 loss 0.013713334877812794\n",
      "Epoch 49 num_samples 16200 loss 0.02110998665192426\n",
      "Epoch 49 num_samples 16300 loss 0.02679066703957271\n",
      "Epoch 49 num_samples 16400 loss 0.02578188612699678\n",
      "Epoch 49 num_samples 16500 loss 0.021935869828036164\n",
      "Epoch 49 num_samples 16600 loss 0.023667576222278185\n",
      "Epoch 49 num_samples 16700 loss 0.012603659458811199\n",
      "Epoch 49 num_samples 16800 loss 0.013223852509504842\n",
      "Epoch 49 num_samples 16900 loss 0.015320957578181159\n",
      "Epoch 49 num_samples 17000 loss 0.01156547379398488\n",
      "Epoch 49 num_samples 17100 loss 0.03518167565764695\n",
      "Epoch 49 num_samples 17200 loss 0.021199361970038515\n",
      "Epoch 49 num_samples 17300 loss 0.023216160550648218\n",
      "Epoch 49 num_samples 17400 loss 0.01895594111856088\n",
      "Epoch 49 num_samples 17500 loss 0.018379010158624854\n",
      "Epoch 49 num_samples 17600 loss 0.018153856603884556\n",
      "Epoch 49 num_samples 17700 loss 0.014260505921638878\n",
      "Epoch 49 num_samples 17800 loss 0.0162610633643673\n",
      "Epoch 49 num_samples 17900 loss 0.02560254257747525\n",
      "Epoch 49 num_samples 18000 loss 0.016585556308726702\n",
      "Epoch 49 num_samples 18100 loss 0.018720086537106\n",
      "Epoch 49 num_samples 18200 loss 0.020028064707790606\n",
      "Epoch 49 num_samples 18300 loss 0.01506422084923154\n",
      "Epoch 49 num_samples 18400 loss 0.03052141000894403\n",
      "Epoch 49 num_samples 18500 loss 0.0202758551144981\n",
      "Epoch 50 num_samples 0 loss 0.0142088424222101\n",
      "Epoch 50 num_samples 100 loss 0.025771575511394945\n",
      "Epoch 50 num_samples 200 loss 0.016555790940335352\n",
      "Epoch 50 num_samples 300 loss 0.014105936683219321\n",
      "Epoch 50 num_samples 400 loss 0.016400061492269663\n",
      "Epoch 50 num_samples 500 loss 0.02422172234941832\n",
      "Epoch 50 num_samples 600 loss 0.027298674450936602\n",
      "Epoch 50 num_samples 700 loss 0.027835777586217914\n",
      "Epoch 50 num_samples 800 loss 0.01722691028005618\n",
      "Epoch 50 num_samples 900 loss 0.02795194871378994\n",
      "Epoch 50 num_samples 1000 loss 0.016939498092398565\n",
      "Epoch 50 num_samples 1100 loss 0.030147536268141456\n",
      "Epoch 50 num_samples 1200 loss 0.017282817583365265\n",
      "Epoch 50 num_samples 1300 loss 0.019724741212444\n",
      "Epoch 50 num_samples 1400 loss 0.021933880204108584\n",
      "Epoch 50 num_samples 1500 loss 0.02969315508352339\n",
      "Epoch 50 num_samples 1600 loss 0.01769945663699981\n",
      "Epoch 50 num_samples 1700 loss 0.016774764764134725\n",
      "Epoch 50 num_samples 1800 loss 0.01682544417523241\n",
      "Epoch 50 num_samples 1900 loss 0.019536694822810993\n",
      "Epoch 50 num_samples 2000 loss 0.023102160133206363\n",
      "Epoch 50 num_samples 2100 loss 0.01248310672180137\n",
      "Epoch 50 num_samples 2200 loss 0.01375319209700117\n",
      "Epoch 50 num_samples 2300 loss 0.009192865849161888\n",
      "Epoch 50 num_samples 2400 loss 0.016202189450330615\n",
      "Epoch 50 num_samples 2500 loss 0.02232668417669494\n",
      "Epoch 50 num_samples 2600 loss 0.023539813481350747\n",
      "Epoch 50 num_samples 2700 loss 0.016130911630062778\n",
      "Epoch 50 num_samples 2800 loss 0.024820522575535506\n",
      "Epoch 50 num_samples 2900 loss 0.02180220504258092\n",
      "Epoch 50 num_samples 3000 loss 0.018332513214383644\n",
      "Epoch 50 num_samples 3100 loss 0.017057502748723884\n",
      "Epoch 50 num_samples 3200 loss 0.04024799747465986\n",
      "Epoch 50 num_samples 3300 loss 0.02019551270648439\n",
      "Epoch 50 num_samples 3400 loss 0.014955206345033134\n",
      "Epoch 50 num_samples 3500 loss 0.015413951111650033\n",
      "Epoch 50 num_samples 3600 loss 0.01053068575272103\n",
      "Epoch 50 num_samples 3700 loss 0.028511386935388783\n",
      "Epoch 50 num_samples 3800 loss 0.016995679162149824\n",
      "Epoch 50 num_samples 3900 loss 0.019803762255319834\n",
      "Epoch 50 num_samples 4000 loss 0.023163604315151555\n",
      "Epoch 50 num_samples 4100 loss 0.03174846829096073\n",
      "Epoch 50 num_samples 4200 loss 0.018566069245929087\n",
      "Epoch 50 num_samples 4300 loss 0.018201843872749465\n",
      "Epoch 50 num_samples 4400 loss 0.02224244340085114\n",
      "Epoch 50 num_samples 4500 loss 0.025864059891874305\n",
      "Epoch 50 num_samples 4600 loss 0.020253047506390863\n",
      "Epoch 50 num_samples 4700 loss 0.012299192992562356\n",
      "Epoch 50 num_samples 4800 loss 0.011996241286370947\n",
      "Epoch 50 num_samples 4900 loss 0.015037431849447041\n",
      "Epoch 50 num_samples 5000 loss 0.014020235290581629\n",
      "Epoch 50 num_samples 5100 loss 0.02500845294704411\n",
      "Epoch 50 num_samples 5200 loss 0.012531614088812077\n",
      "Epoch 50 num_samples 5300 loss 0.016894187291473167\n",
      "Epoch 50 num_samples 5400 loss 0.022457405174646818\n",
      "Epoch 50 num_samples 5500 loss 0.012823933350591128\n",
      "Epoch 50 num_samples 5600 loss 0.05961882522135613\n",
      "Epoch 50 num_samples 5700 loss 0.020530681905105243\n",
      "Epoch 50 num_samples 5800 loss 0.018240548686894217\n",
      "Epoch 50 num_samples 5900 loss 0.02258422317965618\n",
      "Epoch 50 num_samples 6000 loss 0.01849679884642755\n",
      "Epoch 50 num_samples 6100 loss 0.016329571631256052\n",
      "Epoch 50 num_samples 6200 loss 0.019749245996337417\n",
      "Epoch 50 num_samples 6300 loss 0.026892867032036926\n",
      "Epoch 50 num_samples 6400 loss 0.014931814182553205\n",
      "Epoch 50 num_samples 6500 loss 0.01377865191452533\n",
      "Epoch 50 num_samples 6600 loss 0.029030989874195917\n",
      "Epoch 50 num_samples 6700 loss 0.014588120034924427\n",
      "Epoch 50 num_samples 6800 loss 0.009955584767963963\n",
      "Epoch 50 num_samples 6900 loss 0.03815605286325973\n",
      "Epoch 50 num_samples 7000 loss 0.023775666747337235\n",
      "Epoch 50 num_samples 7100 loss 0.012966233182276424\n",
      "Epoch 50 num_samples 7200 loss 0.017863324845220675\n",
      "Epoch 50 num_samples 7300 loss 0.01668593077455738\n",
      "Epoch 50 num_samples 7400 loss 0.013146196698288941\n",
      "Epoch 50 num_samples 7500 loss 0.03141401693395495\n",
      "Epoch 50 num_samples 7600 loss 0.018804878112116796\n",
      "Epoch 50 num_samples 7700 loss 0.029194317686283344\n",
      "Epoch 50 num_samples 7800 loss 0.014935871054271294\n",
      "Epoch 50 num_samples 7900 loss 0.018239537911667686\n",
      "Epoch 50 num_samples 8000 loss 0.01304566855044727\n",
      "Epoch 50 num_samples 8100 loss 0.017035757936761743\n",
      "Epoch 50 num_samples 8200 loss 0.019470131084660103\n",
      "Epoch 50 num_samples 8300 loss 0.01734155057306243\n",
      "Epoch 50 num_samples 8400 loss 0.013473533441188068\n",
      "Epoch 50 num_samples 8500 loss 0.018866168145542067\n",
      "Epoch 50 num_samples 8600 loss 0.018877441792492268\n",
      "Epoch 50 num_samples 8700 loss 0.01867648329523173\n",
      "Epoch 50 num_samples 8800 loss 0.020607167264323576\n",
      "Epoch 50 num_samples 8900 loss 0.02260700237396023\n",
      "Epoch 50 num_samples 9000 loss 0.017539389719906005\n",
      "Epoch 50 num_samples 9100 loss 0.018407686799593297\n",
      "Epoch 50 num_samples 9200 loss 0.01837609815556188\n",
      "Epoch 50 num_samples 9300 loss 0.018186176404491345\n",
      "Epoch 50 num_samples 9400 loss 0.015672464327919012\n",
      "Epoch 50 num_samples 9500 loss 0.01657206052000648\n",
      "Epoch 50 num_samples 9600 loss 0.015878340931776404\n",
      "Epoch 50 num_samples 9700 loss 0.0285492406083651\n",
      "Epoch 50 num_samples 9800 loss 0.011052835055864746\n",
      "Epoch 50 num_samples 9900 loss 0.036042891553536925\n",
      "Epoch 50 num_samples 10000 loss 0.016750386510824593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 num_samples 10100 loss 0.014559819913986355\n",
      "Epoch 50 num_samples 10200 loss 0.022698636901665722\n",
      "Epoch 50 num_samples 10300 loss 0.017762694819958114\n",
      "Epoch 50 num_samples 10400 loss 0.02425963916642919\n",
      "Epoch 50 num_samples 10500 loss 0.015414171527569213\n",
      "Epoch 50 num_samples 10600 loss 0.024559847446885223\n",
      "Epoch 50 num_samples 10700 loss 0.016583469252311567\n",
      "Epoch 50 num_samples 10800 loss 0.021845356214633717\n",
      "Epoch 50 num_samples 10900 loss 0.015131560869333911\n",
      "Epoch 50 num_samples 11000 loss 0.013868755138682892\n",
      "Epoch 50 num_samples 11100 loss 0.017942118407488838\n",
      "Epoch 50 num_samples 11200 loss 0.014933573038735796\n",
      "Epoch 50 num_samples 11300 loss 0.026203046146236808\n",
      "Epoch 50 num_samples 11400 loss 0.018174796319325313\n",
      "Epoch 50 num_samples 11500 loss 0.017546244695503973\n",
      "Epoch 50 num_samples 11600 loss 0.01583341678931429\n",
      "Epoch 50 num_samples 11700 loss 0.024004493911920787\n",
      "Epoch 50 num_samples 11800 loss 0.016251187174166067\n",
      "Epoch 50 num_samples 11900 loss 0.014868205442676571\n",
      "Epoch 50 num_samples 12000 loss 0.012402120871220376\n",
      "Epoch 50 num_samples 12100 loss 0.015011916951270748\n",
      "Epoch 50 num_samples 12200 loss 0.02280550277050091\n",
      "Epoch 50 num_samples 12300 loss 0.013020312787593448\n",
      "Epoch 50 num_samples 12400 loss 0.023645636049975396\n",
      "Epoch 50 num_samples 12500 loss 0.019939372867649564\n",
      "Epoch 50 num_samples 12600 loss 0.024651485136594695\n",
      "Epoch 50 num_samples 12700 loss 0.01958234690620942\n",
      "Epoch 50 num_samples 12800 loss 0.03256864526680623\n",
      "Epoch 50 num_samples 12900 loss 0.01633975545395635\n",
      "Epoch 50 num_samples 13000 loss 0.014157385070263468\n",
      "Epoch 50 num_samples 13100 loss 0.02870611226458053\n",
      "Epoch 50 num_samples 13200 loss 0.011475540646951917\n",
      "Epoch 50 num_samples 13300 loss 0.01351045964278062\n",
      "Epoch 50 num_samples 13400 loss 0.008732208594931038\n",
      "Epoch 50 num_samples 13500 loss 0.013849248951487423\n",
      "Epoch 50 num_samples 13600 loss 0.02525329936579515\n",
      "Epoch 50 num_samples 13700 loss 0.017792744227855425\n",
      "Epoch 50 num_samples 13800 loss 0.01646942113125408\n",
      "Epoch 50 num_samples 13900 loss 0.007050896672558666\n",
      "Epoch 50 num_samples 14000 loss 0.012790191246585854\n",
      "Epoch 50 num_samples 14100 loss 0.016571921189144558\n",
      "Epoch 50 num_samples 14200 loss 0.013591885793860234\n",
      "Epoch 50 num_samples 14300 loss 0.019597879915943073\n",
      "Epoch 50 num_samples 14400 loss 0.019606151111939193\n",
      "Epoch 50 num_samples 14500 loss 0.022252904546869456\n",
      "Epoch 50 num_samples 14600 loss 0.017190368768053542\n",
      "Epoch 50 num_samples 14700 loss 0.017892821677390928\n",
      "Epoch 50 num_samples 14800 loss 0.016510267207481468\n",
      "Epoch 50 num_samples 14900 loss 0.021325498147680585\n",
      "Epoch 50 num_samples 15000 loss 0.0156660235532168\n",
      "Epoch 50 num_samples 15100 loss 0.018355708146029725\n",
      "Epoch 50 num_samples 15200 loss 0.02039157842548602\n",
      "Epoch 50 num_samples 15300 loss 0.019675439210079068\n",
      "Epoch 50 num_samples 15400 loss 0.01213227499500624\n",
      "Epoch 50 num_samples 15500 loss 0.020408769841227938\n",
      "Epoch 50 num_samples 15600 loss 0.019375885487651564\n",
      "Epoch 50 num_samples 15700 loss 0.012638150746975047\n",
      "Epoch 50 num_samples 15800 loss 0.023827875095593132\n",
      "Epoch 50 num_samples 15900 loss 0.012867414418903218\n",
      "Epoch 50 num_samples 16000 loss 0.02506152217945698\n",
      "Epoch 50 num_samples 16100 loss 0.013142975113647405\n",
      "Epoch 50 num_samples 16200 loss 0.020253552456633156\n",
      "Epoch 50 num_samples 16300 loss 0.025582372410502\n",
      "Epoch 50 num_samples 16400 loss 0.02477090654323003\n",
      "Epoch 50 num_samples 16500 loss 0.021212754029618947\n",
      "Epoch 50 num_samples 16600 loss 0.022613656910509875\n",
      "Epoch 50 num_samples 16700 loss 0.012187964252242733\n",
      "Epoch 50 num_samples 16800 loss 0.012714997743731684\n",
      "Epoch 50 num_samples 16900 loss 0.01474717645032515\n",
      "Epoch 50 num_samples 17000 loss 0.011149692162537552\n",
      "Epoch 50 num_samples 17100 loss 0.033257010275435456\n",
      "Epoch 50 num_samples 17200 loss 0.020431663594412522\n",
      "Epoch 50 num_samples 17300 loss 0.02218594342612133\n",
      "Epoch 50 num_samples 17400 loss 0.0182503183377391\n",
      "Epoch 50 num_samples 17500 loss 0.017720699131079203\n",
      "Epoch 50 num_samples 17600 loss 0.017308483805783686\n",
      "Epoch 50 num_samples 17700 loss 0.01374333720295643\n",
      "Epoch 50 num_samples 17800 loss 0.015555246632757673\n",
      "Epoch 50 num_samples 17900 loss 0.024498605732059663\n",
      "Epoch 50 num_samples 18000 loss 0.015997898878625696\n",
      "Epoch 50 num_samples 18100 loss 0.018060892461865038\n",
      "Epoch 50 num_samples 18200 loss 0.019196805893948263\n",
      "Epoch 50 num_samples 18300 loss 0.014347446163722508\n",
      "Epoch 50 num_samples 18400 loss 0.028976028735250646\n",
      "Epoch 50 num_samples 18500 loss 0.019600046398138383\n",
      "Epoch 51 num_samples 0 loss 0.013706204833113422\n",
      "Epoch 51 num_samples 100 loss 0.024836860294787752\n",
      "Epoch 51 num_samples 200 loss 0.01576119517140114\n",
      "Epoch 51 num_samples 300 loss 0.013537082833025611\n",
      "Epoch 51 num_samples 400 loss 0.01574242104303445\n",
      "Epoch 51 num_samples 500 loss 0.02342059219536675\n",
      "Epoch 51 num_samples 600 loss 0.026392469355689285\n",
      "Epoch 51 num_samples 700 loss 0.026894589849896487\n",
      "Epoch 51 num_samples 800 loss 0.016522844756273407\n",
      "Epoch 51 num_samples 900 loss 0.02686895141677624\n",
      "Epoch 51 num_samples 1000 loss 0.016240256777631173\n",
      "Epoch 51 num_samples 1100 loss 0.028826321433744865\n",
      "Epoch 51 num_samples 1200 loss 0.016621368999124666\n",
      "Epoch 51 num_samples 1300 loss 0.018904419746337196\n",
      "Epoch 51 num_samples 1400 loss 0.020891028507613228\n",
      "Epoch 51 num_samples 1500 loss 0.02815570829428047\n",
      "Epoch 51 num_samples 1600 loss 0.017161942448100594\n",
      "Epoch 51 num_samples 1700 loss 0.016179707820986867\n",
      "Epoch 51 num_samples 1800 loss 0.01606947610876897\n",
      "Epoch 51 num_samples 1900 loss 0.018959361737071734\n",
      "Epoch 51 num_samples 2000 loss 0.022290428349921863\n",
      "Epoch 51 num_samples 2100 loss 0.012010142717614412\n",
      "Epoch 51 num_samples 2200 loss 0.013308218672780729\n",
      "Epoch 51 num_samples 2300 loss 0.008914923782467159\n",
      "Epoch 51 num_samples 2400 loss 0.01573557399778994\n",
      "Epoch 51 num_samples 2500 loss 0.02138993593022592\n",
      "Epoch 51 num_samples 2600 loss 0.022555480685441026\n",
      "Epoch 51 num_samples 2700 loss 0.015433902592465276\n",
      "Epoch 51 num_samples 2800 loss 0.023775259896267005\n",
      "Epoch 51 num_samples 2900 loss 0.0209142043605328\n",
      "Epoch 51 num_samples 3000 loss 0.017587384208203587\n",
      "Epoch 51 num_samples 3100 loss 0.016301729501479744\n",
      "Epoch 51 num_samples 3200 loss 0.03742629207937703\n",
      "Epoch 51 num_samples 3300 loss 0.019231897799979882\n",
      "Epoch 51 num_samples 3400 loss 0.01448214212731453\n",
      "Epoch 51 num_samples 3500 loss 0.014816228703862865\n",
      "Epoch 51 num_samples 3600 loss 0.010209349527241342\n",
      "Epoch 51 num_samples 3700 loss 0.027409018555117442\n",
      "Epoch 51 num_samples 3800 loss 0.016278518370136455\n",
      "Epoch 51 num_samples 3900 loss 0.019040134268488676\n",
      "Epoch 51 num_samples 4000 loss 0.022162624939505424\n",
      "Epoch 51 num_samples 4100 loss 0.030106909713635985\n",
      "Epoch 51 num_samples 4200 loss 0.017879646665460287\n",
      "Epoch 51 num_samples 4300 loss 0.017526492656044036\n",
      "Epoch 51 num_samples 4400 loss 0.021213186440716073\n",
      "Epoch 51 num_samples 4500 loss 0.02478358798069956\n",
      "Epoch 51 num_samples 4600 loss 0.01949099086622645\n",
      "Epoch 51 num_samples 4700 loss 0.011786938679137387\n",
      "Epoch 51 num_samples 4800 loss 0.01158172444479102\n",
      "Epoch 51 num_samples 4900 loss 0.014540401849489747\n",
      "Epoch 51 num_samples 5000 loss 0.01355255273112046\n",
      "Epoch 51 num_samples 5100 loss 0.024115239688252254\n",
      "Epoch 51 num_samples 5200 loss 0.012070784962926911\n",
      "Epoch 51 num_samples 5300 loss 0.016202750954884815\n",
      "Epoch 51 num_samples 5400 loss 0.021667400684056287\n",
      "Epoch 51 num_samples 5500 loss 0.01245601291678664\n",
      "Epoch 51 num_samples 5600 loss 0.056726682342715835\n",
      "Epoch 51 num_samples 5700 loss 0.019407526984240257\n",
      "Epoch 51 num_samples 5800 loss 0.017572645153292283\n",
      "Epoch 51 num_samples 5900 loss 0.02173383547210398\n",
      "Epoch 51 num_samples 6000 loss 0.01769926682309866\n",
      "Epoch 51 num_samples 6100 loss 0.015714652023262596\n",
      "Epoch 51 num_samples 6200 loss 0.018967026884564753\n",
      "Epoch 51 num_samples 6300 loss 0.025640914386017524\n",
      "Epoch 51 num_samples 6400 loss 0.014328059382577259\n",
      "Epoch 51 num_samples 6500 loss 0.01319821941744141\n",
      "Epoch 51 num_samples 6600 loss 0.028072658318841072\n",
      "Epoch 51 num_samples 6700 loss 0.014066619228041012\n",
      "Epoch 51 num_samples 6800 loss 0.009557608951478613\n",
      "Epoch 51 num_samples 6900 loss 0.03661671033893596\n",
      "Epoch 51 num_samples 7000 loss 0.022809340905958056\n",
      "Epoch 51 num_samples 7100 loss 0.012464692081847185\n",
      "Epoch 51 num_samples 7200 loss 0.0172270996852686\n",
      "Epoch 51 num_samples 7300 loss 0.016063622944316437\n",
      "Epoch 51 num_samples 7400 loss 0.012658341324855668\n",
      "Epoch 51 num_samples 7500 loss 0.02996074373755905\n",
      "Epoch 51 num_samples 7600 loss 0.018163818062750095\n",
      "Epoch 51 num_samples 7700 loss 0.027874919747832193\n",
      "Epoch 51 num_samples 7800 loss 0.014399233394683755\n",
      "Epoch 51 num_samples 7900 loss 0.01768661420185025\n",
      "Epoch 51 num_samples 8000 loss 0.01252618329629752\n",
      "Epoch 51 num_samples 8100 loss 0.016464771310920324\n",
      "Epoch 51 num_samples 8200 loss 0.01877658697786731\n",
      "Epoch 51 num_samples 8300 loss 0.016665008529708366\n",
      "Epoch 51 num_samples 8400 loss 0.01293709925926379\n",
      "Epoch 51 num_samples 8500 loss 0.018156809592377945\n",
      "Epoch 51 num_samples 8600 loss 0.018062899743343453\n",
      "Epoch 51 num_samples 8700 loss 0.017932131604617166\n",
      "Epoch 51 num_samples 8800 loss 0.019549124740362932\n",
      "Epoch 51 num_samples 8900 loss 0.021679522667487433\n",
      "Epoch 51 num_samples 9000 loss 0.01686636192794675\n",
      "Epoch 51 num_samples 9100 loss 0.017702695518170566\n",
      "Epoch 51 num_samples 9200 loss 0.017650413766606723\n",
      "Epoch 51 num_samples 9300 loss 0.017574239711239944\n",
      "Epoch 51 num_samples 9400 loss 0.015104641902806857\n",
      "Epoch 51 num_samples 9500 loss 0.015931923060347387\n",
      "Epoch 51 num_samples 9600 loss 0.01540345144030348\n",
      "Epoch 51 num_samples 9700 loss 0.027348786158555627\n",
      "Epoch 51 num_samples 9800 loss 0.010669129497354362\n",
      "Epoch 51 num_samples 9900 loss 0.034557878915527314\n",
      "Epoch 51 num_samples 10000 loss 0.016132935094884324\n",
      "Epoch 51 num_samples 10100 loss 0.014058880709118062\n",
      "Epoch 51 num_samples 10200 loss 0.021763102250602514\n",
      "Epoch 51 num_samples 10300 loss 0.017001077577509426\n",
      "Epoch 51 num_samples 10400 loss 0.023103089725333766\n",
      "Epoch 51 num_samples 10500 loss 0.01485545228410826\n",
      "Epoch 51 num_samples 10600 loss 0.023154177637264642\n",
      "Epoch 51 num_samples 10700 loss 0.015916817483291667\n",
      "Epoch 51 num_samples 10800 loss 0.020923395258526493\n",
      "Epoch 51 num_samples 10900 loss 0.014522266442080243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 num_samples 11000 loss 0.013371203608622286\n",
      "Epoch 51 num_samples 11100 loss 0.017325521842953284\n",
      "Epoch 51 num_samples 11200 loss 0.014329669329961986\n",
      "Epoch 51 num_samples 11300 loss 0.02498063219751567\n",
      "Epoch 51 num_samples 11400 loss 0.017399115351820958\n",
      "Epoch 51 num_samples 11500 loss 0.016824324747030592\n",
      "Epoch 51 num_samples 11600 loss 0.015268986638626107\n",
      "Epoch 51 num_samples 11700 loss 0.022943886724090055\n",
      "Epoch 51 num_samples 11800 loss 0.015557196097592476\n",
      "Epoch 51 num_samples 11900 loss 0.01427574942538027\n",
      "Epoch 51 num_samples 12000 loss 0.011925282481718464\n",
      "Epoch 51 num_samples 12100 loss 0.01418934048896312\n",
      "Epoch 51 num_samples 12200 loss 0.02181423056513711\n",
      "Epoch 51 num_samples 12300 loss 0.01258785336041718\n",
      "Epoch 51 num_samples 12400 loss 0.022682330226317098\n",
      "Epoch 51 num_samples 12500 loss 0.019258015120530415\n",
      "Epoch 51 num_samples 12600 loss 0.023646653770479052\n",
      "Epoch 51 num_samples 12700 loss 0.01884812000040134\n",
      "Epoch 51 num_samples 12800 loss 0.030975231992709223\n",
      "Epoch 51 num_samples 12900 loss 0.015796296174605408\n",
      "Epoch 51 num_samples 13000 loss 0.01372217460215492\n",
      "Epoch 51 num_samples 13100 loss 0.02695212878219981\n",
      "Epoch 51 num_samples 13200 loss 0.010891775793536184\n",
      "Epoch 51 num_samples 13300 loss 0.01296534556700331\n",
      "Epoch 51 num_samples 13400 loss 0.008510833020806687\n",
      "Epoch 51 num_samples 13500 loss 0.01333158919855978\n",
      "Epoch 51 num_samples 13600 loss 0.02420040027787862\n",
      "Epoch 51 num_samples 13700 loss 0.01712051671331663\n",
      "Epoch 51 num_samples 13800 loss 0.015741846445905306\n",
      "Epoch 51 num_samples 13900 loss 0.006809541259859006\n",
      "Epoch 51 num_samples 14000 loss 0.012331617361091942\n",
      "Epoch 51 num_samples 14100 loss 0.01594645295736012\n",
      "Epoch 51 num_samples 14200 loss 0.013009651072888134\n",
      "Epoch 51 num_samples 14300 loss 0.01872144903514309\n",
      "Epoch 51 num_samples 14400 loss 0.01884341576217124\n",
      "Epoch 51 num_samples 14500 loss 0.021483431440505348\n",
      "Epoch 51 num_samples 14600 loss 0.01651444017387931\n",
      "Epoch 51 num_samples 14700 loss 0.017104815828145603\n",
      "Epoch 51 num_samples 14800 loss 0.016030734385875704\n",
      "Epoch 51 num_samples 14900 loss 0.02044404956676968\n",
      "Epoch 51 num_samples 15000 loss 0.015149122724722122\n",
      "Epoch 51 num_samples 15100 loss 0.01762440369455128\n",
      "Epoch 51 num_samples 15200 loss 0.019596682772099673\n",
      "Epoch 51 num_samples 15300 loss 0.019030753699618964\n",
      "Epoch 51 num_samples 15400 loss 0.011629977773334783\n",
      "Epoch 51 num_samples 15500 loss 0.019365383053375092\n",
      "Epoch 51 num_samples 15600 loss 0.01873437978541965\n",
      "Epoch 51 num_samples 15700 loss 0.012177760579919053\n",
      "Epoch 51 num_samples 15800 loss 0.02269887623367047\n",
      "Epoch 51 num_samples 15900 loss 0.01246362708789055\n",
      "Epoch 51 num_samples 16000 loss 0.024091756554112234\n",
      "Epoch 51 num_samples 16100 loss 0.012690186398064412\n",
      "Epoch 51 num_samples 16200 loss 0.019540666945485216\n",
      "Epoch 51 num_samples 16300 loss 0.02430924959229105\n",
      "Epoch 51 num_samples 16400 loss 0.02371930528043092\n",
      "Epoch 51 num_samples 16500 loss 0.0204230473545512\n",
      "Epoch 51 num_samples 16600 loss 0.021792752687230257\n",
      "Epoch 51 num_samples 16700 loss 0.011745180691819472\n",
      "Epoch 51 num_samples 16800 loss 0.01214022092274937\n",
      "Epoch 51 num_samples 16900 loss 0.014212671397130288\n",
      "Epoch 51 num_samples 17000 loss 0.010789213228507632\n",
      "Epoch 51 num_samples 17100 loss 0.031613543631790385\n",
      "Epoch 51 num_samples 17200 loss 0.019573152086998384\n",
      "Epoch 51 num_samples 17300 loss 0.02136634066584016\n",
      "Epoch 51 num_samples 17400 loss 0.017608550846935942\n",
      "Epoch 51 num_samples 17500 loss 0.017146404211189816\n",
      "Epoch 51 num_samples 17600 loss 0.016669636277300972\n",
      "Epoch 51 num_samples 17700 loss 0.013246443949249303\n",
      "Epoch 51 num_samples 17800 loss 0.014913077840447988\n",
      "Epoch 51 num_samples 17900 loss 0.02346739051041995\n",
      "Epoch 51 num_samples 18000 loss 0.015406074721582598\n",
      "Epoch 51 num_samples 18100 loss 0.017361477415899794\n",
      "Epoch 51 num_samples 18200 loss 0.018496533292120674\n",
      "Epoch 51 num_samples 18300 loss 0.013861894995569734\n",
      "Epoch 51 num_samples 18400 loss 0.02780040860087647\n",
      "Epoch 51 num_samples 18500 loss 0.018791142539975245\n",
      "Epoch 52 num_samples 0 loss 0.013099393547040839\n",
      "Epoch 52 num_samples 100 loss 0.023786735150780506\n",
      "Epoch 52 num_samples 200 loss 0.015380139713464627\n",
      "Epoch 52 num_samples 300 loss 0.01303521634252623\n",
      "Epoch 52 num_samples 400 loss 0.015190507107054683\n",
      "Epoch 52 num_samples 500 loss 0.02261640689142104\n",
      "Epoch 52 num_samples 600 loss 0.025205629389916277\n",
      "Epoch 52 num_samples 700 loss 0.02574785233447436\n",
      "Epoch 52 num_samples 800 loss 0.015821499442205726\n",
      "Epoch 52 num_samples 900 loss 0.02599386622128502\n",
      "Epoch 52 num_samples 1000 loss 0.015669699755804727\n",
      "Epoch 52 num_samples 1100 loss 0.027441554324633737\n",
      "Epoch 52 num_samples 1200 loss 0.016036217267468886\n",
      "Epoch 52 num_samples 1300 loss 0.01838410839114766\n",
      "Epoch 52 num_samples 1400 loss 0.020219530035273187\n",
      "Epoch 52 num_samples 1500 loss 0.02658434718706398\n",
      "Epoch 52 num_samples 1600 loss 0.01636274048192847\n",
      "Epoch 52 num_samples 1700 loss 0.015663467165787363\n",
      "Epoch 52 num_samples 1800 loss 0.015535218087343407\n",
      "Epoch 52 num_samples 1900 loss 0.018164122138853087\n",
      "Epoch 52 num_samples 2000 loss 0.021355491547889054\n",
      "Epoch 52 num_samples 2100 loss 0.01161668771539389\n",
      "Epoch 52 num_samples 2200 loss 0.012839481241715084\n",
      "Epoch 52 num_samples 2300 loss 0.008626173387330491\n",
      "Epoch 52 num_samples 2400 loss 0.015049514481828976\n",
      "Epoch 52 num_samples 2500 loss 0.02056230780789685\n",
      "Epoch 52 num_samples 2600 loss 0.021685382762183028\n",
      "Epoch 52 num_samples 2700 loss 0.014770485577213792\n",
      "Epoch 52 num_samples 2800 loss 0.022962977460029625\n",
      "Epoch 52 num_samples 2900 loss 0.020049802963567953\n",
      "Epoch 52 num_samples 3000 loss 0.016897451365185084\n",
      "Epoch 52 num_samples 3100 loss 0.015716573300153188\n",
      "Epoch 52 num_samples 3200 loss 0.035528654414459016\n",
      "Epoch 52 num_samples 3300 loss 0.018549394212694158\n",
      "Epoch 52 num_samples 3400 loss 0.013930126144511274\n",
      "Epoch 52 num_samples 3500 loss 0.014346050031126292\n",
      "Epoch 52 num_samples 3600 loss 0.009825269757030653\n",
      "Epoch 52 num_samples 3700 loss 0.02634050385303323\n",
      "Epoch 52 num_samples 3800 loss 0.015597617821575947\n",
      "Epoch 52 num_samples 3900 loss 0.01813067590599907\n",
      "Epoch 52 num_samples 4000 loss 0.02115148852501557\n",
      "Epoch 52 num_samples 4100 loss 0.02869562812070294\n",
      "Epoch 52 num_samples 4200 loss 0.01722217560558351\n",
      "Epoch 52 num_samples 4300 loss 0.016729594334397264\n",
      "Epoch 52 num_samples 4400 loss 0.020237185288606484\n",
      "Epoch 52 num_samples 4500 loss 0.02383176867404438\n",
      "Epoch 52 num_samples 4600 loss 0.018774691327886624\n",
      "Epoch 52 num_samples 4700 loss 0.011502932569898223\n",
      "Epoch 52 num_samples 4800 loss 0.011231823165662123\n",
      "Epoch 52 num_samples 4900 loss 0.014068059489618064\n",
      "Epoch 52 num_samples 5000 loss 0.01294138760191613\n",
      "Epoch 52 num_samples 5100 loss 0.02336572330470315\n",
      "Epoch 52 num_samples 5200 loss 0.011683351124023056\n",
      "Epoch 52 num_samples 5300 loss 0.01572515470492683\n",
      "Epoch 52 num_samples 5400 loss 0.020675760819730417\n",
      "Epoch 52 num_samples 5500 loss 0.012080886490839035\n",
      "Epoch 52 num_samples 5600 loss 0.053926392384358764\n",
      "Epoch 52 num_samples 5700 loss 0.018483288786244282\n",
      "Epoch 52 num_samples 5800 loss 0.016734033151523713\n",
      "Epoch 52 num_samples 5900 loss 0.021100410394624482\n",
      "Epoch 52 num_samples 6000 loss 0.01711664878198338\n",
      "Epoch 52 num_samples 6100 loss 0.015116813914103995\n",
      "Epoch 52 num_samples 6200 loss 0.018360408006788793\n",
      "Epoch 52 num_samples 6300 loss 0.02449783708748925\n",
      "Epoch 52 num_samples 6400 loss 0.013803585016403663\n",
      "Epoch 52 num_samples 6500 loss 0.012775166979553903\n",
      "Epoch 52 num_samples 6600 loss 0.02708890894368741\n",
      "Epoch 52 num_samples 6700 loss 0.013589011122938246\n",
      "Epoch 52 num_samples 6800 loss 0.009277780434833828\n",
      "Epoch 52 num_samples 6900 loss 0.03519747663729808\n",
      "Epoch 52 num_samples 7000 loss 0.02184568730835041\n",
      "Epoch 52 num_samples 7100 loss 0.011726318172488428\n",
      "Epoch 52 num_samples 7200 loss 0.016641998460898838\n",
      "Epoch 52 num_samples 7300 loss 0.01562963917855691\n",
      "Epoch 52 num_samples 7400 loss 0.012312163392176181\n",
      "Epoch 52 num_samples 7500 loss 0.02879154658772237\n",
      "Epoch 52 num_samples 7600 loss 0.01743468629242535\n",
      "Epoch 52 num_samples 7700 loss 0.02656291666045039\n",
      "Epoch 52 num_samples 7800 loss 0.013944494097522454\n",
      "Epoch 52 num_samples 7900 loss 0.017081625865444615\n",
      "Epoch 52 num_samples 8000 loss 0.011973848912205685\n",
      "Epoch 52 num_samples 8100 loss 0.0157590220948273\n",
      "Epoch 52 num_samples 8200 loss 0.018095649971494435\n",
      "Epoch 52 num_samples 8300 loss 0.015555505296368077\n",
      "Epoch 52 num_samples 8400 loss 0.012391109385589048\n",
      "Epoch 52 num_samples 8500 loss 0.017403262151679692\n",
      "Epoch 52 num_samples 8600 loss 0.01753057253893326\n",
      "Epoch 52 num_samples 8700 loss 0.01727108041741434\n",
      "Epoch 52 num_samples 8800 loss 0.018638070225754012\n",
      "Epoch 52 num_samples 8900 loss 0.020831052817994754\n",
      "Epoch 52 num_samples 9000 loss 0.016431656190936086\n",
      "Epoch 52 num_samples 9100 loss 0.01723818494933614\n",
      "Epoch 52 num_samples 9200 loss 0.017059519570874038\n",
      "Epoch 52 num_samples 9300 loss 0.01700626911171638\n",
      "Epoch 52 num_samples 9400 loss 0.01455921255926244\n",
      "Epoch 52 num_samples 9500 loss 0.015093507846911018\n",
      "Epoch 52 num_samples 9600 loss 0.014869818023465925\n",
      "Epoch 52 num_samples 9700 loss 0.026245020659356126\n",
      "Epoch 52 num_samples 9800 loss 0.010322866184358036\n",
      "Epoch 52 num_samples 9900 loss 0.03316684638088681\n",
      "Epoch 52 num_samples 10000 loss 0.015359606507909901\n",
      "Epoch 52 num_samples 10100 loss 0.013519405718843358\n",
      "Epoch 52 num_samples 10200 loss 0.020950316118589565\n",
      "Epoch 52 num_samples 10300 loss 0.016383303693255618\n",
      "Epoch 52 num_samples 10400 loss 0.022206602635975018\n",
      "Epoch 52 num_samples 10500 loss 0.014404596909263106\n",
      "Epoch 52 num_samples 10600 loss 0.021923013298690716\n",
      "Epoch 52 num_samples 10700 loss 0.015349879912744646\n",
      "Epoch 52 num_samples 10800 loss 0.02007467662477034\n",
      "Epoch 52 num_samples 10900 loss 0.01395478024175913\n",
      "Epoch 52 num_samples 11000 loss 0.012869685510751874\n",
      "Epoch 52 num_samples 11100 loss 0.016692737176073013\n",
      "Epoch 52 num_samples 11200 loss 0.013823930904507373\n",
      "Epoch 52 num_samples 11300 loss 0.02396514340488416\n",
      "Epoch 52 num_samples 11400 loss 0.01662786227474761\n",
      "Epoch 52 num_samples 11500 loss 0.016138719944597053\n",
      "Epoch 52 num_samples 11600 loss 0.014712237964614718\n",
      "Epoch 52 num_samples 11700 loss 0.021901721948028932\n",
      "Epoch 52 num_samples 11800 loss 0.014964166531199412\n",
      "Epoch 52 num_samples 11900 loss 0.013762453559052892\n",
      "Epoch 52 num_samples 12000 loss 0.011533439568022927\n",
      "Epoch 52 num_samples 12100 loss 0.013564955648108647\n",
      "Epoch 52 num_samples 12200 loss 0.020954085131706414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 num_samples 12300 loss 0.012187326393761792\n",
      "Epoch 52 num_samples 12400 loss 0.02185795662500164\n",
      "Epoch 52 num_samples 12500 loss 0.018361676369207033\n",
      "Epoch 52 num_samples 12600 loss 0.02270882217070588\n",
      "Epoch 52 num_samples 12700 loss 0.01813806499501879\n",
      "Epoch 52 num_samples 12800 loss 0.029897109186018705\n",
      "Epoch 52 num_samples 12900 loss 0.015155012629958156\n",
      "Epoch 52 num_samples 13000 loss 0.013354309625296818\n",
      "Epoch 52 num_samples 13100 loss 0.025370462402579036\n",
      "Epoch 52 num_samples 13200 loss 0.01045268673486166\n",
      "Epoch 52 num_samples 13300 loss 0.012498031987950482\n",
      "Epoch 52 num_samples 13400 loss 0.00820913471191785\n",
      "Epoch 52 num_samples 13500 loss 0.012676423567685542\n",
      "Epoch 52 num_samples 13600 loss 0.02298908601137933\n",
      "Epoch 52 num_samples 13700 loss 0.016315164824504024\n",
      "Epoch 52 num_samples 13800 loss 0.015205519696997998\n",
      "Epoch 52 num_samples 13900 loss 0.006569673795374863\n",
      "Epoch 52 num_samples 14000 loss 0.011711553724442046\n",
      "Epoch 52 num_samples 14100 loss 0.015351031043857244\n",
      "Epoch 52 num_samples 14200 loss 0.012617402360432127\n",
      "Epoch 52 num_samples 14300 loss 0.01795960758789015\n",
      "Epoch 52 num_samples 14400 loss 0.018116410359335068\n",
      "Epoch 52 num_samples 14500 loss 0.020759075416313902\n",
      "Epoch 52 num_samples 14600 loss 0.015900014892396255\n",
      "Epoch 52 num_samples 14700 loss 0.016489413247256116\n",
      "Epoch 52 num_samples 14800 loss 0.015388253343528679\n",
      "Epoch 52 num_samples 14900 loss 0.019583244977372474\n",
      "Epoch 52 num_samples 15000 loss 0.014635305213708283\n",
      "Epoch 52 num_samples 15100 loss 0.01704424719572551\n",
      "Epoch 52 num_samples 15200 loss 0.018683410428414652\n",
      "Epoch 52 num_samples 15300 loss 0.01824394966564789\n",
      "Epoch 52 num_samples 15400 loss 0.011258743926111871\n",
      "Epoch 52 num_samples 15500 loss 0.018709292553961195\n",
      "Epoch 52 num_samples 15600 loss 0.017996686898838165\n",
      "Epoch 52 num_samples 15700 loss 0.01169774236947816\n",
      "Epoch 52 num_samples 15800 loss 0.02179034950487717\n",
      "Epoch 52 num_samples 15900 loss 0.012028230787078415\n",
      "Epoch 52 num_samples 16000 loss 0.02338402128150576\n",
      "Epoch 52 num_samples 16100 loss 0.012184242361074165\n",
      "Epoch 52 num_samples 16200 loss 0.01886386084812974\n",
      "Epoch 52 num_samples 16300 loss 0.023335670539657398\n",
      "Epoch 52 num_samples 16400 loss 0.022836874124905676\n",
      "Epoch 52 num_samples 16500 loss 0.019825259587041743\n",
      "Epoch 52 num_samples 16600 loss 0.020991272984831257\n",
      "Epoch 52 num_samples 16700 loss 0.011333012633406773\n",
      "Epoch 52 num_samples 16800 loss 0.011816500676746475\n",
      "Epoch 52 num_samples 16900 loss 0.013681496696764767\n",
      "Epoch 52 num_samples 17000 loss 0.010350677428281814\n",
      "Epoch 52 num_samples 17100 loss 0.030080664079065872\n",
      "Epoch 52 num_samples 17200 loss 0.01892419745261605\n",
      "Epoch 52 num_samples 17300 loss 0.020348904120754595\n",
      "Epoch 52 num_samples 17400 loss 0.016927203995443924\n",
      "Epoch 52 num_samples 17500 loss 0.01655296710997045\n",
      "Epoch 52 num_samples 17600 loss 0.01612522317329462\n",
      "Epoch 52 num_samples 17700 loss 0.012811034931858943\n",
      "Epoch 52 num_samples 17800 loss 0.01436458887368734\n",
      "Epoch 52 num_samples 17900 loss 0.022471272053074864\n",
      "Epoch 52 num_samples 18000 loss 0.014866551357900834\n",
      "Epoch 52 num_samples 18100 loss 0.01678480530670347\n",
      "Epoch 52 num_samples 18200 loss 0.01781957146746925\n",
      "Epoch 52 num_samples 18300 loss 0.01337246440101635\n",
      "Epoch 52 num_samples 18400 loss 0.02676771851395072\n",
      "Epoch 52 num_samples 18500 loss 0.018120107162752114\n",
      "Epoch 53 num_samples 0 loss 0.012536863640828864\n",
      "Epoch 53 num_samples 100 loss 0.0227450476756733\n",
      "Epoch 53 num_samples 200 loss 0.014800898591839275\n",
      "Epoch 53 num_samples 300 loss 0.012577362905669074\n",
      "Epoch 53 num_samples 400 loss 0.014724767481641672\n",
      "Epoch 53 num_samples 500 loss 0.021801912142481405\n",
      "Epoch 53 num_samples 600 loss 0.024074869879859833\n",
      "Epoch 53 num_samples 700 loss 0.02480708941076891\n",
      "Epoch 53 num_samples 800 loss 0.015207689955325635\n",
      "Epoch 53 num_samples 900 loss 0.025183232856655486\n",
      "Epoch 53 num_samples 1000 loss 0.015144670775390343\n",
      "Epoch 53 num_samples 1100 loss 0.026394206371156206\n",
      "Epoch 53 num_samples 1200 loss 0.015406218566054926\n",
      "Epoch 53 num_samples 1300 loss 0.017726390358439537\n",
      "Epoch 53 num_samples 1400 loss 0.019355764391765496\n",
      "Epoch 53 num_samples 1500 loss 0.0254099216590635\n",
      "Epoch 53 num_samples 1600 loss 0.01592963191747977\n",
      "Epoch 53 num_samples 1700 loss 0.015127550181106031\n",
      "Epoch 53 num_samples 1800 loss 0.014882470790459807\n",
      "Epoch 53 num_samples 1900 loss 0.0177025532028555\n",
      "Epoch 53 num_samples 2000 loss 0.02075433145719806\n",
      "Epoch 53 num_samples 2100 loss 0.01117392625817961\n",
      "Epoch 53 num_samples 2200 loss 0.012334442968328077\n",
      "Epoch 53 num_samples 2300 loss 0.008265883416735453\n",
      "Epoch 53 num_samples 2400 loss 0.014345252781945794\n",
      "Epoch 53 num_samples 2500 loss 0.01979050167613788\n",
      "Epoch 53 num_samples 2600 loss 0.02087172863285799\n",
      "Epoch 53 num_samples 2700 loss 0.01427920052663906\n",
      "Epoch 53 num_samples 2800 loss 0.02189312037815948\n",
      "Epoch 53 num_samples 2900 loss 0.01928011963097287\n",
      "Epoch 53 num_samples 3000 loss 0.016348646293120484\n",
      "Epoch 53 num_samples 3100 loss 0.01510988528638721\n",
      "Epoch 53 num_samples 3200 loss 0.03334648111524935\n",
      "Epoch 53 num_samples 3300 loss 0.01778176665308413\n",
      "Epoch 53 num_samples 3400 loss 0.01349435175797557\n",
      "Epoch 53 num_samples 3500 loss 0.01383922560409633\n",
      "Epoch 53 num_samples 3600 loss 0.009502963572721474\n",
      "Epoch 53 num_samples 3700 loss 0.025420760473574364\n",
      "Epoch 53 num_samples 3800 loss 0.014914753983010058\n",
      "Epoch 53 num_samples 3900 loss 0.017612573527944594\n",
      "Epoch 53 num_samples 4000 loss 0.02040535807491281\n",
      "Epoch 53 num_samples 4100 loss 0.02722573116544681\n",
      "Epoch 53 num_samples 4200 loss 0.016598680210069227\n",
      "Epoch 53 num_samples 4300 loss 0.016040770927465\n",
      "Epoch 53 num_samples 4400 loss 0.019284186861965077\n",
      "Epoch 53 num_samples 4500 loss 0.022969159224808397\n",
      "Epoch 53 num_samples 4600 loss 0.01818479662338825\n",
      "Epoch 53 num_samples 4700 loss 0.010995639116176672\n",
      "Epoch 53 num_samples 4800 loss 0.010850457988790719\n",
      "Epoch 53 num_samples 4900 loss 0.013646751691874192\n",
      "Epoch 53 num_samples 5000 loss 0.012508206001509425\n",
      "Epoch 53 num_samples 5100 loss 0.02240701726308669\n",
      "Epoch 53 num_samples 5200 loss 0.011260326367929802\n",
      "Epoch 53 num_samples 5300 loss 0.015088874609890326\n",
      "Epoch 53 num_samples 5400 loss 0.020199208157197862\n",
      "Epoch 53 num_samples 5500 loss 0.011654854985728031\n",
      "Epoch 53 num_samples 5600 loss 0.051757160813000976\n",
      "Epoch 53 num_samples 5700 loss 0.01767942084699783\n",
      "Epoch 53 num_samples 5800 loss 0.016186459702871903\n",
      "Epoch 53 num_samples 5900 loss 0.020238409209688\n",
      "Epoch 53 num_samples 6000 loss 0.016373276607496105\n",
      "Epoch 53 num_samples 6100 loss 0.014607176028950857\n",
      "Epoch 53 num_samples 6200 loss 0.01758820544634444\n",
      "Epoch 53 num_samples 6300 loss 0.023450954240100956\n",
      "Epoch 53 num_samples 6400 loss 0.013321651783236656\n",
      "Epoch 53 num_samples 6500 loss 0.012260867229521138\n",
      "Epoch 53 num_samples 6600 loss 0.02620880164564716\n",
      "Epoch 53 num_samples 6700 loss 0.013068964215339162\n",
      "Epoch 53 num_samples 6800 loss 0.0089011247541066\n",
      "Epoch 53 num_samples 6900 loss 0.033985466032585177\n",
      "Epoch 53 num_samples 7000 loss 0.02097139485839721\n",
      "Epoch 53 num_samples 7100 loss 0.011423874697381632\n",
      "Epoch 53 num_samples 7200 loss 0.01600471751883825\n",
      "Epoch 53 num_samples 7300 loss 0.015106252442277408\n",
      "Epoch 53 num_samples 7400 loss 0.011728599806416416\n",
      "Epoch 53 num_samples 7500 loss 0.027643683599241218\n",
      "Epoch 53 num_samples 7600 loss 0.016798220336394266\n",
      "Epoch 53 num_samples 7700 loss 0.0254110276160175\n",
      "Epoch 53 num_samples 7800 loss 0.013493122814731175\n",
      "Epoch 53 num_samples 7900 loss 0.016494635532007768\n",
      "Epoch 53 num_samples 8000 loss 0.011622410308460345\n",
      "Epoch 53 num_samples 8100 loss 0.015208357018122813\n",
      "Epoch 53 num_samples 8200 loss 0.01750391630465522\n",
      "Epoch 53 num_samples 8300 loss 0.015112068406121852\n",
      "Epoch 53 num_samples 8400 loss 0.011888435418657237\n",
      "Epoch 53 num_samples 8500 loss 0.016653937859888016\n",
      "Epoch 53 num_samples 8600 loss 0.016893935967437664\n",
      "Epoch 53 num_samples 8700 loss 0.016552481205103362\n",
      "Epoch 53 num_samples 8800 loss 0.017753859833964346\n",
      "Epoch 53 num_samples 8900 loss 0.020126451509375472\n",
      "Epoch 53 num_samples 9000 loss 0.01583848758176576\n",
      "Epoch 53 num_samples 9100 loss 0.016481916198717708\n",
      "Epoch 53 num_samples 9200 loss 0.01653574043558257\n",
      "Epoch 53 num_samples 9300 loss 0.016387993297734087\n",
      "Epoch 53 num_samples 9400 loss 0.014124848535882797\n",
      "Epoch 53 num_samples 9500 loss 0.01463808793870846\n",
      "Epoch 53 num_samples 9600 loss 0.014350255140094786\n",
      "Epoch 53 num_samples 9700 loss 0.02526686725262904\n",
      "Epoch 53 num_samples 9800 loss 0.009956504652369491\n",
      "Epoch 53 num_samples 9900 loss 0.03179520563887368\n",
      "Epoch 53 num_samples 10000 loss 0.014795321458227682\n",
      "Epoch 53 num_samples 10100 loss 0.013014515167636832\n",
      "Epoch 53 num_samples 10200 loss 0.020167241191721894\n",
      "Epoch 53 num_samples 10300 loss 0.015783213280992445\n",
      "Epoch 53 num_samples 10400 loss 0.021356727916221657\n",
      "Epoch 53 num_samples 10500 loss 0.013862056589971656\n",
      "Epoch 53 num_samples 10600 loss 0.020911634056514052\n",
      "Epoch 53 num_samples 10700 loss 0.014789271128012964\n",
      "Epoch 53 num_samples 10800 loss 0.01920850046554603\n",
      "Epoch 53 num_samples 10900 loss 0.013531838005038398\n",
      "Epoch 53 num_samples 11000 loss 0.012461794853615642\n",
      "Epoch 53 num_samples 11100 loss 0.016160537582684754\n",
      "Epoch 53 num_samples 11200 loss 0.013253938133406007\n",
      "Epoch 53 num_samples 11300 loss 0.02294226658868843\n",
      "Epoch 53 num_samples 11400 loss 0.015970894149188126\n",
      "Epoch 53 num_samples 11500 loss 0.015501234951178357\n",
      "Epoch 53 num_samples 11600 loss 0.014226469458206333\n",
      "Epoch 53 num_samples 11700 loss 0.020994337779086446\n",
      "Epoch 53 num_samples 11800 loss 0.014393563632392801\n",
      "Epoch 53 num_samples 11900 loss 0.013109630733535296\n",
      "Epoch 53 num_samples 12000 loss 0.011115290980777473\n",
      "Epoch 53 num_samples 12100 loss 0.013045406079446972\n",
      "Epoch 53 num_samples 12200 loss 0.020086952287401476\n",
      "Epoch 53 num_samples 12300 loss 0.011867211977125001\n",
      "Epoch 53 num_samples 12400 loss 0.02101642168408882\n",
      "Epoch 53 num_samples 12500 loss 0.017559381358930908\n",
      "Epoch 53 num_samples 12600 loss 0.021949986041437573\n",
      "Epoch 53 num_samples 12700 loss 0.017484274765647966\n",
      "Epoch 53 num_samples 12800 loss 0.028271241204278773\n",
      "Epoch 53 num_samples 12900 loss 0.014512040767992753\n",
      "Epoch 53 num_samples 13000 loss 0.012893177898034281\n",
      "Epoch 53 num_samples 13100 loss 0.02425428976091436\n",
      "Epoch 53 num_samples 13200 loss 0.010058191605440622\n",
      "Epoch 53 num_samples 13300 loss 0.012055046333819345\n",
      "Epoch 53 num_samples 13400 loss 0.007985077305292899\n",
      "Epoch 53 num_samples 13500 loss 0.01229651803846074\n",
      "Epoch 53 num_samples 13600 loss 0.022241024934795448\n",
      "Epoch 53 num_samples 13700 loss 0.015724751628536274\n",
      "Epoch 53 num_samples 13800 loss 0.01458837545312449\n",
      "Epoch 53 num_samples 13900 loss 0.006327898435211108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 num_samples 14000 loss 0.01131128992184676\n",
      "Epoch 53 num_samples 14100 loss 0.014769227441457531\n",
      "Epoch 53 num_samples 14200 loss 0.01223918089542023\n",
      "Epoch 53 num_samples 14300 loss 0.01729161281187433\n",
      "Epoch 53 num_samples 14400 loss 0.017525884069755804\n",
      "Epoch 53 num_samples 14500 loss 0.020128444029474828\n",
      "Epoch 53 num_samples 14600 loss 0.015409300438855727\n",
      "Epoch 53 num_samples 14700 loss 0.015866424128439707\n",
      "Epoch 53 num_samples 14800 loss 0.014884505431637026\n",
      "Epoch 53 num_samples 14900 loss 0.018741141294136284\n",
      "Epoch 53 num_samples 15000 loss 0.01417548930799364\n",
      "Epoch 53 num_samples 15100 loss 0.01639470672633497\n",
      "Epoch 53 num_samples 15200 loss 0.017938974563451345\n",
      "Epoch 53 num_samples 15300 loss 0.017649085354521466\n",
      "Epoch 53 num_samples 15400 loss 0.010893597035160591\n",
      "Epoch 53 num_samples 15500 loss 0.01776032025943668\n",
      "Epoch 53 num_samples 15600 loss 0.01746992571143414\n",
      "Epoch 53 num_samples 15700 loss 0.011283951270678785\n",
      "Epoch 53 num_samples 15800 loss 0.020864820038436607\n",
      "Epoch 53 num_samples 15900 loss 0.011623072579760939\n",
      "Epoch 53 num_samples 16000 loss 0.02253795594309381\n",
      "Epoch 53 num_samples 16100 loss 0.011822662599708496\n",
      "Epoch 53 num_samples 16200 loss 0.018208897395278298\n",
      "Epoch 53 num_samples 16300 loss 0.022347184676740028\n",
      "Epoch 53 num_samples 16400 loss 0.022047810286157783\n",
      "Epoch 53 num_samples 16500 loss 0.019132337689248723\n",
      "Epoch 53 num_samples 16600 loss 0.020093758115898516\n",
      "Epoch 53 num_samples 16700 loss 0.010945466579600533\n",
      "Epoch 53 num_samples 16800 loss 0.011245254187131784\n",
      "Epoch 53 num_samples 16900 loss 0.01324409736779153\n",
      "Epoch 53 num_samples 17000 loss 0.010030394816137211\n",
      "Epoch 53 num_samples 17100 loss 0.028751256115438818\n",
      "Epoch 53 num_samples 17200 loss 0.018237413505257653\n",
      "Epoch 53 num_samples 17300 loss 0.01957834721803418\n",
      "Epoch 53 num_samples 17400 loss 0.016270886317357843\n",
      "Epoch 53 num_samples 17500 loss 0.015988920405987907\n",
      "Epoch 53 num_samples 17600 loss 0.015435348449520617\n",
      "Epoch 53 num_samples 17700 loss 0.012355892342337454\n",
      "Epoch 53 num_samples 17800 loss 0.013791863956371268\n",
      "Epoch 53 num_samples 17900 loss 0.02158477763270353\n",
      "Epoch 53 num_samples 18000 loss 0.014310630804968052\n",
      "Epoch 53 num_samples 18100 loss 0.0161159772535225\n",
      "Epoch 53 num_samples 18200 loss 0.017123038527110244\n",
      "Epoch 53 num_samples 18300 loss 0.012901228632858287\n",
      "Epoch 53 num_samples 18400 loss 0.025722395909085583\n",
      "Epoch 53 num_samples 18500 loss 0.017354554145364135\n",
      "Epoch 54 num_samples 0 loss 0.012078263875419042\n",
      "Epoch 54 num_samples 100 loss 0.02206871114602031\n",
      "Epoch 54 num_samples 200 loss 0.014241626432935993\n",
      "Epoch 54 num_samples 300 loss 0.012132719514660389\n",
      "Epoch 54 num_samples 400 loss 0.014259198548817995\n",
      "Epoch 54 num_samples 500 loss 0.020998614323105597\n",
      "Epoch 54 num_samples 600 loss 0.023207491549419066\n",
      "Epoch 54 num_samples 700 loss 0.023824736876043303\n",
      "Epoch 54 num_samples 800 loss 0.014559236650078638\n",
      "Epoch 54 num_samples 900 loss 0.02436465980625787\n",
      "Epoch 54 num_samples 1000 loss 0.014586213794649354\n",
      "Epoch 54 num_samples 1100 loss 0.025304293356063136\n",
      "Epoch 54 num_samples 1200 loss 0.014799564207789037\n",
      "Epoch 54 num_samples 1300 loss 0.01715918412214732\n",
      "Epoch 54 num_samples 1400 loss 0.018493773721065972\n",
      "Epoch 54 num_samples 1500 loss 0.02419002377541997\n",
      "Epoch 54 num_samples 1600 loss 0.015311876657194396\n",
      "Epoch 54 num_samples 1700 loss 0.014590922171582843\n",
      "Epoch 54 num_samples 1800 loss 0.014335534612196398\n",
      "Epoch 54 num_samples 1900 loss 0.017035698860754653\n",
      "Epoch 54 num_samples 2000 loss 0.020045563495540587\n",
      "Epoch 54 num_samples 2100 loss 0.010852054320612942\n",
      "Epoch 54 num_samples 2200 loss 0.011938259347815595\n",
      "Epoch 54 num_samples 2300 loss 0.0079979052314415\n",
      "Epoch 54 num_samples 2400 loss 0.013856831948517834\n",
      "Epoch 54 num_samples 2500 loss 0.019043532125839105\n",
      "Epoch 54 num_samples 2600 loss 0.02013876368994216\n",
      "Epoch 54 num_samples 2700 loss 0.01375567384885362\n",
      "Epoch 54 num_samples 2800 loss 0.02103136321482024\n",
      "Epoch 54 num_samples 2900 loss 0.01852675914464925\n",
      "Epoch 54 num_samples 3000 loss 0.015594545321538072\n",
      "Epoch 54 num_samples 3100 loss 0.014495664486998842\n",
      "Epoch 54 num_samples 3200 loss 0.03154739011832959\n",
      "Epoch 54 num_samples 3300 loss 0.01720739631154111\n",
      "Epoch 54 num_samples 3400 loss 0.0130282631988351\n",
      "Epoch 54 num_samples 3500 loss 0.013355760182933345\n",
      "Epoch 54 num_samples 3600 loss 0.009224372032783042\n",
      "Epoch 54 num_samples 3700 loss 0.02444591184345839\n",
      "Epoch 54 num_samples 3800 loss 0.01422525960821147\n",
      "Epoch 54 num_samples 3900 loss 0.016861840881266348\n",
      "Epoch 54 num_samples 4000 loss 0.019493793643492158\n",
      "Epoch 54 num_samples 4100 loss 0.02613943471129137\n",
      "Epoch 54 num_samples 4200 loss 0.016034609003048025\n",
      "Epoch 54 num_samples 4300 loss 0.015476887518322989\n",
      "Epoch 54 num_samples 4400 loss 0.018507153641245083\n",
      "Epoch 54 num_samples 4500 loss 0.022125709212682552\n",
      "Epoch 54 num_samples 4600 loss 0.01768700384343437\n",
      "Epoch 54 num_samples 4700 loss 0.010613172244050872\n",
      "Epoch 54 num_samples 4800 loss 0.010512353202288131\n",
      "Epoch 54 num_samples 4900 loss 0.01326577424165886\n",
      "Epoch 54 num_samples 5000 loss 0.012086500905004356\n",
      "Epoch 54 num_samples 5100 loss 0.021546490830236943\n",
      "Epoch 54 num_samples 5200 loss 0.010866039602589677\n",
      "Epoch 54 num_samples 5300 loss 0.014604363418331682\n",
      "Epoch 54 num_samples 5400 loss 0.019524348229015727\n",
      "Epoch 54 num_samples 5500 loss 0.01128533875388384\n",
      "Epoch 54 num_samples 5600 loss 0.04938690654344436\n",
      "Epoch 54 num_samples 5700 loss 0.017023951010188786\n",
      "Epoch 54 num_samples 5800 loss 0.01555596267881303\n",
      "Epoch 54 num_samples 5900 loss 0.01967187485325854\n",
      "Epoch 54 num_samples 6000 loss 0.015803217864836024\n",
      "Epoch 54 num_samples 6100 loss 0.014158236527902029\n",
      "Epoch 54 num_samples 6200 loss 0.016937409088858518\n",
      "Epoch 54 num_samples 6300 loss 0.022508019138989324\n",
      "Epoch 54 num_samples 6400 loss 0.012875662765294414\n",
      "Epoch 54 num_samples 6500 loss 0.011819646844672632\n",
      "Epoch 54 num_samples 6600 loss 0.025367357234228186\n",
      "Epoch 54 num_samples 6700 loss 0.012772041383481696\n",
      "Epoch 54 num_samples 6800 loss 0.008639374994960584\n",
      "Epoch 54 num_samples 6900 loss 0.032814968796852466\n",
      "Epoch 54 num_samples 7000 loss 0.020180643937963146\n",
      "Epoch 54 num_samples 7100 loss 0.011038480665910323\n",
      "Epoch 54 num_samples 7200 loss 0.015521163849265683\n",
      "Epoch 54 num_samples 7300 loss 0.014587642874927703\n",
      "Epoch 54 num_samples 7400 loss 0.011192287521133335\n",
      "Epoch 54 num_samples 7500 loss 0.026438184171313713\n",
      "Epoch 54 num_samples 7600 loss 0.016229372786897515\n",
      "Epoch 54 num_samples 7700 loss 0.02431134505029444\n",
      "Epoch 54 num_samples 7800 loss 0.013039455985381681\n",
      "Epoch 54 num_samples 7900 loss 0.015976319199308017\n",
      "Epoch 54 num_samples 8000 loss 0.011194941920856814\n",
      "Epoch 54 num_samples 8100 loss 0.014721158884400709\n",
      "Epoch 54 num_samples 8200 loss 0.016822781604976488\n",
      "Epoch 54 num_samples 8300 loss 0.01451718436612606\n",
      "Epoch 54 num_samples 8400 loss 0.011485127011298979\n",
      "Epoch 54 num_samples 8500 loss 0.01621296169266062\n",
      "Epoch 54 num_samples 8600 loss 0.016289856082065984\n",
      "Epoch 54 num_samples 8700 loss 0.01600869753800787\n",
      "Epoch 54 num_samples 8800 loss 0.016857804465690015\n",
      "Epoch 54 num_samples 8900 loss 0.019344732895328422\n",
      "Epoch 54 num_samples 9000 loss 0.015380915657623874\n",
      "Epoch 54 num_samples 9100 loss 0.01595180924301426\n",
      "Epoch 54 num_samples 9200 loss 0.016022575345059676\n",
      "Epoch 54 num_samples 9300 loss 0.015791356770641796\n",
      "Epoch 54 num_samples 9400 loss 0.013586033064071966\n",
      "Epoch 54 num_samples 9500 loss 0.014113548755059187\n",
      "Epoch 54 num_samples 9600 loss 0.013925836565300283\n",
      "Epoch 54 num_samples 9700 loss 0.024276585139218022\n",
      "Epoch 54 num_samples 9800 loss 0.009626690798921372\n",
      "Epoch 54 num_samples 9900 loss 0.03048109468953269\n",
      "Epoch 54 num_samples 10000 loss 0.014230982775958871\n",
      "Epoch 54 num_samples 10100 loss 0.012610154398542272\n",
      "Epoch 54 num_samples 10200 loss 0.01932913677946654\n",
      "Epoch 54 num_samples 10300 loss 0.015203519523456057\n",
      "Epoch 54 num_samples 10400 loss 0.02054124502435688\n",
      "Epoch 54 num_samples 10500 loss 0.013482658157914164\n",
      "Epoch 54 num_samples 10600 loss 0.019962061228498067\n",
      "Epoch 54 num_samples 10700 loss 0.014248955051213572\n",
      "Epoch 54 num_samples 10800 loss 0.018505049771059916\n",
      "Epoch 54 num_samples 10900 loss 0.013172457954599577\n",
      "Epoch 54 num_samples 11000 loss 0.012012351424810861\n",
      "Epoch 54 num_samples 11100 loss 0.015678252000115914\n",
      "Epoch 54 num_samples 11200 loss 0.012821825215833678\n",
      "Epoch 54 num_samples 11300 loss 0.022046249042848052\n",
      "Epoch 54 num_samples 11400 loss 0.015369742988227327\n",
      "Epoch 54 num_samples 11500 loss 0.014849488956558566\n",
      "Epoch 54 num_samples 11600 loss 0.013674954306447886\n",
      "Epoch 54 num_samples 11700 loss 0.020255421825432888\n",
      "Epoch 54 num_samples 11800 loss 0.013866673917205242\n",
      "Epoch 54 num_samples 11900 loss 0.012486830056878713\n",
      "Epoch 54 num_samples 12000 loss 0.010758243983873723\n",
      "Epoch 54 num_samples 12100 loss 0.012406425170455164\n",
      "Epoch 54 num_samples 12200 loss 0.019208416315232082\n",
      "Epoch 54 num_samples 12300 loss 0.01153915562883028\n",
      "Epoch 54 num_samples 12400 loss 0.02012371867527578\n",
      "Epoch 54 num_samples 12500 loss 0.017078572784305746\n",
      "Epoch 54 num_samples 12600 loss 0.021171170011959548\n",
      "Epoch 54 num_samples 12700 loss 0.016635397887707973\n",
      "Epoch 54 num_samples 12800 loss 0.027170177287665666\n",
      "Epoch 54 num_samples 12900 loss 0.014068402940323108\n",
      "Epoch 54 num_samples 13000 loss 0.012497160395244487\n",
      "Epoch 54 num_samples 13100 loss 0.022883435689284505\n",
      "Epoch 54 num_samples 13200 loss 0.009590641115084014\n",
      "Epoch 54 num_samples 13300 loss 0.011647569524053374\n",
      "Epoch 54 num_samples 13400 loss 0.0077070161652705756\n",
      "Epoch 54 num_samples 13500 loss 0.011770398829790163\n",
      "Epoch 54 num_samples 13600 loss 0.02135644095513264\n",
      "Epoch 54 num_samples 13700 loss 0.015232601493441397\n",
      "Epoch 54 num_samples 13800 loss 0.01410384080872654\n",
      "Epoch 54 num_samples 13900 loss 0.006091087498739581\n",
      "Epoch 54 num_samples 14000 loss 0.010771974904463893\n",
      "Epoch 54 num_samples 14100 loss 0.01424181588723511\n",
      "Epoch 54 num_samples 14200 loss 0.011737307209709322\n",
      "Epoch 54 num_samples 14300 loss 0.01659962490210952\n",
      "Epoch 54 num_samples 14400 loss 0.016933915208557474\n",
      "Epoch 54 num_samples 14500 loss 0.019500559689156923\n",
      "Epoch 54 num_samples 14600 loss 0.014821918045618826\n",
      "Epoch 54 num_samples 14700 loss 0.01531646286538773\n",
      "Epoch 54 num_samples 14800 loss 0.014383962838505269\n",
      "Epoch 54 num_samples 14900 loss 0.0181149432650172\n",
      "Epoch 54 num_samples 15000 loss 0.013740755021934128\n",
      "Epoch 54 num_samples 15100 loss 0.015808530627845055\n",
      "Epoch 54 num_samples 15200 loss 0.01719044657114007\n",
      "Epoch 54 num_samples 15300 loss 0.016982462817385646\n",
      "Epoch 54 num_samples 15400 loss 0.010531127267172664\n",
      "Epoch 54 num_samples 15500 loss 0.017067999612381965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 num_samples 15600 loss 0.016922283307991056\n",
      "Epoch 54 num_samples 15700 loss 0.01084509528810674\n",
      "Epoch 54 num_samples 15800 loss 0.019864234849685906\n",
      "Epoch 54 num_samples 15900 loss 0.011273020837038022\n",
      "Epoch 54 num_samples 16000 loss 0.021896786536634447\n",
      "Epoch 54 num_samples 16100 loss 0.0113838014556148\n",
      "Epoch 54 num_samples 16200 loss 0.017635082685431305\n",
      "Epoch 54 num_samples 16300 loss 0.02143062143999276\n",
      "Epoch 54 num_samples 16400 loss 0.021150978296124084\n",
      "Epoch 54 num_samples 16500 loss 0.018410291568173802\n",
      "Epoch 54 num_samples 16600 loss 0.019348686390176395\n",
      "Epoch 54 num_samples 16700 loss 0.010550225057866175\n",
      "Epoch 54 num_samples 16800 loss 0.010890842897760256\n",
      "Epoch 54 num_samples 16900 loss 0.01283179015049369\n",
      "Epoch 54 num_samples 17000 loss 0.009691880801603586\n",
      "Epoch 54 num_samples 17100 loss 0.027494120751530203\n",
      "Epoch 54 num_samples 17200 loss 0.017620012493126783\n",
      "Epoch 54 num_samples 17300 loss 0.01868999851853434\n",
      "Epoch 54 num_samples 17400 loss 0.015625881672216246\n",
      "Epoch 54 num_samples 17500 loss 0.015491636681182676\n",
      "Epoch 54 num_samples 17600 loss 0.014782213365101096\n",
      "Epoch 54 num_samples 17700 loss 0.01197507947994579\n",
      "Epoch 54 num_samples 17800 loss 0.013237116720325414\n",
      "Epoch 54 num_samples 17900 loss 0.02075361167045907\n",
      "Epoch 54 num_samples 18000 loss 0.013885893165231776\n",
      "Epoch 54 num_samples 18100 loss 0.015607689597342187\n",
      "Epoch 54 num_samples 18200 loss 0.016472136044861262\n",
      "Epoch 54 num_samples 18300 loss 0.012405581089137994\n",
      "Epoch 54 num_samples 18400 loss 0.024627651005734216\n",
      "Epoch 54 num_samples 18500 loss 0.016770758740298614\n",
      "Epoch 55 num_samples 0 loss 0.011721175793972723\n",
      "Epoch 55 num_samples 100 loss 0.021308576038391754\n",
      "Epoch 55 num_samples 200 loss 0.013673020346502583\n",
      "Epoch 55 num_samples 300 loss 0.011724418597443633\n",
      "Epoch 55 num_samples 400 loss 0.01373197500171647\n",
      "Epoch 55 num_samples 500 loss 0.02051766144402729\n",
      "Epoch 55 num_samples 600 loss 0.02238663281845726\n",
      "Epoch 55 num_samples 700 loss 0.023024626428233153\n",
      "Epoch 55 num_samples 800 loss 0.014034815789371912\n",
      "Epoch 55 num_samples 900 loss 0.02352647548375466\n",
      "Epoch 55 num_samples 1000 loss 0.014053567224361236\n",
      "Epoch 55 num_samples 1100 loss 0.0241975697664223\n",
      "Epoch 55 num_samples 1200 loss 0.014290245958806761\n",
      "Epoch 55 num_samples 1300 loss 0.016423685772433586\n",
      "Epoch 55 num_samples 1400 loss 0.017865184479622893\n",
      "Epoch 55 num_samples 1500 loss 0.023109161913365376\n",
      "Epoch 55 num_samples 1600 loss 0.014772881484021304\n",
      "Epoch 55 num_samples 1700 loss 0.014134757060112238\n",
      "Epoch 55 num_samples 1800 loss 0.0137962098015186\n",
      "Epoch 55 num_samples 1900 loss 0.01643104426956367\n",
      "Epoch 55 num_samples 2000 loss 0.019354163159780956\n",
      "Epoch 55 num_samples 2100 loss 0.010462350910464853\n",
      "Epoch 55 num_samples 2200 loss 0.011469370942284205\n",
      "Epoch 55 num_samples 2300 loss 0.007777740196578402\n",
      "Epoch 55 num_samples 2400 loss 0.013376121609035957\n",
      "Epoch 55 num_samples 2500 loss 0.01835196368344302\n",
      "Epoch 55 num_samples 2600 loss 0.019346283178195266\n",
      "Epoch 55 num_samples 2700 loss 0.013225336787847835\n",
      "Epoch 55 num_samples 2800 loss 0.02014916232528522\n",
      "Epoch 55 num_samples 2900 loss 0.017812062167667987\n",
      "Epoch 55 num_samples 3000 loss 0.015026908298245574\n",
      "Epoch 55 num_samples 3100 loss 0.013985356292147118\n",
      "Epoch 55 num_samples 3200 loss 0.029741685166899484\n",
      "Epoch 55 num_samples 3300 loss 0.016436493466625065\n",
      "Epoch 55 num_samples 3400 loss 0.012589140726338878\n",
      "Epoch 55 num_samples 3500 loss 0.012925596922585486\n",
      "Epoch 55 num_samples 3600 loss 0.00893083181162322\n",
      "Epoch 55 num_samples 3700 loss 0.023604134644005653\n",
      "Epoch 55 num_samples 3800 loss 0.013640509414694137\n",
      "Epoch 55 num_samples 3900 loss 0.016341522619451068\n",
      "Epoch 55 num_samples 4000 loss 0.01867879158204484\n",
      "Epoch 55 num_samples 4100 loss 0.0249205772268961\n",
      "Epoch 55 num_samples 4200 loss 0.015528716688974509\n",
      "Epoch 55 num_samples 4300 loss 0.014835473321316158\n",
      "Epoch 55 num_samples 4400 loss 0.0177213901237856\n",
      "Epoch 55 num_samples 4500 loss 0.021272777837287114\n",
      "Epoch 55 num_samples 4600 loss 0.017081747838432356\n",
      "Epoch 55 num_samples 4700 loss 0.010212085106701818\n",
      "Epoch 55 num_samples 4800 loss 0.010203061506379077\n",
      "Epoch 55 num_samples 4900 loss 0.012802042883820131\n",
      "Epoch 55 num_samples 5000 loss 0.011626250864493363\n",
      "Epoch 55 num_samples 5100 loss 0.02087367947692694\n",
      "Epoch 55 num_samples 5200 loss 0.010523278897658268\n",
      "Epoch 55 num_samples 5300 loss 0.014066952817682199\n",
      "Epoch 55 num_samples 5400 loss 0.018788593260726964\n",
      "Epoch 55 num_samples 5500 loss 0.010972138771594628\n",
      "Epoch 55 num_samples 5600 loss 0.04724402408778089\n",
      "Epoch 55 num_samples 5700 loss 0.01603899687767344\n",
      "Epoch 55 num_samples 5800 loss 0.014936730257289406\n",
      "Epoch 55 num_samples 5900 loss 0.019018709188040113\n",
      "Epoch 55 num_samples 6000 loss 0.015282493578600804\n",
      "Epoch 55 num_samples 6100 loss 0.013686616994285482\n",
      "Epoch 55 num_samples 6200 loss 0.01631387165422222\n",
      "Epoch 55 num_samples 6300 loss 0.021692596868078368\n",
      "Epoch 55 num_samples 6400 loss 0.012384069817228434\n",
      "Epoch 55 num_samples 6500 loss 0.011446489638140012\n",
      "Epoch 55 num_samples 6600 loss 0.02458948055043554\n",
      "Epoch 55 num_samples 6700 loss 0.012318563747638655\n",
      "Epoch 55 num_samples 6800 loss 0.008385242809264329\n",
      "Epoch 55 num_samples 6900 loss 0.031729899990962304\n",
      "Epoch 55 num_samples 7000 loss 0.019240487939430225\n",
      "Epoch 55 num_samples 7100 loss 0.010457234810453329\n",
      "Epoch 55 num_samples 7200 loss 0.014970948817234174\n",
      "Epoch 55 num_samples 7300 loss 0.01415470835032643\n",
      "Epoch 55 num_samples 7400 loss 0.01093293443686\n",
      "Epoch 55 num_samples 7500 loss 0.025508248069714908\n",
      "Epoch 55 num_samples 7600 loss 0.015689834405761806\n",
      "Epoch 55 num_samples 7700 loss 0.02336153492164161\n",
      "Epoch 55 num_samples 7800 loss 0.012635973738366023\n",
      "Epoch 55 num_samples 7900 loss 0.015538408505283255\n",
      "Epoch 55 num_samples 8000 loss 0.010839761091269814\n",
      "Epoch 55 num_samples 8100 loss 0.01416197808302593\n",
      "Epoch 55 num_samples 8200 loss 0.0163680186507277\n",
      "Epoch 55 num_samples 8300 loss 0.013831525050887002\n",
      "Epoch 55 num_samples 8400 loss 0.011019084201399954\n",
      "Epoch 55 num_samples 8500 loss 0.0155407267748355\n",
      "Epoch 55 num_samples 8600 loss 0.015771984445702315\n",
      "Epoch 55 num_samples 8700 loss 0.015387988166617093\n",
      "Epoch 55 num_samples 8800 loss 0.016257921278413186\n",
      "Epoch 55 num_samples 8900 loss 0.018562146786900924\n",
      "Epoch 55 num_samples 9000 loss 0.014943744749351208\n",
      "Epoch 55 num_samples 9100 loss 0.015451096355825235\n",
      "Epoch 55 num_samples 9200 loss 0.015448062241170258\n",
      "Epoch 55 num_samples 9300 loss 0.015391601106098962\n",
      "Epoch 55 num_samples 9400 loss 0.013116973422293088\n",
      "Epoch 55 num_samples 9500 loss 0.01344994730909068\n",
      "Epoch 55 num_samples 9600 loss 0.01356148400574248\n",
      "Epoch 55 num_samples 9700 loss 0.023373687757559606\n",
      "Epoch 55 num_samples 9800 loss 0.00934929687881248\n",
      "Epoch 55 num_samples 9900 loss 0.029389924834347367\n",
      "Epoch 55 num_samples 10000 loss 0.013615005114046286\n",
      "Epoch 55 num_samples 10100 loss 0.012129671421068848\n",
      "Epoch 55 num_samples 10200 loss 0.01873469122922673\n",
      "Epoch 55 num_samples 10300 loss 0.01469243831979952\n",
      "Epoch 55 num_samples 10400 loss 0.01969057340508479\n",
      "Epoch 55 num_samples 10500 loss 0.012998017651833544\n",
      "Epoch 55 num_samples 10600 loss 0.019087125665092092\n",
      "Epoch 55 num_samples 10700 loss 0.013701452095674393\n",
      "Epoch 55 num_samples 10800 loss 0.017829315447915824\n",
      "Epoch 55 num_samples 10900 loss 0.012727959323473323\n",
      "Epoch 55 num_samples 11000 loss 0.011588088098338558\n",
      "Epoch 55 num_samples 11100 loss 0.015151752399099397\n",
      "Epoch 55 num_samples 11200 loss 0.012441008686043066\n",
      "Epoch 55 num_samples 11300 loss 0.021215895859862152\n",
      "Epoch 55 num_samples 11400 loss 0.014763181654674025\n",
      "Epoch 55 num_samples 11500 loss 0.014274756785685603\n",
      "Epoch 55 num_samples 11600 loss 0.013169609647525844\n",
      "Epoch 55 num_samples 11700 loss 0.019441398878997096\n",
      "Epoch 55 num_samples 11800 loss 0.013325258579398862\n",
      "Epoch 55 num_samples 11900 loss 0.011976959695242395\n",
      "Epoch 55 num_samples 12000 loss 0.010391260994824826\n",
      "Epoch 55 num_samples 12100 loss 0.01195749570322579\n",
      "Epoch 55 num_samples 12200 loss 0.018451067399401437\n",
      "Epoch 55 num_samples 12300 loss 0.011196975530163326\n",
      "Epoch 55 num_samples 12400 loss 0.019399714155684006\n",
      "Epoch 55 num_samples 12500 loss 0.016485290624206277\n",
      "Epoch 55 num_samples 12600 loss 0.0203557658407731\n",
      "Epoch 55 num_samples 12700 loss 0.016105471062527178\n",
      "Epoch 55 num_samples 12800 loss 0.026002500484704746\n",
      "Epoch 55 num_samples 12900 loss 0.013579477612071358\n",
      "Epoch 55 num_samples 13000 loss 0.01206698514790184\n",
      "Epoch 55 num_samples 13100 loss 0.021922563712870363\n",
      "Epoch 55 num_samples 13200 loss 0.009207675057176701\n",
      "Epoch 55 num_samples 13300 loss 0.011333746619640482\n",
      "Epoch 55 num_samples 13400 loss 0.007504248120758128\n",
      "Epoch 55 num_samples 13500 loss 0.011396876015200688\n",
      "Epoch 55 num_samples 13600 loss 0.020426809750002783\n",
      "Epoch 55 num_samples 13700 loss 0.01456716845872581\n",
      "Epoch 55 num_samples 13800 loss 0.013575792619473082\n",
      "Epoch 55 num_samples 13900 loss 0.005867880077837193\n",
      "Epoch 55 num_samples 14000 loss 0.010395887237235496\n",
      "Epoch 55 num_samples 14100 loss 0.013727460243924088\n",
      "Epoch 55 num_samples 14200 loss 0.011394140498624914\n",
      "Epoch 55 num_samples 14300 loss 0.01601242309722194\n",
      "Epoch 55 num_samples 14400 loss 0.016411883654490353\n",
      "Epoch 55 num_samples 14500 loss 0.01892986008666712\n",
      "Epoch 55 num_samples 14600 loss 0.014323678503335477\n",
      "Epoch 55 num_samples 14700 loss 0.014839070192570136\n",
      "Epoch 55 num_samples 14800 loss 0.013906577068920732\n",
      "Epoch 55 num_samples 14900 loss 0.01731233234318673\n",
      "Epoch 55 num_samples 15000 loss 0.013283718802183922\n",
      "Epoch 55 num_samples 15100 loss 0.01536452403235452\n",
      "Epoch 55 num_samples 15200 loss 0.016554578586141913\n",
      "Epoch 55 num_samples 15300 loss 0.01639341870167694\n",
      "Epoch 55 num_samples 15400 loss 0.010222819590101935\n",
      "Epoch 55 num_samples 15500 loss 0.016420625396742224\n",
      "Epoch 55 num_samples 15600 loss 0.016260391141190884\n",
      "Epoch 55 num_samples 15700 loss 0.010518971226432743\n",
      "Epoch 55 num_samples 15800 loss 0.019112737738876437\n",
      "Epoch 55 num_samples 15900 loss 0.010953897565319915\n",
      "Epoch 55 num_samples 16000 loss 0.021149800416085343\n",
      "Epoch 55 num_samples 16100 loss 0.011013749303875928\n",
      "Epoch 55 num_samples 16200 loss 0.016998866847066828\n",
      "Epoch 55 num_samples 16300 loss 0.020536733244172295\n",
      "Epoch 55 num_samples 16400 loss 0.020418987938748367\n",
      "Epoch 55 num_samples 16500 loss 0.017810402709200243\n",
      "Epoch 55 num_samples 16600 loss 0.018720828732426295\n",
      "Epoch 55 num_samples 16700 loss 0.010246519293758107\n",
      "Epoch 55 num_samples 16800 loss 0.010516251519272279\n",
      "Epoch 55 num_samples 16900 loss 0.01237392395168841\n",
      "Epoch 55 num_samples 17000 loss 0.009368662833807528\n",
      "Epoch 55 num_samples 17100 loss 0.02614115058940215\n",
      "Epoch 55 num_samples 17200 loss 0.016965037357285325\n",
      "Epoch 55 num_samples 17300 loss 0.017998933044265947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 num_samples 17400 loss 0.015129764723439116\n",
      "Epoch 55 num_samples 17500 loss 0.014999398850226687\n",
      "Epoch 55 num_samples 17600 loss 0.014239948159368876\n",
      "Epoch 55 num_samples 17700 loss 0.011575715870381633\n",
      "Epoch 55 num_samples 17800 loss 0.01282356274378041\n",
      "Epoch 55 num_samples 17900 loss 0.019846506460545723\n",
      "Epoch 55 num_samples 18000 loss 0.013371064501888524\n",
      "Epoch 55 num_samples 18100 loss 0.015075548464399563\n",
      "Epoch 55 num_samples 18200 loss 0.01594860839647324\n",
      "Epoch 55 num_samples 18300 loss 0.01198060057701086\n",
      "Epoch 55 num_samples 18400 loss 0.023896988147179225\n",
      "Epoch 55 num_samples 18500 loss 0.01613421551099521\n",
      "Epoch 56 num_samples 0 loss 0.011243262928112112\n",
      "Epoch 56 num_samples 100 loss 0.020542444294951848\n",
      "Epoch 56 num_samples 200 loss 0.013292678620017283\n",
      "Epoch 56 num_samples 300 loss 0.011374175749939677\n",
      "Epoch 56 num_samples 400 loss 0.01329713581204523\n",
      "Epoch 56 num_samples 500 loss 0.01977523772527031\n",
      "Epoch 56 num_samples 600 loss 0.021544516723434097\n",
      "Epoch 56 num_samples 700 loss 0.022162880929599522\n",
      "Epoch 56 num_samples 800 loss 0.01343408045944939\n",
      "Epoch 56 num_samples 900 loss 0.0227858711963741\n",
      "Epoch 56 num_samples 1000 loss 0.013627983001621278\n",
      "Epoch 56 num_samples 1100 loss 0.0233828177717067\n",
      "Epoch 56 num_samples 1200 loss 0.013808159508520353\n",
      "Epoch 56 num_samples 1300 loss 0.01602477400446078\n",
      "Epoch 56 num_samples 1400 loss 0.017116823929066282\n",
      "Epoch 56 num_samples 1500 loss 0.0221319300031639\n",
      "Epoch 56 num_samples 1600 loss 0.014328180021374823\n",
      "Epoch 56 num_samples 1700 loss 0.013661368456282536\n",
      "Epoch 56 num_samples 1800 loss 0.013426791186474173\n",
      "Epoch 56 num_samples 1900 loss 0.01596340916874739\n",
      "Epoch 56 num_samples 2000 loss 0.018704873103667953\n",
      "Epoch 56 num_samples 2100 loss 0.010146207842449802\n",
      "Epoch 56 num_samples 2200 loss 0.011105127085275899\n",
      "Epoch 56 num_samples 2300 loss 0.0074577756230124305\n",
      "Epoch 56 num_samples 2400 loss 0.012829261123484356\n",
      "Epoch 56 num_samples 2500 loss 0.01762675785193574\n",
      "Epoch 56 num_samples 2600 loss 0.01867690159099394\n",
      "Epoch 56 num_samples 2700 loss 0.012871098236663365\n",
      "Epoch 56 num_samples 2800 loss 0.019411845998172254\n",
      "Epoch 56 num_samples 2900 loss 0.017175012575482592\n",
      "Epoch 56 num_samples 3000 loss 0.014476606304166759\n",
      "Epoch 56 num_samples 3100 loss 0.013384801228475565\n",
      "Epoch 56 num_samples 3200 loss 0.02839968526687092\n",
      "Epoch 56 num_samples 3300 loss 0.01594086790017256\n",
      "Epoch 56 num_samples 3400 loss 0.012250385127324428\n",
      "Epoch 56 num_samples 3500 loss 0.012516466591966337\n",
      "Epoch 56 num_samples 3600 loss 0.008667263480063424\n",
      "Epoch 56 num_samples 3700 loss 0.022797311159587365\n",
      "Epoch 56 num_samples 3800 loss 0.013165188560650671\n",
      "Epoch 56 num_samples 3900 loss 0.015695036989981568\n",
      "Epoch 56 num_samples 4000 loss 0.01798486817342991\n",
      "Epoch 56 num_samples 4100 loss 0.02378578639369663\n",
      "Epoch 56 num_samples 4200 loss 0.015036836052018998\n",
      "Epoch 56 num_samples 4300 loss 0.014239656802195659\n",
      "Epoch 56 num_samples 4400 loss 0.017065626495533972\n",
      "Epoch 56 num_samples 4500 loss 0.02056817779166855\n",
      "Epoch 56 num_samples 4600 loss 0.016469688678671303\n",
      "Epoch 56 num_samples 4700 loss 0.009892272865973249\n",
      "Epoch 56 num_samples 4800 loss 0.009846292965859248\n",
      "Epoch 56 num_samples 4900 loss 0.012433767456383053\n",
      "Epoch 56 num_samples 5000 loss 0.011251644308232478\n",
      "Epoch 56 num_samples 5100 loss 0.020048078267445358\n",
      "Epoch 56 num_samples 5200 loss 0.010112537185802954\n",
      "Epoch 56 num_samples 5300 loss 0.013579328176188881\n",
      "Epoch 56 num_samples 5400 loss 0.018244118453223445\n",
      "Epoch 56 num_samples 5500 loss 0.0106019980076409\n",
      "Epoch 56 num_samples 5600 loss 0.045281475112253854\n",
      "Epoch 56 num_samples 5700 loss 0.015487693690105421\n",
      "Epoch 56 num_samples 5800 loss 0.01436055796051105\n",
      "Epoch 56 num_samples 5900 loss 0.018324520610895557\n",
      "Epoch 56 num_samples 6000 loss 0.014691319837023174\n",
      "Epoch 56 num_samples 6100 loss 0.013244093039603673\n",
      "Epoch 56 num_samples 6200 loss 0.01578187756090319\n",
      "Epoch 56 num_samples 6300 loss 0.02080598632365124\n",
      "Epoch 56 num_samples 6400 loss 0.01201236187275435\n",
      "Epoch 56 num_samples 6500 loss 0.01103164344222477\n",
      "Epoch 56 num_samples 6600 loss 0.023797544963155046\n",
      "Epoch 56 num_samples 6700 loss 0.011957227333117154\n",
      "Epoch 56 num_samples 6800 loss 0.008093936333307954\n",
      "Epoch 56 num_samples 6900 loss 0.030525193209647607\n",
      "Epoch 56 num_samples 7000 loss 0.018559850848118006\n",
      "Epoch 56 num_samples 7100 loss 0.010187183935509929\n",
      "Epoch 56 num_samples 7200 loss 0.014466511427366347\n",
      "Epoch 56 num_samples 7300 loss 0.013781262136250392\n",
      "Epoch 56 num_samples 7400 loss 0.01047945004120447\n",
      "Epoch 56 num_samples 7500 loss 0.024382020956464297\n",
      "Epoch 56 num_samples 7600 loss 0.015226552291164541\n",
      "Epoch 56 num_samples 7700 loss 0.022340974094784704\n",
      "Epoch 56 num_samples 7800 loss 0.012260196237026002\n",
      "Epoch 56 num_samples 7900 loss 0.01500997918863594\n",
      "Epoch 56 num_samples 8000 loss 0.01043470226327506\n",
      "Epoch 56 num_samples 8100 loss 0.01373118790724328\n",
      "Epoch 56 num_samples 8200 loss 0.015816014697610185\n",
      "Epoch 56 num_samples 8300 loss 0.01326983400951917\n",
      "Epoch 56 num_samples 8400 loss 0.01065716795827621\n",
      "Epoch 56 num_samples 8500 loss 0.015053715399806584\n",
      "Epoch 56 num_samples 8600 loss 0.015106517943742778\n",
      "Epoch 56 num_samples 8700 loss 0.01490422887793376\n",
      "Epoch 56 num_samples 8800 loss 0.01555445235224463\n",
      "Epoch 56 num_samples 8900 loss 0.018032166612611984\n",
      "Epoch 56 num_samples 9000 loss 0.014441584597180248\n",
      "Epoch 56 num_samples 9100 loss 0.014845887159465228\n",
      "Epoch 56 num_samples 9200 loss 0.015006713321805545\n",
      "Epoch 56 num_samples 9300 loss 0.014797398571333649\n",
      "Epoch 56 num_samples 9400 loss 0.012723071974059476\n",
      "Epoch 56 num_samples 9500 loss 0.012917064532566242\n",
      "Epoch 56 num_samples 9600 loss 0.013117266209045606\n",
      "Epoch 56 num_samples 9700 loss 0.02254198356758429\n",
      "Epoch 56 num_samples 9800 loss 0.009015978734304765\n",
      "Epoch 56 num_samples 9900 loss 0.02821617988679986\n",
      "Epoch 56 num_samples 10000 loss 0.013158898670950613\n",
      "Epoch 56 num_samples 10100 loss 0.011732595495225293\n",
      "Epoch 56 num_samples 10200 loss 0.018046821972617474\n",
      "Epoch 56 num_samples 10300 loss 0.014205132465589472\n",
      "Epoch 56 num_samples 10400 loss 0.019082368944236847\n",
      "Epoch 56 num_samples 10500 loss 0.012642515105462908\n",
      "Epoch 56 num_samples 10600 loss 0.018338936550931814\n",
      "Epoch 56 num_samples 10700 loss 0.013223830227142946\n",
      "Epoch 56 num_samples 10800 loss 0.01694365500424327\n",
      "Epoch 56 num_samples 10900 loss 0.0123393764220391\n",
      "Epoch 56 num_samples 11000 loss 0.01125245660134244\n",
      "Epoch 56 num_samples 11100 loss 0.0147060179412347\n",
      "Epoch 56 num_samples 11200 loss 0.011962724111565761\n",
      "Epoch 56 num_samples 11300 loss 0.020504899338266644\n",
      "Epoch 56 num_samples 11400 loss 0.014145831827712856\n",
      "Epoch 56 num_samples 11500 loss 0.013767856696133913\n",
      "Epoch 56 num_samples 11600 loss 0.012858098515123357\n",
      "Epoch 56 num_samples 11700 loss 0.018616610546427364\n",
      "Epoch 56 num_samples 11800 loss 0.01283844472037684\n",
      "Epoch 56 num_samples 11900 loss 0.01150493418133466\n",
      "Epoch 56 num_samples 12000 loss 0.010015537018508804\n",
      "Epoch 56 num_samples 12100 loss 0.011441533487431502\n",
      "Epoch 56 num_samples 12200 loss 0.017750136731027776\n",
      "Epoch 56 num_samples 12300 loss 0.010838023729467938\n",
      "Epoch 56 num_samples 12400 loss 0.01864202839039239\n",
      "Epoch 56 num_samples 12500 loss 0.015847828596011193\n",
      "Epoch 56 num_samples 12600 loss 0.019772806046260468\n",
      "Epoch 56 num_samples 12700 loss 0.015364867139887592\n",
      "Epoch 56 num_samples 12800 loss 0.02494346597381149\n",
      "Epoch 56 num_samples 12900 loss 0.013057114787039449\n",
      "Epoch 56 num_samples 13000 loss 0.01171846323159807\n",
      "Epoch 56 num_samples 13100 loss 0.02090946021240752\n",
      "Epoch 56 num_samples 13200 loss 0.008900502988621876\n",
      "Epoch 56 num_samples 13300 loss 0.010938649962540401\n",
      "Epoch 56 num_samples 13400 loss 0.0072779689463395745\n",
      "Epoch 56 num_samples 13500 loss 0.010959393899417368\n",
      "Epoch 56 num_samples 13600 loss 0.019717395832296935\n",
      "Epoch 56 num_samples 13700 loss 0.01421650398256859\n",
      "Epoch 56 num_samples 13800 loss 0.013106472870589676\n",
      "Epoch 56 num_samples 13900 loss 0.005666496857501542\n",
      "Epoch 56 num_samples 14000 loss 0.010019934186054473\n",
      "Epoch 56 num_samples 14100 loss 0.013168252775484852\n",
      "Epoch 56 num_samples 14200 loss 0.011096228728963908\n",
      "Epoch 56 num_samples 14300 loss 0.015454269444865085\n",
      "Epoch 56 num_samples 14400 loss 0.0159004353101894\n",
      "Epoch 56 num_samples 14500 loss 0.018282253811935077\n",
      "Epoch 56 num_samples 14600 loss 0.013853714583395205\n",
      "Epoch 56 num_samples 14700 loss 0.014326402114766016\n",
      "Epoch 56 num_samples 14800 loss 0.013466617260813057\n",
      "Epoch 56 num_samples 14900 loss 0.01672281458210069\n",
      "Epoch 56 num_samples 15000 loss 0.01289748277119853\n",
      "Epoch 56 num_samples 15100 loss 0.014868901869928803\n",
      "Epoch 56 num_samples 15200 loss 0.01595542778698644\n",
      "Epoch 56 num_samples 15300 loss 0.015819952927645275\n",
      "Epoch 56 num_samples 15400 loss 0.009898730445878624\n",
      "Epoch 56 num_samples 15500 loss 0.01576636179998355\n",
      "Epoch 56 num_samples 15600 loss 0.015809546528964668\n",
      "Epoch 56 num_samples 15700 loss 0.010158031251181022\n",
      "Epoch 56 num_samples 15800 loss 0.01838599262848526\n",
      "Epoch 56 num_samples 15900 loss 0.010578992100740581\n",
      "Epoch 56 num_samples 16000 loss 0.020405999177985256\n",
      "Epoch 56 num_samples 16100 loss 0.010676013151721382\n",
      "Epoch 56 num_samples 16200 loss 0.016477465445081857\n",
      "Epoch 56 num_samples 16300 loss 0.019756105788192424\n",
      "Epoch 56 num_samples 16400 loss 0.019723703765114994\n",
      "Epoch 56 num_samples 16500 loss 0.017163496633594982\n",
      "Epoch 56 num_samples 16600 loss 0.018035455639720244\n",
      "Epoch 56 num_samples 16700 loss 0.009863807227287058\n",
      "Epoch 56 num_samples 16800 loss 0.01012878977796384\n",
      "Epoch 56 num_samples 16900 loss 0.012000609928610044\n",
      "Epoch 56 num_samples 17000 loss 0.009057352974104638\n",
      "Epoch 56 num_samples 17100 loss 0.025105904814157066\n",
      "Epoch 56 num_samples 17200 loss 0.016387235472350273\n",
      "Epoch 56 num_samples 17300 loss 0.017282302118383056\n",
      "Epoch 56 num_samples 17400 loss 0.014558310735459566\n",
      "Epoch 56 num_samples 17500 loss 0.01450052609683636\n",
      "Epoch 56 num_samples 17600 loss 0.013686636664240961\n",
      "Epoch 56 num_samples 17700 loss 0.011164019372563108\n",
      "Epoch 56 num_samples 17800 loss 0.0123216086747346\n",
      "Epoch 56 num_samples 17900 loss 0.01915846619656294\n",
      "Epoch 56 num_samples 18000 loss 0.013042229046466298\n",
      "Epoch 56 num_samples 18100 loss 0.014583557161231298\n",
      "Epoch 56 num_samples 18200 loss 0.015424220131268793\n",
      "Epoch 56 num_samples 18300 loss 0.011535784285950585\n",
      "Epoch 56 num_samples 18400 loss 0.02294931646934926\n",
      "Epoch 56 num_samples 18500 loss 0.015620482668868334\n",
      "Epoch 57 num_samples 0 loss 0.010872009285288364\n",
      "Epoch 57 num_samples 100 loss 0.0197940818408205\n",
      "Epoch 57 num_samples 200 loss 0.01284162783010821\n",
      "Epoch 57 num_samples 300 loss 0.011017161440790069\n",
      "Epoch 57 num_samples 400 loss 0.012847073891472587\n",
      "Epoch 57 num_samples 500 loss 0.01914230843054767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 num_samples 600 loss 0.020738820242540444\n",
      "Epoch 57 num_samples 700 loss 0.021482723497259847\n",
      "Epoch 57 num_samples 800 loss 0.012961672980157823\n",
      "Epoch 57 num_samples 900 loss 0.02203305443901555\n",
      "Epoch 57 num_samples 1000 loss 0.013205422050654279\n",
      "Epoch 57 num_samples 1100 loss 0.022445801240593845\n",
      "Epoch 57 num_samples 1200 loss 0.013278148283132063\n",
      "Epoch 57 num_samples 1300 loss 0.015433017360152288\n",
      "Epoch 57 num_samples 1400 loss 0.016531005258373175\n",
      "Epoch 57 num_samples 1500 loss 0.02113032217788442\n",
      "Epoch 57 num_samples 1600 loss 0.013755328316553803\n",
      "Epoch 57 num_samples 1700 loss 0.013208724417379414\n",
      "Epoch 57 num_samples 1800 loss 0.012896674131142333\n",
      "Epoch 57 num_samples 1900 loss 0.015431785873096513\n",
      "Epoch 57 num_samples 2000 loss 0.018098517886956298\n",
      "Epoch 57 num_samples 2100 loss 0.009775502488549075\n",
      "Epoch 57 num_samples 2200 loss 0.010735621594310251\n",
      "Epoch 57 num_samples 2300 loss 0.0072278512668700915\n",
      "Epoch 57 num_samples 2400 loss 0.012464510403475333\n",
      "Epoch 57 num_samples 2500 loss 0.017001915123933942\n",
      "Epoch 57 num_samples 2600 loss 0.018021204287599065\n",
      "Epoch 57 num_samples 2700 loss 0.012406795042830088\n",
      "Epoch 57 num_samples 2800 loss 0.018603839092557264\n",
      "Epoch 57 num_samples 2900 loss 0.016530003971117594\n",
      "Epoch 57 num_samples 3000 loss 0.013990064022826489\n",
      "Epoch 57 num_samples 3100 loss 0.013028338550819647\n",
      "Epoch 57 num_samples 3200 loss 0.026822655317854396\n",
      "Epoch 57 num_samples 3300 loss 0.0154071314176019\n",
      "Epoch 57 num_samples 3400 loss 0.011758168280981444\n",
      "Epoch 57 num_samples 3500 loss 0.0120625186687201\n",
      "Epoch 57 num_samples 3600 loss 0.00841572532230414\n",
      "Epoch 57 num_samples 3700 loss 0.022046804206745964\n",
      "Epoch 57 num_samples 3800 loss 0.012631822122418607\n",
      "Epoch 57 num_samples 3900 loss 0.015089734307640334\n",
      "Epoch 57 num_samples 4000 loss 0.01731656787236472\n",
      "Epoch 57 num_samples 4100 loss 0.022885980672622264\n",
      "Epoch 57 num_samples 4200 loss 0.01449414353217645\n",
      "Epoch 57 num_samples 4300 loss 0.0137030541038113\n",
      "Epoch 57 num_samples 4400 loss 0.016419458373747163\n",
      "Epoch 57 num_samples 4500 loss 0.019828686137729364\n",
      "Epoch 57 num_samples 4600 loss 0.015993776326378745\n",
      "Epoch 57 num_samples 4700 loss 0.009551018786706712\n",
      "Epoch 57 num_samples 4800 loss 0.009578970905814862\n",
      "Epoch 57 num_samples 4900 loss 0.012054162613242604\n",
      "Epoch 57 num_samples 5000 loss 0.010897404491609964\n",
      "Epoch 57 num_samples 5100 loss 0.01945583373380457\n",
      "Epoch 57 num_samples 5200 loss 0.009765552518890214\n",
      "Epoch 57 num_samples 5300 loss 0.013140187314996297\n",
      "Epoch 57 num_samples 5400 loss 0.017676749732646536\n",
      "Epoch 57 num_samples 5500 loss 0.010307556209125797\n",
      "Epoch 57 num_samples 5600 loss 0.04306919404913178\n",
      "Epoch 57 num_samples 5700 loss 0.014924380053450738\n",
      "Epoch 57 num_samples 5800 loss 0.013865766763849173\n",
      "Epoch 57 num_samples 5900 loss 0.017737501381788583\n",
      "Epoch 57 num_samples 6000 loss 0.014268468163022893\n",
      "Epoch 57 num_samples 6100 loss 0.012860792482067158\n",
      "Epoch 57 num_samples 6200 loss 0.0152202848894012\n",
      "Epoch 57 num_samples 6300 loss 0.020009641079218755\n",
      "Epoch 57 num_samples 6400 loss 0.011601299819466003\n",
      "Epoch 57 num_samples 6500 loss 0.010656528143890351\n",
      "Epoch 57 num_samples 6600 loss 0.02314195267042857\n",
      "Epoch 57 num_samples 6700 loss 0.011553691582416039\n",
      "Epoch 57 num_samples 6800 loss 0.007863388118122705\n",
      "Epoch 57 num_samples 6900 loss 0.029611198632733572\n",
      "Epoch 57 num_samples 7000 loss 0.017993188433217816\n",
      "Epoch 57 num_samples 7100 loss 0.009800080162439063\n",
      "Epoch 57 num_samples 7200 loss 0.01399842538326863\n",
      "Epoch 57 num_samples 7300 loss 0.013385541088277482\n",
      "Epoch 57 num_samples 7400 loss 0.010171601226183819\n",
      "Epoch 57 num_samples 7500 loss 0.023508196064617747\n",
      "Epoch 57 num_samples 7600 loss 0.014653900429483686\n",
      "Epoch 57 num_samples 7700 loss 0.02150175415728265\n",
      "Epoch 57 num_samples 7800 loss 0.01181779982713093\n",
      "Epoch 57 num_samples 7900 loss 0.014609144069454159\n",
      "Epoch 57 num_samples 8000 loss 0.010086957663597976\n",
      "Epoch 57 num_samples 8100 loss 0.013232185818126968\n",
      "Epoch 57 num_samples 8200 loss 0.015242729610013281\n",
      "Epoch 57 num_samples 8300 loss 0.01273294040784259\n",
      "Epoch 57 num_samples 8400 loss 0.010262145323096302\n",
      "Epoch 57 num_samples 8500 loss 0.014455375359315651\n",
      "Epoch 57 num_samples 8600 loss 0.014664529194935626\n",
      "Epoch 57 num_samples 8700 loss 0.014306876629784861\n",
      "Epoch 57 num_samples 8800 loss 0.014905961652076624\n",
      "Epoch 57 num_samples 8900 loss 0.01741929999085401\n",
      "Epoch 57 num_samples 9000 loss 0.013999034474263128\n",
      "Epoch 57 num_samples 9100 loss 0.014332749100052325\n",
      "Epoch 57 num_samples 9200 loss 0.01452356663994677\n",
      "Epoch 57 num_samples 9300 loss 0.014316817099466639\n",
      "Epoch 57 num_samples 9400 loss 0.012347676851578258\n",
      "Epoch 57 num_samples 9500 loss 0.012447759502512179\n",
      "Epoch 57 num_samples 9600 loss 0.01275991505436081\n",
      "Epoch 57 num_samples 9700 loss 0.021717912523212746\n",
      "Epoch 57 num_samples 9800 loss 0.008706613193949646\n",
      "Epoch 57 num_samples 9900 loss 0.02722131164996229\n",
      "Epoch 57 num_samples 10000 loss 0.01267751091965408\n",
      "Epoch 57 num_samples 10100 loss 0.011277885397291056\n",
      "Epoch 57 num_samples 10200 loss 0.017548324353400934\n",
      "Epoch 57 num_samples 10300 loss 0.013759462584583692\n",
      "Epoch 57 num_samples 10400 loss 0.0184282510273816\n",
      "Epoch 57 num_samples 10500 loss 0.012171303275440505\n",
      "Epoch 57 num_samples 10600 loss 0.017611623147932565\n",
      "Epoch 57 num_samples 10700 loss 0.012809999865199026\n",
      "Epoch 57 num_samples 10800 loss 0.016424530868011145\n",
      "Epoch 57 num_samples 10900 loss 0.011939440502562917\n",
      "Epoch 57 num_samples 11000 loss 0.010867653131788757\n",
      "Epoch 57 num_samples 11100 loss 0.014262677119039422\n",
      "Epoch 57 num_samples 11200 loss 0.0116034549819946\n",
      "Epoch 57 num_samples 11300 loss 0.019768028474511465\n",
      "Epoch 57 num_samples 11400 loss 0.013613414480509496\n",
      "Epoch 57 num_samples 11500 loss 0.013262033806201046\n",
      "Epoch 57 num_samples 11600 loss 0.012336122993595076\n",
      "Epoch 57 num_samples 11700 loss 0.017897113264698557\n",
      "Epoch 57 num_samples 11800 loss 0.012443082964137146\n",
      "Epoch 57 num_samples 11900 loss 0.011116581731568227\n",
      "Epoch 57 num_samples 12000 loss 0.009674713914977815\n",
      "Epoch 57 num_samples 12100 loss 0.011028936763386734\n",
      "Epoch 57 num_samples 12200 loss 0.017021746887472204\n",
      "Epoch 57 num_samples 12300 loss 0.010559440165664988\n",
      "Epoch 57 num_samples 12400 loss 0.018019443290392546\n",
      "Epoch 57 num_samples 12500 loss 0.01528213857457269\n",
      "Epoch 57 num_samples 12600 loss 0.01911007231529503\n",
      "Epoch 57 num_samples 12700 loss 0.014856743731661926\n",
      "Epoch 57 num_samples 12800 loss 0.023905627031629625\n",
      "Epoch 57 num_samples 12900 loss 0.01253520504125661\n",
      "Epoch 57 num_samples 13000 loss 0.011275722219057212\n",
      "Epoch 57 num_samples 13100 loss 0.02000745263482603\n",
      "Epoch 57 num_samples 13200 loss 0.008559311205593645\n",
      "Epoch 57 num_samples 13300 loss 0.010612835205371289\n",
      "Epoch 57 num_samples 13400 loss 0.007086610614887047\n",
      "Epoch 57 num_samples 13500 loss 0.010541024813029312\n",
      "Epoch 57 num_samples 13600 loss 0.018952685391762758\n",
      "Epoch 57 num_samples 13700 loss 0.013654375006576895\n",
      "Epoch 57 num_samples 13800 loss 0.012660504341586791\n",
      "Epoch 57 num_samples 13900 loss 0.005472780803243915\n",
      "Epoch 57 num_samples 14000 loss 0.009659243817750403\n",
      "Epoch 57 num_samples 14100 loss 0.012709891130713883\n",
      "Epoch 57 num_samples 14200 loss 0.010780465572140727\n",
      "Epoch 57 num_samples 14300 loss 0.01494263296171089\n",
      "Epoch 57 num_samples 14400 loss 0.015323542200687641\n",
      "Epoch 57 num_samples 14500 loss 0.01776729160022211\n",
      "Epoch 57 num_samples 14600 loss 0.013376821724004041\n",
      "Epoch 57 num_samples 14700 loss 0.013827122539922163\n",
      "Epoch 57 num_samples 14800 loss 0.013066287882539775\n",
      "Epoch 57 num_samples 14900 loss 0.01604215808471843\n",
      "Epoch 57 num_samples 15000 loss 0.01248912030780911\n",
      "Epoch 57 num_samples 15100 loss 0.014407304342935488\n",
      "Epoch 57 num_samples 15200 loss 0.015347108653333415\n",
      "Epoch 57 num_samples 15300 loss 0.015309648977162133\n",
      "Epoch 57 num_samples 15400 loss 0.00964829041971588\n",
      "Epoch 57 num_samples 15500 loss 0.015211349152907084\n",
      "Epoch 57 num_samples 15600 loss 0.015246329954703684\n",
      "Epoch 57 num_samples 15700 loss 0.009884549165571584\n",
      "Epoch 57 num_samples 15800 loss 0.017634753051276788\n",
      "Epoch 57 num_samples 15900 loss 0.010306607070369022\n",
      "Epoch 57 num_samples 16000 loss 0.019757962350897624\n",
      "Epoch 57 num_samples 16100 loss 0.010289102602109272\n",
      "Epoch 57 num_samples 16200 loss 0.015929055546585056\n",
      "Epoch 57 num_samples 16300 loss 0.019112559527421937\n",
      "Epoch 57 num_samples 16400 loss 0.01916545356980219\n",
      "Epoch 57 num_samples 16500 loss 0.016550260901895767\n",
      "Epoch 57 num_samples 16600 loss 0.017454692022071953\n",
      "Epoch 57 num_samples 16700 loss 0.009589892622284685\n",
      "Epoch 57 num_samples 16800 loss 0.00982942272705856\n",
      "Epoch 57 num_samples 16900 loss 0.011608062747659345\n",
      "Epoch 57 num_samples 17000 loss 0.008793271281930788\n",
      "Epoch 57 num_samples 17100 loss 0.023940164277859735\n",
      "Epoch 57 num_samples 17200 loss 0.015826705736866526\n",
      "Epoch 57 num_samples 17300 loss 0.01653251837885025\n",
      "Epoch 57 num_samples 17400 loss 0.014081798382981594\n",
      "Epoch 57 num_samples 17500 loss 0.014011686789284418\n",
      "Epoch 57 num_samples 17600 loss 0.013223933223327227\n",
      "Epoch 57 num_samples 17700 loss 0.01077442711996749\n",
      "Epoch 57 num_samples 17800 loss 0.011874462155178482\n",
      "Epoch 57 num_samples 17900 loss 0.01850405492854032\n",
      "Epoch 57 num_samples 18000 loss 0.012602348688171314\n",
      "Epoch 57 num_samples 18100 loss 0.014155888777247381\n",
      "Epoch 57 num_samples 18200 loss 0.014937044045330538\n",
      "Epoch 57 num_samples 18300 loss 0.0111782341564573\n",
      "Epoch 57 num_samples 18400 loss 0.022193422851329442\n",
      "Epoch 57 num_samples 18500 loss 0.015064529142503292\n",
      "Epoch 58 num_samples 0 loss 0.010482160698562323\n",
      "Epoch 58 num_samples 100 loss 0.019190216608673864\n",
      "Epoch 58 num_samples 200 loss 0.012355698169309615\n",
      "Epoch 58 num_samples 300 loss 0.010659264296637968\n",
      "Epoch 58 num_samples 400 loss 0.012454829963658272\n",
      "Epoch 58 num_samples 500 loss 0.018712447522518934\n",
      "Epoch 58 num_samples 600 loss 0.01995312007683097\n",
      "Epoch 58 num_samples 700 loss 0.020636047539269457\n",
      "Epoch 58 num_samples 800 loss 0.012544535251396644\n",
      "Epoch 58 num_samples 900 loss 0.02128295373883604\n",
      "Epoch 58 num_samples 1000 loss 0.012755908201480187\n",
      "Epoch 58 num_samples 1100 loss 0.02164650294817503\n",
      "Epoch 58 num_samples 1200 loss 0.012933037137510898\n",
      "Epoch 58 num_samples 1300 loss 0.014896838061553657\n",
      "Epoch 58 num_samples 1400 loss 0.01587009154723465\n",
      "Epoch 58 num_samples 1500 loss 0.02033122029518432\n",
      "Epoch 58 num_samples 1600 loss 0.01343855525495026\n",
      "Epoch 58 num_samples 1700 loss 0.012828078647169535\n",
      "Epoch 58 num_samples 1800 loss 0.012483437553890633\n",
      "Epoch 58 num_samples 1900 loss 0.015003486328982924\n",
      "Epoch 58 num_samples 2000 loss 0.017517445674623416\n",
      "Epoch 58 num_samples 2100 loss 0.009408708981211916\n",
      "Epoch 58 num_samples 2200 loss 0.010430869196148978\n",
      "Epoch 58 num_samples 2300 loss 0.006995052289583528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 num_samples 2400 loss 0.01198076093675619\n",
      "Epoch 58 num_samples 2500 loss 0.01646949653595862\n",
      "Epoch 58 num_samples 2600 loss 0.017323231730502476\n",
      "Epoch 58 num_samples 2700 loss 0.011993066306305276\n",
      "Epoch 58 num_samples 2800 loss 0.017965454812271322\n",
      "Epoch 58 num_samples 2900 loss 0.01594452501397669\n",
      "Epoch 58 num_samples 3000 loss 0.013492489398093967\n",
      "Epoch 58 num_samples 3100 loss 0.01256683188373278\n",
      "Epoch 58 num_samples 3200 loss 0.025493555083017067\n",
      "Epoch 58 num_samples 3300 loss 0.01483781848248008\n",
      "Epoch 58 num_samples 3400 loss 0.011405296859008297\n",
      "Epoch 58 num_samples 3500 loss 0.011791276840826988\n",
      "Epoch 58 num_samples 3600 loss 0.008238545402380075\n",
      "Epoch 58 num_samples 3700 loss 0.021276414744876578\n",
      "Epoch 58 num_samples 3800 loss 0.012214974721578753\n",
      "Epoch 58 num_samples 3900 loss 0.014608882365849517\n",
      "Epoch 58 num_samples 4000 loss 0.016695527341823734\n",
      "Epoch 58 num_samples 4100 loss 0.02186654038815626\n",
      "Epoch 58 num_samples 4200 loss 0.014079150454994067\n",
      "Epoch 58 num_samples 4300 loss 0.013297232454499892\n",
      "Epoch 58 num_samples 4400 loss 0.015813046674250972\n",
      "Epoch 58 num_samples 4500 loss 0.01899028108470755\n",
      "Epoch 58 num_samples 4600 loss 0.015457709450001855\n",
      "Epoch 58 num_samples 4700 loss 0.009230637164828848\n",
      "Epoch 58 num_samples 4800 loss 0.00934807122191671\n",
      "Epoch 58 num_samples 4900 loss 0.011685043259980859\n",
      "Epoch 58 num_samples 5000 loss 0.010469347212040509\n",
      "Epoch 58 num_samples 5100 loss 0.018840353219147853\n",
      "Epoch 58 num_samples 5200 loss 0.00944733138144868\n",
      "Epoch 58 num_samples 5300 loss 0.012733954092820028\n",
      "Epoch 58 num_samples 5400 loss 0.017078033080953816\n",
      "Epoch 58 num_samples 5500 loss 0.010047447669440115\n",
      "Epoch 58 num_samples 5600 loss 0.04109469792555534\n",
      "Epoch 58 num_samples 5700 loss 0.014204143311647687\n",
      "Epoch 58 num_samples 5800 loss 0.013330895592802608\n",
      "Epoch 58 num_samples 5900 loss 0.017151231718754233\n",
      "Epoch 58 num_samples 6000 loss 0.013882291802535324\n",
      "Epoch 58 num_samples 6100 loss 0.01242647739777226\n",
      "Epoch 58 num_samples 6200 loss 0.01473809557474382\n",
      "Epoch 58 num_samples 6300 loss 0.0192464640847185\n",
      "Epoch 58 num_samples 6400 loss 0.011282924249516603\n",
      "Epoch 58 num_samples 6500 loss 0.010304097276181248\n",
      "Epoch 58 num_samples 6600 loss 0.02242225320408159\n",
      "Epoch 58 num_samples 6700 loss 0.011280668704869625\n",
      "Epoch 58 num_samples 6800 loss 0.007592339023621355\n",
      "Epoch 58 num_samples 6900 loss 0.02856596489683073\n",
      "Epoch 58 num_samples 7000 loss 0.017311939863222506\n",
      "Epoch 58 num_samples 7100 loss 0.009455627840701985\n",
      "Epoch 58 num_samples 7200 loss 0.013550916392757774\n",
      "Epoch 58 num_samples 7300 loss 0.01298654295746013\n",
      "Epoch 58 num_samples 7400 loss 0.009826583948916978\n",
      "Epoch 58 num_samples 7500 loss 0.02257432161721191\n",
      "Epoch 58 num_samples 7600 loss 0.014275058439373975\n",
      "Epoch 58 num_samples 7700 loss 0.020685432374513056\n",
      "Epoch 58 num_samples 7800 loss 0.01156696765071713\n",
      "Epoch 58 num_samples 7900 loss 0.014136625784204063\n",
      "Epoch 58 num_samples 8000 loss 0.009688301174871882\n",
      "Epoch 58 num_samples 8100 loss 0.01280483471705674\n",
      "Epoch 58 num_samples 8200 loss 0.01475560913412319\n",
      "Epoch 58 num_samples 8300 loss 0.012175733040049269\n",
      "Epoch 58 num_samples 8400 loss 0.009877103255339168\n",
      "Epoch 58 num_samples 8500 loss 0.014066881005494202\n",
      "Epoch 58 num_samples 8600 loss 0.0141278064027961\n",
      "Epoch 58 num_samples 8700 loss 0.013822651071777272\n",
      "Epoch 58 num_samples 8800 loss 0.014266448037701036\n",
      "Epoch 58 num_samples 8900 loss 0.01685332871627953\n",
      "Epoch 58 num_samples 9000 loss 0.01354604533739515\n",
      "Epoch 58 num_samples 9100 loss 0.013835911580715336\n",
      "Epoch 58 num_samples 9200 loss 0.014047313883027136\n",
      "Epoch 58 num_samples 9300 loss 0.01384745789125794\n",
      "Epoch 58 num_samples 9400 loss 0.011844428416405574\n",
      "Epoch 58 num_samples 9500 loss 0.012047947399950364\n",
      "Epoch 58 num_samples 9600 loss 0.012353503712336615\n",
      "Epoch 58 num_samples 9700 loss 0.020893394313764448\n",
      "Epoch 58 num_samples 9800 loss 0.008474317425017669\n",
      "Epoch 58 num_samples 9900 loss 0.02626589515537587\n",
      "Epoch 58 num_samples 10000 loss 0.012170110930768611\n",
      "Epoch 58 num_samples 10100 loss 0.010922554151691619\n",
      "Epoch 58 num_samples 10200 loss 0.01701222728729105\n",
      "Epoch 58 num_samples 10300 loss 0.013241897854340908\n",
      "Epoch 58 num_samples 10400 loss 0.017757094411019532\n",
      "Epoch 58 num_samples 10500 loss 0.011876323517160215\n",
      "Epoch 58 num_samples 10600 loss 0.016846693980668116\n",
      "Epoch 58 num_samples 10700 loss 0.012375490834646327\n",
      "Epoch 58 num_samples 10800 loss 0.015969321257170325\n",
      "Epoch 58 num_samples 10900 loss 0.011595411741516546\n",
      "Epoch 58 num_samples 11000 loss 0.01053980607197881\n",
      "Epoch 58 num_samples 11100 loss 0.013802944887051026\n",
      "Epoch 58 num_samples 11200 loss 0.011231082616059634\n",
      "Epoch 58 num_samples 11300 loss 0.01905566946000103\n",
      "Epoch 58 num_samples 11400 loss 0.013090678102574839\n",
      "Epoch 58 num_samples 11500 loss 0.012788571703076972\n",
      "Epoch 58 num_samples 11600 loss 0.011906774792969593\n",
      "Epoch 58 num_samples 11700 loss 0.017187679556039188\n",
      "Epoch 58 num_samples 11800 loss 0.012058117430389736\n",
      "Epoch 58 num_samples 11900 loss 0.010751719441678693\n",
      "Epoch 58 num_samples 12000 loss 0.009353966009694624\n",
      "Epoch 58 num_samples 12100 loss 0.010569752148293983\n",
      "Epoch 58 num_samples 12200 loss 0.016398648699135977\n",
      "Epoch 58 num_samples 12300 loss 0.010317588652453127\n",
      "Epoch 58 num_samples 12400 loss 0.017338748859460087\n",
      "Epoch 58 num_samples 12500 loss 0.014976295374229447\n",
      "Epoch 58 num_samples 12600 loss 0.01851615293108314\n",
      "Epoch 58 num_samples 12700 loss 0.014305788925657098\n",
      "Epoch 58 num_samples 12800 loss 0.023045137349401282\n",
      "Epoch 58 num_samples 12900 loss 0.01208560474742041\n",
      "Epoch 58 num_samples 13000 loss 0.010980425245075165\n",
      "Epoch 58 num_samples 13100 loss 0.019150155301801364\n",
      "Epoch 58 num_samples 13200 loss 0.008169161454340964\n",
      "Epoch 58 num_samples 13300 loss 0.010273995291924902\n",
      "Epoch 58 num_samples 13400 loss 0.006870012943833418\n",
      "Epoch 58 num_samples 13500 loss 0.010103642641706333\n",
      "Epoch 58 num_samples 13600 loss 0.018244281116794447\n",
      "Epoch 58 num_samples 13700 loss 0.013126989062378224\n",
      "Epoch 58 num_samples 13800 loss 0.012165912720297076\n",
      "Epoch 58 num_samples 13900 loss 0.005323611963824826\n",
      "Epoch 58 num_samples 14000 loss 0.009307656992048436\n",
      "Epoch 58 num_samples 14100 loss 0.012246747972570825\n",
      "Epoch 58 num_samples 14200 loss 0.010387094500969812\n",
      "Epoch 58 num_samples 14300 loss 0.014461306148284553\n",
      "Epoch 58 num_samples 14400 loss 0.014870346065366094\n",
      "Epoch 58 num_samples 14500 loss 0.017258868823505257\n",
      "Epoch 58 num_samples 14600 loss 0.01297334722929236\n",
      "Epoch 58 num_samples 14700 loss 0.013414200825288458\n",
      "Epoch 58 num_samples 14800 loss 0.012590200740142589\n",
      "Epoch 58 num_samples 14900 loss 0.015449212468238781\n",
      "Epoch 58 num_samples 15000 loss 0.012144596322954265\n",
      "Epoch 58 num_samples 15100 loss 0.01394283055206809\n",
      "Epoch 58 num_samples 15200 loss 0.014751483258417984\n",
      "Epoch 58 num_samples 15300 loss 0.014622509126759052\n",
      "Epoch 58 num_samples 15400 loss 0.009387985004338484\n",
      "Epoch 58 num_samples 15500 loss 0.014597872318242344\n",
      "Epoch 58 num_samples 15600 loss 0.014782825943682956\n",
      "Epoch 58 num_samples 15700 loss 0.009550399615008254\n",
      "Epoch 58 num_samples 15800 loss 0.017026451933524003\n",
      "Epoch 58 num_samples 15900 loss 0.009973152555979999\n",
      "Epoch 58 num_samples 16000 loss 0.01910941167216752\n",
      "Epoch 58 num_samples 16100 loss 0.010023928086737332\n",
      "Epoch 58 num_samples 16200 loss 0.015429064838892486\n",
      "Epoch 58 num_samples 16300 loss 0.01838861190833528\n",
      "Epoch 58 num_samples 16400 loss 0.018374025516742533\n",
      "Epoch 58 num_samples 16500 loss 0.016016936287924773\n",
      "Epoch 58 num_samples 16600 loss 0.016830066846521566\n",
      "Epoch 58 num_samples 16700 loss 0.009297922548789316\n",
      "Epoch 58 num_samples 16800 loss 0.009591162693727078\n",
      "Epoch 58 num_samples 16900 loss 0.011215626897668609\n",
      "Epoch 58 num_samples 17000 loss 0.00849692724129176\n",
      "Epoch 58 num_samples 17100 loss 0.022973379076342337\n",
      "Epoch 58 num_samples 17200 loss 0.015394149955824457\n",
      "Epoch 58 num_samples 17300 loss 0.01602227980892765\n",
      "Epoch 58 num_samples 17400 loss 0.013673537741647972\n",
      "Epoch 58 num_samples 17500 loss 0.013639601773114624\n",
      "Epoch 58 num_samples 17600 loss 0.012773497452685412\n",
      "Epoch 58 num_samples 17700 loss 0.010452217779613257\n",
      "Epoch 58 num_samples 17800 loss 0.011505407441868462\n",
      "Epoch 58 num_samples 17900 loss 0.01784747329910281\n",
      "Epoch 58 num_samples 18000 loss 0.01213042308111302\n",
      "Epoch 58 num_samples 18100 loss 0.013686962525129947\n",
      "Epoch 58 num_samples 18200 loss 0.014463447175050716\n",
      "Epoch 58 num_samples 18300 loss 0.010823820002522239\n",
      "Epoch 58 num_samples 18400 loss 0.0214268203891133\n",
      "Epoch 58 num_samples 18500 loss 0.014604233646545665\n",
      "Epoch 59 num_samples 0 loss 0.010098663695290989\n",
      "Epoch 59 num_samples 100 loss 0.018488917603281384\n",
      "Epoch 59 num_samples 200 loss 0.012081713662544047\n",
      "Epoch 59 num_samples 300 loss 0.010334748216062626\n",
      "Epoch 59 num_samples 400 loss 0.012094677442887329\n",
      "Epoch 59 num_samples 500 loss 0.018110487354314413\n",
      "Epoch 59 num_samples 600 loss 0.019244605100836264\n",
      "Epoch 59 num_samples 700 loss 0.019929097358529387\n",
      "Epoch 59 num_samples 800 loss 0.012060276205929506\n",
      "Epoch 59 num_samples 900 loss 0.02066131547980443\n",
      "Epoch 59 num_samples 1000 loss 0.01242756509648248\n",
      "Epoch 59 num_samples 1100 loss 0.02097614065925014\n",
      "Epoch 59 num_samples 1200 loss 0.01240308327977465\n",
      "Epoch 59 num_samples 1300 loss 0.014448114357792904\n",
      "Epoch 59 num_samples 1400 loss 0.015210734002276847\n",
      "Epoch 59 num_samples 1500 loss 0.01959742403642384\n",
      "Epoch 59 num_samples 1600 loss 0.012991719608166523\n",
      "Epoch 59 num_samples 1700 loss 0.012421411216370762\n",
      "Epoch 59 num_samples 1800 loss 0.012074023417573757\n",
      "Epoch 59 num_samples 1900 loss 0.014533419126015365\n",
      "Epoch 59 num_samples 2000 loss 0.0169930854381547\n",
      "Epoch 59 num_samples 2100 loss 0.009092681406186246\n",
      "Epoch 59 num_samples 2200 loss 0.010104419803206956\n",
      "Epoch 59 num_samples 2300 loss 0.006755815624051518\n",
      "Epoch 59 num_samples 2400 loss 0.011623256298879303\n",
      "Epoch 59 num_samples 2500 loss 0.01585661746374524\n",
      "Epoch 59 num_samples 2600 loss 0.01675535533754242\n",
      "Epoch 59 num_samples 2700 loss 0.011622751023351282\n",
      "Epoch 59 num_samples 2800 loss 0.01727310572978708\n",
      "Epoch 59 num_samples 2900 loss 0.01542860174760564\n",
      "Epoch 59 num_samples 3000 loss 0.013030641637610363\n",
      "Epoch 59 num_samples 3100 loss 0.012143827897990955\n",
      "Epoch 59 num_samples 3200 loss 0.0244619700410253\n",
      "Epoch 59 num_samples 3300 loss 0.014471005536964779\n",
      "Epoch 59 num_samples 3400 loss 0.011107693806604176\n",
      "Epoch 59 num_samples 3500 loss 0.011395046666408394\n",
      "Epoch 59 num_samples 3600 loss 0.008014290220746052\n",
      "Epoch 59 num_samples 3700 loss 0.020410147405967756\n",
      "Epoch 59 num_samples 3800 loss 0.01173878294160746\n",
      "Epoch 59 num_samples 3900 loss 0.014096165515012271\n",
      "Epoch 59 num_samples 4000 loss 0.016144516731285086\n",
      "Epoch 59 num_samples 4100 loss 0.02103198316674742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 num_samples 4200 loss 0.01370042766853373\n",
      "Epoch 59 num_samples 4300 loss 0.012814303912964254\n",
      "Epoch 59 num_samples 4400 loss 0.015090612386962615\n",
      "Epoch 59 num_samples 4500 loss 0.018384409715138626\n",
      "Epoch 59 num_samples 4600 loss 0.015089330061560385\n",
      "Epoch 59 num_samples 4700 loss 0.008884696104077567\n",
      "Epoch 59 num_samples 4800 loss 0.008987732751847432\n",
      "Epoch 59 num_samples 4900 loss 0.01135617433221686\n",
      "Epoch 59 num_samples 5000 loss 0.010191296262409827\n",
      "Epoch 59 num_samples 5100 loss 0.01825335831371104\n",
      "Epoch 59 num_samples 5200 loss 0.009142133722229986\n",
      "Epoch 59 num_samples 5300 loss 0.012288708654652272\n",
      "Epoch 59 num_samples 5400 loss 0.01670058452729584\n",
      "Epoch 59 num_samples 5500 loss 0.009739103062997623\n",
      "Epoch 59 num_samples 5600 loss 0.039396509886513977\n",
      "Epoch 59 num_samples 5700 loss 0.013860237892563935\n",
      "Epoch 59 num_samples 5800 loss 0.01296150430192844\n",
      "Epoch 59 num_samples 5900 loss 0.016660241630493365\n",
      "Epoch 59 num_samples 6000 loss 0.01330341017862786\n",
      "Epoch 59 num_samples 6100 loss 0.012046173660700621\n",
      "Epoch 59 num_samples 6200 loss 0.014315157660235757\n",
      "Epoch 59 num_samples 6300 loss 0.018442769258166382\n",
      "Epoch 59 num_samples 6400 loss 0.010933233076775302\n",
      "Epoch 59 num_samples 6500 loss 0.0099460531336378\n",
      "Epoch 59 num_samples 6600 loss 0.02188604712754102\n",
      "Epoch 59 num_samples 6700 loss 0.010948040314670776\n",
      "Epoch 59 num_samples 6800 loss 0.007347933959804114\n",
      "Epoch 59 num_samples 6900 loss 0.027729267754975924\n",
      "Epoch 59 num_samples 7000 loss 0.01669024311622038\n",
      "Epoch 59 num_samples 7100 loss 0.009184246020555441\n",
      "Epoch 59 num_samples 7200 loss 0.01306096234276457\n",
      "Epoch 59 num_samples 7300 loss 0.012629854812282636\n",
      "Epoch 59 num_samples 7400 loss 0.00949351227634519\n",
      "Epoch 59 num_samples 7500 loss 0.02175244049153973\n",
      "Epoch 59 num_samples 7600 loss 0.01375751608219681\n",
      "Epoch 59 num_samples 7700 loss 0.01988452611970994\n",
      "Epoch 59 num_samples 7800 loss 0.011168561937730715\n",
      "Epoch 59 num_samples 7900 loss 0.013748081902570248\n",
      "Epoch 59 num_samples 8000 loss 0.00939235060945536\n",
      "Epoch 59 num_samples 8100 loss 0.012469833672806413\n",
      "Epoch 59 num_samples 8200 loss 0.014319831429412695\n",
      "Epoch 59 num_samples 8300 loss 0.011759604340524006\n",
      "Epoch 59 num_samples 8400 loss 0.009533426037706287\n",
      "Epoch 59 num_samples 8500 loss 0.013747860254829889\n",
      "Epoch 59 num_samples 8600 loss 0.013747223881390026\n",
      "Epoch 59 num_samples 8700 loss 0.013376043204259464\n",
      "Epoch 59 num_samples 8800 loss 0.013759209947802033\n",
      "Epoch 59 num_samples 8900 loss 0.016256518694244958\n",
      "Epoch 59 num_samples 9000 loss 0.013142907353784095\n",
      "Epoch 59 num_samples 9100 loss 0.01334252003804254\n",
      "Epoch 59 num_samples 9200 loss 0.0135803694204049\n",
      "Epoch 59 num_samples 9300 loss 0.013405436941680655\n",
      "Epoch 59 num_samples 9400 loss 0.011460456854675082\n",
      "Epoch 59 num_samples 9500 loss 0.011582990790976995\n",
      "Epoch 59 num_samples 9600 loss 0.011988068640506673\n",
      "Epoch 59 num_samples 9700 loss 0.02025586946911224\n",
      "Epoch 59 num_samples 9800 loss 0.008198272745479141\n",
      "Epoch 59 num_samples 9900 loss 0.02521668810390141\n",
      "Epoch 59 num_samples 10000 loss 0.011684411845162295\n",
      "Epoch 59 num_samples 10100 loss 0.010580075532864846\n",
      "Epoch 59 num_samples 10200 loss 0.016399735569455984\n",
      "Epoch 59 num_samples 10300 loss 0.012863419833172421\n",
      "Epoch 59 num_samples 10400 loss 0.017187212208230954\n",
      "Epoch 59 num_samples 10500 loss 0.011526931820967519\n",
      "Epoch 59 num_samples 10600 loss 0.016208696846750553\n",
      "Epoch 59 num_samples 10700 loss 0.011970163460507183\n",
      "Epoch 59 num_samples 10800 loss 0.015338482345594514\n",
      "Epoch 59 num_samples 10900 loss 0.011195610828171356\n",
      "Epoch 59 num_samples 11000 loss 0.010229168636198842\n",
      "Epoch 59 num_samples 11100 loss 0.013463968761310736\n",
      "Epoch 59 num_samples 11200 loss 0.010854742434661882\n",
      "Epoch 59 num_samples 11300 loss 0.018470537058276285\n",
      "Epoch 59 num_samples 11400 loss 0.01268893013843731\n",
      "Epoch 59 num_samples 11500 loss 0.012336834997936258\n",
      "Epoch 59 num_samples 11600 loss 0.011598472977409808\n",
      "Epoch 59 num_samples 11700 loss 0.016614494765479652\n",
      "Epoch 59 num_samples 11800 loss 0.011649915384168536\n",
      "Epoch 59 num_samples 11900 loss 0.010394126165901501\n",
      "Epoch 59 num_samples 12000 loss 0.009051382536500561\n",
      "Epoch 59 num_samples 12100 loss 0.010193870904378208\n",
      "Epoch 59 num_samples 12200 loss 0.015733401426681292\n",
      "Epoch 59 num_samples 12300 loss 0.009958974890229002\n",
      "Epoch 59 num_samples 12400 loss 0.016829648735782906\n",
      "Epoch 59 num_samples 12500 loss 0.014388944097487994\n",
      "Epoch 59 num_samples 12600 loss 0.01792590863793849\n",
      "Epoch 59 num_samples 12700 loss 0.013743298915793067\n",
      "Epoch 59 num_samples 12800 loss 0.022257700758649756\n",
      "Epoch 59 num_samples 12900 loss 0.011760427362591586\n",
      "Epoch 59 num_samples 13000 loss 0.010619794850547768\n",
      "Epoch 59 num_samples 13100 loss 0.01851462326595002\n",
      "Epoch 59 num_samples 13200 loss 0.007897452313668712\n",
      "Epoch 59 num_samples 13300 loss 0.010027433550499247\n",
      "Epoch 59 num_samples 13400 loss 0.00671991001989819\n",
      "Epoch 59 num_samples 13500 loss 0.009908221624221992\n",
      "Epoch 59 num_samples 13600 loss 0.01766731339062126\n",
      "Epoch 59 num_samples 13700 loss 0.012777097557327494\n",
      "Epoch 59 num_samples 13800 loss 0.011868627631124166\n",
      "Epoch 59 num_samples 13900 loss 0.005140789035827995\n",
      "Epoch 59 num_samples 14000 loss 0.008991922938331924\n",
      "Epoch 59 num_samples 14100 loss 0.011852501758275645\n",
      "Epoch 59 num_samples 14200 loss 0.01012886398674215\n",
      "Epoch 59 num_samples 14300 loss 0.014019343712354426\n",
      "Epoch 59 num_samples 14400 loss 0.0144389848125639\n",
      "Epoch 59 num_samples 14500 loss 0.016736248022167857\n",
      "Epoch 59 num_samples 14600 loss 0.012513822636066724\n",
      "Epoch 59 num_samples 14700 loss 0.012974367698039287\n",
      "Epoch 59 num_samples 14800 loss 0.012208217840422624\n",
      "Epoch 59 num_samples 14900 loss 0.01492727267294066\n",
      "Epoch 59 num_samples 15000 loss 0.011827723845812961\n",
      "Epoch 59 num_samples 15100 loss 0.013533103127533797\n",
      "Epoch 59 num_samples 15200 loss 0.014210086530411552\n",
      "Epoch 59 num_samples 15300 loss 0.014226983321305842\n",
      "Epoch 59 num_samples 15400 loss 0.009113735865741001\n",
      "Epoch 59 num_samples 15500 loss 0.014113797574419449\n",
      "Epoch 59 num_samples 15600 loss 0.014408546553031809\n",
      "Epoch 59 num_samples 15700 loss 0.009262778185098667\n",
      "Epoch 59 num_samples 15800 loss 0.016417875052849317\n",
      "Epoch 59 num_samples 15900 loss 0.009678387191214161\n",
      "Epoch 59 num_samples 16000 loss 0.018574907687488186\n",
      "Epoch 59 num_samples 16100 loss 0.00971698427754715\n",
      "Epoch 59 num_samples 16200 loss 0.014915402526397026\n",
      "Epoch 59 num_samples 16300 loss 0.017870334893317637\n",
      "Epoch 59 num_samples 16400 loss 0.01781616617582385\n",
      "Epoch 59 num_samples 16500 loss 0.015535660005216667\n",
      "Epoch 59 num_samples 16600 loss 0.016310818269252098\n",
      "Epoch 59 num_samples 16700 loss 0.008995060621069586\n",
      "Epoch 59 num_samples 16800 loss 0.009225898628306521\n",
      "Epoch 59 num_samples 16900 loss 0.010896763875797109\n",
      "Epoch 59 num_samples 17000 loss 0.008248872666026679\n",
      "Epoch 59 num_samples 17100 loss 0.022198185956066416\n",
      "Epoch 59 num_samples 17200 loss 0.014926298231400716\n",
      "Epoch 59 num_samples 17300 loss 0.01544368916923479\n",
      "Epoch 59 num_samples 17400 loss 0.013230437873613683\n",
      "Epoch 59 num_samples 17500 loss 0.01320820935512006\n",
      "Epoch 59 num_samples 17600 loss 0.012262080822482462\n",
      "Epoch 59 num_samples 17700 loss 0.010123284168159852\n",
      "Epoch 59 num_samples 17800 loss 0.01108345346997615\n",
      "Epoch 59 num_samples 17900 loss 0.01725642796717018\n",
      "Epoch 59 num_samples 18000 loss 0.011827385841259544\n",
      "Epoch 59 num_samples 18100 loss 0.013225947176258374\n",
      "Epoch 59 num_samples 18200 loss 0.013966111479912762\n",
      "Epoch 59 num_samples 18300 loss 0.010439778620588251\n",
      "Epoch 59 num_samples 18400 loss 0.02078063784998875\n",
      "Epoch 59 num_samples 18500 loss 0.01418034029558824\n",
      "Epoch 60 num_samples 0 loss 0.00979025747100696\n",
      "Epoch 60 num_samples 100 loss 0.0179336100451329\n",
      "Epoch 60 num_samples 200 loss 0.011648927957023667\n",
      "Epoch 60 num_samples 300 loss 0.010046626625322524\n",
      "Epoch 60 num_samples 400 loss 0.01174528522635454\n",
      "Epoch 60 num_samples 500 loss 0.017570867561714994\n",
      "Epoch 60 num_samples 600 loss 0.01862152396748811\n",
      "Epoch 60 num_samples 700 loss 0.019309912601521106\n",
      "Epoch 60 num_samples 800 loss 0.011640993149048586\n",
      "Epoch 60 num_samples 900 loss 0.02001025126957682\n",
      "Epoch 60 num_samples 1000 loss 0.012068374973563603\n",
      "Epoch 60 num_samples 1100 loss 0.020357897273039112\n",
      "Epoch 60 num_samples 1200 loss 0.01198938633736929\n",
      "Epoch 60 num_samples 1300 loss 0.014019038147952825\n",
      "Epoch 60 num_samples 1400 loss 0.014658814358156844\n",
      "Epoch 60 num_samples 1500 loss 0.018664283517114792\n",
      "Epoch 60 num_samples 1600 loss 0.012554724693555263\n",
      "Epoch 60 num_samples 1700 loss 0.011985056622703043\n",
      "Epoch 60 num_samples 1800 loss 0.011697204999063024\n",
      "Epoch 60 num_samples 1900 loss 0.014078897768857268\n",
      "Epoch 60 num_samples 2000 loss 0.016418628810045056\n",
      "Epoch 60 num_samples 2100 loss 0.008824724996964075\n",
      "Epoch 60 num_samples 2200 loss 0.009747782654778415\n",
      "Epoch 60 num_samples 2300 loss 0.006547109225758916\n",
      "Epoch 60 num_samples 2400 loss 0.01125438126237434\n",
      "Epoch 60 num_samples 2500 loss 0.015344071484540478\n",
      "Epoch 60 num_samples 2600 loss 0.016239159924545877\n",
      "Epoch 60 num_samples 2700 loss 0.011279121274172991\n",
      "Epoch 60 num_samples 2800 loss 0.016624742249272958\n",
      "Epoch 60 num_samples 2900 loss 0.0149844392592794\n",
      "Epoch 60 num_samples 3000 loss 0.01255055349989322\n",
      "Epoch 60 num_samples 3100 loss 0.011749503716965402\n",
      "Epoch 60 num_samples 3200 loss 0.023206677391382567\n",
      "Epoch 60 num_samples 3300 loss 0.014030415615860548\n",
      "Epoch 60 num_samples 3400 loss 0.010705689423202517\n",
      "Epoch 60 num_samples 3500 loss 0.011077122065486049\n",
      "Epoch 60 num_samples 3600 loss 0.007850926917425482\n",
      "Epoch 60 num_samples 3700 loss 0.01986968355795087\n",
      "Epoch 60 num_samples 3800 loss 0.011347727644922385\n",
      "Epoch 60 num_samples 3900 loss 0.013637310253041485\n",
      "Epoch 60 num_samples 4000 loss 0.015449091618235676\n",
      "Epoch 60 num_samples 4100 loss 0.020122426770335437\n",
      "Epoch 60 num_samples 4200 loss 0.0133478896325887\n",
      "Epoch 60 num_samples 4300 loss 0.012358904650018186\n",
      "Epoch 60 num_samples 4400 loss 0.014616341543168319\n",
      "Epoch 60 num_samples 4500 loss 0.017772744260238057\n",
      "Epoch 60 num_samples 4600 loss 0.01453589309916918\n",
      "Epoch 60 num_samples 4700 loss 0.008641712853327559\n",
      "Epoch 60 num_samples 4800 loss 0.0087835503028711\n",
      "Epoch 60 num_samples 4900 loss 0.01099099697317389\n",
      "Epoch 60 num_samples 5000 loss 0.009853325756450896\n",
      "Epoch 60 num_samples 5100 loss 0.017638642031018736\n",
      "Epoch 60 num_samples 5200 loss 0.008823100029014357\n",
      "Epoch 60 num_samples 5300 loss 0.011876950083328114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 num_samples 5400 loss 0.016100762168229227\n",
      "Epoch 60 num_samples 5500 loss 0.009489123662958192\n",
      "Epoch 60 num_samples 5600 loss 0.03769328070581834\n",
      "Epoch 60 num_samples 5700 loss 0.013336513402858761\n",
      "Epoch 60 num_samples 5800 loss 0.012425902934737354\n",
      "Epoch 60 num_samples 5900 loss 0.01606645816820289\n",
      "Epoch 60 num_samples 6000 loss 0.012883075840527631\n",
      "Epoch 60 num_samples 6100 loss 0.011684140632981408\n",
      "Epoch 60 num_samples 6200 loss 0.01384718708017436\n",
      "Epoch 60 num_samples 6300 loss 0.017856066008466284\n",
      "Epoch 60 num_samples 6400 loss 0.01060724845581437\n",
      "Epoch 60 num_samples 6500 loss 0.009619706042660676\n",
      "Epoch 60 num_samples 6600 loss 0.021183571423409767\n",
      "Epoch 60 num_samples 6700 loss 0.010627185190147223\n",
      "Epoch 60 num_samples 6800 loss 0.007121544898198201\n",
      "Epoch 60 num_samples 6900 loss 0.02693037970146493\n",
      "Epoch 60 num_samples 7000 loss 0.016160972509850574\n",
      "Epoch 60 num_samples 7100 loss 0.008885014319180894\n",
      "Epoch 60 num_samples 7200 loss 0.012704485463098023\n",
      "Epoch 60 num_samples 7300 loss 0.012249769699872485\n",
      "Epoch 60 num_samples 7400 loss 0.009282669927377106\n",
      "Epoch 60 num_samples 7500 loss 0.021006807838019847\n",
      "Epoch 60 num_samples 7600 loss 0.01332839226201417\n",
      "Epoch 60 num_samples 7700 loss 0.019203665616149793\n",
      "Epoch 60 num_samples 7800 loss 0.010881310652140673\n",
      "Epoch 60 num_samples 7900 loss 0.013287338650608072\n",
      "Epoch 60 num_samples 8000 loss 0.009066184735410812\n",
      "Epoch 60 num_samples 8100 loss 0.01206409593534723\n",
      "Epoch 60 num_samples 8200 loss 0.013880814983742065\n",
      "Epoch 60 num_samples 8300 loss 0.011323509282865352\n",
      "Epoch 60 num_samples 8400 loss 0.0092140983357903\n",
      "Epoch 60 num_samples 8500 loss 0.013165791235269411\n",
      "Epoch 60 num_samples 8600 loss 0.01331654631702121\n",
      "Epoch 60 num_samples 8700 loss 0.01299310064506639\n",
      "Epoch 60 num_samples 8800 loss 0.013233469630651019\n",
      "Epoch 60 num_samples 8900 loss 0.01573206580327078\n",
      "Epoch 60 num_samples 9000 loss 0.012794752353629616\n",
      "Epoch 60 num_samples 9100 loss 0.012927065583896814\n",
      "Epoch 60 num_samples 9200 loss 0.013315066023823626\n",
      "Epoch 60 num_samples 9300 loss 0.013041772636586126\n",
      "Epoch 60 num_samples 9400 loss 0.011135884068261114\n",
      "Epoch 60 num_samples 9500 loss 0.01120168901584253\n",
      "Epoch 60 num_samples 9600 loss 0.011645917990314718\n",
      "Epoch 60 num_samples 9700 loss 0.019468193345190666\n",
      "Epoch 60 num_samples 9800 loss 0.007957805576198513\n",
      "Epoch 60 num_samples 9900 loss 0.024366192011750082\n",
      "Epoch 60 num_samples 10000 loss 0.011368343628149211\n",
      "Epoch 60 num_samples 10100 loss 0.010177208993137782\n",
      "Epoch 60 num_samples 10200 loss 0.015912577920161406\n",
      "Epoch 60 num_samples 10300 loss 0.012502792915431634\n",
      "Epoch 60 num_samples 10400 loss 0.01666594917293636\n",
      "Epoch 60 num_samples 10500 loss 0.01129416896601259\n",
      "Epoch 60 num_samples 10600 loss 0.015480581728935254\n",
      "Epoch 60 num_samples 10700 loss 0.011659933497449239\n",
      "Epoch 60 num_samples 10800 loss 0.014877422739393093\n",
      "Epoch 60 num_samples 10900 loss 0.010864309700954018\n",
      "Epoch 60 num_samples 11000 loss 0.009949470432719612\n",
      "Epoch 60 num_samples 11100 loss 0.013096502156888987\n",
      "Epoch 60 num_samples 11200 loss 0.010450578805997313\n",
      "Epoch 60 num_samples 11300 loss 0.017748639488615527\n",
      "Epoch 60 num_samples 11400 loss 0.012257120991940032\n",
      "Epoch 60 num_samples 11500 loss 0.011856204377585005\n",
      "Epoch 60 num_samples 11600 loss 0.011242227086687177\n",
      "Epoch 60 num_samples 11700 loss 0.015984637428730245\n",
      "Epoch 60 num_samples 11800 loss 0.011291117402546291\n",
      "Epoch 60 num_samples 11900 loss 0.010019812400301096\n",
      "Epoch 60 num_samples 12000 loss 0.008792999952014336\n",
      "Epoch 60 num_samples 12100 loss 0.009844513856216297\n",
      "Epoch 60 num_samples 12200 loss 0.015180080606138697\n",
      "Epoch 60 num_samples 12300 loss 0.009746692974493914\n",
      "Epoch 60 num_samples 12400 loss 0.016238301667018864\n",
      "Epoch 60 num_samples 12500 loss 0.013962718568070121\n",
      "Epoch 60 num_samples 12600 loss 0.017346135276130964\n",
      "Epoch 60 num_samples 12700 loss 0.013290324460119964\n",
      "Epoch 60 num_samples 12800 loss 0.021334998116278224\n",
      "Epoch 60 num_samples 12900 loss 0.011323481094389907\n",
      "Epoch 60 num_samples 13000 loss 0.010302752988392257\n",
      "Epoch 60 num_samples 13100 loss 0.017708797041661353\n",
      "Epoch 60 num_samples 13200 loss 0.007587639083713248\n",
      "Epoch 60 num_samples 13300 loss 0.009757058499603751\n",
      "Epoch 60 num_samples 13400 loss 0.006506629276464511\n",
      "Epoch 60 num_samples 13500 loss 0.00952304512564581\n",
      "Epoch 60 num_samples 13600 loss 0.01697297169907762\n",
      "Epoch 60 num_samples 13700 loss 0.01238598247796787\n",
      "Epoch 60 num_samples 13800 loss 0.011457534286387436\n",
      "Epoch 60 num_samples 13900 loss 0.004972409813532052\n",
      "Epoch 60 num_samples 14000 loss 0.00868435203323074\n",
      "Epoch 60 num_samples 14100 loss 0.011522783820162212\n",
      "Epoch 60 num_samples 14200 loss 0.009841186161019585\n",
      "Epoch 60 num_samples 14300 loss 0.013567025462222312\n",
      "Epoch 60 num_samples 14400 loss 0.013940430500294664\n",
      "Epoch 60 num_samples 14500 loss 0.016268865948760747\n",
      "Epoch 60 num_samples 14600 loss 0.01212164440416593\n",
      "Epoch 60 num_samples 14700 loss 0.012549503138277412\n",
      "Epoch 60 num_samples 14800 loss 0.011810514173462173\n",
      "Epoch 60 num_samples 14900 loss 0.014383282167764064\n",
      "Epoch 60 num_samples 15000 loss 0.011477511503293712\n",
      "Epoch 60 num_samples 15100 loss 0.0131244283742291\n",
      "Epoch 60 num_samples 15200 loss 0.01374540240302244\n",
      "Epoch 60 num_samples 15300 loss 0.013738261144512948\n",
      "Epoch 60 num_samples 15400 loss 0.008886689027904593\n",
      "Epoch 60 num_samples 15500 loss 0.0136255277743615\n",
      "Epoch 60 num_samples 15600 loss 0.013894432103206072\n",
      "Epoch 60 num_samples 15700 loss 0.008972542469226148\n",
      "Epoch 60 num_samples 15800 loss 0.01585466216123934\n",
      "Epoch 60 num_samples 15900 loss 0.009410273557574768\n",
      "Epoch 60 num_samples 16000 loss 0.018033380368682173\n",
      "Epoch 60 num_samples 16100 loss 0.009414294847290616\n",
      "Epoch 60 num_samples 16200 loss 0.014445324108262585\n",
      "Epoch 60 num_samples 16300 loss 0.01721935942515983\n",
      "Epoch 60 num_samples 16400 loss 0.017220901397155538\n",
      "Epoch 60 num_samples 16500 loss 0.014983668272186945\n",
      "Epoch 60 num_samples 16600 loss 0.015797572751267957\n",
      "Epoch 60 num_samples 16700 loss 0.008788292261107153\n",
      "Epoch 60 num_samples 16800 loss 0.008933889496368206\n",
      "Epoch 60 num_samples 16900 loss 0.010549160104086148\n",
      "Epoch 60 num_samples 17000 loss 0.00800367555648116\n",
      "Epoch 60 num_samples 17100 loss 0.021340747590137897\n",
      "Epoch 60 num_samples 17200 loss 0.014395530778714534\n",
      "Epoch 60 num_samples 17300 loss 0.014924992602642094\n",
      "Epoch 60 num_samples 17400 loss 0.012817897050388159\n",
      "Epoch 60 num_samples 17500 loss 0.012799835277010724\n",
      "Epoch 60 num_samples 17600 loss 0.01185609607723809\n",
      "Epoch 60 num_samples 17700 loss 0.009776919881171025\n",
      "Epoch 60 num_samples 17800 loss 0.0107070127139751\n",
      "Epoch 60 num_samples 17900 loss 0.016698023034987703\n",
      "Epoch 60 num_samples 18000 loss 0.011490279204630638\n",
      "Epoch 60 num_samples 18100 loss 0.01284261941933178\n",
      "Epoch 60 num_samples 18200 loss 0.013585928571838464\n",
      "Epoch 60 num_samples 18300 loss 0.010206595912527136\n",
      "Epoch 60 num_samples 18400 loss 0.020144166423790365\n",
      "Epoch 60 num_samples 18500 loss 0.013766266478994357\n",
      "Epoch 61 num_samples 0 loss 0.009524380884546697\n",
      "Epoch 61 num_samples 100 loss 0.017308358142787476\n",
      "Epoch 61 num_samples 200 loss 0.011368810804838288\n",
      "Epoch 61 num_samples 300 loss 0.009774408392803698\n",
      "Epoch 61 num_samples 400 loss 0.01140496750903945\n",
      "Epoch 61 num_samples 500 loss 0.0170274284013448\n",
      "Epoch 61 num_samples 600 loss 0.017909618331795985\n",
      "Epoch 61 num_samples 700 loss 0.018830170616641776\n",
      "Epoch 61 num_samples 800 loss 0.011240460662088482\n",
      "Epoch 61 num_samples 900 loss 0.019403292946267973\n",
      "Epoch 61 num_samples 1000 loss 0.011704517912024547\n",
      "Epoch 61 num_samples 1100 loss 0.019664212506498475\n",
      "Epoch 61 num_samples 1200 loss 0.011595944047032207\n",
      "Epoch 61 num_samples 1300 loss 0.013569803066198283\n",
      "Epoch 61 num_samples 1400 loss 0.014286363151284464\n",
      "Epoch 61 num_samples 1500 loss 0.017937634588119124\n",
      "Epoch 61 num_samples 1600 loss 0.012163865811331448\n",
      "Epoch 61 num_samples 1700 loss 0.01169169746249245\n",
      "Epoch 61 num_samples 1800 loss 0.011327768448755897\n",
      "Epoch 61 num_samples 1900 loss 0.013663960841084566\n",
      "Epoch 61 num_samples 2000 loss 0.016007001754975585\n",
      "Epoch 61 num_samples 2100 loss 0.008529826800759739\n",
      "Epoch 61 num_samples 2200 loss 0.009465445543070114\n",
      "Epoch 61 num_samples 2300 loss 0.006400450084800493\n",
      "Epoch 61 num_samples 2400 loss 0.010834994115183865\n",
      "Epoch 61 num_samples 2500 loss 0.014861715706050566\n",
      "Epoch 61 num_samples 2600 loss 0.015692674303355532\n",
      "Epoch 61 num_samples 2700 loss 0.010887120409793697\n",
      "Epoch 61 num_samples 2800 loss 0.01605401591822591\n",
      "Epoch 61 num_samples 2900 loss 0.014477518747037893\n",
      "Epoch 61 num_samples 3000 loss 0.012188242824497741\n",
      "Epoch 61 num_samples 3100 loss 0.011373775942827952\n",
      "Epoch 61 num_samples 3200 loss 0.022244034050153374\n",
      "Epoch 61 num_samples 3300 loss 0.013565662832532657\n",
      "Epoch 61 num_samples 3400 loss 0.010429144127665711\n",
      "Epoch 61 num_samples 3500 loss 0.010714938078072632\n",
      "Epoch 61 num_samples 3600 loss 0.0076428449246622445\n",
      "Epoch 61 num_samples 3700 loss 0.019213459761514607\n",
      "Epoch 61 num_samples 3800 loss 0.010937241171387444\n",
      "Epoch 61 num_samples 3900 loss 0.013109735083870448\n",
      "Epoch 61 num_samples 4000 loss 0.015002191579557836\n",
      "Epoch 61 num_samples 4100 loss 0.019324756020288648\n",
      "Epoch 61 num_samples 4200 loss 0.01297882983067209\n",
      "Epoch 61 num_samples 4300 loss 0.011931280450047045\n",
      "Epoch 61 num_samples 4400 loss 0.01408613384709264\n",
      "Epoch 61 num_samples 4500 loss 0.017009447060673304\n",
      "Epoch 61 num_samples 4600 loss 0.014130232520337089\n",
      "Epoch 61 num_samples 4700 loss 0.008297492115596612\n",
      "Epoch 61 num_samples 4800 loss 0.00845332904536898\n",
      "Epoch 61 num_samples 4900 loss 0.010687010655572322\n",
      "Epoch 61 num_samples 5000 loss 0.009546701660747538\n",
      "Epoch 61 num_samples 5100 loss 0.01711825279254219\n",
      "Epoch 61 num_samples 5200 loss 0.008516407242268278\n",
      "Epoch 61 num_samples 5300 loss 0.01151053135228994\n",
      "Epoch 61 num_samples 5400 loss 0.01574565593881899\n",
      "Epoch 61 num_samples 5500 loss 0.009224163229098534\n",
      "Epoch 61 num_samples 5600 loss 0.03613259306043184\n",
      "Epoch 61 num_samples 5700 loss 0.012979420730454327\n",
      "Epoch 61 num_samples 5800 loss 0.01200952475035217\n",
      "Epoch 61 num_samples 5900 loss 0.015578300158279365\n",
      "Epoch 61 num_samples 6000 loss 0.012501568299496717\n",
      "Epoch 61 num_samples 6100 loss 0.011366303274013938\n",
      "Epoch 61 num_samples 6200 loss 0.013447179846404547\n",
      "Epoch 61 num_samples 6300 loss 0.017176602024992774\n",
      "Epoch 61 num_samples 6400 loss 0.010333814166236766\n",
      "Epoch 61 num_samples 6500 loss 0.009297869919431606\n",
      "Epoch 61 num_samples 6600 loss 0.02064224227271698\n",
      "Epoch 61 num_samples 6700 loss 0.010300402108809805\n",
      "Epoch 61 num_samples 6800 loss 0.0068994785851122275\n",
      "Epoch 61 num_samples 6900 loss 0.02612793324837853\n",
      "Epoch 61 num_samples 7000 loss 0.015632254982941893\n",
      "Epoch 61 num_samples 7100 loss 0.008631088353354546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 num_samples 7200 loss 0.01235741637642235\n",
      "Epoch 61 num_samples 7300 loss 0.011925504878255486\n",
      "Epoch 61 num_samples 7400 loss 0.008940472450738412\n",
      "Epoch 61 num_samples 7500 loss 0.020373105895657738\n",
      "Epoch 61 num_samples 7600 loss 0.012937203784585143\n",
      "Epoch 61 num_samples 7700 loss 0.018494622687028305\n",
      "Epoch 61 num_samples 7800 loss 0.01059958822364243\n",
      "Epoch 61 num_samples 7900 loss 0.012973413023047895\n",
      "Epoch 61 num_samples 8000 loss 0.008773023183805927\n",
      "Epoch 61 num_samples 8100 loss 0.011777680732037686\n",
      "Epoch 61 num_samples 8200 loss 0.013493691709791667\n",
      "Epoch 61 num_samples 8300 loss 0.010861674038527128\n",
      "Epoch 61 num_samples 8400 loss 0.008915583309827446\n",
      "Epoch 61 num_samples 8500 loss 0.012827327625720033\n",
      "Epoch 61 num_samples 8600 loss 0.012982008843229188\n",
      "Epoch 61 num_samples 8700 loss 0.0125804148342165\n",
      "Epoch 61 num_samples 8800 loss 0.012798322044844247\n",
      "Epoch 61 num_samples 8900 loss 0.01522442037539835\n",
      "Epoch 61 num_samples 9000 loss 0.012392501302757238\n",
      "Epoch 61 num_samples 9100 loss 0.012539507636968707\n",
      "Epoch 61 num_samples 9200 loss 0.012911454599652867\n",
      "Epoch 61 num_samples 9300 loss 0.012648409869308841\n",
      "Epoch 61 num_samples 9400 loss 0.010784735177714048\n",
      "Epoch 61 num_samples 9500 loss 0.010795870734289715\n",
      "Epoch 61 num_samples 9600 loss 0.011364237275694187\n",
      "Epoch 61 num_samples 9700 loss 0.01883706163006731\n",
      "Epoch 61 num_samples 9800 loss 0.007702498326923033\n",
      "Epoch 61 num_samples 9900 loss 0.023594944956166427\n",
      "Epoch 61 num_samples 10000 loss 0.010970233931455195\n",
      "Epoch 61 num_samples 10100 loss 0.009883949791756406\n",
      "Epoch 61 num_samples 10200 loss 0.015412415137686368\n",
      "Epoch 61 num_samples 10300 loss 0.012066337814322587\n",
      "Epoch 61 num_samples 10400 loss 0.016171237399292916\n",
      "Epoch 61 num_samples 10500 loss 0.010948143972793659\n",
      "Epoch 61 num_samples 10600 loss 0.015018266229302668\n",
      "Epoch 61 num_samples 10700 loss 0.011199805296389607\n",
      "Epoch 61 num_samples 10800 loss 0.014394945783875021\n",
      "Epoch 61 num_samples 10900 loss 0.010577075519241712\n",
      "Epoch 61 num_samples 11000 loss 0.0096211620401239\n",
      "Epoch 61 num_samples 11100 loss 0.012734427150164285\n",
      "Epoch 61 num_samples 11200 loss 0.010164985240369889\n",
      "Epoch 61 num_samples 11300 loss 0.017221049332068913\n",
      "Epoch 61 num_samples 11400 loss 0.011798675896789814\n",
      "Epoch 61 num_samples 11500 loss 0.011467505141175251\n",
      "Epoch 61 num_samples 11600 loss 0.010911036147460206\n",
      "Epoch 61 num_samples 11700 loss 0.015460011212524365\n",
      "Epoch 61 num_samples 11800 loss 0.010953656365667825\n",
      "Epoch 61 num_samples 11900 loss 0.00970008002636639\n",
      "Epoch 61 num_samples 12000 loss 0.00853490355499777\n",
      "Epoch 61 num_samples 12100 loss 0.009537992481651804\n",
      "Epoch 61 num_samples 12200 loss 0.014566923701980865\n",
      "Epoch 61 num_samples 12300 loss 0.0094668332248895\n",
      "Epoch 61 num_samples 12400 loss 0.015691643440661082\n",
      "Epoch 61 num_samples 12500 loss 0.013594932967967028\n",
      "Epoch 61 num_samples 12600 loss 0.016855092938486593\n",
      "Epoch 61 num_samples 12700 loss 0.012843930892350959\n",
      "Epoch 61 num_samples 12800 loss 0.020589054867494544\n",
      "Epoch 61 num_samples 12900 loss 0.010930205866585574\n",
      "Epoch 61 num_samples 13000 loss 0.009988045909586313\n",
      "Epoch 61 num_samples 13100 loss 0.017119295761743248\n",
      "Epoch 61 num_samples 13200 loss 0.007359588472851475\n",
      "Epoch 61 num_samples 13300 loss 0.009480012978452537\n",
      "Epoch 61 num_samples 13400 loss 0.006396115188347045\n",
      "Epoch 61 num_samples 13500 loss 0.009288206567416446\n",
      "Epoch 61 num_samples 13600 loss 0.016472666697298483\n",
      "Epoch 61 num_samples 13700 loss 0.011964658626035502\n",
      "Epoch 61 num_samples 13800 loss 0.011074668498123805\n",
      "Epoch 61 num_samples 13900 loss 0.004822110679970617\n",
      "Epoch 61 num_samples 14000 loss 0.008428140766905887\n",
      "Epoch 61 num_samples 14100 loss 0.011118195700424915\n",
      "Epoch 61 num_samples 14200 loss 0.00957785133526542\n",
      "Epoch 61 num_samples 14300 loss 0.01316860823989731\n",
      "Epoch 61 num_samples 14400 loss 0.013576247484366593\n",
      "Epoch 61 num_samples 14500 loss 0.015867112473296224\n",
      "Epoch 61 num_samples 14600 loss 0.011761504530549418\n",
      "Epoch 61 num_samples 14700 loss 0.012168374070047965\n",
      "Epoch 61 num_samples 14800 loss 0.011451513656056274\n",
      "Epoch 61 num_samples 14900 loss 0.013905004216422594\n",
      "Epoch 61 num_samples 15000 loss 0.011160277141673286\n",
      "Epoch 61 num_samples 15100 loss 0.012740751522392835\n",
      "Epoch 61 num_samples 15200 loss 0.013300301624505528\n",
      "Epoch 61 num_samples 15300 loss 0.013278140848411366\n",
      "Epoch 61 num_samples 15400 loss 0.0086421862694707\n",
      "Epoch 61 num_samples 15500 loss 0.013189485963272114\n",
      "Epoch 61 num_samples 15600 loss 0.013545155035445504\n",
      "Epoch 61 num_samples 15700 loss 0.008738378376030968\n",
      "Epoch 61 num_samples 15800 loss 0.015380623846132318\n",
      "Epoch 61 num_samples 15900 loss 0.009139542277334474\n",
      "Epoch 61 num_samples 16000 loss 0.01752207178250004\n",
      "Epoch 61 num_samples 16100 loss 0.009137566801099388\n",
      "Epoch 61 num_samples 16200 loss 0.013979496223064904\n",
      "Epoch 61 num_samples 16300 loss 0.01664283345743096\n",
      "Epoch 61 num_samples 16400 loss 0.01670353097697623\n",
      "Epoch 61 num_samples 16500 loss 0.014502620021186968\n",
      "Epoch 61 num_samples 16600 loss 0.015352304507981957\n",
      "Epoch 61 num_samples 16700 loss 0.008491897158533665\n",
      "Epoch 61 num_samples 16800 loss 0.008627442925796225\n",
      "Epoch 61 num_samples 16900 loss 0.010245602053886622\n",
      "Epoch 61 num_samples 17000 loss 0.007773638393020452\n",
      "Epoch 61 num_samples 17100 loss 0.02056422007930753\n",
      "Epoch 61 num_samples 17200 loss 0.01396803609804421\n",
      "Epoch 61 num_samples 17300 loss 0.014379072160048283\n",
      "Epoch 61 num_samples 17400 loss 0.012391194668838385\n",
      "Epoch 61 num_samples 17500 loss 0.012470990183405304\n",
      "Epoch 61 num_samples 17600 loss 0.011445846755155482\n",
      "Epoch 61 num_samples 17700 loss 0.009484830507630056\n",
      "Epoch 61 num_samples 17800 loss 0.010350112696454012\n",
      "Epoch 61 num_samples 17900 loss 0.01615028500104009\n",
      "Epoch 61 num_samples 18000 loss 0.011168943018522807\n",
      "Epoch 61 num_samples 18100 loss 0.01245225349293387\n",
      "Epoch 61 num_samples 18200 loss 0.013187384054627365\n",
      "Epoch 61 num_samples 18300 loss 0.009895203737791023\n",
      "Epoch 61 num_samples 18400 loss 0.01952470211219498\n",
      "Epoch 61 num_samples 18500 loss 0.01332853214011518\n",
      "Epoch 62 num_samples 0 loss 0.009253327091346736\n",
      "Epoch 62 num_samples 100 loss 0.016820326742689688\n",
      "Epoch 62 num_samples 200 loss 0.0109840931471686\n",
      "Epoch 62 num_samples 300 loss 0.00947168357873977\n",
      "Epoch 62 num_samples 400 loss 0.011078346218149737\n",
      "Epoch 62 num_samples 500 loss 0.016561929857326577\n",
      "Epoch 62 num_samples 600 loss 0.01737413760238436\n",
      "Epoch 62 num_samples 700 loss 0.018173534070373455\n",
      "Epoch 62 num_samples 800 loss 0.010892552293138364\n",
      "Epoch 62 num_samples 900 loss 0.018810178874915137\n",
      "Epoch 62 num_samples 1000 loss 0.01132311249406166\n",
      "Epoch 62 num_samples 1100 loss 0.01903193492521377\n",
      "Epoch 62 num_samples 1200 loss 0.011234040047323333\n",
      "Epoch 62 num_samples 1300 loss 0.013148880634427217\n",
      "Epoch 62 num_samples 1400 loss 0.013719661088378281\n",
      "Epoch 62 num_samples 1500 loss 0.017233394017402284\n",
      "Epoch 62 num_samples 1600 loss 0.011798587909172636\n",
      "Epoch 62 num_samples 1700 loss 0.011333999972143318\n",
      "Epoch 62 num_samples 1800 loss 0.0109657744767078\n",
      "Epoch 62 num_samples 1900 loss 0.01325440909687759\n",
      "Epoch 62 num_samples 2000 loss 0.015484312067088462\n",
      "Epoch 62 num_samples 2100 loss 0.00827768002139172\n",
      "Epoch 62 num_samples 2200 loss 0.009156010512221358\n",
      "Epoch 62 num_samples 2300 loss 0.0061835610690801615\n",
      "Epoch 62 num_samples 2400 loss 0.010530346509511315\n",
      "Epoch 62 num_samples 2500 loss 0.014346154005360242\n",
      "Epoch 62 num_samples 2600 loss 0.015231059711810224\n",
      "Epoch 62 num_samples 2700 loss 0.010577474560649868\n",
      "Epoch 62 num_samples 2800 loss 0.01553297354577972\n",
      "Epoch 62 num_samples 2900 loss 0.013982374520679521\n",
      "Epoch 62 num_samples 3000 loss 0.011842150700417078\n",
      "Epoch 62 num_samples 3100 loss 0.011023780291088046\n",
      "Epoch 62 num_samples 3200 loss 0.021252415783953486\n",
      "Epoch 62 num_samples 3300 loss 0.013082164703896827\n",
      "Epoch 62 num_samples 3400 loss 0.010110157803142419\n",
      "Epoch 62 num_samples 3500 loss 0.010408339270192843\n",
      "Epoch 62 num_samples 3600 loss 0.0074698391931778615\n",
      "Epoch 62 num_samples 3700 loss 0.018695163045984647\n",
      "Epoch 62 num_samples 3800 loss 0.010557701351137533\n",
      "Epoch 62 num_samples 3900 loss 0.012779887620897759\n",
      "Epoch 62 num_samples 4000 loss 0.014388749733898976\n",
      "Epoch 62 num_samples 4100 loss 0.018722447991042362\n",
      "Epoch 62 num_samples 4200 loss 0.012615131416672143\n",
      "Epoch 62 num_samples 4300 loss 0.011612448999296745\n",
      "Epoch 62 num_samples 4400 loss 0.013618169590286945\n",
      "Epoch 62 num_samples 4500 loss 0.016598764716453367\n",
      "Epoch 62 num_samples 4600 loss 0.013685546430120672\n",
      "Epoch 62 num_samples 4700 loss 0.008059314091603272\n",
      "Epoch 62 num_samples 4800 loss 0.00826862899132957\n",
      "Epoch 62 num_samples 4900 loss 0.010415780633252762\n",
      "Epoch 62 num_samples 5000 loss 0.009298313483182752\n",
      "Epoch 62 num_samples 5100 loss 0.016677047588472958\n",
      "Epoch 62 num_samples 5200 loss 0.008277253366582171\n",
      "Epoch 62 num_samples 5300 loss 0.011179716740604407\n",
      "Epoch 62 num_samples 5400 loss 0.015293084124459667\n",
      "Epoch 62 num_samples 5500 loss 0.00898587071080144\n",
      "Epoch 62 num_samples 5600 loss 0.034863472174239414\n",
      "Epoch 62 num_samples 5700 loss 0.012424806262955865\n",
      "Epoch 62 num_samples 5800 loss 0.011659050053893182\n",
      "Epoch 62 num_samples 5900 loss 0.015111591361778046\n",
      "Epoch 62 num_samples 6000 loss 0.012188397219476399\n",
      "Epoch 62 num_samples 6100 loss 0.010991962042398027\n",
      "Epoch 62 num_samples 6200 loss 0.012983832343983441\n",
      "Epoch 62 num_samples 6300 loss 0.01667250332437712\n",
      "Epoch 62 num_samples 6400 loss 0.010022320330361824\n",
      "Epoch 62 num_samples 6500 loss 0.009013579039675076\n",
      "Epoch 62 num_samples 6600 loss 0.020109235080871913\n",
      "Epoch 62 num_samples 6700 loss 0.010069019210026372\n",
      "Epoch 62 num_samples 6800 loss 0.0067165365700312\n",
      "Epoch 62 num_samples 6900 loss 0.02530627936783663\n",
      "Epoch 62 num_samples 7000 loss 0.015104784153802507\n",
      "Epoch 62 num_samples 7100 loss 0.008324787528998111\n",
      "Epoch 62 num_samples 7200 loss 0.01196272669055261\n",
      "Epoch 62 num_samples 7300 loss 0.011574417491596935\n",
      "Epoch 62 num_samples 7400 loss 0.008730974285424272\n",
      "Epoch 62 num_samples 7500 loss 0.019653391456410773\n",
      "Epoch 62 num_samples 7600 loss 0.012538794313595383\n",
      "Epoch 62 num_samples 7700 loss 0.017862313704850162\n",
      "Epoch 62 num_samples 7800 loss 0.010242940669283196\n",
      "Epoch 62 num_samples 7900 loss 0.012616754678160475\n",
      "Epoch 62 num_samples 8000 loss 0.008509275052536049\n",
      "Epoch 62 num_samples 8100 loss 0.011349193800691664\n",
      "Epoch 62 num_samples 8200 loss 0.013045907745689074\n",
      "Epoch 62 num_samples 8300 loss 0.010476519619653523\n",
      "Epoch 62 num_samples 8400 loss 0.008618947462871656\n",
      "Epoch 62 num_samples 8500 loss 0.012383586949501969\n",
      "Epoch 62 num_samples 8600 loss 0.012559690289386442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 num_samples 8700 loss 0.012244529890328794\n",
      "Epoch 62 num_samples 8800 loss 0.012376599198155014\n",
      "Epoch 62 num_samples 8900 loss 0.014771147676257552\n",
      "Epoch 62 num_samples 9000 loss 0.012065631631328733\n",
      "Epoch 62 num_samples 9100 loss 0.012152676498477096\n",
      "Epoch 62 num_samples 9200 loss 0.012518959707615651\n",
      "Epoch 62 num_samples 9300 loss 0.012242428225374753\n",
      "Epoch 62 num_samples 9400 loss 0.010477316326306265\n",
      "Epoch 62 num_samples 9500 loss 0.010422205085453827\n",
      "Epoch 62 num_samples 9600 loss 0.010962378259743982\n",
      "Epoch 62 num_samples 9700 loss 0.018260991509663756\n",
      "Epoch 62 num_samples 9800 loss 0.007484660491018538\n",
      "Epoch 62 num_samples 9900 loss 0.022850682331346673\n",
      "Epoch 62 num_samples 10000 loss 0.010543777119467019\n",
      "Epoch 62 num_samples 10100 loss 0.00957571779300512\n",
      "Epoch 62 num_samples 10200 loss 0.014939461428638326\n",
      "Epoch 62 num_samples 10300 loss 0.011781158102342077\n",
      "Epoch 62 num_samples 10400 loss 0.0156696208728262\n",
      "Epoch 62 num_samples 10500 loss 0.010556279200455715\n",
      "Epoch 62 num_samples 10600 loss 0.014365683426796262\n",
      "Epoch 62 num_samples 10700 loss 0.01091623388486728\n",
      "Epoch 62 num_samples 10800 loss 0.014004714600604144\n",
      "Epoch 62 num_samples 10900 loss 0.010220943239525892\n",
      "Epoch 62 num_samples 11000 loss 0.009344154532491091\n",
      "Epoch 62 num_samples 11100 loss 0.012399283211867623\n",
      "Epoch 62 num_samples 11200 loss 0.009853856071966349\n",
      "Epoch 62 num_samples 11300 loss 0.016708799528771925\n",
      "Epoch 62 num_samples 11400 loss 0.011427404067151472\n",
      "Epoch 62 num_samples 11500 loss 0.011118969406110764\n",
      "Epoch 62 num_samples 11600 loss 0.010545561572970884\n",
      "Epoch 62 num_samples 11700 loss 0.014915548905410938\n",
      "Epoch 62 num_samples 11800 loss 0.01064414701346053\n",
      "Epoch 62 num_samples 11900 loss 0.009425332404249332\n",
      "Epoch 62 num_samples 12000 loss 0.00825077478089129\n",
      "Epoch 62 num_samples 12100 loss 0.00924383919086518\n",
      "Epoch 62 num_samples 12200 loss 0.014071581101264559\n",
      "Epoch 62 num_samples 12300 loss 0.009190119319580983\n",
      "Epoch 62 num_samples 12400 loss 0.015196667750529951\n",
      "Epoch 62 num_samples 12500 loss 0.013179326284807325\n",
      "Epoch 62 num_samples 12600 loss 0.016300413994356847\n",
      "Epoch 62 num_samples 12700 loss 0.012339669040619445\n",
      "Epoch 62 num_samples 12800 loss 0.019896454348626736\n",
      "Epoch 62 num_samples 12900 loss 0.010639770477523085\n",
      "Epoch 62 num_samples 13000 loss 0.009688781915211483\n",
      "Epoch 62 num_samples 13100 loss 0.016542773420432234\n",
      "Epoch 62 num_samples 13200 loss 0.0070789635585617305\n",
      "Epoch 62 num_samples 13300 loss 0.009207112949404222\n",
      "Epoch 62 num_samples 13400 loss 0.006176879844237998\n",
      "Epoch 62 num_samples 13500 loss 0.00894940527017605\n",
      "Epoch 62 num_samples 13600 loss 0.01587264802239896\n",
      "Epoch 62 num_samples 13700 loss 0.011624475680403439\n",
      "Epoch 62 num_samples 13800 loss 0.010787134720652115\n",
      "Epoch 62 num_samples 13900 loss 0.00468742022281921\n",
      "Epoch 62 num_samples 14000 loss 0.008176504433865486\n",
      "Epoch 62 num_samples 14100 loss 0.010786078953302573\n",
      "Epoch 62 num_samples 14200 loss 0.009348655556921394\n",
      "Epoch 62 num_samples 14300 loss 0.012779132202334304\n",
      "Epoch 62 num_samples 14400 loss 0.013195213054323815\n",
      "Epoch 62 num_samples 14500 loss 0.015359893939009052\n",
      "Epoch 62 num_samples 14600 loss 0.011389900455329236\n",
      "Epoch 62 num_samples 14700 loss 0.011747091891043821\n",
      "Epoch 62 num_samples 14800 loss 0.011101291329487126\n",
      "Epoch 62 num_samples 14900 loss 0.01344269915402617\n",
      "Epoch 62 num_samples 15000 loss 0.010835753066107796\n",
      "Epoch 62 num_samples 15100 loss 0.012354295959276325\n",
      "Epoch 62 num_samples 15200 loss 0.012747513319685527\n",
      "Epoch 62 num_samples 15300 loss 0.012872538149013039\n",
      "Epoch 62 num_samples 15400 loss 0.008422249238506626\n",
      "Epoch 62 num_samples 15500 loss 0.012754940527503469\n",
      "Epoch 62 num_samples 15600 loss 0.013018538622729408\n",
      "Epoch 62 num_samples 15700 loss 0.008489245558533557\n",
      "Epoch 62 num_samples 15800 loss 0.014818165526862286\n",
      "Epoch 62 num_samples 15900 loss 0.008907377004619516\n",
      "Epoch 62 num_samples 16000 loss 0.016998359516188315\n",
      "Epoch 62 num_samples 16100 loss 0.008839549666060754\n",
      "Epoch 62 num_samples 16200 loss 0.013597750433408709\n",
      "Epoch 62 num_samples 16300 loss 0.016148148930377134\n",
      "Epoch 62 num_samples 16400 loss 0.016130120128039986\n",
      "Epoch 62 num_samples 16500 loss 0.014045921389669553\n",
      "Epoch 62 num_samples 16600 loss 0.01492957122936374\n",
      "Epoch 62 num_samples 16700 loss 0.008305359090738748\n",
      "Epoch 62 num_samples 16800 loss 0.008393581045713312\n",
      "Epoch 62 num_samples 16900 loss 0.009970369913127684\n",
      "Epoch 62 num_samples 17000 loss 0.007548343537714719\n",
      "Epoch 62 num_samples 17100 loss 0.019823308881238278\n",
      "Epoch 62 num_samples 17200 loss 0.01354700140428496\n",
      "Epoch 62 num_samples 17300 loss 0.013966017110904365\n",
      "Epoch 62 num_samples 17400 loss 0.012070551919582242\n",
      "Epoch 62 num_samples 17500 loss 0.012118284692012175\n",
      "Epoch 62 num_samples 17600 loss 0.011121401431866084\n",
      "Epoch 62 num_samples 17700 loss 0.009183086211939927\n",
      "Epoch 62 num_samples 17800 loss 0.010048334025800888\n",
      "Epoch 62 num_samples 17900 loss 0.015622822266626053\n",
      "Epoch 62 num_samples 18000 loss 0.010906735232011204\n",
      "Epoch 62 num_samples 18100 loss 0.012114692713977325\n",
      "Epoch 62 num_samples 18200 loss 0.012744119839280593\n",
      "Epoch 62 num_samples 18300 loss 0.009589792551731095\n",
      "Epoch 62 num_samples 18400 loss 0.018881881685668872\n",
      "Epoch 62 num_samples 18500 loss 0.012957296668572418\n",
      "Epoch 63 num_samples 0 loss 0.008985931620664482\n",
      "Epoch 63 num_samples 100 loss 0.016295217907324428\n",
      "Epoch 63 num_samples 200 loss 0.01067788932282557\n",
      "Epoch 63 num_samples 300 loss 0.009209787427519584\n",
      "Epoch 63 num_samples 400 loss 0.010774143113345416\n",
      "Epoch 63 num_samples 500 loss 0.016095198553724453\n",
      "Epoch 63 num_samples 600 loss 0.01680932479676499\n",
      "Epoch 63 num_samples 700 loss 0.01762400976603131\n",
      "Epoch 63 num_samples 800 loss 0.010510794662252633\n",
      "Epoch 63 num_samples 900 loss 0.018307223161609532\n",
      "Epoch 63 num_samples 1000 loss 0.01101323806167132\n",
      "Epoch 63 num_samples 1100 loss 0.01843599220330508\n",
      "Epoch 63 num_samples 1200 loss 0.010851675570374182\n",
      "Epoch 63 num_samples 1300 loss 0.01282612151241688\n",
      "Epoch 63 num_samples 1400 loss 0.013295927385102829\n",
      "Epoch 63 num_samples 1500 loss 0.016629519104653205\n",
      "Epoch 63 num_samples 1600 loss 0.011455301809358148\n",
      "Epoch 63 num_samples 1700 loss 0.010975444360566564\n",
      "Epoch 63 num_samples 1800 loss 0.010651358062927345\n",
      "Epoch 63 num_samples 1900 loss 0.012790958527700553\n",
      "Epoch 63 num_samples 2000 loss 0.015008182349437469\n",
      "Epoch 63 num_samples 2100 loss 0.008014725335454866\n",
      "Epoch 63 num_samples 2200 loss 0.008901680758858204\n",
      "Epoch 63 num_samples 2300 loss 0.006012217339772116\n",
      "Epoch 63 num_samples 2400 loss 0.01021826358668844\n",
      "Epoch 63 num_samples 2500 loss 0.013846304638863587\n",
      "Epoch 63 num_samples 2600 loss 0.014758041877251653\n",
      "Epoch 63 num_samples 2700 loss 0.010241890054631447\n",
      "Epoch 63 num_samples 2800 loss 0.015054234750741156\n",
      "Epoch 63 num_samples 2900 loss 0.01354409895721458\n",
      "Epoch 63 num_samples 3000 loss 0.011409828963724998\n",
      "Epoch 63 num_samples 3100 loss 0.010688178987117682\n",
      "Epoch 63 num_samples 3200 loss 0.0204218547411286\n",
      "Epoch 63 num_samples 3300 loss 0.012762799164180829\n",
      "Epoch 63 num_samples 3400 loss 0.009818175430443565\n",
      "Epoch 63 num_samples 3500 loss 0.010122071414423658\n",
      "Epoch 63 num_samples 3600 loss 0.007279101572986217\n",
      "Epoch 63 num_samples 3700 loss 0.01809942600795122\n",
      "Epoch 63 num_samples 3800 loss 0.010264634896691414\n",
      "Epoch 63 num_samples 3900 loss 0.012248224007444799\n",
      "Epoch 63 num_samples 4000 loss 0.013925600315879957\n",
      "Epoch 63 num_samples 4100 loss 0.018003006767693237\n",
      "Epoch 63 num_samples 4200 loss 0.012270933476617795\n",
      "Epoch 63 num_samples 4300 loss 0.011213372679808844\n",
      "Epoch 63 num_samples 4400 loss 0.013207221438633777\n",
      "Epoch 63 num_samples 4500 loss 0.015971896442711502\n",
      "Epoch 63 num_samples 4600 loss 0.013308627589249429\n",
      "Epoch 63 num_samples 4700 loss 0.007810115581093486\n",
      "Epoch 63 num_samples 4800 loss 0.008032615934380306\n",
      "Epoch 63 num_samples 4900 loss 0.010084279285033713\n",
      "Epoch 63 num_samples 5000 loss 0.009006593391801885\n",
      "Epoch 63 num_samples 5100 loss 0.016187250398708494\n",
      "Epoch 63 num_samples 5200 loss 0.00807257903072101\n",
      "Epoch 63 num_samples 5300 loss 0.010844699011696633\n",
      "Epoch 63 num_samples 5400 loss 0.014824927424432937\n",
      "Epoch 63 num_samples 5500 loss 0.008730559066664577\n",
      "Epoch 63 num_samples 5600 loss 0.033419009361992075\n",
      "Epoch 63 num_samples 5700 loss 0.012073185307073861\n",
      "Epoch 63 num_samples 5800 loss 0.011260288424326581\n",
      "Epoch 63 num_samples 5900 loss 0.014647487053797042\n",
      "Epoch 63 num_samples 6000 loss 0.011749526983689682\n",
      "Epoch 63 num_samples 6100 loss 0.010665402963833635\n",
      "Epoch 63 num_samples 6200 loss 0.012602172942994563\n",
      "Epoch 63 num_samples 6300 loss 0.01605982344790713\n",
      "Epoch 63 num_samples 6400 loss 0.009730337585085005\n",
      "Epoch 63 num_samples 6500 loss 0.008733020895118144\n",
      "Epoch 63 num_samples 6600 loss 0.01956563448989335\n",
      "Epoch 63 num_samples 6700 loss 0.009827505083483339\n",
      "Epoch 63 num_samples 6800 loss 0.006528635063007275\n",
      "Epoch 63 num_samples 6900 loss 0.024573803792832173\n",
      "Epoch 63 num_samples 7000 loss 0.014651928793372621\n",
      "Epoch 63 num_samples 7100 loss 0.008097428373459035\n",
      "Epoch 63 num_samples 7200 loss 0.01162006188745176\n",
      "Epoch 63 num_samples 7300 loss 0.011292020964910747\n",
      "Epoch 63 num_samples 7400 loss 0.008511353903984123\n",
      "Epoch 63 num_samples 7500 loss 0.01905507004585767\n",
      "Epoch 63 num_samples 7600 loss 0.012108363902793027\n",
      "Epoch 63 num_samples 7700 loss 0.01723250270766679\n",
      "Epoch 63 num_samples 7800 loss 0.010023299894238108\n",
      "Epoch 63 num_samples 7900 loss 0.012261553177086725\n",
      "Epoch 63 num_samples 8000 loss 0.008228578928420249\n",
      "Epoch 63 num_samples 8100 loss 0.01103108602093529\n",
      "Epoch 63 num_samples 8200 loss 0.012666935292513962\n",
      "Epoch 63 num_samples 8300 loss 0.010166816479127799\n",
      "Epoch 63 num_samples 8400 loss 0.008365819234243172\n",
      "Epoch 63 num_samples 8500 loss 0.011972130931924478\n",
      "Epoch 63 num_samples 8600 loss 0.012189200805405191\n",
      "Epoch 63 num_samples 8700 loss 0.011846537540056773\n",
      "Epoch 63 num_samples 8800 loss 0.011984019360702002\n",
      "Epoch 63 num_samples 8900 loss 0.014320438417876846\n",
      "Epoch 63 num_samples 9000 loss 0.01177955786485741\n",
      "Epoch 63 num_samples 9100 loss 0.011725133994594602\n",
      "Epoch 63 num_samples 9200 loss 0.012223764903645008\n",
      "Epoch 63 num_samples 9300 loss 0.012010122521500877\n",
      "Epoch 63 num_samples 9400 loss 0.010161200871478546\n",
      "Epoch 63 num_samples 9500 loss 0.010129571277303321\n",
      "Epoch 63 num_samples 9600 loss 0.010734181494074875\n",
      "Epoch 63 num_samples 9700 loss 0.017517479155868224\n",
      "Epoch 63 num_samples 9800 loss 0.007276458160899379\n",
      "Epoch 63 num_samples 9900 loss 0.022045991759483404\n",
      "Epoch 63 num_samples 10000 loss 0.010248910678251738\n",
      "Epoch 63 num_samples 10100 loss 0.009220822150268973\n",
      "Epoch 63 num_samples 10200 loss 0.014470471283821871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 num_samples 10300 loss 0.011391770004151067\n",
      "Epoch 63 num_samples 10400 loss 0.015286282479319646\n",
      "Epoch 63 num_samples 10500 loss 0.010368119816172229\n",
      "Epoch 63 num_samples 10600 loss 0.013939624591867839\n",
      "Epoch 63 num_samples 10700 loss 0.010632101204578217\n",
      "Epoch 63 num_samples 10800 loss 0.013588952734082322\n",
      "Epoch 63 num_samples 10900 loss 0.00999182954753375\n",
      "Epoch 63 num_samples 11000 loss 0.009107331547874404\n",
      "Epoch 63 num_samples 11100 loss 0.012042386527032205\n",
      "Epoch 63 num_samples 11200 loss 0.009532297737588475\n",
      "Epoch 63 num_samples 11300 loss 0.016151934062929543\n",
      "Epoch 63 num_samples 11400 loss 0.01110695552876882\n",
      "Epoch 63 num_samples 11500 loss 0.010744816179039272\n",
      "Epoch 63 num_samples 11600 loss 0.010251379083388168\n",
      "Epoch 63 num_samples 11700 loss 0.014466276409601832\n",
      "Epoch 63 num_samples 11800 loss 0.010355946702723218\n",
      "Epoch 63 num_samples 11900 loss 0.009157344320493728\n",
      "Epoch 63 num_samples 12000 loss 0.008016430902687449\n",
      "Epoch 63 num_samples 12100 loss 0.008978028160796911\n",
      "Epoch 63 num_samples 12200 loss 0.013582962951648665\n",
      "Epoch 63 num_samples 12300 loss 0.009000188835553759\n",
      "Epoch 63 num_samples 12400 loss 0.014725161195762995\n",
      "Epoch 63 num_samples 12500 loss 0.012840410358415884\n",
      "Epoch 63 num_samples 12600 loss 0.01585934102259588\n",
      "Epoch 63 num_samples 12700 loss 0.011931180119402173\n",
      "Epoch 63 num_samples 12800 loss 0.019164271803066155\n",
      "Epoch 63 num_samples 12900 loss 0.010257545774376828\n",
      "Epoch 63 num_samples 13000 loss 0.009439321858394219\n",
      "Epoch 63 num_samples 13100 loss 0.01586779077888305\n",
      "Epoch 63 num_samples 13200 loss 0.006802232517268863\n",
      "Epoch 63 num_samples 13300 loss 0.00896596954991356\n",
      "Epoch 63 num_samples 13400 loss 0.006032164939373509\n",
      "Epoch 63 num_samples 13500 loss 0.008686566070240329\n",
      "Epoch 63 num_samples 13600 loss 0.015358187830056096\n",
      "Epoch 63 num_samples 13700 loss 0.011286636965147884\n",
      "Epoch 63 num_samples 13800 loss 0.010497496365852989\n",
      "Epoch 63 num_samples 13900 loss 0.0045424176783479715\n",
      "Epoch 63 num_samples 14000 loss 0.00792176529951136\n",
      "Epoch 63 num_samples 14100 loss 0.010472427115207364\n",
      "Epoch 63 num_samples 14200 loss 0.00908914791859168\n",
      "Epoch 63 num_samples 14300 loss 0.01231069183996817\n",
      "Epoch 63 num_samples 14400 loss 0.012771328382609916\n",
      "Epoch 63 num_samples 14500 loss 0.014976168470407045\n",
      "Epoch 63 num_samples 14600 loss 0.01109501000419646\n",
      "Epoch 63 num_samples 14700 loss 0.011432356389937332\n",
      "Epoch 63 num_samples 14800 loss 0.010793340612065582\n",
      "Epoch 63 num_samples 14900 loss 0.013066330256546592\n",
      "Epoch 63 num_samples 15000 loss 0.010557602911987374\n",
      "Epoch 63 num_samples 15100 loss 0.01198972212392155\n",
      "Epoch 63 num_samples 15200 loss 0.01237741816816678\n",
      "Epoch 63 num_samples 15300 loss 0.012468335644483379\n",
      "Epoch 63 num_samples 15400 loss 0.008223121799942334\n",
      "Epoch 63 num_samples 15500 loss 0.012324489583299821\n",
      "Epoch 63 num_samples 15600 loss 0.01263690513989919\n",
      "Epoch 63 num_samples 15700 loss 0.008204355352887325\n",
      "Epoch 63 num_samples 15800 loss 0.014342744156396301\n",
      "Epoch 63 num_samples 15900 loss 0.00869873025972533\n",
      "Epoch 63 num_samples 16000 loss 0.016577149553640702\n",
      "Epoch 63 num_samples 16100 loss 0.00858195069428525\n",
      "Epoch 63 num_samples 16200 loss 0.013206023653299757\n",
      "Epoch 63 num_samples 16300 loss 0.01563831291518828\n",
      "Epoch 63 num_samples 16400 loss 0.01566383194239557\n",
      "Epoch 63 num_samples 16500 loss 0.013574124527456138\n",
      "Epoch 63 num_samples 16600 loss 0.014488817148309956\n",
      "Epoch 63 num_samples 16700 loss 0.008041025922373959\n",
      "Epoch 63 num_samples 16800 loss 0.00813098803771066\n",
      "Epoch 63 num_samples 16900 loss 0.009698965409585477\n",
      "Epoch 63 num_samples 17000 loss 0.007331648355444186\n",
      "Epoch 63 num_samples 17100 loss 0.01914655986915495\n",
      "Epoch 63 num_samples 17200 loss 0.013137694880628192\n",
      "Epoch 63 num_samples 17300 loss 0.013502247702204545\n",
      "Epoch 63 num_samples 17400 loss 0.011699409836092333\n",
      "Epoch 63 num_samples 17500 loss 0.011783160502237607\n",
      "Epoch 63 num_samples 17600 loss 0.010754602745419341\n",
      "Epoch 63 num_samples 17700 loss 0.008878844875003926\n",
      "Epoch 63 num_samples 17800 loss 0.009744871776318477\n",
      "Epoch 63 num_samples 17900 loss 0.01512680693891539\n",
      "Epoch 63 num_samples 18000 loss 0.010564655998848869\n",
      "Epoch 63 num_samples 18100 loss 0.011800833415470526\n",
      "Epoch 63 num_samples 18200 loss 0.012401900043166054\n",
      "Epoch 63 num_samples 18300 loss 0.009286967509945995\n",
      "Epoch 63 num_samples 18400 loss 0.01835562319261621\n",
      "Epoch 63 num_samples 18500 loss 0.012578678413698991\n",
      "Epoch 64 num_samples 0 loss 0.008691347393865694\n",
      "Epoch 64 num_samples 100 loss 0.01578293770045732\n",
      "Epoch 64 num_samples 200 loss 0.010359165297147756\n",
      "Epoch 64 num_samples 300 loss 0.008908920306848362\n",
      "Epoch 64 num_samples 400 loss 0.010502722732919769\n",
      "Epoch 64 num_samples 500 loss 0.015712946119299288\n",
      "Epoch 64 num_samples 600 loss 0.016372120725097566\n",
      "Epoch 64 num_samples 700 loss 0.017123864877642975\n",
      "Epoch 64 num_samples 800 loss 0.010168046514924905\n",
      "Epoch 64 num_samples 900 loss 0.017714052355206775\n",
      "Epoch 64 num_samples 1000 loss 0.01066849642351161\n",
      "Epoch 64 num_samples 1100 loss 0.017828577405821812\n",
      "Epoch 64 num_samples 1200 loss 0.010555508737320342\n",
      "Epoch 64 num_samples 1300 loss 0.012454184720405279\n",
      "Epoch 64 num_samples 1400 loss 0.01291155688933876\n",
      "Epoch 64 num_samples 1500 loss 0.016070840264230214\n",
      "Epoch 64 num_samples 1600 loss 0.01109098648990235\n",
      "Epoch 64 num_samples 1700 loss 0.010691811855458\n",
      "Epoch 64 num_samples 1800 loss 0.010394206732581172\n",
      "Epoch 64 num_samples 1900 loss 0.012468918365128742\n",
      "Epoch 64 num_samples 2000 loss 0.014579737554047477\n",
      "Epoch 64 num_samples 2100 loss 0.007795947935308032\n",
      "Epoch 64 num_samples 2200 loss 0.008642225494906744\n",
      "Epoch 64 num_samples 2300 loss 0.005829461820323842\n",
      "Epoch 64 num_samples 2400 loss 0.009880017908678687\n",
      "Epoch 64 num_samples 2500 loss 0.013350339600072161\n",
      "Epoch 64 num_samples 2600 loss 0.014337687248545316\n",
      "Epoch 64 num_samples 2700 loss 0.009949575317067305\n",
      "Epoch 64 num_samples 2800 loss 0.01458662293557209\n",
      "Epoch 64 num_samples 2900 loss 0.013144450643907098\n",
      "Epoch 64 num_samples 3000 loss 0.011061004857893854\n",
      "Epoch 64 num_samples 3100 loss 0.010361340454958562\n",
      "Epoch 64 num_samples 3200 loss 0.019637754685604962\n",
      "Epoch 64 num_samples 3300 loss 0.012284396721572397\n",
      "Epoch 64 num_samples 3400 loss 0.00954480658951907\n",
      "Epoch 64 num_samples 3500 loss 0.009824791002363447\n",
      "Epoch 64 num_samples 3600 loss 0.007080393375764389\n",
      "Epoch 64 num_samples 3700 loss 0.017576864249849066\n",
      "Epoch 64 num_samples 3800 loss 0.009909104809943782\n",
      "Epoch 64 num_samples 3900 loss 0.011938886284577484\n",
      "Epoch 64 num_samples 4000 loss 0.013489337353748188\n",
      "Epoch 64 num_samples 4100 loss 0.0173670883081901\n",
      "Epoch 64 num_samples 4200 loss 0.0120068924849925\n",
      "Epoch 64 num_samples 4300 loss 0.010886630200742226\n",
      "Epoch 64 num_samples 4400 loss 0.01273465529548346\n",
      "Epoch 64 num_samples 4500 loss 0.015484742815916098\n",
      "Epoch 64 num_samples 4600 loss 0.013020384718762913\n",
      "Epoch 64 num_samples 4700 loss 0.007566875681975358\n",
      "Epoch 64 num_samples 4800 loss 0.0078085716489972225\n",
      "Epoch 64 num_samples 4900 loss 0.009835366693209426\n",
      "Epoch 64 num_samples 5000 loss 0.008796197119885657\n",
      "Epoch 64 num_samples 5100 loss 0.015744836018202646\n",
      "Epoch 64 num_samples 5200 loss 0.00781685260392851\n",
      "Epoch 64 num_samples 5300 loss 0.010530622862538568\n",
      "Epoch 64 num_samples 5400 loss 0.014439283580354874\n",
      "Epoch 64 num_samples 5500 loss 0.008514449015278137\n",
      "Epoch 64 num_samples 5600 loss 0.032187927166860905\n",
      "Epoch 64 num_samples 5700 loss 0.011774653380243232\n",
      "Epoch 64 num_samples 5800 loss 0.010973809531586397\n",
      "Epoch 64 num_samples 5900 loss 0.014239070005627541\n",
      "Epoch 64 num_samples 6000 loss 0.011419942440743638\n",
      "Epoch 64 num_samples 6100 loss 0.01043620587530806\n",
      "Epoch 64 num_samples 6200 loss 0.01224427206784553\n",
      "Epoch 64 num_samples 6300 loss 0.0156044593978429\n",
      "Epoch 64 num_samples 6400 loss 0.00947864130279366\n",
      "Epoch 64 num_samples 6500 loss 0.008445668822960217\n",
      "Epoch 64 num_samples 6600 loss 0.019075256007725725\n",
      "Epoch 64 num_samples 6700 loss 0.00952683615446053\n",
      "Epoch 64 num_samples 6800 loss 0.00634830327784214\n",
      "Epoch 64 num_samples 6900 loss 0.023825933776008484\n",
      "Epoch 64 num_samples 7000 loss 0.014190320800684955\n",
      "Epoch 64 num_samples 7100 loss 0.007864784577083254\n",
      "Epoch 64 num_samples 7200 loss 0.011293377876894144\n",
      "Epoch 64 num_samples 7300 loss 0.011056896747804794\n",
      "Epoch 64 num_samples 7400 loss 0.008264196679757491\n",
      "Epoch 64 num_samples 7500 loss 0.01838253996957618\n",
      "Epoch 64 num_samples 7600 loss 0.011819021164352272\n",
      "Epoch 64 num_samples 7700 loss 0.016640055027818176\n",
      "Epoch 64 num_samples 7800 loss 0.009771362298839813\n",
      "Epoch 64 num_samples 7900 loss 0.011960469236663673\n",
      "Epoch 64 num_samples 8000 loss 0.007983864112746096\n",
      "Epoch 64 num_samples 8100 loss 0.010770956901013071\n",
      "Epoch 64 num_samples 8200 loss 0.012346996076680945\n",
      "Epoch 64 num_samples 8300 loss 0.009807851177282213\n",
      "Epoch 64 num_samples 8400 loss 0.008080785125070078\n",
      "Epoch 64 num_samples 8500 loss 0.01170485855727045\n",
      "Epoch 64 num_samples 8600 loss 0.011823983850030155\n",
      "Epoch 64 num_samples 8700 loss 0.011517572831484427\n",
      "Epoch 64 num_samples 8800 loss 0.011568151867881024\n",
      "Epoch 64 num_samples 8900 loss 0.013877272194409571\n",
      "Epoch 64 num_samples 9000 loss 0.011411420313417459\n",
      "Epoch 64 num_samples 9100 loss 0.01140102007664347\n",
      "Epoch 64 num_samples 9200 loss 0.011847088808614918\n",
      "Epoch 64 num_samples 9300 loss 0.011608065735709496\n",
      "Epoch 64 num_samples 9400 loss 0.009853497259242753\n",
      "Epoch 64 num_samples 9500 loss 0.009749306528398345\n",
      "Epoch 64 num_samples 9600 loss 0.010400387127959694\n",
      "Epoch 64 num_samples 9700 loss 0.01699633787901992\n",
      "Epoch 64 num_samples 9800 loss 0.007053261116972802\n",
      "Epoch 64 num_samples 9900 loss 0.021387838417637566\n",
      "Epoch 64 num_samples 10000 loss 0.009911740934347314\n",
      "Epoch 64 num_samples 10100 loss 0.008968585741714776\n",
      "Epoch 64 num_samples 10200 loss 0.013996894311488513\n",
      "Epoch 64 num_samples 10300 loss 0.011051157264892792\n",
      "Epoch 64 num_samples 10400 loss 0.01477256433024099\n",
      "Epoch 64 num_samples 10500 loss 0.010077446764871158\n",
      "Epoch 64 num_samples 10600 loss 0.013462223553225598\n",
      "Epoch 64 num_samples 10700 loss 0.010247913252681371\n",
      "Epoch 64 num_samples 10800 loss 0.013144183698813957\n",
      "Epoch 64 num_samples 10900 loss 0.009696382854996499\n",
      "Epoch 64 num_samples 11000 loss 0.00886870307255629\n",
      "Epoch 64 num_samples 11100 loss 0.011717857674966494\n",
      "Epoch 64 num_samples 11200 loss 0.009255117668073316\n",
      "Epoch 64 num_samples 11300 loss 0.015718294839884163\n",
      "Epoch 64 num_samples 11400 loss 0.010735269286449942\n",
      "Epoch 64 num_samples 11500 loss 0.010433663013429408\n",
      "Epoch 64 num_samples 11600 loss 0.00995865213008337\n",
      "Epoch 64 num_samples 11700 loss 0.01402983140796171\n",
      "Epoch 64 num_samples 11800 loss 0.010057454650764746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 num_samples 11900 loss 0.008846509527562491\n",
      "Epoch 64 num_samples 12000 loss 0.007742842757879078\n",
      "Epoch 64 num_samples 12100 loss 0.008717397386726835\n",
      "Epoch 64 num_samples 12200 loss 0.013087472077399288\n",
      "Epoch 64 num_samples 12300 loss 0.008750289927286261\n",
      "Epoch 64 num_samples 12400 loss 0.014292158136557941\n",
      "Epoch 64 num_samples 12500 loss 0.01248166610932472\n",
      "Epoch 64 num_samples 12600 loss 0.015318813753548363\n",
      "Epoch 64 num_samples 12700 loss 0.011519907173134924\n",
      "Epoch 64 num_samples 12800 loss 0.018521851977025307\n",
      "Epoch 64 num_samples 12900 loss 0.009958503797250821\n",
      "Epoch 64 num_samples 13000 loss 0.009213301912532404\n",
      "Epoch 64 num_samples 13100 loss 0.01539954548394965\n",
      "Epoch 64 num_samples 13200 loss 0.0065747113631652145\n",
      "Epoch 64 num_samples 13300 loss 0.008716177908356099\n",
      "Epoch 64 num_samples 13400 loss 0.00588081786922444\n",
      "Epoch 64 num_samples 13500 loss 0.008419586099199678\n",
      "Epoch 64 num_samples 13600 loss 0.014937138630791078\n",
      "Epoch 64 num_samples 13700 loss 0.010924280640579313\n",
      "Epoch 64 num_samples 13800 loss 0.01022454604299986\n",
      "Epoch 64 num_samples 13900 loss 0.004405788521074399\n",
      "Epoch 64 num_samples 14000 loss 0.007673760337317323\n",
      "Epoch 64 num_samples 14100 loss 0.010146170136249483\n",
      "Epoch 64 num_samples 14200 loss 0.00885283485645532\n",
      "Epoch 64 num_samples 14300 loss 0.01200062623505747\n",
      "Epoch 64 num_samples 14400 loss 0.01236794827908931\n",
      "Epoch 64 num_samples 14500 loss 0.01460882582762915\n",
      "Epoch 64 num_samples 14600 loss 0.010744821453371377\n",
      "Epoch 64 num_samples 14700 loss 0.01107332337764715\n",
      "Epoch 64 num_samples 14800 loss 0.010468657639144001\n",
      "Epoch 64 num_samples 14900 loss 0.01265580689639457\n",
      "Epoch 64 num_samples 15000 loss 0.01025396450502344\n",
      "Epoch 64 num_samples 15100 loss 0.011613955698020493\n",
      "Epoch 64 num_samples 15200 loss 0.011953673639045164\n",
      "Epoch 64 num_samples 15300 loss 0.01210501732743406\n",
      "Epoch 64 num_samples 15400 loss 0.008044816141637275\n",
      "Epoch 64 num_samples 15500 loss 0.011984249254503938\n",
      "Epoch 64 num_samples 15600 loss 0.01229854046720098\n",
      "Epoch 64 num_samples 15700 loss 0.00798511089985423\n",
      "Epoch 64 num_samples 15800 loss 0.013837199475774163\n",
      "Epoch 64 num_samples 15900 loss 0.008466520689832748\n",
      "Epoch 64 num_samples 16000 loss 0.01609276149801187\n",
      "Epoch 64 num_samples 16100 loss 0.00830963239453048\n",
      "Epoch 64 num_samples 16200 loss 0.012823734623029605\n",
      "Epoch 64 num_samples 16300 loss 0.01513622568863487\n",
      "Epoch 64 num_samples 16400 loss 0.015152917379721093\n",
      "Epoch 64 num_samples 16500 loss 0.013218253695348419\n",
      "Epoch 64 num_samples 16600 loss 0.014097572487979475\n",
      "Epoch 64 num_samples 16700 loss 0.007827356928648438\n",
      "Epoch 64 num_samples 16800 loss 0.00788736775736776\n",
      "Epoch 64 num_samples 16900 loss 0.009428532763423753\n",
      "Epoch 64 num_samples 17000 loss 0.007119491882666004\n",
      "Epoch 64 num_samples 17100 loss 0.018487410850825295\n",
      "Epoch 64 num_samples 17200 loss 0.012733278174643828\n",
      "Epoch 64 num_samples 17300 loss 0.013014291859409692\n",
      "Epoch 64 num_samples 17400 loss 0.011340120315190933\n",
      "Epoch 64 num_samples 17500 loss 0.011444859343537313\n",
      "Epoch 64 num_samples 17600 loss 0.010453375057900465\n",
      "Epoch 64 num_samples 17700 loss 0.008635682260646886\n",
      "Epoch 64 num_samples 17800 loss 0.009429349208675747\n",
      "Epoch 64 num_samples 17900 loss 0.014691019669479128\n",
      "Epoch 64 num_samples 18000 loss 0.010322669690637984\n",
      "Epoch 64 num_samples 18100 loss 0.011466943218978802\n",
      "Epoch 64 num_samples 18200 loss 0.012139797602815236\n",
      "Epoch 64 num_samples 18300 loss 0.009092246851177214\n",
      "Epoch 64 num_samples 18400 loss 0.01786016551526379\n",
      "Epoch 64 num_samples 18500 loss 0.01224631231644337\n",
      "Epoch 65 num_samples 0 loss 0.008445475506676662\n",
      "Epoch 65 num_samples 100 loss 0.015322945279341473\n",
      "Epoch 65 num_samples 200 loss 0.010044666169678975\n",
      "Epoch 65 num_samples 300 loss 0.008662783841478052\n",
      "Epoch 65 num_samples 400 loss 0.010211461185849235\n",
      "Epoch 65 num_samples 500 loss 0.015258028400085326\n",
      "Epoch 65 num_samples 600 loss 0.015792919351540126\n",
      "Epoch 65 num_samples 700 loss 0.016590074160231595\n",
      "Epoch 65 num_samples 800 loss 0.009860928557771521\n",
      "Epoch 65 num_samples 900 loss 0.01724581147177552\n",
      "Epoch 65 num_samples 1000 loss 0.01039950185551597\n",
      "Epoch 65 num_samples 1100 loss 0.01737277381234965\n",
      "Epoch 65 num_samples 1200 loss 0.010225502156449904\n",
      "Epoch 65 num_samples 1300 loss 0.012129090099007893\n",
      "Epoch 65 num_samples 1400 loss 0.012421885583059447\n",
      "Epoch 65 num_samples 1500 loss 0.015509221316088638\n",
      "Epoch 65 num_samples 1600 loss 0.010774512163506706\n",
      "Epoch 65 num_samples 1700 loss 0.010355298886242023\n",
      "Epoch 65 num_samples 1800 loss 0.01002812397603728\n",
      "Epoch 65 num_samples 1900 loss 0.012120502708390553\n",
      "Epoch 65 num_samples 2000 loss 0.014169583598361866\n",
      "Epoch 65 num_samples 2100 loss 0.007552761556570931\n",
      "Epoch 65 num_samples 2200 loss 0.008401048133130208\n",
      "Epoch 65 num_samples 2300 loss 0.005673095244110069\n",
      "Epoch 65 num_samples 2400 loss 0.009601355254687935\n",
      "Epoch 65 num_samples 2500 loss 0.012976056315730964\n",
      "Epoch 65 num_samples 2600 loss 0.01397095667515971\n",
      "Epoch 65 num_samples 2700 loss 0.009660712484479415\n",
      "Epoch 65 num_samples 2800 loss 0.014039451948633465\n",
      "Epoch 65 num_samples 2900 loss 0.012740226351960607\n",
      "Epoch 65 num_samples 3000 loss 0.010701365611244448\n",
      "Epoch 65 num_samples 3100 loss 0.01010925868830229\n",
      "Epoch 65 num_samples 3200 loss 0.018924622774563873\n",
      "Epoch 65 num_samples 3300 loss 0.012006373662998459\n",
      "Epoch 65 num_samples 3400 loss 0.009268659484778235\n",
      "Epoch 65 num_samples 3500 loss 0.009560089483707622\n",
      "Epoch 65 num_samples 3600 loss 0.006947212030065534\n",
      "Epoch 65 num_samples 3700 loss 0.01700539148049394\n",
      "Epoch 65 num_samples 3800 loss 0.009557477265396358\n",
      "Epoch 65 num_samples 3900 loss 0.011534221018949369\n",
      "Epoch 65 num_samples 4000 loss 0.01296477114061609\n",
      "Epoch 65 num_samples 4100 loss 0.016810025977347185\n",
      "Epoch 65 num_samples 4200 loss 0.011679756599630364\n",
      "Epoch 65 num_samples 4300 loss 0.010603377435762033\n",
      "Epoch 65 num_samples 4400 loss 0.012365560820006984\n",
      "Epoch 65 num_samples 4500 loss 0.015043219260374042\n",
      "Epoch 65 num_samples 4600 loss 0.012668977567194581\n",
      "Epoch 65 num_samples 4700 loss 0.007299158486827904\n",
      "Epoch 65 num_samples 4800 loss 0.007578994530605681\n",
      "Epoch 65 num_samples 4900 loss 0.009583067999423756\n",
      "Epoch 65 num_samples 5000 loss 0.008561588144076523\n",
      "Epoch 65 num_samples 5100 loss 0.015293203070511099\n",
      "Epoch 65 num_samples 5200 loss 0.007582029483508187\n",
      "Epoch 65 num_samples 5300 loss 0.010226722805147555\n",
      "Epoch 65 num_samples 5400 loss 0.014073730717367816\n",
      "Epoch 65 num_samples 5500 loss 0.0083064127907566\n",
      "Epoch 65 num_samples 5600 loss 0.03093437124282553\n",
      "Epoch 65 num_samples 5700 loss 0.011360539710565968\n",
      "Epoch 65 num_samples 5800 loss 0.010653539740427013\n",
      "Epoch 65 num_samples 5900 loss 0.013795219592857988\n",
      "Epoch 65 num_samples 6000 loss 0.011080044379532208\n",
      "Epoch 65 num_samples 6100 loss 0.010173304974969514\n",
      "Epoch 65 num_samples 6200 loss 0.011848654212034293\n",
      "Epoch 65 num_samples 6300 loss 0.015049350849146619\n",
      "Epoch 65 num_samples 6400 loss 0.009238026032319435\n",
      "Epoch 65 num_samples 6500 loss 0.00821558262609614\n",
      "Epoch 65 num_samples 6600 loss 0.018640318081248\n",
      "Epoch 65 num_samples 6700 loss 0.009285924096261845\n",
      "Epoch 65 num_samples 6800 loss 0.006148165051570231\n",
      "Epoch 65 num_samples 6900 loss 0.023194175780990277\n",
      "Epoch 65 num_samples 7000 loss 0.013797088914469449\n",
      "Epoch 65 num_samples 7100 loss 0.0076274439587599874\n",
      "Epoch 65 num_samples 7200 loss 0.010943509850520878\n",
      "Epoch 65 num_samples 7300 loss 0.010793651690745304\n",
      "Epoch 65 num_samples 7400 loss 0.00805802492617977\n",
      "Epoch 65 num_samples 7500 loss 0.017845570883355925\n",
      "Epoch 65 num_samples 7600 loss 0.011456897441871368\n",
      "Epoch 65 num_samples 7700 loss 0.01607608435477863\n",
      "Epoch 65 num_samples 7800 loss 0.009482021280737458\n",
      "Epoch 65 num_samples 7900 loss 0.011635465196487185\n",
      "Epoch 65 num_samples 8000 loss 0.007728221921465603\n",
      "Epoch 65 num_samples 8100 loss 0.010434217724004926\n",
      "Epoch 65 num_samples 8200 loss 0.012057064093594194\n",
      "Epoch 65 num_samples 8300 loss 0.009508087831204349\n",
      "Epoch 65 num_samples 8400 loss 0.00783623608130875\n",
      "Epoch 65 num_samples 8500 loss 0.011360663407685935\n",
      "Epoch 65 num_samples 8600 loss 0.011446511665713843\n",
      "Epoch 65 num_samples 8700 loss 0.011163027141294286\n",
      "Epoch 65 num_samples 8800 loss 0.011197950949863098\n",
      "Epoch 65 num_samples 8900 loss 0.013504953529682338\n",
      "Epoch 65 num_samples 9000 loss 0.011173251403491053\n",
      "Epoch 65 num_samples 9100 loss 0.011046867719035076\n",
      "Epoch 65 num_samples 9200 loss 0.011544757549639932\n",
      "Epoch 65 num_samples 9300 loss 0.011302655308039769\n",
      "Epoch 65 num_samples 9400 loss 0.009614373453850387\n",
      "Epoch 65 num_samples 9500 loss 0.009518729519538423\n",
      "Epoch 65 num_samples 9600 loss 0.010202391906481272\n",
      "Epoch 65 num_samples 9700 loss 0.016451372977815962\n",
      "Epoch 65 num_samples 9800 loss 0.006878662660363037\n",
      "Epoch 65 num_samples 9900 loss 0.020645232635391926\n",
      "Epoch 65 num_samples 10000 loss 0.00954860189590675\n",
      "Epoch 65 num_samples 10100 loss 0.008687306562573086\n",
      "Epoch 65 num_samples 10200 loss 0.013607963219939213\n",
      "Epoch 65 num_samples 10300 loss 0.010741434505495426\n",
      "Epoch 65 num_samples 10400 loss 0.014374804928935878\n",
      "Epoch 65 num_samples 10500 loss 0.009879398241412558\n",
      "Epoch 65 num_samples 10600 loss 0.013038708522468554\n",
      "Epoch 65 num_samples 10700 loss 0.010028596326868899\n",
      "Epoch 65 num_samples 10800 loss 0.012771713350438927\n",
      "Epoch 65 num_samples 10900 loss 0.009452452652259573\n",
      "Epoch 65 num_samples 11000 loss 0.008619749668575505\n",
      "Epoch 65 num_samples 11100 loss 0.011445906122761354\n",
      "Epoch 65 num_samples 11200 loss 0.008995505764714345\n",
      "Epoch 65 num_samples 11300 loss 0.015237947103616575\n",
      "Epoch 65 num_samples 11400 loss 0.010418602443471457\n",
      "Epoch 65 num_samples 11500 loss 0.010107019374727766\n",
      "Epoch 65 num_samples 11600 loss 0.009675499085456086\n",
      "Epoch 65 num_samples 11700 loss 0.013515507963886689\n",
      "Epoch 65 num_samples 11800 loss 0.009732918840632696\n",
      "Epoch 65 num_samples 11900 loss 0.008594744427363\n",
      "Epoch 65 num_samples 12000 loss 0.007532146467585785\n",
      "Epoch 65 num_samples 12100 loss 0.008457035056639218\n",
      "Epoch 65 num_samples 12200 loss 0.012705795243529256\n",
      "Epoch 65 num_samples 12300 loss 0.008499757578440369\n",
      "Epoch 65 num_samples 12400 loss 0.013838405179061698\n",
      "Epoch 65 num_samples 12500 loss 0.012103599536394284\n",
      "Epoch 65 num_samples 12600 loss 0.01491417532683511\n",
      "Epoch 65 num_samples 12700 loss 0.011200657875577655\n",
      "Epoch 65 num_samples 12800 loss 0.017903801155484365\n",
      "Epoch 65 num_samples 12900 loss 0.009629915251870068\n",
      "Epoch 65 num_samples 13000 loss 0.009009811962051136\n",
      "Epoch 65 num_samples 13100 loss 0.014884537800035257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 num_samples 13200 loss 0.006429046363281248\n",
      "Epoch 65 num_samples 13300 loss 0.00847065023907675\n",
      "Epoch 65 num_samples 13400 loss 0.005725736333144299\n",
      "Epoch 65 num_samples 13500 loss 0.008131684304924516\n",
      "Epoch 65 num_samples 13600 loss 0.0145261679928353\n",
      "Epoch 65 num_samples 13700 loss 0.010632926478834886\n",
      "Epoch 65 num_samples 13800 loss 0.009918676371476951\n",
      "Epoch 65 num_samples 13900 loss 0.004281318898001728\n",
      "Epoch 65 num_samples 14000 loss 0.007470357220445061\n",
      "Epoch 65 num_samples 14100 loss 0.00988265821346434\n",
      "Epoch 65 num_samples 14200 loss 0.008606693931856826\n",
      "Epoch 65 num_samples 14300 loss 0.011667158850412522\n",
      "Epoch 65 num_samples 14400 loss 0.012012292348019064\n",
      "Epoch 65 num_samples 14500 loss 0.014245851799064308\n",
      "Epoch 65 num_samples 14600 loss 0.010405802824069468\n",
      "Epoch 65 num_samples 14700 loss 0.010771372017566259\n",
      "Epoch 65 num_samples 14800 loss 0.010178365326285918\n",
      "Epoch 65 num_samples 14900 loss 0.012266337972368212\n",
      "Epoch 65 num_samples 15000 loss 0.010025052156496819\n",
      "Epoch 65 num_samples 15100 loss 0.011318444322329979\n",
      "Epoch 65 num_samples 15200 loss 0.011552117364164713\n",
      "Epoch 65 num_samples 15300 loss 0.011734451981171259\n",
      "Epoch 65 num_samples 15400 loss 0.00785803329726103\n",
      "Epoch 65 num_samples 15500 loss 0.011578457731025732\n",
      "Epoch 65 num_samples 15600 loss 0.011977563467790595\n",
      "Epoch 65 num_samples 15700 loss 0.0078079296267273566\n",
      "Epoch 65 num_samples 15800 loss 0.013429577994497581\n",
      "Epoch 65 num_samples 15900 loss 0.00822583494612242\n",
      "Epoch 65 num_samples 16000 loss 0.015686511536400646\n",
      "Epoch 65 num_samples 16100 loss 0.008119271975793318\n",
      "Epoch 65 num_samples 16200 loss 0.012433103990337565\n",
      "Epoch 65 num_samples 16300 loss 0.014661002751796841\n",
      "Epoch 65 num_samples 16400 loss 0.014735963923348994\n",
      "Epoch 65 num_samples 16500 loss 0.012816374037201008\n",
      "Epoch 65 num_samples 16600 loss 0.013726736265680956\n",
      "Epoch 65 num_samples 16700 loss 0.0076303261558006855\n",
      "Epoch 65 num_samples 16800 loss 0.0076965104180460354\n",
      "Epoch 65 num_samples 16900 loss 0.009141065779895706\n",
      "Epoch 65 num_samples 17000 loss 0.006940056427711927\n",
      "Epoch 65 num_samples 17100 loss 0.017950584194676565\n",
      "Epoch 65 num_samples 17200 loss 0.012361197108083697\n",
      "Epoch 65 num_samples 17300 loss 0.012697951807586802\n",
      "Epoch 65 num_samples 17400 loss 0.011081312251102713\n",
      "Epoch 65 num_samples 17500 loss 0.011157467330306058\n",
      "Epoch 65 num_samples 17600 loss 0.010147661250309834\n",
      "Epoch 65 num_samples 17700 loss 0.008394353926325841\n",
      "Epoch 65 num_samples 17800 loss 0.009145506966021887\n",
      "Epoch 65 num_samples 17900 loss 0.014253672092363707\n",
      "Epoch 65 num_samples 18000 loss 0.010015097740796852\n",
      "Epoch 65 num_samples 18100 loss 0.011133713307426702\n",
      "Epoch 65 num_samples 18200 loss 0.011824374047444639\n",
      "Epoch 65 num_samples 18300 loss 0.00882234763782602\n",
      "Epoch 65 num_samples 18400 loss 0.017226173521830816\n",
      "Epoch 65 num_samples 18500 loss 0.01193151936560022\n",
      "Epoch 66 num_samples 0 loss 0.008208086706401094\n",
      "Epoch 66 num_samples 100 loss 0.014877177557612371\n",
      "Epoch 66 num_samples 200 loss 0.009842829372523277\n",
      "Epoch 66 num_samples 300 loss 0.00839566594985337\n",
      "Epoch 66 num_samples 400 loss 0.00998355681654516\n",
      "Epoch 66 num_samples 500 loss 0.014889995026095035\n",
      "Epoch 66 num_samples 600 loss 0.015335916732929843\n",
      "Epoch 66 num_samples 700 loss 0.016083295517732642\n",
      "Epoch 66 num_samples 800 loss 0.009554810361132073\n",
      "Epoch 66 num_samples 900 loss 0.016796496950128196\n",
      "Epoch 66 num_samples 1000 loss 0.010081659693032438\n",
      "Epoch 66 num_samples 1100 loss 0.01691782479429729\n",
      "Epoch 66 num_samples 1200 loss 0.009932515837259044\n",
      "Epoch 66 num_samples 1300 loss 0.011784977910819705\n",
      "Epoch 66 num_samples 1400 loss 0.012080131101430254\n",
      "Epoch 66 num_samples 1500 loss 0.015037375643750356\n",
      "Epoch 66 num_samples 1600 loss 0.010453693264400064\n",
      "Epoch 66 num_samples 1700 loss 0.010081523714975216\n",
      "Epoch 66 num_samples 1800 loss 0.009774122250927856\n",
      "Epoch 66 num_samples 1900 loss 0.011725643239202867\n",
      "Epoch 66 num_samples 2000 loss 0.013774672215818233\n",
      "Epoch 66 num_samples 2100 loss 0.007365945160377871\n",
      "Epoch 66 num_samples 2200 loss 0.008179220313641149\n",
      "Epoch 66 num_samples 2300 loss 0.005508683516081227\n",
      "Epoch 66 num_samples 2400 loss 0.009279262229938192\n",
      "Epoch 66 num_samples 2500 loss 0.012603613977264096\n",
      "Epoch 66 num_samples 2600 loss 0.013521980899082886\n",
      "Epoch 66 num_samples 2700 loss 0.009397671643653783\n",
      "Epoch 66 num_samples 2800 loss 0.01365177987681053\n",
      "Epoch 66 num_samples 2900 loss 0.012385710796068736\n",
      "Epoch 66 num_samples 3000 loss 0.010427016088247617\n",
      "Epoch 66 num_samples 3100 loss 0.00983734118751601\n",
      "Epoch 66 num_samples 3200 loss 0.01825521839016477\n",
      "Epoch 66 num_samples 3300 loss 0.01157445500565581\n",
      "Epoch 66 num_samples 3400 loss 0.008994286575128288\n",
      "Epoch 66 num_samples 3500 loss 0.00929208083386649\n",
      "Epoch 66 num_samples 3600 loss 0.006778525711536909\n",
      "Epoch 66 num_samples 3700 loss 0.01651784721648578\n",
      "Epoch 66 num_samples 3800 loss 0.009271969423382449\n",
      "Epoch 66 num_samples 3900 loss 0.011183375874872399\n",
      "Epoch 66 num_samples 4000 loss 0.012531473212661464\n",
      "Epoch 66 num_samples 4100 loss 0.016228472817435443\n",
      "Epoch 66 num_samples 4200 loss 0.011347961447133494\n",
      "Epoch 66 num_samples 4300 loss 0.010282979131552388\n",
      "Epoch 66 num_samples 4400 loss 0.011972057512182999\n",
      "Epoch 66 num_samples 4500 loss 0.014452759943108845\n",
      "Epoch 66 num_samples 4600 loss 0.012258283659299011\n",
      "Epoch 66 num_samples 4700 loss 0.007120118858272109\n",
      "Epoch 66 num_samples 4800 loss 0.0074108750620825725\n",
      "Epoch 66 num_samples 4900 loss 0.009322604672885017\n",
      "Epoch 66 num_samples 5000 loss 0.008314419142933625\n",
      "Epoch 66 num_samples 5100 loss 0.01492364173972738\n",
      "Epoch 66 num_samples 5200 loss 0.0073943891311086295\n",
      "Epoch 66 num_samples 5300 loss 0.009976138212518878\n",
      "Epoch 66 num_samples 5400 loss 0.01363827390519683\n",
      "Epoch 66 num_samples 5500 loss 0.008114411179769814\n",
      "Epoch 66 num_samples 5600 loss 0.029751503975828687\n",
      "Epoch 66 num_samples 5700 loss 0.01093216645214175\n",
      "Epoch 66 num_samples 5800 loss 0.01032373807798045\n",
      "Epoch 66 num_samples 5900 loss 0.013413260247091796\n",
      "Epoch 66 num_samples 6000 loss 0.01073439433093005\n",
      "Epoch 66 num_samples 6100 loss 0.009863805664178422\n",
      "Epoch 66 num_samples 6200 loss 0.011511907000631547\n",
      "Epoch 66 num_samples 6300 loss 0.01458960955830362\n",
      "Epoch 66 num_samples 6400 loss 0.008995206004426007\n",
      "Epoch 66 num_samples 6500 loss 0.00800188225907045\n",
      "Epoch 66 num_samples 6600 loss 0.018090492714102294\n",
      "Epoch 66 num_samples 6700 loss 0.009066202265264512\n",
      "Epoch 66 num_samples 6800 loss 0.00597717205194492\n",
      "Epoch 66 num_samples 6900 loss 0.02243846836708934\n",
      "Epoch 66 num_samples 7000 loss 0.013398880460222619\n",
      "Epoch 66 num_samples 7100 loss 0.007431979004586281\n",
      "Epoch 66 num_samples 7200 loss 0.010689795051378912\n",
      "Epoch 66 num_samples 7300 loss 0.010563259172226877\n",
      "Epoch 66 num_samples 7400 loss 0.007897607133614773\n",
      "Epoch 66 num_samples 7500 loss 0.017297630404531684\n",
      "Epoch 66 num_samples 7600 loss 0.011184008282016537\n",
      "Epoch 66 num_samples 7700 loss 0.015540378454155013\n",
      "Epoch 66 num_samples 7800 loss 0.009199241849581785\n",
      "Epoch 66 num_samples 7900 loss 0.011354979493455515\n",
      "Epoch 66 num_samples 8000 loss 0.007526306082915189\n",
      "Epoch 66 num_samples 8100 loss 0.010110948071037327\n",
      "Epoch 66 num_samples 8200 loss 0.011686024391665346\n",
      "Epoch 66 num_samples 8300 loss 0.009198671387653989\n",
      "Epoch 66 num_samples 8400 loss 0.007620740831197257\n",
      "Epoch 66 num_samples 8500 loss 0.010953326399476026\n",
      "Epoch 66 num_samples 8600 loss 0.011113836569174387\n",
      "Epoch 66 num_samples 8700 loss 0.010864659837304301\n",
      "Epoch 66 num_samples 8800 loss 0.01089636190750721\n",
      "Epoch 66 num_samples 8900 loss 0.013077674772426655\n",
      "Epoch 66 num_samples 9000 loss 0.01083634900220361\n",
      "Epoch 66 num_samples 9100 loss 0.010737528382786028\n",
      "Epoch 66 num_samples 9200 loss 0.011242930277325485\n",
      "Epoch 66 num_samples 9300 loss 0.010980214898080822\n",
      "Epoch 66 num_samples 9400 loss 0.009344653397717713\n",
      "Epoch 66 num_samples 9500 loss 0.009248372091297512\n",
      "Epoch 66 num_samples 9600 loss 0.009858817519431877\n",
      "Epoch 66 num_samples 9700 loss 0.015910207758549753\n",
      "Epoch 66 num_samples 9800 loss 0.006711421697381519\n",
      "Epoch 66 num_samples 9900 loss 0.020117715676730822\n",
      "Epoch 66 num_samples 10000 loss 0.009304834321937943\n",
      "Epoch 66 num_samples 10100 loss 0.008450539465407409\n",
      "Epoch 66 num_samples 10200 loss 0.013171986647927354\n",
      "Epoch 66 num_samples 10300 loss 0.010435567261191018\n",
      "Epoch 66 num_samples 10400 loss 0.01395466299333929\n",
      "Epoch 66 num_samples 10500 loss 0.009582761314197816\n",
      "Epoch 66 num_samples 10600 loss 0.012581277185992007\n",
      "Epoch 66 num_samples 10700 loss 0.00969323453745541\n",
      "Epoch 66 num_samples 10800 loss 0.012420580226603915\n",
      "Epoch 66 num_samples 10900 loss 0.009203974474056678\n",
      "Epoch 66 num_samples 11000 loss 0.008415736041310547\n",
      "Epoch 66 num_samples 11100 loss 0.011136258053117519\n",
      "Epoch 66 num_samples 11200 loss 0.008780593276033522\n",
      "Epoch 66 num_samples 11300 loss 0.01474538636445561\n",
      "Epoch 66 num_samples 11400 loss 0.010089595274293374\n",
      "Epoch 66 num_samples 11500 loss 0.009853582510582066\n",
      "Epoch 66 num_samples 11600 loss 0.009394807502660713\n",
      "Epoch 66 num_samples 11700 loss 0.013198210094481116\n",
      "Epoch 66 num_samples 11800 loss 0.009496898255243313\n",
      "Epoch 66 num_samples 11900 loss 0.00838628253640757\n",
      "Epoch 66 num_samples 12000 loss 0.00732488232988092\n",
      "Epoch 66 num_samples 12100 loss 0.008209524214724451\n",
      "Epoch 66 num_samples 12200 loss 0.012224046539258562\n",
      "Epoch 66 num_samples 12300 loss 0.00831242696034316\n",
      "Epoch 66 num_samples 12400 loss 0.013413297638983614\n",
      "Epoch 66 num_samples 12500 loss 0.011718118683446011\n",
      "Epoch 66 num_samples 12600 loss 0.014438073488335052\n",
      "Epoch 66 num_samples 12700 loss 0.010855228582302513\n",
      "Epoch 66 num_samples 12800 loss 0.017321563711590035\n",
      "Epoch 66 num_samples 12900 loss 0.009380119788276542\n",
      "Epoch 66 num_samples 13000 loss 0.008721355352713043\n",
      "Epoch 66 num_samples 13100 loss 0.014385230712794374\n",
      "Epoch 66 num_samples 13200 loss 0.006175329695133386\n",
      "Epoch 66 num_samples 13300 loss 0.008281494288030919\n",
      "Epoch 66 num_samples 13400 loss 0.005583174139428013\n",
      "Epoch 66 num_samples 13500 loss 0.007886426070871753\n",
      "Epoch 66 num_samples 13600 loss 0.014095671142867982\n",
      "Epoch 66 num_samples 13700 loss 0.01029443534789406\n",
      "Epoch 66 num_samples 13800 loss 0.009704161425339948\n",
      "Epoch 66 num_samples 13900 loss 0.004165129517363628\n",
      "Epoch 66 num_samples 14000 loss 0.0072356724270566655\n",
      "Epoch 66 num_samples 14100 loss 0.009597018329787469\n",
      "Epoch 66 num_samples 14200 loss 0.008405500204479414\n",
      "Epoch 66 num_samples 14300 loss 0.011414375528905568\n",
      "Epoch 66 num_samples 14400 loss 0.011675124088705323\n",
      "Epoch 66 num_samples 14500 loss 0.01385220868738311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 num_samples 14600 loss 0.010148578856480022\n",
      "Epoch 66 num_samples 14700 loss 0.010514036398203652\n",
      "Epoch 66 num_samples 14800 loss 0.009947888845454146\n",
      "Epoch 66 num_samples 14900 loss 0.011836605730202898\n",
      "Epoch 66 num_samples 15000 loss 0.009760116484785674\n",
      "Epoch 66 num_samples 15100 loss 0.011010405668025367\n",
      "Epoch 66 num_samples 15200 loss 0.011137702109364468\n",
      "Epoch 66 num_samples 15300 loss 0.01138213039013287\n",
      "Epoch 66 num_samples 15400 loss 0.007672351388771135\n",
      "Epoch 66 num_samples 15500 loss 0.011227907397931485\n",
      "Epoch 66 num_samples 15600 loss 0.011610648658355267\n",
      "Epoch 66 num_samples 15700 loss 0.007541798708336562\n",
      "Epoch 66 num_samples 15800 loss 0.012984163028199623\n",
      "Epoch 66 num_samples 15900 loss 0.008053731636795599\n",
      "Epoch 66 num_samples 16000 loss 0.015251339727118144\n",
      "Epoch 66 num_samples 16100 loss 0.007922584985936754\n",
      "Epoch 66 num_samples 16200 loss 0.012082268943879284\n",
      "Epoch 66 num_samples 16300 loss 0.01418253677257724\n",
      "Epoch 66 num_samples 16400 loss 0.01432492933652882\n",
      "Epoch 66 num_samples 16500 loss 0.01246137515980438\n",
      "Epoch 66 num_samples 16600 loss 0.013358697093649358\n",
      "Epoch 66 num_samples 16700 loss 0.007413062813304315\n",
      "Epoch 66 num_samples 16800 loss 0.007496167273067639\n",
      "Epoch 66 num_samples 16900 loss 0.00887030994412672\n",
      "Epoch 66 num_samples 17000 loss 0.006763305115414192\n",
      "Epoch 66 num_samples 17100 loss 0.01741089395668812\n",
      "Epoch 66 num_samples 17200 loss 0.012007982004590911\n",
      "Epoch 66 num_samples 17300 loss 0.012273219194959762\n",
      "Epoch 66 num_samples 17400 loss 0.010761890277465673\n",
      "Epoch 66 num_samples 17500 loss 0.010856301100956804\n",
      "Epoch 66 num_samples 17600 loss 0.009851110526798768\n",
      "Epoch 66 num_samples 17700 loss 0.008167613377738268\n",
      "Epoch 66 num_samples 17800 loss 0.00891938194009874\n",
      "Epoch 66 num_samples 17900 loss 0.013922687726684767\n",
      "Epoch 66 num_samples 18000 loss 0.009782466763123398\n",
      "Epoch 66 num_samples 18100 loss 0.010862728464877427\n",
      "Epoch 66 num_samples 18200 loss 0.011448951656038342\n",
      "Epoch 66 num_samples 18300 loss 0.008593806294165911\n",
      "Epoch 66 num_samples 18400 loss 0.01672480953317476\n",
      "Epoch 66 num_samples 18500 loss 0.011654874694803218\n",
      "Epoch 67 num_samples 0 loss 0.007973922493008594\n",
      "Epoch 67 num_samples 100 loss 0.014480034376856552\n",
      "Epoch 67 num_samples 200 loss 0.009587362484677774\n",
      "Epoch 67 num_samples 300 loss 0.008182000566043325\n",
      "Epoch 67 num_samples 400 loss 0.009691856644537138\n",
      "Epoch 67 num_samples 500 loss 0.014555530027988537\n",
      "Epoch 67 num_samples 600 loss 0.01481337971858563\n",
      "Epoch 67 num_samples 700 loss 0.015642447810456893\n",
      "Epoch 67 num_samples 800 loss 0.009311657309930608\n",
      "Epoch 67 num_samples 900 loss 0.0163417355619331\n",
      "Epoch 67 num_samples 1000 loss 0.009816088618088848\n",
      "Epoch 67 num_samples 1100 loss 0.01629214431102736\n",
      "Epoch 67 num_samples 1200 loss 0.009669605170168736\n",
      "Epoch 67 num_samples 1300 loss 0.011441129861040747\n",
      "Epoch 67 num_samples 1400 loss 0.01174724995338448\n",
      "Epoch 67 num_samples 1500 loss 0.01447889615103709\n",
      "Epoch 67 num_samples 1600 loss 0.010132939535433547\n",
      "Epoch 67 num_samples 1700 loss 0.009827501779081196\n",
      "Epoch 67 num_samples 1800 loss 0.0095285654517397\n",
      "Epoch 67 num_samples 1900 loss 0.011467869841841918\n",
      "Epoch 67 num_samples 2000 loss 0.013414525492869762\n",
      "Epoch 67 num_samples 2100 loss 0.007142663886626741\n",
      "Epoch 67 num_samples 2200 loss 0.007953283267364544\n",
      "Epoch 67 num_samples 2300 loss 0.005406191854246857\n",
      "Epoch 67 num_samples 2400 loss 0.009032963075079838\n",
      "Epoch 67 num_samples 2500 loss 0.012237586430979061\n",
      "Epoch 67 num_samples 2600 loss 0.013159928393839086\n",
      "Epoch 67 num_samples 2700 loss 0.00914648118455969\n",
      "Epoch 67 num_samples 2800 loss 0.013257045307457123\n",
      "Epoch 67 num_samples 2900 loss 0.012095368477108237\n",
      "Epoch 67 num_samples 3000 loss 0.010109469602779546\n",
      "Epoch 67 num_samples 3100 loss 0.009542606987482893\n",
      "Epoch 67 num_samples 3200 loss 0.01755381360093412\n",
      "Epoch 67 num_samples 3300 loss 0.011254253345623546\n",
      "Epoch 67 num_samples 3400 loss 0.008785150244317336\n",
      "Epoch 67 num_samples 3500 loss 0.00902938034999054\n",
      "Epoch 67 num_samples 3600 loss 0.006635984825807517\n",
      "Epoch 67 num_samples 3700 loss 0.016055161435297283\n",
      "Epoch 67 num_samples 3800 loss 0.008936509191595911\n",
      "Epoch 67 num_samples 3900 loss 0.010862729918751573\n",
      "Epoch 67 num_samples 4000 loss 0.012174547282186476\n",
      "Epoch 67 num_samples 4100 loss 0.015717964402429032\n",
      "Epoch 67 num_samples 4200 loss 0.011141544100904644\n",
      "Epoch 67 num_samples 4300 loss 0.009941505896231755\n",
      "Epoch 67 num_samples 4400 loss 0.011630990701853498\n",
      "Epoch 67 num_samples 4500 loss 0.014101631878374876\n",
      "Epoch 67 num_samples 4600 loss 0.011961705439901184\n",
      "Epoch 67 num_samples 4700 loss 0.006914261932997423\n",
      "Epoch 67 num_samples 4800 loss 0.007212910495811386\n",
      "Epoch 67 num_samples 4900 loss 0.009133974017428112\n",
      "Epoch 67 num_samples 5000 loss 0.008098190693657832\n",
      "Epoch 67 num_samples 5100 loss 0.014431205308278754\n",
      "Epoch 67 num_samples 5200 loss 0.007173976253901211\n",
      "Epoch 67 num_samples 5300 loss 0.009654912141745029\n",
      "Epoch 67 num_samples 5400 loss 0.01332055855801732\n",
      "Epoch 67 num_samples 5500 loss 0.007893774251480152\n",
      "Epoch 67 num_samples 5600 loss 0.02887256910251698\n",
      "Epoch 67 num_samples 5700 loss 0.010708321540212958\n",
      "Epoch 67 num_samples 5800 loss 0.010115552506381614\n",
      "Epoch 67 num_samples 5900 loss 0.013010347875702212\n",
      "Epoch 67 num_samples 6000 loss 0.010464677730323968\n",
      "Epoch 67 num_samples 6100 loss 0.00963579678996361\n",
      "Epoch 67 num_samples 6200 loss 0.011210573268641338\n",
      "Epoch 67 num_samples 6300 loss 0.014130891161713524\n",
      "Epoch 67 num_samples 6400 loss 0.008784720647704171\n",
      "Epoch 67 num_samples 6500 loss 0.007747446402934668\n",
      "Epoch 67 num_samples 6600 loss 0.017670386973249214\n",
      "Epoch 67 num_samples 6700 loss 0.008840870068367453\n",
      "Epoch 67 num_samples 6800 loss 0.005793450853978056\n",
      "Epoch 67 num_samples 6900 loss 0.021850109168733294\n",
      "Epoch 67 num_samples 7000 loss 0.013016861204360148\n",
      "Epoch 67 num_samples 7100 loss 0.007214969762261838\n",
      "Epoch 67 num_samples 7200 loss 0.010385932115457503\n",
      "Epoch 67 num_samples 7300 loss 0.010279919249035853\n",
      "Epoch 67 num_samples 7400 loss 0.007648021758429268\n",
      "Epoch 67 num_samples 7500 loss 0.016692911504297955\n",
      "Epoch 67 num_samples 7600 loss 0.010882210108749285\n",
      "Epoch 67 num_samples 7700 loss 0.015049943829687046\n",
      "Epoch 67 num_samples 7800 loss 0.008970784881833845\n",
      "Epoch 67 num_samples 7900 loss 0.01102095764918403\n",
      "Epoch 67 num_samples 8000 loss 0.007344759827373048\n",
      "Epoch 67 num_samples 8100 loss 0.009868165224264279\n",
      "Epoch 67 num_samples 8200 loss 0.01140327013892353\n",
      "Epoch 67 num_samples 8300 loss 0.008959690110217742\n",
      "Epoch 67 num_samples 8400 loss 0.007396087723118296\n",
      "Epoch 67 num_samples 8500 loss 0.010763425444991967\n",
      "Epoch 67 num_samples 8600 loss 0.010810034075202654\n",
      "Epoch 67 num_samples 8700 loss 0.010632949488575434\n",
      "Epoch 67 num_samples 8800 loss 0.010569624013804284\n",
      "Epoch 67 num_samples 8900 loss 0.012767998095616639\n",
      "Epoch 67 num_samples 9000 loss 0.010601403096497814\n",
      "Epoch 67 num_samples 9100 loss 0.010387290863107069\n",
      "Epoch 67 num_samples 9200 loss 0.011027300911315978\n",
      "Epoch 67 num_samples 9300 loss 0.01070988577907262\n",
      "Epoch 67 num_samples 9400 loss 0.009076925773373365\n",
      "Epoch 67 num_samples 9500 loss 0.008975933473274491\n",
      "Epoch 67 num_samples 9600 loss 0.00965116931783438\n",
      "Epoch 67 num_samples 9700 loss 0.015437927419162447\n",
      "Epoch 67 num_samples 9800 loss 0.006528684416785836\n",
      "Epoch 67 num_samples 9900 loss 0.01958382862549961\n",
      "Epoch 67 num_samples 10000 loss 0.00904406006741809\n",
      "Epoch 67 num_samples 10100 loss 0.008218197650150437\n",
      "Epoch 67 num_samples 10200 loss 0.012821146875410765\n",
      "Epoch 67 num_samples 10300 loss 0.010201708024614495\n",
      "Epoch 67 num_samples 10400 loss 0.013529590560659912\n",
      "Epoch 67 num_samples 10500 loss 0.00941474774455257\n",
      "Epoch 67 num_samples 10600 loss 0.012202700297238231\n",
      "Epoch 67 num_samples 10700 loss 0.0094587489047123\n",
      "Epoch 67 num_samples 10800 loss 0.012055452379885772\n",
      "Epoch 67 num_samples 10900 loss 0.008952819476115554\n",
      "Epoch 67 num_samples 11000 loss 0.008194936935916344\n",
      "Epoch 67 num_samples 11100 loss 0.01084130852079535\n",
      "Epoch 67 num_samples 11200 loss 0.008552558850954744\n",
      "Epoch 67 num_samples 11300 loss 0.014356911168712502\n",
      "Epoch 67 num_samples 11400 loss 0.009816212108980987\n",
      "Epoch 67 num_samples 11500 loss 0.00948953857596835\n",
      "Epoch 67 num_samples 11600 loss 0.009149230568723438\n",
      "Epoch 67 num_samples 11700 loss 0.012772906752966677\n",
      "Epoch 67 num_samples 11800 loss 0.009200032872255563\n",
      "Epoch 67 num_samples 11900 loss 0.00810023390238509\n",
      "Epoch 67 num_samples 12000 loss 0.007123910345046045\n",
      "Epoch 67 num_samples 12100 loss 0.0080293507596289\n",
      "Epoch 67 num_samples 12200 loss 0.011853266641149846\n",
      "Epoch 67 num_samples 12300 loss 0.008122889716559088\n",
      "Epoch 67 num_samples 12400 loss 0.013028424133285452\n",
      "Epoch 67 num_samples 12500 loss 0.011494631564177616\n",
      "Epoch 67 num_samples 12600 loss 0.014115991602312828\n",
      "Epoch 67 num_samples 12700 loss 0.01053452732047167\n",
      "Epoch 67 num_samples 12800 loss 0.016751637308677587\n",
      "Epoch 67 num_samples 12900 loss 0.009166606752329463\n",
      "Epoch 67 num_samples 13000 loss 0.008524005991946944\n",
      "Epoch 67 num_samples 13100 loss 0.013988892708012703\n",
      "Epoch 67 num_samples 13200 loss 0.005987362239535014\n",
      "Epoch 67 num_samples 13300 loss 0.008036174625076706\n",
      "Epoch 67 num_samples 13400 loss 0.005413285342602072\n",
      "Epoch 67 num_samples 13500 loss 0.007681146725502253\n",
      "Epoch 67 num_samples 13600 loss 0.01367873945899888\n",
      "Epoch 67 num_samples 13700 loss 0.010107597486002878\n",
      "Epoch 67 num_samples 13800 loss 0.009413405422679762\n",
      "Epoch 67 num_samples 13900 loss 0.004052761673455141\n",
      "Epoch 67 num_samples 14000 loss 0.007057810905140178\n",
      "Epoch 67 num_samples 14100 loss 0.00934760936264808\n",
      "Epoch 67 num_samples 14200 loss 0.008229943016223477\n",
      "Epoch 67 num_samples 14300 loss 0.011073240342770654\n",
      "Epoch 67 num_samples 14400 loss 0.011354521485520519\n",
      "Epoch 67 num_samples 14500 loss 0.013510062974108807\n",
      "Epoch 67 num_samples 14600 loss 0.00981750523318834\n",
      "Epoch 67 num_samples 14700 loss 0.01022027703700123\n",
      "Epoch 67 num_samples 14800 loss 0.009686570896670127\n",
      "Epoch 67 num_samples 14900 loss 0.011535046515862613\n",
      "Epoch 67 num_samples 15000 loss 0.009526021837290287\n",
      "Epoch 67 num_samples 15100 loss 0.010690927324508628\n",
      "Epoch 67 num_samples 15200 loss 0.010779884070684967\n",
      "Epoch 67 num_samples 15300 loss 0.011084406713192935\n",
      "Epoch 67 num_samples 15400 loss 0.0075053819395139686\n",
      "Epoch 67 num_samples 15500 loss 0.010832257766311271\n",
      "Epoch 67 num_samples 15600 loss 0.011245945298493853\n",
      "Epoch 67 num_samples 15700 loss 0.007364699291776161\n",
      "Epoch 67 num_samples 15800 loss 0.01260967331696084\n",
      "Epoch 67 num_samples 15900 loss 0.007839248755869964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 num_samples 16000 loss 0.014836341357815717\n",
      "Epoch 67 num_samples 16100 loss 0.0076801247800923214\n",
      "Epoch 67 num_samples 16200 loss 0.011776180766984551\n",
      "Epoch 67 num_samples 16300 loss 0.013724466061606344\n",
      "Epoch 67 num_samples 16400 loss 0.013863058600019356\n",
      "Epoch 67 num_samples 16500 loss 0.01204665676178791\n",
      "Epoch 67 num_samples 16600 loss 0.012997658172950937\n",
      "Epoch 67 num_samples 16700 loss 0.007237916673296034\n",
      "Epoch 67 num_samples 16800 loss 0.007281486330599488\n",
      "Epoch 67 num_samples 16900 loss 0.008666677366737848\n",
      "Epoch 67 num_samples 17000 loss 0.006584586466468703\n",
      "Epoch 67 num_samples 17100 loss 0.016931085981792195\n",
      "Epoch 67 num_samples 17200 loss 0.011684811357768355\n",
      "Epoch 67 num_samples 17300 loss 0.011936541212410333\n",
      "Epoch 67 num_samples 17400 loss 0.010443967290841993\n",
      "Epoch 67 num_samples 17500 loss 0.010547638150905685\n",
      "Epoch 67 num_samples 17600 loss 0.009598732855615267\n",
      "Epoch 67 num_samples 17700 loss 0.007945604610569772\n",
      "Epoch 67 num_samples 17800 loss 0.008662996971428083\n",
      "Epoch 67 num_samples 17900 loss 0.013474359107103791\n",
      "Epoch 67 num_samples 18000 loss 0.009537795668771339\n",
      "Epoch 67 num_samples 18100 loss 0.010589214372234782\n",
      "Epoch 67 num_samples 18200 loss 0.011203576998695968\n",
      "Epoch 67 num_samples 18300 loss 0.008330472930708979\n",
      "Epoch 67 num_samples 18400 loss 0.01613283945906829\n",
      "Epoch 67 num_samples 18500 loss 0.011342094717050345\n",
      "Epoch 68 num_samples 0 loss 0.007814816783459294\n",
      "Epoch 68 num_samples 100 loss 0.014061895250462746\n",
      "Epoch 68 num_samples 200 loss 0.009319227311260482\n",
      "Epoch 68 num_samples 300 loss 0.00796064470035981\n",
      "Epoch 68 num_samples 400 loss 0.009425915810749192\n",
      "Epoch 68 num_samples 500 loss 0.014193489056978828\n",
      "Epoch 68 num_samples 600 loss 0.014445215700649739\n",
      "Epoch 68 num_samples 700 loss 0.015276271395755332\n",
      "Epoch 68 num_samples 800 loss 0.009033781682904096\n",
      "Epoch 68 num_samples 900 loss 0.01589163549255459\n",
      "Epoch 68 num_samples 1000 loss 0.009562007953056508\n",
      "Epoch 68 num_samples 1100 loss 0.015881824421502513\n",
      "Epoch 68 num_samples 1200 loss 0.009411820782408709\n",
      "Epoch 68 num_samples 1300 loss 0.011166711144983472\n",
      "Epoch 68 num_samples 1400 loss 0.011493147172480303\n",
      "Epoch 68 num_samples 1500 loss 0.014020426062035468\n",
      "Epoch 68 num_samples 1600 loss 0.009892271847020519\n",
      "Epoch 68 num_samples 1700 loss 0.009527934620028579\n",
      "Epoch 68 num_samples 1800 loss 0.009266066146974498\n",
      "Epoch 68 num_samples 1900 loss 0.011087391633781274\n",
      "Epoch 68 num_samples 2000 loss 0.013071337020051081\n",
      "Epoch 68 num_samples 2100 loss 0.006969441295729447\n",
      "Epoch 68 num_samples 2200 loss 0.007748786085957848\n",
      "Epoch 68 num_samples 2300 loss 0.005246340196649918\n",
      "Epoch 68 num_samples 2400 loss 0.008768357466553465\n",
      "Epoch 68 num_samples 2500 loss 0.011868714593099182\n",
      "Epoch 68 num_samples 2600 loss 0.012834140886507117\n",
      "Epoch 68 num_samples 2700 loss 0.008905793162460318\n",
      "Epoch 68 num_samples 2800 loss 0.012871307068046756\n",
      "Epoch 68 num_samples 2900 loss 0.011744057645509223\n",
      "Epoch 68 num_samples 3000 loss 0.009821624900469072\n",
      "Epoch 68 num_samples 3100 loss 0.009299836667801618\n",
      "Epoch 68 num_samples 3200 loss 0.01697857355455682\n",
      "Epoch 68 num_samples 3300 loss 0.01094134067242102\n",
      "Epoch 68 num_samples 3400 loss 0.00855671805769417\n",
      "Epoch 68 num_samples 3500 loss 0.008775764950371833\n",
      "Epoch 68 num_samples 3600 loss 0.006502339145887783\n",
      "Epoch 68 num_samples 3700 loss 0.015610751550298934\n",
      "Epoch 68 num_samples 3800 loss 0.008696841397282676\n",
      "Epoch 68 num_samples 3900 loss 0.010546956142213395\n",
      "Epoch 68 num_samples 4000 loss 0.011823117182304187\n",
      "Epoch 68 num_samples 4100 loss 0.015201176848951836\n",
      "Epoch 68 num_samples 4200 loss 0.01080085124704764\n",
      "Epoch 68 num_samples 4300 loss 0.009647921135119617\n",
      "Epoch 68 num_samples 4400 loss 0.011274952841078134\n",
      "Epoch 68 num_samples 4500 loss 0.013682172673014338\n",
      "Epoch 68 num_samples 4600 loss 0.011611214935117473\n",
      "Epoch 68 num_samples 4700 loss 0.006716008264546602\n",
      "Epoch 68 num_samples 4800 loss 0.007022588300307121\n",
      "Epoch 68 num_samples 4900 loss 0.008879258658918823\n",
      "Epoch 68 num_samples 5000 loss 0.007880347457872628\n",
      "Epoch 68 num_samples 5100 loss 0.014098773304680613\n",
      "Epoch 68 num_samples 5200 loss 0.006983738500117731\n",
      "Epoch 68 num_samples 5300 loss 0.009462126146671457\n",
      "Epoch 68 num_samples 5400 loss 0.012907516780359429\n",
      "Epoch 68 num_samples 5500 loss 0.007714728729403367\n",
      "Epoch 68 num_samples 5600 loss 0.02767253987817429\n",
      "Epoch 68 num_samples 5700 loss 0.010328422908800499\n",
      "Epoch 68 num_samples 5800 loss 0.009785110089793858\n",
      "Epoch 68 num_samples 5900 loss 0.012711298705896308\n",
      "Epoch 68 num_samples 6000 loss 0.010197380598791576\n",
      "Epoch 68 num_samples 6100 loss 0.00937095493553684\n",
      "Epoch 68 num_samples 6200 loss 0.010901301038954349\n",
      "Epoch 68 num_samples 6300 loss 0.01374464252886928\n",
      "Epoch 68 num_samples 6400 loss 0.008559786910520048\n",
      "Epoch 68 num_samples 6500 loss 0.00754240438281906\n",
      "Epoch 68 num_samples 6600 loss 0.017219201963626515\n",
      "Epoch 68 num_samples 6700 loss 0.008613724615990765\n",
      "Epoch 68 num_samples 6800 loss 0.005656474592787207\n",
      "Epoch 68 num_samples 6900 loss 0.021271349251748187\n",
      "Epoch 68 num_samples 7000 loss 0.012663390687652785\n",
      "Epoch 68 num_samples 7100 loss 0.007038315112730537\n",
      "Epoch 68 num_samples 7200 loss 0.010137487679675346\n",
      "Epoch 68 num_samples 7300 loss 0.010036320236821552\n",
      "Epoch 68 num_samples 7400 loss 0.007459008814418392\n",
      "Epoch 68 num_samples 7500 loss 0.016261643679919675\n",
      "Epoch 68 num_samples 7600 loss 0.010576142923663956\n",
      "Epoch 68 num_samples 7700 loss 0.014583368259633413\n",
      "Epoch 68 num_samples 7800 loss 0.008756426083826567\n",
      "Epoch 68 num_samples 7900 loss 0.010769853063092851\n",
      "Epoch 68 num_samples 8000 loss 0.007110262235237801\n",
      "Epoch 68 num_samples 8100 loss 0.009554460632459523\n",
      "Epoch 68 num_samples 8200 loss 0.011111670815237468\n",
      "Epoch 68 num_samples 8300 loss 0.008661752068125464\n",
      "Epoch 68 num_samples 8400 loss 0.007211885249828873\n",
      "Epoch 68 num_samples 8500 loss 0.010453021050215916\n",
      "Epoch 68 num_samples 8600 loss 0.010543385648672392\n",
      "Epoch 68 num_samples 8700 loss 0.010300601912507625\n",
      "Epoch 68 num_samples 8800 loss 0.010267832817965932\n",
      "Epoch 68 num_samples 8900 loss 0.012376836403014459\n",
      "Epoch 68 num_samples 9000 loss 0.01035488180489644\n",
      "Epoch 68 num_samples 9100 loss 0.010093719936712521\n",
      "Epoch 68 num_samples 9200 loss 0.01074050846459878\n",
      "Epoch 68 num_samples 9300 loss 0.010466941921164263\n",
      "Epoch 68 num_samples 9400 loss 0.008846291794198803\n",
      "Epoch 68 num_samples 9500 loss 0.008743212222316252\n",
      "Epoch 68 num_samples 9600 loss 0.009430249192625117\n",
      "Epoch 68 num_samples 9700 loss 0.01492135378576926\n",
      "Epoch 68 num_samples 9800 loss 0.006348823467064192\n",
      "Epoch 68 num_samples 9900 loss 0.0189019146325691\n",
      "Epoch 68 num_samples 10000 loss 0.008768208510751899\n",
      "Epoch 68 num_samples 10100 loss 0.007986699388348235\n",
      "Epoch 68 num_samples 10200 loss 0.012443045732740365\n",
      "Epoch 68 num_samples 10300 loss 0.009881158545832533\n",
      "Epoch 68 num_samples 10400 loss 0.013200585554147892\n",
      "Epoch 68 num_samples 10500 loss 0.009171253281562528\n",
      "Epoch 68 num_samples 10600 loss 0.011815436197972796\n",
      "Epoch 68 num_samples 10700 loss 0.009179933965983732\n",
      "Epoch 68 num_samples 10800 loss 0.011716133518097678\n",
      "Epoch 68 num_samples 10900 loss 0.008729944931777818\n",
      "Epoch 68 num_samples 11000 loss 0.0079946737525924\n",
      "Epoch 68 num_samples 11100 loss 0.010565049484088936\n",
      "Epoch 68 num_samples 11200 loss 0.008318864329601676\n",
      "Epoch 68 num_samples 11300 loss 0.013943686907377417\n",
      "Epoch 68 num_samples 11400 loss 0.009543833377953805\n",
      "Epoch 68 num_samples 11500 loss 0.00923573637130372\n",
      "Epoch 68 num_samples 11600 loss 0.008875201635595907\n",
      "Epoch 68 num_samples 11700 loss 0.012324603167786403\n",
      "Epoch 68 num_samples 11800 loss 0.00896579193165994\n",
      "Epoch 68 num_samples 11900 loss 0.007904692625160645\n",
      "Epoch 68 num_samples 12000 loss 0.006896441898160348\n",
      "Epoch 68 num_samples 12100 loss 0.007788277524350855\n",
      "Epoch 68 num_samples 12200 loss 0.011454168134878002\n",
      "Epoch 68 num_samples 12300 loss 0.007934699665695787\n",
      "Epoch 68 num_samples 12400 loss 0.012680246914381282\n",
      "Epoch 68 num_samples 12500 loss 0.011109036127080245\n",
      "Epoch 68 num_samples 12600 loss 0.013706508862112523\n",
      "Epoch 68 num_samples 12700 loss 0.010257646393643875\n",
      "Epoch 68 num_samples 12800 loss 0.01615699223115914\n",
      "Epoch 68 num_samples 12900 loss 0.008886725731233166\n",
      "Epoch 68 num_samples 13000 loss 0.008349478147105174\n",
      "Epoch 68 num_samples 13100 loss 0.013534183249573086\n",
      "Epoch 68 num_samples 13200 loss 0.005837049511143602\n",
      "Epoch 68 num_samples 13300 loss 0.007825943532948108\n",
      "Epoch 68 num_samples 13400 loss 0.005290717047865936\n",
      "Epoch 68 num_samples 13500 loss 0.007461912440767338\n",
      "Epoch 68 num_samples 13600 loss 0.013309127756287186\n",
      "Epoch 68 num_samples 13700 loss 0.009807407127851362\n",
      "Epoch 68 num_samples 13800 loss 0.00917298575061871\n",
      "Epoch 68 num_samples 13900 loss 0.003937366971736716\n",
      "Epoch 68 num_samples 14000 loss 0.006872836876588422\n",
      "Epoch 68 num_samples 14100 loss 0.009095650142026103\n",
      "Epoch 68 num_samples 14200 loss 0.008036012087188687\n",
      "Epoch 68 num_samples 14300 loss 0.010800399314616205\n",
      "Epoch 68 num_samples 14400 loss 0.011025047273291835\n",
      "Epoch 68 num_samples 14500 loss 0.01319426951379854\n",
      "Epoch 68 num_samples 14600 loss 0.009574693247449771\n",
      "Epoch 68 num_samples 14700 loss 0.009921135991029992\n",
      "Epoch 68 num_samples 14800 loss 0.009449655857938905\n",
      "Epoch 68 num_samples 14900 loss 0.011206381535269943\n",
      "Epoch 68 num_samples 15000 loss 0.009295285648918475\n",
      "Epoch 68 num_samples 15100 loss 0.010427506554806756\n",
      "Epoch 68 num_samples 15200 loss 0.010446436731356876\n",
      "Epoch 68 num_samples 15300 loss 0.010744535624516903\n",
      "Epoch 68 num_samples 15400 loss 0.007337046434531405\n",
      "Epoch 68 num_samples 15500 loss 0.01055371421052363\n",
      "Epoch 68 num_samples 15600 loss 0.010966875678369204\n",
      "Epoch 68 num_samples 15700 loss 0.007184528674022196\n",
      "Epoch 68 num_samples 15800 loss 0.01222827299920275\n",
      "Epoch 68 num_samples 15900 loss 0.007672597415481659\n",
      "Epoch 68 num_samples 16000 loss 0.014395160587891564\n",
      "Epoch 68 num_samples 16100 loss 0.00749500660056017\n",
      "Epoch 68 num_samples 16200 loss 0.011459831220187797\n",
      "Epoch 68 num_samples 16300 loss 0.01330182334804543\n",
      "Epoch 68 num_samples 16400 loss 0.013499625535021162\n",
      "Epoch 68 num_samples 16500 loss 0.011705002340486388\n",
      "Epoch 68 num_samples 16600 loss 0.012638161518383404\n",
      "Epoch 68 num_samples 16700 loss 0.007064620330712454\n",
      "Epoch 68 num_samples 16800 loss 0.007104095243191218\n",
      "Epoch 68 num_samples 16900 loss 0.008393295408975019\n",
      "Epoch 68 num_samples 17000 loss 0.006407480486273745\n",
      "Epoch 68 num_samples 17100 loss 0.016396115374825687\n",
      "Epoch 68 num_samples 17200 loss 0.011385780174637454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 num_samples 17300 loss 0.011562306006353567\n",
      "Epoch 68 num_samples 17400 loss 0.010130726607575954\n",
      "Epoch 68 num_samples 17500 loss 0.010292226578675423\n",
      "Epoch 68 num_samples 17600 loss 0.009332079860615159\n",
      "Epoch 68 num_samples 17700 loss 0.007748700618884656\n",
      "Epoch 68 num_samples 17800 loss 0.00844809627907214\n",
      "Epoch 68 num_samples 17900 loss 0.013128191488820445\n",
      "Epoch 68 num_samples 18000 loss 0.009288551120706532\n",
      "Epoch 68 num_samples 18100 loss 0.010279560556973526\n",
      "Epoch 68 num_samples 18200 loss 0.010941863545671154\n",
      "Epoch 68 num_samples 18300 loss 0.008158149760450484\n",
      "Epoch 68 num_samples 18400 loss 0.015707614867219836\n",
      "Epoch 68 num_samples 18500 loss 0.011091826094552415\n",
      "Epoch 69 num_samples 0 loss 0.007580094885832432\n",
      "Epoch 69 num_samples 100 loss 0.013708990021043288\n",
      "Epoch 69 num_samples 200 loss 0.009077673322946966\n",
      "Epoch 69 num_samples 300 loss 0.00776592006486554\n",
      "Epoch 69 num_samples 400 loss 0.0091801980987036\n",
      "Epoch 69 num_samples 500 loss 0.013830257576823187\n",
      "Epoch 69 num_samples 600 loss 0.013936220901222035\n",
      "Epoch 69 num_samples 700 loss 0.014834729424140039\n",
      "Epoch 69 num_samples 800 loss 0.00877339625807414\n",
      "Epoch 69 num_samples 900 loss 0.015430237191283527\n",
      "Epoch 69 num_samples 1000 loss 0.009321792112241\n",
      "Epoch 69 num_samples 1100 loss 0.015458724908820587\n",
      "Epoch 69 num_samples 1200 loss 0.009194684488179812\n",
      "Epoch 69 num_samples 1300 loss 0.010902636791572684\n",
      "Epoch 69 num_samples 1400 loss 0.011145878750543443\n",
      "Epoch 69 num_samples 1500 loss 0.013653995885491137\n",
      "Epoch 69 num_samples 1600 loss 0.009608347048252409\n",
      "Epoch 69 num_samples 1700 loss 0.009277934817925637\n",
      "Epoch 69 num_samples 1800 loss 0.009043502309308452\n",
      "Epoch 69 num_samples 1900 loss 0.010817399167008161\n",
      "Epoch 69 num_samples 2000 loss 0.01274387812265886\n",
      "Epoch 69 num_samples 2100 loss 0.006785601177149611\n",
      "Epoch 69 num_samples 2200 loss 0.007565896190059119\n",
      "Epoch 69 num_samples 2300 loss 0.005101014579160575\n",
      "Epoch 69 num_samples 2400 loss 0.008546388469622494\n",
      "Epoch 69 num_samples 2500 loss 0.011545183618871453\n",
      "Epoch 69 num_samples 2600 loss 0.012501870917483565\n",
      "Epoch 69 num_samples 2700 loss 0.00869447938505076\n",
      "Epoch 69 num_samples 2800 loss 0.012465838896675971\n",
      "Epoch 69 num_samples 2900 loss 0.01142318393628628\n",
      "Epoch 69 num_samples 3000 loss 0.009566907317537636\n",
      "Epoch 69 num_samples 3100 loss 0.00909305340617172\n",
      "Epoch 69 num_samples 3200 loss 0.016409429537405217\n",
      "Epoch 69 num_samples 3300 loss 0.01054879047506111\n",
      "Epoch 69 num_samples 3400 loss 0.00833289626642751\n",
      "Epoch 69 num_samples 3500 loss 0.008601250097523916\n",
      "Epoch 69 num_samples 3600 loss 0.006333051051991196\n",
      "Epoch 69 num_samples 3700 loss 0.01514798868096783\n",
      "Epoch 69 num_samples 3800 loss 0.008453726460730102\n",
      "Epoch 69 num_samples 3900 loss 0.010245605568866842\n",
      "Epoch 69 num_samples 4000 loss 0.011431783514505696\n",
      "Epoch 69 num_samples 4100 loss 0.014724041002445915\n",
      "Epoch 69 num_samples 4200 loss 0.010555511951666065\n",
      "Epoch 69 num_samples 4300 loss 0.009429125810334782\n",
      "Epoch 69 num_samples 4400 loss 0.010973655872611725\n",
      "Epoch 69 num_samples 4500 loss 0.013234698029250447\n",
      "Epoch 69 num_samples 4600 loss 0.011372548526098099\n",
      "Epoch 69 num_samples 4700 loss 0.006503680483818228\n",
      "Epoch 69 num_samples 4800 loss 0.006833732738087131\n",
      "Epoch 69 num_samples 4900 loss 0.008659651335444224\n",
      "Epoch 69 num_samples 5000 loss 0.007663504154129579\n",
      "Epoch 69 num_samples 5100 loss 0.013779596285338362\n",
      "Epoch 69 num_samples 5200 loss 0.006778100651300551\n",
      "Epoch 69 num_samples 5300 loss 0.009190659942930281\n",
      "Epoch 69 num_samples 5400 loss 0.012691106423826244\n",
      "Epoch 69 num_samples 5500 loss 0.00750238015968441\n",
      "Epoch 69 num_samples 5600 loss 0.026791344573206723\n",
      "Epoch 69 num_samples 5700 loss 0.010012676880631899\n",
      "Epoch 69 num_samples 5800 loss 0.00959324075342361\n",
      "Epoch 69 num_samples 5900 loss 0.012350752086840824\n",
      "Epoch 69 num_samples 6000 loss 0.009901328087690708\n",
      "Epoch 69 num_samples 6100 loss 0.009115682620121399\n",
      "Epoch 69 num_samples 6200 loss 0.010572927040344644\n",
      "Epoch 69 num_samples 6300 loss 0.01329791824042471\n",
      "Epoch 69 num_samples 6400 loss 0.008327747055115664\n",
      "Epoch 69 num_samples 6500 loss 0.007325807964908406\n",
      "Epoch 69 num_samples 6600 loss 0.016822071546420677\n",
      "Epoch 69 num_samples 6700 loss 0.008413583235175182\n",
      "Epoch 69 num_samples 6800 loss 0.005525529228194721\n",
      "Epoch 69 num_samples 6900 loss 0.020722288335382418\n",
      "Epoch 69 num_samples 7000 loss 0.012301065070298578\n",
      "Epoch 69 num_samples 7100 loss 0.006840219459161076\n",
      "Epoch 69 num_samples 7200 loss 0.009824869690751298\n",
      "Epoch 69 num_samples 7300 loss 0.009822276428346256\n",
      "Epoch 69 num_samples 7400 loss 0.0072984329854504405\n",
      "Epoch 69 num_samples 7500 loss 0.015775504504690716\n",
      "Epoch 69 num_samples 7600 loss 0.010323697603686859\n",
      "Epoch 69 num_samples 7700 loss 0.014197863686095168\n",
      "Epoch 69 num_samples 7800 loss 0.008521659740953822\n",
      "Epoch 69 num_samples 7900 loss 0.01049887802866169\n",
      "Epoch 69 num_samples 8000 loss 0.00694512129923354\n",
      "Epoch 69 num_samples 8100 loss 0.009340497060257335\n",
      "Epoch 69 num_samples 8200 loss 0.010793513076912177\n",
      "Epoch 69 num_samples 8300 loss 0.008389864582718355\n",
      "Epoch 69 num_samples 8400 loss 0.006961328229294981\n",
      "Epoch 69 num_samples 8500 loss 0.010082671206704787\n",
      "Epoch 69 num_samples 8600 loss 0.010221126212116665\n",
      "Epoch 69 num_samples 8700 loss 0.010023644095140085\n",
      "Epoch 69 num_samples 8800 loss 0.009996841401481\n",
      "Epoch 69 num_samples 8900 loss 0.012080447764028128\n",
      "Epoch 69 num_samples 9000 loss 0.01004500508915365\n",
      "Epoch 69 num_samples 9100 loss 0.009788970790419477\n",
      "Epoch 69 num_samples 9200 loss 0.010374029326864305\n",
      "Epoch 69 num_samples 9300 loss 0.010200091110789558\n",
      "Epoch 69 num_samples 9400 loss 0.008571776856137534\n",
      "Epoch 69 num_samples 9500 loss 0.00850459757497826\n",
      "Epoch 69 num_samples 9600 loss 0.009227472461015662\n",
      "Epoch 69 num_samples 9700 loss 0.014476801866835955\n",
      "Epoch 69 num_samples 9800 loss 0.006160431485178519\n",
      "Epoch 69 num_samples 9900 loss 0.0184263441076435\n",
      "Epoch 69 num_samples 10000 loss 0.008487410402870847\n",
      "Epoch 69 num_samples 10100 loss 0.0077543375314542825\n",
      "Epoch 69 num_samples 10200 loss 0.012131859168205684\n",
      "Epoch 69 num_samples 10300 loss 0.009609139810784713\n",
      "Epoch 69 num_samples 10400 loss 0.0127908225907834\n",
      "Epoch 69 num_samples 10500 loss 0.008959583597694892\n",
      "Epoch 69 num_samples 10600 loss 0.011515597129865846\n",
      "Epoch 69 num_samples 10700 loss 0.008909884793917976\n",
      "Epoch 69 num_samples 10800 loss 0.011426412053760621\n",
      "Epoch 69 num_samples 10900 loss 0.008482208676267988\n",
      "Epoch 69 num_samples 11000 loss 0.007792412808973577\n",
      "Epoch 69 num_samples 11100 loss 0.01034203664170174\n",
      "Epoch 69 num_samples 11200 loss 0.008135367739228551\n",
      "Epoch 69 num_samples 11300 loss 0.013538291661586021\n",
      "Epoch 69 num_samples 11400 loss 0.00926361116384723\n",
      "Epoch 69 num_samples 11500 loss 0.008997526684577543\n",
      "Epoch 69 num_samples 11600 loss 0.008645353038270636\n",
      "Epoch 69 num_samples 11700 loss 0.012025306705174701\n",
      "Epoch 69 num_samples 11800 loss 0.008723605574607718\n",
      "Epoch 69 num_samples 11900 loss 0.007682781600515887\n",
      "Epoch 69 num_samples 12000 loss 0.0067375384029818046\n",
      "Epoch 69 num_samples 12100 loss 0.007526537805940301\n",
      "Epoch 69 num_samples 12200 loss 0.011171928079923813\n",
      "Epoch 69 num_samples 12300 loss 0.007720410453324607\n",
      "Epoch 69 num_samples 12400 loss 0.012334050782174834\n",
      "Epoch 69 num_samples 12500 loss 0.010827003741732373\n",
      "Epoch 69 num_samples 12600 loss 0.013306902321276442\n",
      "Epoch 69 num_samples 12700 loss 0.00997004692921814\n",
      "Epoch 69 num_samples 12800 loss 0.015688702885778665\n",
      "Epoch 69 num_samples 12900 loss 0.008677649860775623\n",
      "Epoch 69 num_samples 13000 loss 0.008116987720975636\n",
      "Epoch 69 num_samples 13100 loss 0.013153653636846542\n",
      "Epoch 69 num_samples 13200 loss 0.005686042023631872\n",
      "Epoch 69 num_samples 13300 loss 0.0076622119182549065\n",
      "Epoch 69 num_samples 13400 loss 0.005176561267495176\n",
      "Epoch 69 num_samples 13500 loss 0.007290054549027997\n",
      "Epoch 69 num_samples 13600 loss 0.013001379279450012\n",
      "Epoch 69 num_samples 13700 loss 0.009481980379722525\n",
      "Epoch 69 num_samples 13800 loss 0.008996433197727942\n",
      "Epoch 69 num_samples 13900 loss 0.0038447430540463064\n",
      "Epoch 69 num_samples 14000 loss 0.006690002655414326\n",
      "Epoch 69 num_samples 14100 loss 0.008858080173663949\n",
      "Epoch 69 num_samples 14200 loss 0.007811002611194416\n",
      "Epoch 69 num_samples 14300 loss 0.010516979964028266\n",
      "Epoch 69 num_samples 14400 loss 0.01074028792657197\n",
      "Epoch 69 num_samples 14500 loss 0.012879639965370423\n",
      "Epoch 69 num_samples 14600 loss 0.009270586697645638\n",
      "Epoch 69 num_samples 14700 loss 0.009689103586700666\n",
      "Epoch 69 num_samples 14800 loss 0.00919892469828913\n",
      "Epoch 69 num_samples 14900 loss 0.010890161984797388\n",
      "Epoch 69 num_samples 15000 loss 0.009053330184084078\n",
      "Epoch 69 num_samples 15100 loss 0.01020501090598624\n",
      "Epoch 69 num_samples 15200 loss 0.010133808849654577\n",
      "Epoch 69 num_samples 15300 loss 0.01048270954082445\n",
      "Epoch 69 num_samples 15400 loss 0.007172705106132028\n",
      "Epoch 69 num_samples 15500 loss 0.010185947637607311\n",
      "Epoch 69 num_samples 15600 loss 0.01066852359986447\n",
      "Epoch 69 num_samples 15700 loss 0.006993511805860442\n",
      "Epoch 69 num_samples 15800 loss 0.011855438251449666\n",
      "Epoch 69 num_samples 15900 loss 0.0074827517582590165\n",
      "Epoch 69 num_samples 16000 loss 0.014119197365439318\n",
      "Epoch 69 num_samples 16100 loss 0.007302472173853625\n",
      "Epoch 69 num_samples 16200 loss 0.01113096574168014\n",
      "Epoch 69 num_samples 16300 loss 0.012945425785204256\n",
      "Epoch 69 num_samples 16400 loss 0.013132997301521822\n",
      "Epoch 69 num_samples 16500 loss 0.011339884807833432\n",
      "Epoch 69 num_samples 16600 loss 0.012343718992390644\n",
      "Epoch 69 num_samples 16700 loss 0.006892196490106168\n",
      "Epoch 69 num_samples 16800 loss 0.006943729927138788\n",
      "Epoch 69 num_samples 16900 loss 0.008154021988208257\n",
      "Epoch 69 num_samples 17000 loss 0.006260609734841966\n",
      "Epoch 69 num_samples 17100 loss 0.015900592301759886\n",
      "Epoch 69 num_samples 17200 loss 0.011077508229930836\n",
      "Epoch 69 num_samples 17300 loss 0.011272336784622517\n",
      "Epoch 69 num_samples 17400 loss 0.009834596775374637\n",
      "Epoch 69 num_samples 17500 loss 0.010032312107327562\n",
      "Epoch 69 num_samples 17600 loss 0.00906486930386988\n",
      "Epoch 69 num_samples 17700 loss 0.00753516911944773\n",
      "Epoch 69 num_samples 17800 loss 0.00821304299207369\n",
      "Epoch 69 num_samples 17900 loss 0.012768498280326139\n",
      "Epoch 69 num_samples 18000 loss 0.009076623900683593\n",
      "Epoch 69 num_samples 18100 loss 0.010019155870662816\n",
      "Epoch 69 num_samples 18200 loss 0.010624008820132327\n",
      "Epoch 69 num_samples 18300 loss 0.00788568254948143\n",
      "Epoch 69 num_samples 18400 loss 0.015258553376063728\n",
      "Epoch 69 num_samples 18500 loss 0.010828422199634763\n",
      "Epoch 70 num_samples 0 loss 0.007444218619697043\n",
      "Epoch 70 num_samples 100 loss 0.01334948376360289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 num_samples 200 loss 0.008831495135959308\n",
      "Epoch 70 num_samples 300 loss 0.00756201250362583\n",
      "Epoch 70 num_samples 400 loss 0.008956312223787323\n",
      "Epoch 70 num_samples 500 loss 0.013543802729552206\n",
      "Epoch 70 num_samples 600 loss 0.01359765400010715\n",
      "Epoch 70 num_samples 700 loss 0.014462429969863116\n",
      "Epoch 70 num_samples 800 loss 0.00851070459562026\n",
      "Epoch 70 num_samples 900 loss 0.01510847863033069\n",
      "Epoch 70 num_samples 1000 loss 0.009069217661112551\n",
      "Epoch 70 num_samples 1100 loss 0.015070487776678718\n",
      "Epoch 70 num_samples 1200 loss 0.008932731976859032\n",
      "Epoch 70 num_samples 1300 loss 0.010603788412071975\n",
      "Epoch 70 num_samples 1400 loss 0.010763540199894535\n",
      "Epoch 70 num_samples 1500 loss 0.013123037730081243\n",
      "Epoch 70 num_samples 1600 loss 0.0093429852065873\n",
      "Epoch 70 num_samples 1700 loss 0.009070275462660947\n",
      "Epoch 70 num_samples 1800 loss 0.0088183760142831\n",
      "Epoch 70 num_samples 1900 loss 0.010543889878694009\n",
      "Epoch 70 num_samples 2000 loss 0.012424531320646531\n",
      "Epoch 70 num_samples 2100 loss 0.006587875298133724\n",
      "Epoch 70 num_samples 2200 loss 0.007343863687472885\n",
      "Epoch 70 num_samples 2300 loss 0.004969323630438148\n",
      "Epoch 70 num_samples 2400 loss 0.008285736650732812\n",
      "Epoch 70 num_samples 2500 loss 0.011220514774561612\n",
      "Epoch 70 num_samples 2600 loss 0.01213512632909325\n",
      "Epoch 70 num_samples 2700 loss 0.008469876253278295\n",
      "Epoch 70 num_samples 2800 loss 0.012140263263337926\n",
      "Epoch 70 num_samples 2900 loss 0.011094758559351992\n",
      "Epoch 70 num_samples 3000 loss 0.009312639904614346\n",
      "Epoch 70 num_samples 3100 loss 0.00888918763562319\n",
      "Epoch 70 num_samples 3200 loss 0.015916500551918136\n",
      "Epoch 70 num_samples 3300 loss 0.010282347111408914\n",
      "Epoch 70 num_samples 3400 loss 0.00809538167712808\n",
      "Epoch 70 num_samples 3500 loss 0.00835147608914695\n",
      "Epoch 70 num_samples 3600 loss 0.006220102145966009\n",
      "Epoch 70 num_samples 3700 loss 0.014774052021070117\n",
      "Epoch 70 num_samples 3800 loss 0.008178409547953552\n",
      "Epoch 70 num_samples 3900 loss 0.01000640224372302\n",
      "Epoch 70 num_samples 4000 loss 0.011133823744003062\n",
      "Epoch 70 num_samples 4100 loss 0.014290707783534577\n",
      "Epoch 70 num_samples 4200 loss 0.01028800439114173\n",
      "Epoch 70 num_samples 4300 loss 0.00915822526366869\n",
      "Epoch 70 num_samples 4400 loss 0.010642947519575237\n",
      "Epoch 70 num_samples 4500 loss 0.0129453326631835\n",
      "Epoch 70 num_samples 4600 loss 0.011019861637189085\n",
      "Epoch 70 num_samples 4700 loss 0.006368754324961197\n",
      "Epoch 70 num_samples 4800 loss 0.006682128682657381\n",
      "Epoch 70 num_samples 4900 loss 0.008460259477353299\n",
      "Epoch 70 num_samples 5000 loss 0.007485269250370821\n",
      "Epoch 70 num_samples 5100 loss 0.013369965594561\n",
      "Epoch 70 num_samples 5200 loss 0.006595066458751475\n",
      "Epoch 70 num_samples 5300 loss 0.008996143003600464\n",
      "Epoch 70 num_samples 5400 loss 0.012343588834668955\n",
      "Epoch 70 num_samples 5500 loss 0.0073391688609285985\n",
      "Epoch 70 num_samples 5600 loss 0.025858365155606328\n",
      "Epoch 70 num_samples 5700 loss 0.009810099121329161\n",
      "Epoch 70 num_samples 5800 loss 0.009303229824803467\n",
      "Epoch 70 num_samples 5900 loss 0.011993941318282608\n",
      "Epoch 70 num_samples 6000 loss 0.00967288805661507\n",
      "Epoch 70 num_samples 6100 loss 0.008880018417644296\n",
      "Epoch 70 num_samples 6200 loss 0.01031771507530172\n",
      "Epoch 70 num_samples 6300 loss 0.012907093894921996\n",
      "Epoch 70 num_samples 6400 loss 0.00811340528449765\n",
      "Epoch 70 num_samples 6500 loss 0.007131380726497209\n",
      "Epoch 70 num_samples 6600 loss 0.01636979521774041\n",
      "Epoch 70 num_samples 6700 loss 0.008189468539817826\n",
      "Epoch 70 num_samples 6800 loss 0.005371894761469407\n",
      "Epoch 70 num_samples 6900 loss 0.020155663465003817\n",
      "Epoch 70 num_samples 7000 loss 0.011986416007166038\n",
      "Epoch 70 num_samples 7100 loss 0.006692754288632421\n",
      "Epoch 70 num_samples 7200 loss 0.009583333457939738\n",
      "Epoch 70 num_samples 7300 loss 0.009588350517151177\n",
      "Epoch 70 num_samples 7400 loss 0.007116868581483276\n",
      "Epoch 70 num_samples 7500 loss 0.015303340343917747\n",
      "Epoch 70 num_samples 7600 loss 0.010035178544930695\n",
      "Epoch 70 num_samples 7700 loss 0.013764909150912193\n",
      "Epoch 70 num_samples 7800 loss 0.008344774362651783\n",
      "Epoch 70 num_samples 7900 loss 0.010232376998361856\n",
      "Epoch 70 num_samples 8000 loss 0.006773930420167083\n",
      "Epoch 70 num_samples 8100 loss 0.009040218822529138\n",
      "Epoch 70 num_samples 8200 loss 0.010516119741451906\n",
      "Epoch 70 num_samples 8300 loss 0.008218052072802486\n",
      "Epoch 70 num_samples 8400 loss 0.0067956006923748195\n",
      "Epoch 70 num_samples 8500 loss 0.00994041329353391\n",
      "Epoch 70 num_samples 8600 loss 0.009989421275783006\n",
      "Epoch 70 num_samples 8700 loss 0.00981291256336096\n",
      "Epoch 70 num_samples 8800 loss 0.00971954061551307\n",
      "Epoch 70 num_samples 8900 loss 0.011723472550577247\n",
      "Epoch 70 num_samples 9000 loss 0.009822597725918314\n",
      "Epoch 70 num_samples 9100 loss 0.009538158590313513\n",
      "Epoch 70 num_samples 9200 loss 0.01023938811484955\n",
      "Epoch 70 num_samples 9300 loss 0.009910942258257048\n",
      "Epoch 70 num_samples 9400 loss 0.008401483375913767\n",
      "Epoch 70 num_samples 9500 loss 0.008288088022305599\n",
      "Epoch 70 num_samples 9600 loss 0.008958648016447931\n",
      "Epoch 70 num_samples 9700 loss 0.014072599039624895\n",
      "Epoch 70 num_samples 9800 loss 0.005999972367995852\n",
      "Epoch 70 num_samples 9900 loss 0.017968241974830667\n",
      "Epoch 70 num_samples 10000 loss 0.008312976849884841\n",
      "Epoch 70 num_samples 10100 loss 0.0075694372546622635\n",
      "Epoch 70 num_samples 10200 loss 0.011798625289464933\n",
      "Epoch 70 num_samples 10300 loss 0.009434407133895066\n",
      "Epoch 70 num_samples 10400 loss 0.012512917235042973\n",
      "Epoch 70 num_samples 10500 loss 0.008828712761115711\n",
      "Epoch 70 num_samples 10600 loss 0.011160227530744709\n",
      "Epoch 70 num_samples 10700 loss 0.00868405011618462\n",
      "Epoch 70 num_samples 10800 loss 0.011090860133621372\n",
      "Epoch 70 num_samples 10900 loss 0.008262773078309108\n",
      "Epoch 70 num_samples 11000 loss 0.00761169061942629\n",
      "Epoch 70 num_samples 11100 loss 0.010089848329605236\n",
      "Epoch 70 num_samples 11200 loss 0.007903439996014457\n",
      "Epoch 70 num_samples 11300 loss 0.013180260264534727\n",
      "Epoch 70 num_samples 11400 loss 0.009047615224166247\n",
      "Epoch 70 num_samples 11500 loss 0.008723145161146395\n",
      "Epoch 70 num_samples 11600 loss 0.00845342265243312\n",
      "Epoch 70 num_samples 11700 loss 0.011691685657459221\n",
      "Epoch 70 num_samples 11800 loss 0.008497612742509921\n",
      "Epoch 70 num_samples 11900 loss 0.007455429909842749\n",
      "Epoch 70 num_samples 12000 loss 0.006564972028169893\n",
      "Epoch 70 num_samples 12100 loss 0.007361470688548225\n",
      "Epoch 70 num_samples 12200 loss 0.01081786514654139\n",
      "Epoch 70 num_samples 12300 loss 0.007546213964006783\n",
      "Epoch 70 num_samples 12400 loss 0.011998647685918693\n",
      "Epoch 70 num_samples 12500 loss 0.010528800169308163\n",
      "Epoch 70 num_samples 12600 loss 0.013004479225070002\n",
      "Epoch 70 num_samples 12700 loss 0.009678478182750389\n",
      "Epoch 70 num_samples 12800 loss 0.015187663346947091\n",
      "Epoch 70 num_samples 12900 loss 0.008447407458968485\n",
      "Epoch 70 num_samples 13000 loss 0.007911286854377532\n",
      "Epoch 70 num_samples 13100 loss 0.012798952951168811\n",
      "Epoch 70 num_samples 13200 loss 0.005509687040471143\n",
      "Epoch 70 num_samples 13300 loss 0.007452564479041135\n",
      "Epoch 70 num_samples 13400 loss 0.005035030273081883\n",
      "Epoch 70 num_samples 13500 loss 0.007065328447184427\n",
      "Epoch 70 num_samples 13600 loss 0.012607781064218428\n",
      "Epoch 70 num_samples 13700 loss 0.009248045604117254\n",
      "Epoch 70 num_samples 13800 loss 0.008774927849404777\n",
      "Epoch 70 num_samples 13900 loss 0.003740104811389111\n",
      "Epoch 70 num_samples 14000 loss 0.006509903361626992\n",
      "Epoch 70 num_samples 14100 loss 0.008642082827905951\n",
      "Epoch 70 num_samples 14200 loss 0.007672043449958639\n",
      "Epoch 70 num_samples 14300 loss 0.01030690360833909\n",
      "Epoch 70 num_samples 14400 loss 0.010469475634410346\n",
      "Epoch 70 num_samples 14500 loss 0.01256155616002764\n",
      "Epoch 70 num_samples 14600 loss 0.008963977521559505\n",
      "Epoch 70 num_samples 14700 loss 0.009443061217405447\n",
      "Epoch 70 num_samples 14800 loss 0.008977131370382713\n",
      "Epoch 70 num_samples 14900 loss 0.010643414751456755\n",
      "Epoch 70 num_samples 15000 loss 0.008848520965165347\n",
      "Epoch 70 num_samples 15100 loss 0.00993374815992274\n",
      "Epoch 70 num_samples 15200 loss 0.009873082529669147\n",
      "Epoch 70 num_samples 15300 loss 0.010210256239158088\n",
      "Epoch 70 num_samples 15400 loss 0.007041701063544408\n",
      "Epoch 70 num_samples 15500 loss 0.009922233928603176\n",
      "Epoch 70 num_samples 15600 loss 0.010380365602017631\n",
      "Epoch 70 num_samples 15700 loss 0.006821492287034206\n",
      "Epoch 70 num_samples 15800 loss 0.011535747390280085\n",
      "Epoch 70 num_samples 15900 loss 0.007297117802125767\n",
      "Epoch 70 num_samples 16000 loss 0.013710372998963908\n",
      "Epoch 70 num_samples 16100 loss 0.007136630867734315\n",
      "Epoch 70 num_samples 16200 loss 0.010887349374632338\n",
      "Epoch 70 num_samples 16300 loss 0.012567001781301919\n",
      "Epoch 70 num_samples 16400 loss 0.012811941541616826\n",
      "Epoch 70 num_samples 16500 loss 0.011048954193138734\n",
      "Epoch 70 num_samples 16600 loss 0.012038286792048068\n",
      "Epoch 70 num_samples 16700 loss 0.006704092520206361\n",
      "Epoch 70 num_samples 16800 loss 0.006763708933633261\n",
      "Epoch 70 num_samples 16900 loss 0.007968859515912651\n",
      "Epoch 70 num_samples 17000 loss 0.0061056710728373785\n",
      "Epoch 70 num_samples 17100 loss 0.015461287006385827\n",
      "Epoch 70 num_samples 17200 loss 0.010758438122114158\n",
      "Epoch 70 num_samples 17300 loss 0.01093497569950578\n",
      "Epoch 70 num_samples 17400 loss 0.009585330757657638\n",
      "Epoch 70 num_samples 17500 loss 0.00977230765119104\n",
      "Epoch 70 num_samples 17600 loss 0.008859612449325132\n",
      "Epoch 70 num_samples 17700 loss 0.007364447926950318\n",
      "Epoch 70 num_samples 17800 loss 0.007990931532905268\n",
      "Epoch 70 num_samples 17900 loss 0.01235789824777152\n",
      "Epoch 70 num_samples 18000 loss 0.008838552792222646\n",
      "Epoch 70 num_samples 18100 loss 0.009774905703304793\n",
      "Epoch 70 num_samples 18200 loss 0.010371135542659261\n",
      "Epoch 70 num_samples 18300 loss 0.00769665933814196\n",
      "Epoch 70 num_samples 18400 loss 0.014813233275583638\n",
      "Epoch 70 num_samples 18500 loss 0.010597081754962096\n",
      "Epoch 71 num_samples 0 loss 0.007265056528775293\n",
      "Epoch 71 num_samples 100 loss 0.013032421079464021\n",
      "Epoch 71 num_samples 200 loss 0.008634135651554466\n",
      "Epoch 71 num_samples 300 loss 0.007375213188290481\n",
      "Epoch 71 num_samples 400 loss 0.008716381754201292\n",
      "Epoch 71 num_samples 500 loss 0.013183057980808034\n",
      "Epoch 71 num_samples 600 loss 0.013175874319454725\n",
      "Epoch 71 num_samples 700 loss 0.014100632949426695\n",
      "Epoch 71 num_samples 800 loss 0.00830749702555273\n",
      "Epoch 71 num_samples 900 loss 0.014724275869135358\n",
      "Epoch 71 num_samples 1000 loss 0.008836276085901753\n",
      "Epoch 71 num_samples 1100 loss 0.014686237526484671\n",
      "Epoch 71 num_samples 1200 loss 0.008695803829085311\n",
      "Epoch 71 num_samples 1300 loss 0.01032801621325497\n",
      "Epoch 71 num_samples 1400 loss 0.010537836716761317\n",
      "Epoch 71 num_samples 1500 loss 0.012800627000655066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 num_samples 1600 loss 0.00915684529440144\n",
      "Epoch 71 num_samples 1700 loss 0.008799327702893494\n",
      "Epoch 71 num_samples 1800 loss 0.008597332428788457\n",
      "Epoch 71 num_samples 1900 loss 0.010273839921711474\n",
      "Epoch 71 num_samples 2000 loss 0.012175828342750581\n",
      "Epoch 71 num_samples 2100 loss 0.006428595552772075\n",
      "Epoch 71 num_samples 2200 loss 0.007191902788943296\n",
      "Epoch 71 num_samples 2300 loss 0.004851507639202823\n",
      "Epoch 71 num_samples 2400 loss 0.00807735474690261\n",
      "Epoch 71 num_samples 2500 loss 0.010900414355480415\n",
      "Epoch 71 num_samples 2600 loss 0.011847919043834775\n",
      "Epoch 71 num_samples 2700 loss 0.008251965813393497\n",
      "Epoch 71 num_samples 2800 loss 0.011778928922870564\n",
      "Epoch 71 num_samples 2900 loss 0.010833497858924162\n",
      "Epoch 71 num_samples 3000 loss 0.008992963402526612\n",
      "Epoch 71 num_samples 3100 loss 0.008679028693605418\n",
      "Epoch 71 num_samples 3200 loss 0.01536081134767735\n",
      "Epoch 71 num_samples 3300 loss 0.009877483784595641\n",
      "Epoch 71 num_samples 3400 loss 0.00790873130921193\n",
      "Epoch 71 num_samples 3500 loss 0.008152019408626986\n",
      "Epoch 71 num_samples 3600 loss 0.006065117389423674\n",
      "Epoch 71 num_samples 3700 loss 0.014352148632362222\n",
      "Epoch 71 num_samples 3800 loss 0.007969634277461543\n",
      "Epoch 71 num_samples 3900 loss 0.009738420115841787\n",
      "Epoch 71 num_samples 4000 loss 0.010835405545655102\n",
      "Epoch 71 num_samples 4100 loss 0.013827192665395267\n",
      "Epoch 71 num_samples 4200 loss 0.010100363091847373\n",
      "Epoch 71 num_samples 4300 loss 0.00895045660495603\n",
      "Epoch 71 num_samples 4400 loss 0.0103038726961571\n",
      "Epoch 71 num_samples 4500 loss 0.012559753856896543\n",
      "Epoch 71 num_samples 4600 loss 0.010748214360288387\n",
      "Epoch 71 num_samples 4700 loss 0.006220818803396797\n",
      "Epoch 71 num_samples 4800 loss 0.006513077061040557\n",
      "Epoch 71 num_samples 4900 loss 0.00824868485298048\n",
      "Epoch 71 num_samples 5000 loss 0.00729533216379324\n",
      "Epoch 71 num_samples 5100 loss 0.013110203801262266\n",
      "Epoch 71 num_samples 5200 loss 0.006424897540337091\n",
      "Epoch 71 num_samples 5300 loss 0.00873568111292141\n",
      "Epoch 71 num_samples 5400 loss 0.011989238338218624\n",
      "Epoch 71 num_samples 5500 loss 0.007169394208311018\n",
      "Epoch 71 num_samples 5600 loss 0.025062297059090244\n",
      "Epoch 71 num_samples 5700 loss 0.009460370741285896\n",
      "Epoch 71 num_samples 5800 loss 0.009054468528144583\n",
      "Epoch 71 num_samples 5900 loss 0.011685282426742492\n",
      "Epoch 71 num_samples 6000 loss 0.009421858037946405\n",
      "Epoch 71 num_samples 6100 loss 0.008664525928979039\n",
      "Epoch 71 num_samples 6200 loss 0.01003595173027144\n",
      "Epoch 71 num_samples 6300 loss 0.012525213615252592\n",
      "Epoch 71 num_samples 6400 loss 0.007945149993221486\n",
      "Epoch 71 num_samples 6500 loss 0.006956251590032509\n",
      "Epoch 71 num_samples 6600 loss 0.016014594045550692\n",
      "Epoch 71 num_samples 6700 loss 0.008055661495946881\n",
      "Epoch 71 num_samples 6800 loss 0.005219911197446794\n",
      "Epoch 71 num_samples 6900 loss 0.019647883352346688\n",
      "Epoch 71 num_samples 7000 loss 0.01163799161563019\n",
      "Epoch 71 num_samples 7100 loss 0.006529390397159576\n",
      "Epoch 71 num_samples 7200 loss 0.009318414914373971\n",
      "Epoch 71 num_samples 7300 loss 0.009358678876061515\n",
      "Epoch 71 num_samples 7400 loss 0.006958643497817003\n",
      "Epoch 71 num_samples 7500 loss 0.01483441305575436\n",
      "Epoch 71 num_samples 7600 loss 0.009824625057373552\n",
      "Epoch 71 num_samples 7700 loss 0.013367568744232856\n",
      "Epoch 71 num_samples 7800 loss 0.008130263617669508\n",
      "Epoch 71 num_samples 7900 loss 0.009961402931093634\n",
      "Epoch 71 num_samples 8000 loss 0.006590573130648664\n",
      "Epoch 71 num_samples 8100 loss 0.008819562984454932\n",
      "Epoch 71 num_samples 8200 loss 0.010298255089178768\n",
      "Epoch 71 num_samples 8300 loss 0.007979150209314898\n",
      "Epoch 71 num_samples 8400 loss 0.006598887031208947\n",
      "Epoch 71 num_samples 8500 loss 0.009709695245791693\n",
      "Epoch 71 num_samples 8600 loss 0.009693532843389396\n",
      "Epoch 71 num_samples 8700 loss 0.00954285963413213\n",
      "Epoch 71 num_samples 8800 loss 0.00944789152433165\n",
      "Epoch 71 num_samples 8900 loss 0.011455961964418039\n",
      "Epoch 71 num_samples 9000 loss 0.009623899692082301\n",
      "Epoch 71 num_samples 9100 loss 0.00928385122753641\n",
      "Epoch 71 num_samples 9200 loss 0.010019461820039705\n",
      "Epoch 71 num_samples 9300 loss 0.009693365323195226\n",
      "Epoch 71 num_samples 9400 loss 0.008167959043759896\n",
      "Epoch 71 num_samples 9500 loss 0.00808013783278391\n",
      "Epoch 71 num_samples 9600 loss 0.008777410525262916\n",
      "Epoch 71 num_samples 9700 loss 0.013643973376266877\n",
      "Epoch 71 num_samples 9800 loss 0.005871220891644006\n",
      "Epoch 71 num_samples 9900 loss 0.017423758692366332\n",
      "Epoch 71 num_samples 10000 loss 0.008090242295911224\n",
      "Epoch 71 num_samples 10100 loss 0.007379775619507297\n",
      "Epoch 71 num_samples 10200 loss 0.011510258259050775\n",
      "Epoch 71 num_samples 10300 loss 0.009184857417968578\n",
      "Epoch 71 num_samples 10400 loss 0.012208781685025712\n",
      "Epoch 71 num_samples 10500 loss 0.008616178376083786\n",
      "Epoch 71 num_samples 10600 loss 0.010836229115997242\n",
      "Epoch 71 num_samples 10700 loss 0.008443048823406029\n",
      "Epoch 71 num_samples 10800 loss 0.01083537088898063\n",
      "Epoch 71 num_samples 10900 loss 0.008090503248057214\n",
      "Epoch 71 num_samples 11000 loss 0.007410402453999991\n",
      "Epoch 71 num_samples 11100 loss 0.009868847466291937\n",
      "Epoch 71 num_samples 11200 loss 0.007723760328565809\n",
      "Epoch 71 num_samples 11300 loss 0.012833690675966241\n",
      "Epoch 71 num_samples 11400 loss 0.008815175289649592\n",
      "Epoch 71 num_samples 11500 loss 0.008489199806805058\n",
      "Epoch 71 num_samples 11600 loss 0.008204456792872895\n",
      "Epoch 71 num_samples 11700 loss 0.011356681572226721\n",
      "Epoch 71 num_samples 11800 loss 0.008309363414008415\n",
      "Epoch 71 num_samples 11900 loss 0.0072821513057785125\n",
      "Epoch 71 num_samples 12000 loss 0.006381251046664596\n",
      "Epoch 71 num_samples 12100 loss 0.00718550614385875\n",
      "Epoch 71 num_samples 12200 loss 0.010529924054640719\n",
      "Epoch 71 num_samples 12300 loss 0.007404588266498211\n",
      "Epoch 71 num_samples 12400 loss 0.011702597264065204\n",
      "Epoch 71 num_samples 12500 loss 0.010238480410952554\n",
      "Epoch 71 num_samples 12600 loss 0.012653309777241835\n",
      "Epoch 71 num_samples 12700 loss 0.009397203848898892\n",
      "Epoch 71 num_samples 12800 loss 0.014768146510325496\n",
      "Epoch 71 num_samples 12900 loss 0.008216446807944977\n",
      "Epoch 71 num_samples 13000 loss 0.007723700935055661\n",
      "Epoch 71 num_samples 13100 loss 0.012432349865362412\n",
      "Epoch 71 num_samples 13200 loss 0.005375685182386219\n",
      "Epoch 71 num_samples 13300 loss 0.007282923470321299\n",
      "Epoch 71 num_samples 13400 loss 0.004905682246924594\n",
      "Epoch 71 num_samples 13500 loss 0.006873937080307264\n",
      "Epoch 71 num_samples 13600 loss 0.012293313907832892\n",
      "Epoch 71 num_samples 13700 loss 0.008977395038589542\n",
      "Epoch 71 num_samples 13800 loss 0.0085648304623522\n",
      "Epoch 71 num_samples 13900 loss 0.0036431930919378873\n",
      "Epoch 71 num_samples 14000 loss 0.006334862627671101\n",
      "Epoch 71 num_samples 14100 loss 0.008408996119395138\n",
      "Epoch 71 num_samples 14200 loss 0.007500604238848483\n",
      "Epoch 71 num_samples 14300 loss 0.010015520213589908\n",
      "Epoch 71 num_samples 14400 loss 0.01014752656957572\n",
      "Epoch 71 num_samples 14500 loss 0.012288016377032416\n",
      "Epoch 71 num_samples 14600 loss 0.008743348388571928\n",
      "Epoch 71 num_samples 14700 loss 0.009216146685982602\n",
      "Epoch 71 num_samples 14800 loss 0.008769162970643635\n",
      "Epoch 71 num_samples 14900 loss 0.01037275391487224\n",
      "Epoch 71 num_samples 15000 loss 0.0086411827729375\n",
      "Epoch 71 num_samples 15100 loss 0.009679867771689048\n",
      "Epoch 71 num_samples 15200 loss 0.009566542044458759\n",
      "Epoch 71 num_samples 15300 loss 0.009965238553353494\n",
      "Epoch 71 num_samples 15400 loss 0.0068833689988051705\n",
      "Epoch 71 num_samples 15500 loss 0.009663186829578082\n",
      "Epoch 71 num_samples 15600 loss 0.010135951577222685\n",
      "Epoch 71 num_samples 15700 loss 0.006647835643780416\n",
      "Epoch 71 num_samples 15800 loss 0.011212104997586469\n",
      "Epoch 71 num_samples 15900 loss 0.007147936545276183\n",
      "Epoch 71 num_samples 16000 loss 0.013386721880928527\n",
      "Epoch 71 num_samples 16100 loss 0.006940822567845577\n",
      "Epoch 71 num_samples 16200 loss 0.010591852018683961\n",
      "Epoch 71 num_samples 16300 loss 0.012243318620523502\n",
      "Epoch 71 num_samples 16400 loss 0.012455866132993244\n",
      "Epoch 71 num_samples 16500 loss 0.010711445031037247\n",
      "Epoch 71 num_samples 16600 loss 0.011757463043483067\n",
      "Epoch 71 num_samples 16700 loss 0.006530340526952952\n",
      "Epoch 71 num_samples 16800 loss 0.0066215477702546354\n",
      "Epoch 71 num_samples 16900 loss 0.007737257793975272\n",
      "Epoch 71 num_samples 17000 loss 0.00593230336075863\n",
      "Epoch 71 num_samples 17100 loss 0.01499189381617437\n",
      "Epoch 71 num_samples 17200 loss 0.01050605888815968\n",
      "Epoch 71 num_samples 17300 loss 0.010661269697994129\n",
      "Epoch 71 num_samples 17400 loss 0.009311681035950042\n",
      "Epoch 71 num_samples 17500 loss 0.009538462736625982\n",
      "Epoch 71 num_samples 17600 loss 0.00861680732635952\n",
      "Epoch 71 num_samples 17700 loss 0.007171362614294094\n",
      "Epoch 71 num_samples 17800 loss 0.007793905330559856\n",
      "Epoch 71 num_samples 17900 loss 0.0120252291402127\n",
      "Epoch 71 num_samples 18000 loss 0.00861277081293321\n",
      "Epoch 71 num_samples 18100 loss 0.009528709862564348\n",
      "Epoch 71 num_samples 18200 loss 0.010132999915509843\n",
      "Epoch 71 num_samples 18300 loss 0.007492989424463281\n",
      "Epoch 71 num_samples 18400 loss 0.014458669069160365\n",
      "Epoch 71 num_samples 18500 loss 0.010300202987301646\n",
      "Epoch 72 num_samples 0 loss 0.007073124007342943\n",
      "Epoch 72 num_samples 100 loss 0.012686447856998044\n",
      "Epoch 72 num_samples 200 loss 0.008402398437133309\n",
      "Epoch 72 num_samples 300 loss 0.007189494514482833\n",
      "Epoch 72 num_samples 400 loss 0.008542826603566183\n",
      "Epoch 72 num_samples 500 loss 0.012866105143655868\n",
      "Epoch 72 num_samples 600 loss 0.012823454816614472\n",
      "Epoch 72 num_samples 700 loss 0.013755306837927273\n",
      "Epoch 72 num_samples 800 loss 0.008069706347047978\n",
      "Epoch 72 num_samples 900 loss 0.014314856274741787\n",
      "Epoch 72 num_samples 1000 loss 0.008631489918932258\n",
      "Epoch 72 num_samples 1100 loss 0.014295232752846667\n",
      "Epoch 72 num_samples 1200 loss 0.008445712059043008\n",
      "Epoch 72 num_samples 1300 loss 0.010130644504852166\n",
      "Epoch 72 num_samples 1400 loss 0.010248199922461475\n",
      "Epoch 72 num_samples 1500 loss 0.012407046716657724\n",
      "Epoch 72 num_samples 1600 loss 0.008917349211261036\n",
      "Epoch 72 num_samples 1700 loss 0.008610064431280873\n",
      "Epoch 72 num_samples 1800 loss 0.008388653306290673\n",
      "Epoch 72 num_samples 1900 loss 0.010009252442509362\n",
      "Epoch 72 num_samples 2000 loss 0.011825168257475158\n",
      "Epoch 72 num_samples 2100 loss 0.006273424535853026\n",
      "Epoch 72 num_samples 2200 loss 0.007006127576724944\n",
      "Epoch 72 num_samples 2300 loss 0.0047253985740930435\n",
      "Epoch 72 num_samples 2400 loss 0.007872888740649486\n",
      "Epoch 72 num_samples 2500 loss 0.010622556080263029\n",
      "Epoch 72 num_samples 2600 loss 0.011508780246072563\n",
      "Epoch 72 num_samples 2700 loss 0.008059338756902224\n",
      "Epoch 72 num_samples 2800 loss 0.011500161815950398\n",
      "Epoch 72 num_samples 2900 loss 0.010543436842620659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 num_samples 3000 loss 0.008817886978527706\n",
      "Epoch 72 num_samples 3100 loss 0.008431255799102276\n",
      "Epoch 72 num_samples 3200 loss 0.014888825979520334\n",
      "Epoch 72 num_samples 3300 loss 0.009636048759180331\n",
      "Epoch 72 num_samples 3400 loss 0.00771524803718223\n",
      "Epoch 72 num_samples 3500 loss 0.007964808753086874\n",
      "Epoch 72 num_samples 3600 loss 0.005948438479433521\n",
      "Epoch 72 num_samples 3700 loss 0.013942015650627915\n",
      "Epoch 72 num_samples 3800 loss 0.0077354450625378626\n",
      "Epoch 72 num_samples 3900 loss 0.009484072252565642\n",
      "Epoch 72 num_samples 4000 loss 0.010532895942428589\n",
      "Epoch 72 num_samples 4100 loss 0.013444640212129872\n",
      "Epoch 72 num_samples 4200 loss 0.009851446244466681\n",
      "Epoch 72 num_samples 4300 loss 0.008683501136379035\n",
      "Epoch 72 num_samples 4400 loss 0.010025751590418217\n",
      "Epoch 72 num_samples 4500 loss 0.012246027054028987\n",
      "Epoch 72 num_samples 4600 loss 0.010489808167329931\n",
      "Epoch 72 num_samples 4700 loss 0.0060315725007946954\n",
      "Epoch 72 num_samples 4800 loss 0.006372030335419137\n",
      "Epoch 72 num_samples 4900 loss 0.008078443916639975\n",
      "Epoch 72 num_samples 5000 loss 0.007127278923950954\n",
      "Epoch 72 num_samples 5100 loss 0.012763878275109008\n",
      "Epoch 72 num_samples 5200 loss 0.006270299480973732\n",
      "Epoch 72 num_samples 5300 loss 0.008547153053054403\n",
      "Epoch 72 num_samples 5400 loss 0.011654456805369504\n",
      "Epoch 72 num_samples 5500 loss 0.007001117813869009\n",
      "Epoch 72 num_samples 5600 loss 0.0242402327552221\n",
      "Epoch 72 num_samples 5700 loss 0.009153301728024914\n",
      "Epoch 72 num_samples 5800 loss 0.008867493628796215\n",
      "Epoch 72 num_samples 5900 loss 0.011455239681899636\n",
      "Epoch 72 num_samples 6000 loss 0.009218297780975366\n",
      "Epoch 72 num_samples 6100 loss 0.0084604902538607\n",
      "Epoch 72 num_samples 6200 loss 0.009799877406101788\n",
      "Epoch 72 num_samples 6300 loss 0.012210905363486813\n",
      "Epoch 72 num_samples 6400 loss 0.007715123036823428\n",
      "Epoch 72 num_samples 6500 loss 0.006764368257027007\n",
      "Epoch 72 num_samples 6600 loss 0.015639401298064036\n",
      "Epoch 72 num_samples 6700 loss 0.007829349575301693\n",
      "Epoch 72 num_samples 6800 loss 0.005106903866964757\n",
      "Epoch 72 num_samples 6900 loss 0.019173603538180633\n",
      "Epoch 72 num_samples 7000 loss 0.011423522241466722\n",
      "Epoch 72 num_samples 7100 loss 0.006357550461111707\n",
      "Epoch 72 num_samples 7200 loss 0.009151098424501786\n",
      "Epoch 72 num_samples 7300 loss 0.00916140647659546\n",
      "Epoch 72 num_samples 7400 loss 0.006782448102584378\n",
      "Epoch 72 num_samples 7500 loss 0.014417303569564444\n",
      "Epoch 72 num_samples 7600 loss 0.009579114529058623\n",
      "Epoch 72 num_samples 7700 loss 0.013024497879247136\n",
      "Epoch 72 num_samples 7800 loss 0.007912137021316198\n",
      "Epoch 72 num_samples 7900 loss 0.009770588121156524\n",
      "Epoch 72 num_samples 8000 loss 0.006452197557911457\n",
      "Epoch 72 num_samples 8100 loss 0.008566151561830887\n",
      "Epoch 72 num_samples 8200 loss 0.010030930446210356\n",
      "Epoch 72 num_samples 8300 loss 0.007765585955243495\n",
      "Epoch 72 num_samples 8400 loss 0.006437839671861423\n",
      "Epoch 72 num_samples 8500 loss 0.009449149520133147\n",
      "Epoch 72 num_samples 8600 loss 0.009467777737001016\n",
      "Epoch 72 num_samples 8700 loss 0.00931463163851923\n",
      "Epoch 72 num_samples 8800 loss 0.00918684556086254\n",
      "Epoch 72 num_samples 8900 loss 0.011160986391234116\n",
      "Epoch 72 num_samples 9000 loss 0.009373143299600728\n",
      "Epoch 72 num_samples 9100 loss 0.009070684032190503\n",
      "Epoch 72 num_samples 9200 loss 0.009738656634814692\n",
      "Epoch 72 num_samples 9300 loss 0.009456196538429485\n",
      "Epoch 72 num_samples 9400 loss 0.007993748574095284\n",
      "Epoch 72 num_samples 9500 loss 0.007858805495636272\n",
      "Epoch 72 num_samples 9600 loss 0.008540623155720977\n",
      "Epoch 72 num_samples 9700 loss 0.01332156748105405\n",
      "Epoch 72 num_samples 9800 loss 0.005722016698144123\n",
      "Epoch 72 num_samples 9900 loss 0.016913808238887235\n",
      "Epoch 72 num_samples 10000 loss 0.007818736047140047\n",
      "Epoch 72 num_samples 10100 loss 0.007187176390134644\n",
      "Epoch 72 num_samples 10200 loss 0.01119074915930506\n",
      "Epoch 72 num_samples 10300 loss 0.008996780326213654\n",
      "Epoch 72 num_samples 10400 loss 0.0118903809188326\n",
      "Epoch 72 num_samples 10500 loss 0.008423422233759153\n",
      "Epoch 72 num_samples 10600 loss 0.010602671290154242\n",
      "Epoch 72 num_samples 10700 loss 0.00821036215894416\n",
      "Epoch 72 num_samples 10800 loss 0.010525175691623572\n",
      "Epoch 72 num_samples 10900 loss 0.007845844062837885\n",
      "Epoch 72 num_samples 11000 loss 0.007283122113807736\n",
      "Epoch 72 num_samples 11100 loss 0.00962021371052786\n",
      "Epoch 72 num_samples 11200 loss 0.007538645763956595\n",
      "Epoch 72 num_samples 11300 loss 0.012502089060881336\n",
      "Epoch 72 num_samples 11400 loss 0.008550629029654484\n",
      "Epoch 72 num_samples 11500 loss 0.008269746640402888\n",
      "Epoch 72 num_samples 11600 loss 0.008015490366292687\n",
      "Epoch 72 num_samples 11700 loss 0.01104430108976886\n",
      "Epoch 72 num_samples 11800 loss 0.00806763034335893\n",
      "Epoch 72 num_samples 11900 loss 0.007089412215967163\n",
      "Epoch 72 num_samples 12000 loss 0.006226484149515239\n",
      "Epoch 72 num_samples 12100 loss 0.006991365471565396\n",
      "Epoch 72 num_samples 12200 loss 0.010197433934731501\n",
      "Epoch 72 num_samples 12300 loss 0.007182828191555416\n",
      "Epoch 72 num_samples 12400 loss 0.011360245780062632\n",
      "Epoch 72 num_samples 12500 loss 0.010011320690270371\n",
      "Epoch 72 num_samples 12600 loss 0.01233787664614077\n",
      "Epoch 72 num_samples 12700 loss 0.00917100358472148\n",
      "Epoch 72 num_samples 12800 loss 0.01437539123423824\n",
      "Epoch 72 num_samples 12900 loss 0.008012015803674001\n",
      "Epoch 72 num_samples 13000 loss 0.007539338843140878\n",
      "Epoch 72 num_samples 13100 loss 0.012113589706460828\n",
      "Epoch 72 num_samples 13200 loss 0.005215031058668294\n",
      "Epoch 72 num_samples 13300 loss 0.007132528495723718\n",
      "Epoch 72 num_samples 13400 loss 0.004785451213153661\n",
      "Epoch 72 num_samples 13500 loss 0.0067016388578285515\n",
      "Epoch 72 num_samples 13600 loss 0.011956924423379239\n",
      "Epoch 72 num_samples 13700 loss 0.008744451439034682\n",
      "Epoch 72 num_samples 13800 loss 0.008367879187105822\n",
      "Epoch 72 num_samples 13900 loss 0.0035575561917447008\n",
      "Epoch 72 num_samples 14000 loss 0.006165321972382203\n",
      "Epoch 72 num_samples 14100 loss 0.008188942702460839\n",
      "Epoch 72 num_samples 14200 loss 0.007328757704338927\n",
      "Epoch 72 num_samples 14300 loss 0.00979357711216217\n",
      "Epoch 72 num_samples 14400 loss 0.009897335938740847\n",
      "Epoch 72 num_samples 14500 loss 0.012007083673713902\n",
      "Epoch 72 num_samples 14600 loss 0.00849014180108359\n",
      "Epoch 72 num_samples 14700 loss 0.00895239828839567\n",
      "Epoch 72 num_samples 14800 loss 0.008557025248020256\n",
      "Epoch 72 num_samples 14900 loss 0.010082323632419565\n",
      "Epoch 72 num_samples 15000 loss 0.008436511550893804\n",
      "Epoch 72 num_samples 15100 loss 0.00944401532902673\n",
      "Epoch 72 num_samples 15200 loss 0.009296572846433685\n",
      "Epoch 72 num_samples 15300 loss 0.009691045976418218\n",
      "Epoch 72 num_samples 15400 loss 0.006733110365196757\n",
      "Epoch 72 num_samples 15500 loss 0.009418840577688346\n",
      "Epoch 72 num_samples 15600 loss 0.009899682872279736\n",
      "Epoch 72 num_samples 15700 loss 0.006500512104014584\n",
      "Epoch 72 num_samples 15800 loss 0.010930620717507878\n",
      "Epoch 72 num_samples 15900 loss 0.006978230018317457\n",
      "Epoch 72 num_samples 16000 loss 0.013036921167952431\n",
      "Epoch 72 num_samples 16100 loss 0.006781373906901102\n",
      "Epoch 72 num_samples 16200 loss 0.010343446415273525\n",
      "Epoch 72 num_samples 16300 loss 0.011884330400768021\n",
      "Epoch 72 num_samples 16400 loss 0.01215468724747797\n",
      "Epoch 72 num_samples 16500 loss 0.010452510264253076\n",
      "Epoch 72 num_samples 16600 loss 0.011480355449765344\n",
      "Epoch 72 num_samples 16700 loss 0.006387650963347886\n",
      "Epoch 72 num_samples 16800 loss 0.006451543303560594\n",
      "Epoch 72 num_samples 16900 loss 0.007535219723610141\n",
      "Epoch 72 num_samples 17000 loss 0.0057971654263520534\n",
      "Epoch 72 num_samples 17100 loss 0.014618183838070635\n",
      "Epoch 72 num_samples 17200 loss 0.010213026787120385\n",
      "Epoch 72 num_samples 17300 loss 0.010391478820813337\n",
      "Epoch 72 num_samples 17400 loss 0.009044709171400253\n",
      "Epoch 72 num_samples 17500 loss 0.009332838930329646\n",
      "Epoch 72 num_samples 17600 loss 0.008389053738480517\n",
      "Epoch 72 num_samples 17700 loss 0.0069964834484781855\n",
      "Epoch 72 num_samples 17800 loss 0.007562145697584382\n",
      "Epoch 72 num_samples 17900 loss 0.011749866975967787\n",
      "Epoch 72 num_samples 18000 loss 0.008443216411528844\n",
      "Epoch 72 num_samples 18100 loss 0.009291883572152205\n",
      "Epoch 72 num_samples 18200 loss 0.00987130409958581\n",
      "Epoch 72 num_samples 18300 loss 0.0073063880837352865\n",
      "Epoch 72 num_samples 18400 loss 0.01399869528424682\n",
      "Epoch 72 num_samples 18500 loss 0.0100857829320216\n",
      "Epoch 73 num_samples 0 loss 0.006923038256879348\n",
      "Epoch 73 num_samples 100 loss 0.012379244631104696\n",
      "Epoch 73 num_samples 200 loss 0.008191033415877687\n",
      "Epoch 73 num_samples 300 loss 0.006999134277632499\n",
      "Epoch 73 num_samples 400 loss 0.0083410702022666\n",
      "Epoch 73 num_samples 500 loss 0.012598590117066296\n",
      "Epoch 73 num_samples 600 loss 0.0125956066128841\n",
      "Epoch 73 num_samples 700 loss 0.013455973778294182\n",
      "Epoch 73 num_samples 800 loss 0.007894876064602466\n",
      "Epoch 73 num_samples 900 loss 0.014002103902202894\n",
      "Epoch 73 num_samples 1000 loss 0.008389739923661158\n",
      "Epoch 73 num_samples 1100 loss 0.013906571912233141\n",
      "Epoch 73 num_samples 1200 loss 0.008317291180473783\n",
      "Epoch 73 num_samples 1300 loss 0.009822330573577457\n",
      "Epoch 73 num_samples 1400 loss 0.010012439149057062\n",
      "Epoch 73 num_samples 1500 loss 0.012018856952016828\n",
      "Epoch 73 num_samples 1600 loss 0.00865860884038023\n",
      "Epoch 73 num_samples 1700 loss 0.00838517728271128\n",
      "Epoch 73 num_samples 1800 loss 0.008213214297335214\n",
      "Epoch 73 num_samples 1900 loss 0.009765990886518328\n",
      "Epoch 73 num_samples 2000 loss 0.011551011469643662\n",
      "Epoch 73 num_samples 2100 loss 0.00613040746305584\n",
      "Epoch 73 num_samples 2200 loss 0.00684930686772246\n",
      "Epoch 73 num_samples 2300 loss 0.004613261542016783\n",
      "Epoch 73 num_samples 2400 loss 0.007687395750611677\n",
      "Epoch 73 num_samples 2500 loss 0.010316224962842846\n",
      "Epoch 73 num_samples 2600 loss 0.011232837926714643\n",
      "Epoch 73 num_samples 2700 loss 0.007890587870326577\n",
      "Epoch 73 num_samples 2800 loss 0.01116788079970449\n",
      "Epoch 73 num_samples 2900 loss 0.010289308805385988\n",
      "Epoch 73 num_samples 3000 loss 0.008585027049123638\n",
      "Epoch 73 num_samples 3100 loss 0.008230211710155543\n",
      "Epoch 73 num_samples 3200 loss 0.01445046050699558\n",
      "Epoch 73 num_samples 3300 loss 0.009353710508545198\n",
      "Epoch 73 num_samples 3400 loss 0.0074815266243609254\n",
      "Epoch 73 num_samples 3500 loss 0.0077574182888240474\n",
      "Epoch 73 num_samples 3600 loss 0.005834033795967952\n",
      "Epoch 73 num_samples 3700 loss 0.013612522610687764\n",
      "Epoch 73 num_samples 3800 loss 0.007495976744561776\n",
      "Epoch 73 num_samples 3900 loss 0.009266407510159008\n",
      "Epoch 73 num_samples 4000 loss 0.01019280277094722\n",
      "Epoch 73 num_samples 4100 loss 0.013066334485305482\n",
      "Epoch 73 num_samples 4200 loss 0.009609169524955831\n",
      "Epoch 73 num_samples 4300 loss 0.008435258845587773\n",
      "Epoch 73 num_samples 4400 loss 0.009755629626961623\n",
      "Epoch 73 num_samples 4500 loss 0.011916258782995187\n",
      "Epoch 73 num_samples 4600 loss 0.010216253150282118\n",
      "Epoch 73 num_samples 4700 loss 0.005904725424801516\n",
      "Epoch 73 num_samples 4800 loss 0.006202188139425759\n",
      "Epoch 73 num_samples 4900 loss 0.007893729352204162\n",
      "Epoch 73 num_samples 5000 loss 0.006957475021476203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 num_samples 5100 loss 0.012441924066996856\n",
      "Epoch 73 num_samples 5200 loss 0.0061049115801823615\n",
      "Epoch 73 num_samples 5300 loss 0.008318522426958928\n",
      "Epoch 73 num_samples 5400 loss 0.011404271216909581\n",
      "Epoch 73 num_samples 5500 loss 0.006864034798682012\n",
      "Epoch 73 num_samples 5600 loss 0.023545332355518287\n",
      "Epoch 73 num_samples 5700 loss 0.008974681485463314\n",
      "Epoch 73 num_samples 5800 loss 0.00864604538684677\n",
      "Epoch 73 num_samples 5900 loss 0.011114827207963418\n",
      "Epoch 73 num_samples 6000 loss 0.008992610190703153\n",
      "Epoch 73 num_samples 6100 loss 0.00826826095168963\n",
      "Epoch 73 num_samples 6200 loss 0.009555511570354924\n",
      "Epoch 73 num_samples 6300 loss 0.011884419755569215\n",
      "Epoch 73 num_samples 6400 loss 0.00754094025647162\n",
      "Epoch 73 num_samples 6500 loss 0.006593545803465312\n",
      "Epoch 73 num_samples 6600 loss 0.015268854862026787\n",
      "Epoch 73 num_samples 6700 loss 0.007670275940270929\n",
      "Epoch 73 num_samples 6800 loss 0.004968357655414497\n",
      "Epoch 73 num_samples 6900 loss 0.01868267509228168\n",
      "Epoch 73 num_samples 7000 loss 0.011085476825567162\n",
      "Epoch 73 num_samples 7100 loss 0.006187049917648926\n",
      "Epoch 73 num_samples 7200 loss 0.008925329419623445\n",
      "Epoch 73 num_samples 7300 loss 0.008933910619969034\n",
      "Epoch 73 num_samples 7400 loss 0.0066325640444102095\n",
      "Epoch 73 num_samples 7500 loss 0.014008074141884722\n",
      "Epoch 73 num_samples 7600 loss 0.009356752181618433\n",
      "Epoch 73 num_samples 7700 loss 0.01272523075258169\n",
      "Epoch 73 num_samples 7800 loss 0.007728618543629879\n",
      "Epoch 73 num_samples 7900 loss 0.00952477508945451\n",
      "Epoch 73 num_samples 8000 loss 0.006285598166363974\n",
      "Epoch 73 num_samples 8100 loss 0.008365191802170829\n",
      "Epoch 73 num_samples 8200 loss 0.009792883377181386\n",
      "Epoch 73 num_samples 8300 loss 0.00756181608803018\n",
      "Epoch 73 num_samples 8400 loss 0.006261779899930864\n",
      "Epoch 73 num_samples 8500 loss 0.009148773765582142\n",
      "Epoch 73 num_samples 8600 loss 0.009216984512006567\n",
      "Epoch 73 num_samples 8700 loss 0.009104634127722411\n",
      "Epoch 73 num_samples 8800 loss 0.008976522207689734\n",
      "Epoch 73 num_samples 8900 loss 0.010874828587388103\n",
      "Epoch 73 num_samples 9000 loss 0.009129456752958788\n",
      "Epoch 73 num_samples 9100 loss 0.008833037653708048\n",
      "Epoch 73 num_samples 9200 loss 0.00952710475757175\n",
      "Epoch 73 num_samples 9300 loss 0.009227999477864448\n",
      "Epoch 73 num_samples 9400 loss 0.007775263852996572\n",
      "Epoch 73 num_samples 9500 loss 0.007682405992239838\n",
      "Epoch 73 num_samples 9600 loss 0.008370731320339928\n",
      "Epoch 73 num_samples 9700 loss 0.012907091464771113\n",
      "Epoch 73 num_samples 9800 loss 0.0055891443036519\n",
      "Epoch 73 num_samples 9900 loss 0.016536251412746488\n",
      "Epoch 73 num_samples 10000 loss 0.007651945467305147\n",
      "Epoch 73 num_samples 10100 loss 0.007006412627706559\n",
      "Epoch 73 num_samples 10200 loss 0.010894654038242649\n",
      "Epoch 73 num_samples 10300 loss 0.00873458422563258\n",
      "Epoch 73 num_samples 10400 loss 0.011638033326199657\n",
      "Epoch 73 num_samples 10500 loss 0.0082027292322558\n",
      "Epoch 73 num_samples 10600 loss 0.01032333684297151\n",
      "Epoch 73 num_samples 10700 loss 0.007998512408163145\n",
      "Epoch 73 num_samples 10800 loss 0.010303959369322525\n",
      "Epoch 73 num_samples 10900 loss 0.007686467332218604\n",
      "Epoch 73 num_samples 11000 loss 0.007096649536244028\n",
      "Epoch 73 num_samples 11100 loss 0.009424066883810048\n",
      "Epoch 73 num_samples 11200 loss 0.007378078740479723\n",
      "Epoch 73 num_samples 11300 loss 0.012182995477020876\n",
      "Epoch 73 num_samples 11400 loss 0.008313832405737137\n",
      "Epoch 73 num_samples 11500 loss 0.00802951586639557\n",
      "Epoch 73 num_samples 11600 loss 0.007818250251193155\n",
      "Epoch 73 num_samples 11700 loss 0.010754333560061368\n",
      "Epoch 73 num_samples 11800 loss 0.007878359457242476\n",
      "Epoch 73 num_samples 11900 loss 0.006906163077858737\n",
      "Epoch 73 num_samples 12000 loss 0.0060646565829546\n",
      "Epoch 73 num_samples 12100 loss 0.006827391529723963\n",
      "Epoch 73 num_samples 12200 loss 0.009918011505285249\n",
      "Epoch 73 num_samples 12300 loss 0.007055486598186556\n",
      "Epoch 73 num_samples 12400 loss 0.011086801869186194\n",
      "Epoch 73 num_samples 12500 loss 0.0097342376508464\n",
      "Epoch 73 num_samples 12600 loss 0.01203381115052556\n",
      "Epoch 73 num_samples 12700 loss 0.008917210761432221\n",
      "Epoch 73 num_samples 12800 loss 0.013945596595860067\n",
      "Epoch 73 num_samples 12900 loss 0.007822041124082841\n",
      "Epoch 73 num_samples 13000 loss 0.007365724908209565\n",
      "Epoch 73 num_samples 13100 loss 0.01174933351160791\n",
      "Epoch 73 num_samples 13200 loss 0.005102791217060356\n",
      "Epoch 73 num_samples 13300 loss 0.006942326031786563\n",
      "Epoch 73 num_samples 13400 loss 0.004666728062403265\n",
      "Epoch 73 num_samples 13500 loss 0.00648691390456203\n",
      "Epoch 73 num_samples 13600 loss 0.011628428502290542\n",
      "Epoch 73 num_samples 13700 loss 0.008527065167781553\n",
      "Epoch 73 num_samples 13800 loss 0.008182859593752822\n",
      "Epoch 73 num_samples 13900 loss 0.003476271198268974\n",
      "Epoch 73 num_samples 14000 loss 0.006020397841209006\n",
      "Epoch 73 num_samples 14100 loss 0.00799476422974763\n",
      "Epoch 73 num_samples 14200 loss 0.007169004636968315\n",
      "Epoch 73 num_samples 14300 loss 0.009538824505834797\n",
      "Epoch 73 num_samples 14400 loss 0.009653150585292076\n",
      "Epoch 73 num_samples 14500 loss 0.011738126794510296\n",
      "Epoch 73 num_samples 14600 loss 0.008278587071276534\n",
      "Epoch 73 num_samples 14700 loss 0.008765174426738374\n",
      "Epoch 73 num_samples 14800 loss 0.008342313811652973\n",
      "Epoch 73 num_samples 14900 loss 0.009848575287217103\n",
      "Epoch 73 num_samples 15000 loss 0.008266519446859695\n",
      "Epoch 73 num_samples 15100 loss 0.009200218849658815\n",
      "Epoch 73 num_samples 15200 loss 0.008996274164857671\n",
      "Epoch 73 num_samples 15300 loss 0.009424948613185961\n",
      "Epoch 73 num_samples 15400 loss 0.006582536437967519\n",
      "Epoch 73 num_samples 15500 loss 0.009166429632114512\n",
      "Epoch 73 num_samples 15600 loss 0.00962519833036724\n",
      "Epoch 73 num_samples 15700 loss 0.006346140374527518\n",
      "Epoch 73 num_samples 15800 loss 0.010592818985305823\n",
      "Epoch 73 num_samples 15900 loss 0.00683949676214378\n",
      "Epoch 73 num_samples 16000 loss 0.012708470793362354\n",
      "Epoch 73 num_samples 16100 loss 0.006625261860589011\n",
      "Epoch 73 num_samples 16200 loss 0.010068330813178117\n",
      "Epoch 73 num_samples 16300 loss 0.011580805184764453\n",
      "Epoch 73 num_samples 16400 loss 0.011835657372883258\n",
      "Epoch 73 num_samples 16500 loss 0.010132208291477327\n",
      "Epoch 73 num_samples 16600 loss 0.011202459710867958\n",
      "Epoch 73 num_samples 16700 loss 0.0062200715187985785\n",
      "Epoch 73 num_samples 16800 loss 0.006316681006827701\n",
      "Epoch 73 num_samples 16900 loss 0.0073587387163957275\n",
      "Epoch 73 num_samples 17000 loss 0.005659381530605134\n",
      "Epoch 73 num_samples 17100 loss 0.014205478809994742\n",
      "Epoch 73 num_samples 17200 loss 0.009998364737445652\n",
      "Epoch 73 num_samples 17300 loss 0.010091571430892194\n",
      "Epoch 73 num_samples 17400 loss 0.008842623769759734\n",
      "Epoch 73 num_samples 17500 loss 0.009099543727917752\n",
      "Epoch 73 num_samples 17600 loss 0.00820688115110222\n",
      "Epoch 73 num_samples 17700 loss 0.006819616851008228\n",
      "Epoch 73 num_samples 17800 loss 0.007370172102622823\n",
      "Epoch 73 num_samples 17900 loss 0.011407745219554274\n",
      "Epoch 73 num_samples 18000 loss 0.008238718558610332\n",
      "Epoch 73 num_samples 18100 loss 0.009036067631804534\n",
      "Epoch 73 num_samples 18200 loss 0.00967985789833564\n",
      "Epoch 73 num_samples 18300 loss 0.007164220800814247\n",
      "Epoch 73 num_samples 18400 loss 0.013691234852139265\n",
      "Epoch 73 num_samples 18500 loss 0.009856888731682376\n",
      "Epoch 74 num_samples 0 loss 0.006779139700377701\n",
      "Epoch 74 num_samples 100 loss 0.012100034444929447\n",
      "Epoch 74 num_samples 200 loss 0.007996629734843066\n",
      "Epoch 74 num_samples 300 loss 0.006825215366457742\n",
      "Epoch 74 num_samples 400 loss 0.008142936621629607\n",
      "Epoch 74 num_samples 500 loss 0.012316058237046132\n",
      "Epoch 74 num_samples 600 loss 0.012218722635023835\n",
      "Epoch 74 num_samples 700 loss 0.013099492455887117\n",
      "Epoch 74 num_samples 800 loss 0.0076769216958729744\n",
      "Epoch 74 num_samples 900 loss 0.013647957654236167\n",
      "Epoch 74 num_samples 1000 loss 0.008186363242687855\n",
      "Epoch 74 num_samples 1100 loss 0.013618121247340695\n",
      "Epoch 74 num_samples 1200 loss 0.008131630935155598\n",
      "Epoch 74 num_samples 1300 loss 0.009618579997226066\n",
      "Epoch 74 num_samples 1400 loss 0.009699390974831145\n",
      "Epoch 74 num_samples 1500 loss 0.011697062867704127\n",
      "Epoch 74 num_samples 1600 loss 0.008474746625892725\n",
      "Epoch 74 num_samples 1700 loss 0.008160537563086899\n",
      "Epoch 74 num_samples 1800 loss 0.007990207590772888\n",
      "Epoch 74 num_samples 1900 loss 0.00956320126282695\n",
      "Epoch 74 num_samples 2000 loss 0.011292848757478588\n",
      "Epoch 74 num_samples 2100 loss 0.005960875157754507\n",
      "Epoch 74 num_samples 2200 loss 0.006683888492573405\n",
      "Epoch 74 num_samples 2300 loss 0.00450106218471484\n",
      "Epoch 74 num_samples 2400 loss 0.007482124926928532\n",
      "Epoch 74 num_samples 2500 loss 0.010095671679610537\n",
      "Epoch 74 num_samples 2600 loss 0.01097300713403121\n",
      "Epoch 74 num_samples 2700 loss 0.007684957211136949\n",
      "Epoch 74 num_samples 2800 loss 0.010854846786680911\n",
      "Epoch 74 num_samples 2900 loss 0.010012168795791658\n",
      "Epoch 74 num_samples 3000 loss 0.008384732896914517\n",
      "Epoch 74 num_samples 3100 loss 0.008078327424361664\n",
      "Epoch 74 num_samples 3200 loss 0.014002862508577447\n",
      "Epoch 74 num_samples 3300 loss 0.009144325179711275\n",
      "Epoch 74 num_samples 3400 loss 0.007324102901376291\n",
      "Epoch 74 num_samples 3500 loss 0.007608203569956644\n",
      "Epoch 74 num_samples 3600 loss 0.00571960564698646\n",
      "Epoch 74 num_samples 3700 loss 0.01329695636695097\n",
      "Epoch 74 num_samples 3800 loss 0.007314433158514215\n",
      "Epoch 74 num_samples 3900 loss 0.009031526508660374\n",
      "Epoch 74 num_samples 4000 loss 0.009945896394569761\n",
      "Epoch 74 num_samples 4100 loss 0.012668976579222502\n",
      "Epoch 74 num_samples 4200 loss 0.009398914900213644\n",
      "Epoch 74 num_samples 4300 loss 0.008245649945176963\n",
      "Epoch 74 num_samples 4400 loss 0.009520038577698713\n",
      "Epoch 74 num_samples 4500 loss 0.011579932966087511\n",
      "Epoch 74 num_samples 4600 loss 0.009971502535796803\n",
      "Epoch 74 num_samples 4700 loss 0.005752935313899561\n",
      "Epoch 74 num_samples 4800 loss 0.006061551484159822\n",
      "Epoch 74 num_samples 4900 loss 0.007708634781262131\n",
      "Epoch 74 num_samples 5000 loss 0.0068107245788867135\n",
      "Epoch 74 num_samples 5100 loss 0.012182242586843292\n",
      "Epoch 74 num_samples 5200 loss 0.005976163897769935\n",
      "Epoch 74 num_samples 5300 loss 0.00814828184096029\n",
      "Epoch 74 num_samples 5400 loss 0.011155471564863456\n",
      "Epoch 74 num_samples 5500 loss 0.006722919001648831\n",
      "Epoch 74 num_samples 5600 loss 0.02273886425236143\n",
      "Epoch 74 num_samples 5700 loss 0.008733728714709739\n",
      "Epoch 74 num_samples 5800 loss 0.008437416844031834\n",
      "Epoch 74 num_samples 5900 loss 0.010796822821598807\n",
      "Epoch 74 num_samples 6000 loss 0.008729813642522632\n",
      "Epoch 74 num_samples 6100 loss 0.008087758540950315\n",
      "Epoch 74 num_samples 6200 loss 0.009304982803145017\n",
      "Epoch 74 num_samples 6300 loss 0.011527592161909786\n",
      "Epoch 74 num_samples 6400 loss 0.007368091658003525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 num_samples 6500 loss 0.006417654068993155\n",
      "Epoch 74 num_samples 6600 loss 0.014884781673048799\n",
      "Epoch 74 num_samples 6700 loss 0.007502331897744643\n",
      "Epoch 74 num_samples 6800 loss 0.004835631037014736\n",
      "Epoch 74 num_samples 6900 loss 0.0182391705139688\n",
      "Epoch 74 num_samples 7000 loss 0.010839029571281848\n",
      "Epoch 74 num_samples 7100 loss 0.006083529551439295\n",
      "Epoch 74 num_samples 7200 loss 0.00871537302018083\n",
      "Epoch 74 num_samples 7300 loss 0.008763974429050523\n",
      "Epoch 74 num_samples 7400 loss 0.006496717245574634\n",
      "Epoch 74 num_samples 7500 loss 0.013616087493254676\n",
      "Epoch 74 num_samples 7600 loss 0.00912844181581767\n",
      "Epoch 74 num_samples 7700 loss 0.01235352163480279\n",
      "Epoch 74 num_samples 7800 loss 0.007557875455211252\n",
      "Epoch 74 num_samples 7900 loss 0.009297822787262957\n",
      "Epoch 74 num_samples 8000 loss 0.00615145872490597\n",
      "Epoch 74 num_samples 8100 loss 0.00813472919624652\n",
      "Epoch 74 num_samples 8200 loss 0.009527165361174874\n",
      "Epoch 74 num_samples 8300 loss 0.0074152797626394805\n",
      "Epoch 74 num_samples 8400 loss 0.006110074896571866\n",
      "Epoch 74 num_samples 8500 loss 0.009044352055510477\n",
      "Epoch 74 num_samples 8600 loss 0.00898945186716562\n",
      "Epoch 74 num_samples 8700 loss 0.00888654555612056\n",
      "Epoch 74 num_samples 8800 loss 0.00870813416089113\n",
      "Epoch 74 num_samples 8900 loss 0.010612172110703706\n",
      "Epoch 74 num_samples 9000 loss 0.008924565049464433\n",
      "Epoch 74 num_samples 9100 loss 0.008630696747544235\n",
      "Epoch 74 num_samples 9200 loss 0.009362996470445185\n",
      "Epoch 74 num_samples 9300 loss 0.00904996670067299\n",
      "Epoch 74 num_samples 9400 loss 0.007589062449605732\n",
      "Epoch 74 num_samples 9500 loss 0.007500086205031563\n",
      "Epoch 74 num_samples 9600 loss 0.008194159327729194\n",
      "Epoch 74 num_samples 9700 loss 0.012563883621059506\n",
      "Epoch 74 num_samples 9800 loss 0.005459096530575476\n",
      "Epoch 74 num_samples 9900 loss 0.016094251422725348\n",
      "Epoch 74 num_samples 10000 loss 0.007475034188054559\n",
      "Epoch 74 num_samples 10100 loss 0.0068091963181802105\n",
      "Epoch 74 num_samples 10200 loss 0.010647248104982594\n",
      "Epoch 74 num_samples 10300 loss 0.008548936670726998\n",
      "Epoch 74 num_samples 10400 loss 0.011350909069590263\n",
      "Epoch 74 num_samples 10500 loss 0.008073015772896455\n",
      "Epoch 74 num_samples 10600 loss 0.010010939442453301\n",
      "Epoch 74 num_samples 10700 loss 0.007809123486346191\n",
      "Epoch 74 num_samples 10800 loss 0.010030254184131566\n",
      "Epoch 74 num_samples 10900 loss 0.00756264006164904\n",
      "Epoch 74 num_samples 11000 loss 0.006939471392312258\n",
      "Epoch 74 num_samples 11100 loss 0.009211682807292025\n",
      "Epoch 74 num_samples 11200 loss 0.007195351912309198\n",
      "Epoch 74 num_samples 11300 loss 0.011852017021958516\n",
      "Epoch 74 num_samples 11400 loss 0.008131200412651389\n",
      "Epoch 74 num_samples 11500 loss 0.00781887477326736\n",
      "Epoch 74 num_samples 11600 loss 0.007637248026148562\n",
      "Epoch 74 num_samples 11700 loss 0.01048068089063004\n",
      "Epoch 74 num_samples 11800 loss 0.0077058171873524255\n",
      "Epoch 74 num_samples 11900 loss 0.006739276025977332\n",
      "Epoch 74 num_samples 12000 loss 0.005922076982906159\n",
      "Epoch 74 num_samples 12100 loss 0.00666609969293278\n",
      "Epoch 74 num_samples 12200 loss 0.009656850156735763\n",
      "Epoch 74 num_samples 12300 loss 0.006879776246532468\n",
      "Epoch 74 num_samples 12400 loss 0.010826049513519702\n",
      "Epoch 74 num_samples 12500 loss 0.009523076991750938\n",
      "Epoch 74 num_samples 12600 loss 0.011750029918172387\n",
      "Epoch 74 num_samples 12700 loss 0.008692744051268466\n",
      "Epoch 74 num_samples 12800 loss 0.013604002247751174\n",
      "Epoch 74 num_samples 12900 loss 0.007616651991317891\n",
      "Epoch 74 num_samples 13000 loss 0.0072335978446247985\n",
      "Epoch 74 num_samples 13100 loss 0.011467432875902985\n",
      "Epoch 74 num_samples 13200 loss 0.004974568151031237\n",
      "Epoch 74 num_samples 13300 loss 0.006806853181482583\n",
      "Epoch 74 num_samples 13400 loss 0.004573451094496291\n",
      "Epoch 74 num_samples 13500 loss 0.006353479312119342\n",
      "Epoch 74 num_samples 13600 loss 0.011354705098528001\n",
      "Epoch 74 num_samples 13700 loss 0.008297372477865533\n",
      "Epoch 74 num_samples 13800 loss 0.00801182665201144\n",
      "Epoch 74 num_samples 13900 loss 0.0033856547228382893\n",
      "Epoch 74 num_samples 14000 loss 0.0058685745538812695\n",
      "Epoch 74 num_samples 14100 loss 0.007784559362768771\n",
      "Epoch 74 num_samples 14200 loss 0.007028613630165086\n",
      "Epoch 74 num_samples 14300 loss 0.009326145965342385\n",
      "Epoch 74 num_samples 14400 loss 0.009404028969103355\n",
      "Epoch 74 num_samples 14500 loss 0.011487112233830947\n",
      "Epoch 74 num_samples 14600 loss 0.008039629582925735\n",
      "Epoch 74 num_samples 14700 loss 0.008562174925175012\n",
      "Epoch 74 num_samples 14800 loss 0.00817555022873694\n",
      "Epoch 74 num_samples 14900 loss 0.009611888944534273\n",
      "Epoch 74 num_samples 15000 loss 0.00809568641235286\n",
      "Epoch 74 num_samples 15100 loss 0.008963089593506317\n",
      "Epoch 74 num_samples 15200 loss 0.008765741220040535\n",
      "Epoch 74 num_samples 15300 loss 0.009219157136604733\n",
      "Epoch 74 num_samples 15400 loss 0.006439104224113522\n",
      "Epoch 74 num_samples 15500 loss 0.00893391116837593\n",
      "Epoch 74 num_samples 15600 loss 0.009406899179720658\n",
      "Epoch 74 num_samples 15700 loss 0.006194841298189693\n",
      "Epoch 74 num_samples 15800 loss 0.010329353973050237\n",
      "Epoch 74 num_samples 15900 loss 0.0066919186754618165\n",
      "Epoch 74 num_samples 16000 loss 0.01244264816772479\n",
      "Epoch 74 num_samples 16100 loss 0.006486958541154828\n",
      "Epoch 74 num_samples 16200 loss 0.009777081942455053\n",
      "Epoch 74 num_samples 16300 loss 0.01129786379999397\n",
      "Epoch 74 num_samples 16400 loss 0.011531332678197542\n",
      "Epoch 74 num_samples 16500 loss 0.009881226721893633\n",
      "Epoch 74 num_samples 16600 loss 0.010955913001284687\n",
      "Epoch 74 num_samples 16700 loss 0.00608008197535719\n",
      "Epoch 74 num_samples 16800 loss 0.006154448869375599\n",
      "Epoch 74 num_samples 16900 loss 0.007181810969129548\n",
      "Epoch 74 num_samples 17000 loss 0.005516500433981893\n",
      "Epoch 74 num_samples 17100 loss 0.013791442255142632\n",
      "Epoch 74 num_samples 17200 loss 0.009728403598514991\n",
      "Epoch 74 num_samples 17300 loss 0.009854970775688693\n",
      "Epoch 74 num_samples 17400 loss 0.0086207898901225\n",
      "Epoch 74 num_samples 17500 loss 0.008885455701092853\n",
      "Epoch 74 num_samples 17600 loss 0.008007069417352821\n",
      "Epoch 74 num_samples 17700 loss 0.006668595372350236\n",
      "Epoch 74 num_samples 17800 loss 0.0072242972105068335\n",
      "Epoch 74 num_samples 17900 loss 0.011132946088100124\n",
      "Epoch 74 num_samples 18000 loss 0.008045613901648386\n",
      "Epoch 74 num_samples 18100 loss 0.008865610096794983\n",
      "Epoch 74 num_samples 18200 loss 0.009447795993806615\n",
      "Epoch 74 num_samples 18300 loss 0.006971092038445553\n",
      "Epoch 74 num_samples 18400 loss 0.013386542622481264\n",
      "Epoch 74 num_samples 18500 loss 0.009641163686320802\n",
      "Epoch 75 num_samples 0 loss 0.006623273200955564\n",
      "Epoch 75 num_samples 100 loss 0.011775813122249307\n",
      "Epoch 75 num_samples 200 loss 0.007816614651172765\n",
      "Epoch 75 num_samples 300 loss 0.006671731219694603\n",
      "Epoch 75 num_samples 400 loss 0.007959677635413916\n",
      "Epoch 75 num_samples 500 loss 0.012006526074078967\n",
      "Epoch 75 num_samples 600 loss 0.01189746195801347\n",
      "Epoch 75 num_samples 700 loss 0.012772277192928004\n",
      "Epoch 75 num_samples 800 loss 0.0074957750111492895\n",
      "Epoch 75 num_samples 900 loss 0.013346756439056074\n",
      "Epoch 75 num_samples 1000 loss 0.008004836647658048\n",
      "Epoch 75 num_samples 1100 loss 0.013249883032436962\n",
      "Epoch 75 num_samples 1200 loss 0.007888049525331758\n",
      "Epoch 75 num_samples 1300 loss 0.009371347241194827\n",
      "Epoch 75 num_samples 1400 loss 0.009470545990145221\n",
      "Epoch 75 num_samples 1500 loss 0.011374729966831074\n",
      "Epoch 75 num_samples 1600 loss 0.008280480341448663\n",
      "Epoch 75 num_samples 1700 loss 0.00796419845741172\n",
      "Epoch 75 num_samples 1800 loss 0.007839291714646363\n",
      "Epoch 75 num_samples 1900 loss 0.009331991398755927\n",
      "Epoch 75 num_samples 2000 loss 0.010998415798788791\n",
      "Epoch 75 num_samples 2100 loss 0.005825761961501088\n",
      "Epoch 75 num_samples 2200 loss 0.0065309363247213455\n",
      "Epoch 75 num_samples 2300 loss 0.004401711568496599\n",
      "Epoch 75 num_samples 2400 loss 0.007311506053626202\n",
      "Epoch 75 num_samples 2500 loss 0.009797836080350378\n",
      "Epoch 75 num_samples 2600 loss 0.010690046695440292\n",
      "Epoch 75 num_samples 2700 loss 0.007533838750081765\n",
      "Epoch 75 num_samples 2800 loss 0.0105741202712171\n",
      "Epoch 75 num_samples 2900 loss 0.0097902746213947\n",
      "Epoch 75 num_samples 3000 loss 0.008162400195337887\n",
      "Epoch 75 num_samples 3100 loss 0.007818870003978457\n",
      "Epoch 75 num_samples 3200 loss 0.013583997287334268\n",
      "Epoch 75 num_samples 3300 loss 0.00890369443251903\n",
      "Epoch 75 num_samples 3400 loss 0.007154776975100665\n",
      "Epoch 75 num_samples 3500 loss 0.007403259684445967\n",
      "Epoch 75 num_samples 3600 loss 0.005606039911875043\n",
      "Epoch 75 num_samples 3700 loss 0.012924453008837735\n",
      "Epoch 75 num_samples 3800 loss 0.007129477421001698\n",
      "Epoch 75 num_samples 3900 loss 0.00882705971181808\n",
      "Epoch 75 num_samples 4000 loss 0.009717343347623529\n",
      "Epoch 75 num_samples 4100 loss 0.012351573686042762\n",
      "Epoch 75 num_samples 4200 loss 0.009184912102679972\n",
      "Epoch 75 num_samples 4300 loss 0.008014417406373764\n",
      "Epoch 75 num_samples 4400 loss 0.009276239333753433\n",
      "Epoch 75 num_samples 4500 loss 0.01131133801466232\n",
      "Epoch 75 num_samples 4600 loss 0.009775211783058518\n",
      "Epoch 75 num_samples 4700 loss 0.005599302477093948\n",
      "Epoch 75 num_samples 4800 loss 0.005928367420900458\n",
      "Epoch 75 num_samples 4900 loss 0.007571980871820447\n",
      "Epoch 75 num_samples 5000 loss 0.0066463658499148525\n",
      "Epoch 75 num_samples 5100 loss 0.011878217960126353\n",
      "Epoch 75 num_samples 5200 loss 0.005818769768306854\n",
      "Epoch 75 num_samples 5300 loss 0.007942860336845525\n",
      "Epoch 75 num_samples 5400 loss 0.01088818900237587\n",
      "Epoch 75 num_samples 5500 loss 0.0065736460695270706\n",
      "Epoch 75 num_samples 5600 loss 0.02202240087416074\n",
      "Epoch 75 num_samples 5700 loss 0.008524534238461891\n",
      "Epoch 75 num_samples 5800 loss 0.008258694755193651\n",
      "Epoch 75 num_samples 5900 loss 0.010575070256712636\n",
      "Epoch 75 num_samples 6000 loss 0.00858273656361949\n",
      "Epoch 75 num_samples 6100 loss 0.007918835847436367\n",
      "Epoch 75 num_samples 6200 loss 0.00903006149052034\n",
      "Epoch 75 num_samples 6300 loss 0.011237779136097073\n",
      "Epoch 75 num_samples 6400 loss 0.007182697407878611\n",
      "Epoch 75 num_samples 6500 loss 0.00626080446424814\n",
      "Epoch 75 num_samples 6600 loss 0.014549999116460903\n",
      "Epoch 75 num_samples 6700 loss 0.007326232383518436\n",
      "Epoch 75 num_samples 6800 loss 0.004735541534751694\n",
      "Epoch 75 num_samples 6900 loss 0.017846567580294796\n",
      "Epoch 75 num_samples 7000 loss 0.010554097892962876\n",
      "Epoch 75 num_samples 7100 loss 0.005923054705890231\n",
      "Epoch 75 num_samples 7200 loss 0.00853557474151766\n",
      "Epoch 75 num_samples 7300 loss 0.008591783963511611\n",
      "Epoch 75 num_samples 7400 loss 0.006350960153626718\n",
      "Epoch 75 num_samples 7500 loss 0.01325804480174499\n",
      "Epoch 75 num_samples 7600 loss 0.008923726894233685\n",
      "Epoch 75 num_samples 7700 loss 0.012038232981235488\n",
      "Epoch 75 num_samples 7800 loss 0.007390535658252235\n",
      "Epoch 75 num_samples 7900 loss 0.009113243141141418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 num_samples 8000 loss 0.006025485233417349\n",
      "Epoch 75 num_samples 8100 loss 0.007930363068286784\n",
      "Epoch 75 num_samples 8200 loss 0.009312673585390462\n",
      "Epoch 75 num_samples 8300 loss 0.007171610907197281\n",
      "Epoch 75 num_samples 8400 loss 0.005940889317424749\n",
      "Epoch 75 num_samples 8500 loss 0.008761064965834994\n",
      "Epoch 75 num_samples 8600 loss 0.008753511113561067\n",
      "Epoch 75 num_samples 8700 loss 0.008637411072864799\n",
      "Epoch 75 num_samples 8800 loss 0.008497197082004948\n",
      "Epoch 75 num_samples 8900 loss 0.01036028450346912\n",
      "Epoch 75 num_samples 9000 loss 0.008667047996347156\n",
      "Epoch 75 num_samples 9100 loss 0.008418340553234012\n",
      "Epoch 75 num_samples 9200 loss 0.00907288354497156\n",
      "Epoch 75 num_samples 9300 loss 0.008818511721833018\n",
      "Epoch 75 num_samples 9400 loss 0.007401905281293324\n",
      "Epoch 75 num_samples 9500 loss 0.007251560535021649\n",
      "Epoch 75 num_samples 9600 loss 0.007950599106610327\n",
      "Epoch 75 num_samples 9700 loss 0.012284988936852719\n",
      "Epoch 75 num_samples 9800 loss 0.0053409251784685315\n",
      "Epoch 75 num_samples 9900 loss 0.01575837619752157\n",
      "Epoch 75 num_samples 10000 loss 0.00726435770444326\n",
      "Epoch 75 num_samples 10100 loss 0.00665577241741378\n",
      "Epoch 75 num_samples 10200 loss 0.010367936890543853\n",
      "Epoch 75 num_samples 10300 loss 0.00838001121279114\n",
      "Epoch 75 num_samples 10400 loss 0.01106015696598681\n",
      "Epoch 75 num_samples 10500 loss 0.007885665410983338\n",
      "Epoch 75 num_samples 10600 loss 0.009818369375223554\n",
      "Epoch 75 num_samples 10700 loss 0.007572844152223204\n",
      "Epoch 75 num_samples 10800 loss 0.009805194819000539\n",
      "Epoch 75 num_samples 10900 loss 0.007328699521731992\n",
      "Epoch 75 num_samples 11000 loss 0.00679020890971195\n",
      "Epoch 75 num_samples 11100 loss 0.009002781632940127\n",
      "Epoch 75 num_samples 11200 loss 0.007054751257827229\n",
      "Epoch 75 num_samples 11300 loss 0.01159855137322941\n",
      "Epoch 75 num_samples 11400 loss 0.00793350517430221\n",
      "Epoch 75 num_samples 11500 loss 0.007638161281609209\n",
      "Epoch 75 num_samples 11600 loss 0.007448283841588335\n",
      "Epoch 75 num_samples 11700 loss 0.010213274928175222\n",
      "Epoch 75 num_samples 11800 loss 0.007483554506486876\n",
      "Epoch 75 num_samples 11900 loss 0.006554591634794473\n",
      "Epoch 75 num_samples 12000 loss 0.005779169387764202\n",
      "Epoch 75 num_samples 12100 loss 0.0065015330976384055\n",
      "Epoch 75 num_samples 12200 loss 0.0093991712639267\n",
      "Epoch 75 num_samples 12300 loss 0.006717478963218056\n",
      "Epoch 75 num_samples 12400 loss 0.010554052651003714\n",
      "Epoch 75 num_samples 12500 loss 0.009300032753921241\n",
      "Epoch 75 num_samples 12600 loss 0.011462644513025309\n",
      "Epoch 75 num_samples 12700 loss 0.008515080065975733\n",
      "Epoch 75 num_samples 12800 loss 0.013245175774568511\n",
      "Epoch 75 num_samples 12900 loss 0.007459176570204958\n",
      "Epoch 75 num_samples 13000 loss 0.007032089861395477\n",
      "Epoch 75 num_samples 13100 loss 0.011197179334977651\n",
      "Epoch 75 num_samples 13200 loss 0.004876384917981166\n",
      "Epoch 75 num_samples 13300 loss 0.006661152229681595\n",
      "Epoch 75 num_samples 13400 loss 0.004470475824997785\n",
      "Epoch 75 num_samples 13500 loss 0.006180654931615535\n",
      "Epoch 75 num_samples 13600 loss 0.011069825608358985\n",
      "Epoch 75 num_samples 13700 loss 0.008102022606722038\n",
      "Epoch 75 num_samples 13800 loss 0.007824132413959706\n",
      "Epoch 75 num_samples 13900 loss 0.0033122316279484186\n",
      "Epoch 75 num_samples 14000 loss 0.00574914540203832\n",
      "Epoch 75 num_samples 14100 loss 0.0075987422636357\n",
      "Epoch 75 num_samples 14200 loss 0.006872235800998705\n",
      "Epoch 75 num_samples 14300 loss 0.009137576817457315\n",
      "Epoch 75 num_samples 14400 loss 0.00918396086333984\n",
      "Epoch 75 num_samples 14500 loss 0.01125321356676151\n",
      "Epoch 75 num_samples 14600 loss 0.007836473065047547\n",
      "Epoch 75 num_samples 14700 loss 0.008368036092245505\n",
      "Epoch 75 num_samples 14800 loss 0.007962311812870621\n",
      "Epoch 75 num_samples 14900 loss 0.009371132560214865\n",
      "Epoch 75 num_samples 15000 loss 0.007921505790232238\n",
      "Epoch 75 num_samples 15100 loss 0.008778178295218575\n",
      "Epoch 75 num_samples 15200 loss 0.008552318212383529\n",
      "Epoch 75 num_samples 15300 loss 0.009010684068892851\n",
      "Epoch 75 num_samples 15400 loss 0.006317763768595481\n",
      "Epoch 75 num_samples 15500 loss 0.00870020266872829\n",
      "Epoch 75 num_samples 15600 loss 0.009182686276009051\n",
      "Epoch 75 num_samples 15700 loss 0.006065171784000301\n",
      "Epoch 75 num_samples 15800 loss 0.010075733346917122\n",
      "Epoch 75 num_samples 15900 loss 0.006543471755832217\n",
      "Epoch 75 num_samples 16000 loss 0.012083761334370844\n",
      "Epoch 75 num_samples 16100 loss 0.006331220615805208\n",
      "Epoch 75 num_samples 16200 loss 0.009578224814491349\n",
      "Epoch 75 num_samples 16300 loss 0.011003388556708378\n",
      "Epoch 75 num_samples 16400 loss 0.011283903464622708\n",
      "Epoch 75 num_samples 16500 loss 0.009617393564022095\n",
      "Epoch 75 num_samples 16600 loss 0.010722773731331849\n",
      "Epoch 75 num_samples 16700 loss 0.005949599135121157\n",
      "Epoch 75 num_samples 16800 loss 0.00602370109925593\n",
      "Epoch 75 num_samples 16900 loss 0.007005814705260682\n",
      "Epoch 75 num_samples 17000 loss 0.005387244298732302\n",
      "Epoch 75 num_samples 17100 loss 0.013459457789328695\n",
      "Epoch 75 num_samples 17200 loss 0.00950291256720766\n",
      "Epoch 75 num_samples 17300 loss 0.009637255169801195\n",
      "Epoch 75 num_samples 17400 loss 0.008408838254454312\n",
      "Epoch 75 num_samples 17500 loss 0.008682228639075876\n",
      "Epoch 75 num_samples 17600 loss 0.0077830401694697375\n",
      "Epoch 75 num_samples 17700 loss 0.0065206107493367685\n",
      "Epoch 75 num_samples 17800 loss 0.007012696071219135\n",
      "Epoch 75 num_samples 17900 loss 0.010843633712309541\n",
      "Epoch 75 num_samples 18000 loss 0.007871476401686521\n",
      "Epoch 75 num_samples 18100 loss 0.008653548369269242\n",
      "Epoch 75 num_samples 18200 loss 0.00922327306484158\n",
      "Epoch 75 num_samples 18300 loss 0.006811968640705235\n",
      "Epoch 75 num_samples 18400 loss 0.013008875105225592\n",
      "Epoch 75 num_samples 18500 loss 0.009405236615103757\n",
      "Epoch 76 num_samples 0 loss 0.0064794732896596855\n",
      "Epoch 76 num_samples 100 loss 0.011489176191422389\n",
      "Epoch 76 num_samples 200 loss 0.007654710394514372\n",
      "Epoch 76 num_samples 300 loss 0.006493161633023028\n",
      "Epoch 76 num_samples 400 loss 0.007784573736042257\n",
      "Epoch 76 num_samples 500 loss 0.011745687929480095\n",
      "Epoch 76 num_samples 600 loss 0.011620177876367372\n",
      "Epoch 76 num_samples 700 loss 0.012479781757060139\n",
      "Epoch 76 num_samples 800 loss 0.007306315042727697\n",
      "Epoch 76 num_samples 900 loss 0.013015126089156772\n",
      "Epoch 76 num_samples 1000 loss 0.007815948579063682\n",
      "Epoch 76 num_samples 1100 loss 0.012947270931531871\n",
      "Epoch 76 num_samples 1200 loss 0.007733051710327574\n",
      "Epoch 76 num_samples 1300 loss 0.009149168336250721\n",
      "Epoch 76 num_samples 1400 loss 0.009217095853108967\n",
      "Epoch 76 num_samples 1500 loss 0.011037305586490393\n",
      "Epoch 76 num_samples 1600 loss 0.008083459719552759\n",
      "Epoch 76 num_samples 1700 loss 0.007790390908430356\n",
      "Epoch 76 num_samples 1800 loss 0.007648712189344603\n",
      "Epoch 76 num_samples 1900 loss 0.00913292935099393\n",
      "Epoch 76 num_samples 2000 loss 0.010770316692355673\n",
      "Epoch 76 num_samples 2100 loss 0.005686868471094193\n",
      "Epoch 76 num_samples 2200 loss 0.006379666401812627\n",
      "Epoch 76 num_samples 2300 loss 0.004299031788914723\n",
      "Epoch 76 num_samples 2400 loss 0.007132985506474154\n",
      "Epoch 76 num_samples 2500 loss 0.00960561645514035\n",
      "Epoch 76 num_samples 2600 loss 0.010465999852993856\n",
      "Epoch 76 num_samples 2700 loss 0.007380754928107906\n",
      "Epoch 76 num_samples 2800 loss 0.010304143157292653\n",
      "Epoch 76 num_samples 2900 loss 0.009546816698599577\n",
      "Epoch 76 num_samples 3000 loss 0.00795176960761302\n",
      "Epoch 76 num_samples 3100 loss 0.007665042416011534\n",
      "Epoch 76 num_samples 3200 loss 0.013214618951172352\n",
      "Epoch 76 num_samples 3300 loss 0.00869951847412379\n",
      "Epoch 76 num_samples 3400 loss 0.006975216893289895\n",
      "Epoch 76 num_samples 3500 loss 0.007255982601611913\n",
      "Epoch 76 num_samples 3600 loss 0.005494298353599747\n",
      "Epoch 76 num_samples 3700 loss 0.012627429625347499\n",
      "Epoch 76 num_samples 3800 loss 0.006921304375233413\n",
      "Epoch 76 num_samples 3900 loss 0.008629578712175139\n",
      "Epoch 76 num_samples 4000 loss 0.009424052350672382\n",
      "Epoch 76 num_samples 4100 loss 0.012008926687543926\n",
      "Epoch 76 num_samples 4200 loss 0.008926326481849331\n",
      "Epoch 76 num_samples 4300 loss 0.007819711249775946\n",
      "Epoch 76 num_samples 4400 loss 0.009019333753176676\n",
      "Epoch 76 num_samples 4500 loss 0.01101901502918952\n",
      "Epoch 76 num_samples 4600 loss 0.009525781509291278\n",
      "Epoch 76 num_samples 4700 loss 0.005472909500422337\n",
      "Epoch 76 num_samples 4800 loss 0.005793792240331323\n",
      "Epoch 76 num_samples 4900 loss 0.007412789750670592\n",
      "Epoch 76 num_samples 5000 loss 0.006500238304593539\n",
      "Epoch 76 num_samples 5100 loss 0.011618085802218282\n",
      "Epoch 76 num_samples 5200 loss 0.005703805583875078\n",
      "Epoch 76 num_samples 5300 loss 0.007803261714679435\n",
      "Epoch 76 num_samples 5400 loss 0.010675260103506572\n",
      "Epoch 76 num_samples 5500 loss 0.006430281202413252\n",
      "Epoch 76 num_samples 5600 loss 0.021497828043122863\n",
      "Epoch 76 num_samples 5700 loss 0.008311281532597966\n",
      "Epoch 76 num_samples 5800 loss 0.008060325403772653\n",
      "Epoch 76 num_samples 5900 loss 0.010298281415381891\n",
      "Epoch 76 num_samples 6000 loss 0.008376765422067379\n",
      "Epoch 76 num_samples 6100 loss 0.007777128433326671\n",
      "Epoch 76 num_samples 6200 loss 0.00885857335162638\n",
      "Epoch 76 num_samples 6300 loss 0.0109222782603484\n",
      "Epoch 76 num_samples 6400 loss 0.007015897331745113\n",
      "Epoch 76 num_samples 6500 loss 0.006111050158025111\n",
      "Epoch 76 num_samples 6600 loss 0.014256443167872444\n",
      "Epoch 76 num_samples 6700 loss 0.007182463530463886\n",
      "Epoch 76 num_samples 6800 loss 0.0045976796151120805\n",
      "Epoch 76 num_samples 6900 loss 0.017384487402585084\n",
      "Epoch 76 num_samples 7000 loss 0.010321892016701067\n",
      "Epoch 76 num_samples 7100 loss 0.005795566721025227\n",
      "Epoch 76 num_samples 7200 loss 0.0083234298339164\n",
      "Epoch 76 num_samples 7300 loss 0.0083986837915961\n",
      "Epoch 76 num_samples 7400 loss 0.006200878314951085\n",
      "Epoch 76 num_samples 7500 loss 0.01288039403637577\n",
      "Epoch 76 num_samples 7600 loss 0.008684159517821049\n",
      "Epoch 76 num_samples 7700 loss 0.011748810796822917\n",
      "Epoch 76 num_samples 7800 loss 0.007237928657124479\n",
      "Epoch 76 num_samples 7900 loss 0.00889198038974205\n",
      "Epoch 76 num_samples 8000 loss 0.005868408221489557\n",
      "Epoch 76 num_samples 8100 loss 0.007728581987871244\n",
      "Epoch 76 num_samples 8200 loss 0.009090039504955261\n",
      "Epoch 76 num_samples 8300 loss 0.007067421777337396\n",
      "Epoch 76 num_samples 8400 loss 0.005817150368008296\n",
      "Epoch 76 num_samples 8500 loss 0.008628436905005706\n",
      "Epoch 76 num_samples 8600 loss 0.008514394988958729\n",
      "Epoch 76 num_samples 8700 loss 0.008469781081566305\n",
      "Epoch 76 num_samples 8800 loss 0.008300027519075113\n",
      "Epoch 76 num_samples 8900 loss 0.010124428441940734\n",
      "Epoch 76 num_samples 9000 loss 0.008523473416769447\n",
      "Epoch 76 num_samples 9100 loss 0.008220038976496435\n",
      "Epoch 76 num_samples 9200 loss 0.008970399938035237\n",
      "Epoch 76 num_samples 9300 loss 0.008614593840563645\n",
      "Epoch 76 num_samples 9400 loss 0.007233318958240683\n",
      "Epoch 76 num_samples 9500 loss 0.007170724831506545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 num_samples 9600 loss 0.007859045547853797\n",
      "Epoch 76 num_samples 9700 loss 0.011923896438570532\n",
      "Epoch 76 num_samples 9800 loss 0.005244621473950379\n",
      "Epoch 76 num_samples 9900 loss 0.01538441532459922\n",
      "Epoch 76 num_samples 10000 loss 0.007105415859192765\n",
      "Epoch 76 num_samples 10100 loss 0.006498623671108879\n",
      "Epoch 76 num_samples 10200 loss 0.010105489153499719\n",
      "Epoch 76 num_samples 10300 loss 0.008175861314811845\n",
      "Epoch 76 num_samples 10400 loss 0.010848083575590266\n",
      "Epoch 76 num_samples 10500 loss 0.007693227021887852\n",
      "Epoch 76 num_samples 10600 loss 0.009563516399158834\n",
      "Epoch 76 num_samples 10700 loss 0.007406738923368576\n",
      "Epoch 76 num_samples 10800 loss 0.009559107964224479\n",
      "Epoch 76 num_samples 10900 loss 0.007197436126877347\n",
      "Epoch 76 num_samples 11000 loss 0.006628316396150948\n",
      "Epoch 76 num_samples 11100 loss 0.008846285064862222\n",
      "Epoch 76 num_samples 11200 loss 0.006874100634325244\n",
      "Epoch 76 num_samples 11300 loss 0.011266931489578079\n",
      "Epoch 76 num_samples 11400 loss 0.007740299447239513\n",
      "Epoch 76 num_samples 11500 loss 0.007424590854489985\n",
      "Epoch 76 num_samples 11600 loss 0.007294628317186275\n",
      "Epoch 76 num_samples 11700 loss 0.009986430812459873\n",
      "Epoch 76 num_samples 11800 loss 0.007337376279803276\n",
      "Epoch 76 num_samples 11900 loss 0.0064153324733523046\n",
      "Epoch 76 num_samples 12000 loss 0.005641708438034395\n",
      "Epoch 76 num_samples 12100 loss 0.006359558195844099\n",
      "Epoch 76 num_samples 12200 loss 0.009157990394415547\n",
      "Epoch 76 num_samples 12300 loss 0.006585663968328911\n",
      "Epoch 76 num_samples 12400 loss 0.010283885935375582\n",
      "Epoch 76 num_samples 12500 loss 0.009080423600953317\n",
      "Epoch 76 num_samples 12600 loss 0.011248287500263387\n",
      "Epoch 76 num_samples 12700 loss 0.008305268068116862\n",
      "Epoch 76 num_samples 12800 loss 0.012909256498070525\n",
      "Epoch 76 num_samples 12900 loss 0.007260168084920768\n",
      "Epoch 76 num_samples 13000 loss 0.006906077136468394\n",
      "Epoch 76 num_samples 13100 loss 0.010875806816813674\n",
      "Epoch 76 num_samples 13200 loss 0.004748432432917801\n",
      "Epoch 76 num_samples 13300 loss 0.006509205204039719\n",
      "Epoch 76 num_samples 13400 loss 0.004366044721367631\n",
      "Epoch 76 num_samples 13500 loss 0.006040874721383202\n",
      "Epoch 76 num_samples 13600 loss 0.010817376392603965\n",
      "Epoch 76 num_samples 13700 loss 0.007912370428401448\n",
      "Epoch 76 num_samples 13800 loss 0.0076598956587673375\n",
      "Epoch 76 num_samples 13900 loss 0.003240933556210192\n",
      "Epoch 76 num_samples 14000 loss 0.005615077990005281\n",
      "Epoch 76 num_samples 14100 loss 0.007392611137544145\n",
      "Epoch 76 num_samples 14200 loss 0.006746247146179992\n",
      "Epoch 76 num_samples 14300 loss 0.008919103574887281\n",
      "Epoch 76 num_samples 14400 loss 0.008973014299704332\n",
      "Epoch 76 num_samples 14500 loss 0.01099774720449778\n",
      "Epoch 76 num_samples 14600 loss 0.007635041737637786\n",
      "Epoch 76 num_samples 14700 loss 0.008182963340079313\n",
      "Epoch 76 num_samples 14800 loss 0.007792933814386194\n",
      "Epoch 76 num_samples 14900 loss 0.00916422465998632\n",
      "Epoch 76 num_samples 15000 loss 0.007724212935494539\n",
      "Epoch 76 num_samples 15100 loss 0.008546095251030655\n",
      "Epoch 76 num_samples 15200 loss 0.008329686655065805\n",
      "Epoch 76 num_samples 15300 loss 0.008783680191120545\n",
      "Epoch 76 num_samples 15400 loss 0.006194079209759066\n",
      "Epoch 76 num_samples 15500 loss 0.008482295225866021\n",
      "Epoch 76 num_samples 15600 loss 0.008984192851118336\n",
      "Epoch 76 num_samples 15700 loss 0.005924972553191323\n",
      "Epoch 76 num_samples 15800 loss 0.009807656338310385\n",
      "Epoch 76 num_samples 15900 loss 0.006391818045064863\n",
      "Epoch 76 num_samples 16000 loss 0.011838428534139932\n",
      "Epoch 76 num_samples 16100 loss 0.006219382707279376\n",
      "Epoch 76 num_samples 16200 loss 0.009320053530910553\n",
      "Epoch 76 num_samples 16300 loss 0.010738182048468934\n",
      "Epoch 76 num_samples 16400 loss 0.010970803275161698\n",
      "Epoch 76 num_samples 16500 loss 0.009410619474576302\n",
      "Epoch 76 num_samples 16600 loss 0.010479148827665262\n",
      "Epoch 76 num_samples 16700 loss 0.0057964582611931695\n",
      "Epoch 76 num_samples 16800 loss 0.005900517820508944\n",
      "Epoch 76 num_samples 16900 loss 0.006832771051279221\n",
      "Epoch 76 num_samples 17000 loss 0.005264948497419748\n",
      "Epoch 76 num_samples 17100 loss 0.013122421680529356\n",
      "Epoch 76 num_samples 17200 loss 0.009274157461238828\n",
      "Epoch 76 num_samples 17300 loss 0.009426382224561169\n",
      "Epoch 76 num_samples 17400 loss 0.008196887130530607\n",
      "Epoch 76 num_samples 17500 loss 0.00849026356208715\n",
      "Epoch 76 num_samples 17600 loss 0.007603986780778426\n",
      "Epoch 76 num_samples 17700 loss 0.006379168893244593\n",
      "Epoch 76 num_samples 17800 loss 0.006857639232890175\n",
      "Epoch 76 num_samples 17900 loss 0.010568126908899175\n",
      "Epoch 76 num_samples 18000 loss 0.007715505127723066\n",
      "Epoch 76 num_samples 18100 loss 0.008457469816241148\n",
      "Epoch 76 num_samples 18200 loss 0.009055037233641932\n",
      "Epoch 76 num_samples 18300 loss 0.006651280679974456\n",
      "Epoch 76 num_samples 18400 loss 0.012672719651180674\n",
      "Epoch 76 num_samples 18500 loss 0.009192606831232564\n",
      "Epoch 77 num_samples 0 loss 0.0063429772634995074\n",
      "Epoch 77 num_samples 100 loss 0.011245559972747924\n",
      "Epoch 77 num_samples 200 loss 0.0074620891711572775\n",
      "Epoch 77 num_samples 300 loss 0.006362048953362771\n",
      "Epoch 77 num_samples 400 loss 0.0075954419522074445\n",
      "Epoch 77 num_samples 500 loss 0.011455541577525733\n",
      "Epoch 77 num_samples 600 loss 0.011358084774444333\n",
      "Epoch 77 num_samples 700 loss 0.0122129153842499\n",
      "Epoch 77 num_samples 800 loss 0.0071429659308677885\n",
      "Epoch 77 num_samples 900 loss 0.012712682690069272\n",
      "Epoch 77 num_samples 1000 loss 0.007645909106455958\n",
      "Epoch 77 num_samples 1100 loss 0.012614659324155685\n",
      "Epoch 77 num_samples 1200 loss 0.007567702716183632\n",
      "Epoch 77 num_samples 1300 loss 0.008958612725776057\n",
      "Epoch 77 num_samples 1400 loss 0.009032005525857388\n",
      "Epoch 77 num_samples 1500 loss 0.01074312652436627\n",
      "Epoch 77 num_samples 1600 loss 0.007907658876367742\n",
      "Epoch 77 num_samples 1700 loss 0.007636897994550177\n",
      "Epoch 77 num_samples 1800 loss 0.007487347507078098\n",
      "Epoch 77 num_samples 1900 loss 0.008938576219277627\n",
      "Epoch 77 num_samples 2000 loss 0.010534922631574352\n",
      "Epoch 77 num_samples 2100 loss 0.005564480759835508\n",
      "Epoch 77 num_samples 2200 loss 0.0062705961769946\n",
      "Epoch 77 num_samples 2300 loss 0.0042006548003062786\n",
      "Epoch 77 num_samples 2400 loss 0.006965854628048127\n",
      "Epoch 77 num_samples 2500 loss 0.00935509463488135\n",
      "Epoch 77 num_samples 2600 loss 0.010222310291167323\n",
      "Epoch 77 num_samples 2700 loss 0.0071933260435167925\n",
      "Epoch 77 num_samples 2800 loss 0.01006982973054226\n",
      "Epoch 77 num_samples 2900 loss 0.009315032792258555\n",
      "Epoch 77 num_samples 3000 loss 0.007748271866882437\n",
      "Epoch 77 num_samples 3100 loss 0.007490034075182874\n",
      "Epoch 77 num_samples 3200 loss 0.012840522034598241\n",
      "Epoch 77 num_samples 3300 loss 0.008421254231027455\n",
      "Epoch 77 num_samples 3400 loss 0.006784078780274151\n",
      "Epoch 77 num_samples 3500 loss 0.007096199344731028\n",
      "Epoch 77 num_samples 3600 loss 0.005406086429086768\n",
      "Epoch 77 num_samples 3700 loss 0.012323210750555336\n",
      "Epoch 77 num_samples 3800 loss 0.006747915499898794\n",
      "Epoch 77 num_samples 3900 loss 0.008454979485658013\n",
      "Epoch 77 num_samples 4000 loss 0.009210853302398\n",
      "Epoch 77 num_samples 4100 loss 0.011704164605776208\n",
      "Epoch 77 num_samples 4200 loss 0.008778843324364198\n",
      "Epoch 77 num_samples 4300 loss 0.007642394054929222\n",
      "Epoch 77 num_samples 4400 loss 0.008803743459682076\n",
      "Epoch 77 num_samples 4500 loss 0.010731800995635792\n",
      "Epoch 77 num_samples 4600 loss 0.009298452350700238\n",
      "Epoch 77 num_samples 4700 loss 0.005359619109703618\n",
      "Epoch 77 num_samples 4800 loss 0.005670369901932207\n",
      "Epoch 77 num_samples 4900 loss 0.007239685339023479\n",
      "Epoch 77 num_samples 5000 loss 0.006368966221002631\n",
      "Epoch 77 num_samples 5100 loss 0.011377149527249459\n",
      "Epoch 77 num_samples 5200 loss 0.005558826434777713\n",
      "Epoch 77 num_samples 5300 loss 0.007607979601673975\n",
      "Epoch 77 num_samples 5400 loss 0.010398331288884241\n",
      "Epoch 77 num_samples 5500 loss 0.006307814336236201\n",
      "Epoch 77 num_samples 5600 loss 0.02080824705691371\n",
      "Epoch 77 num_samples 5700 loss 0.00806591927616616\n",
      "Epoch 77 num_samples 5800 loss 0.00787374030252648\n",
      "Epoch 77 num_samples 5900 loss 0.010031569839890628\n",
      "Epoch 77 num_samples 6000 loss 0.008148913520587622\n",
      "Epoch 77 num_samples 6100 loss 0.007598803167472453\n",
      "Epoch 77 num_samples 6200 loss 0.008626503683561106\n",
      "Epoch 77 num_samples 6300 loss 0.010674259520919445\n",
      "Epoch 77 num_samples 6400 loss 0.006892468790963479\n",
      "Epoch 77 num_samples 6500 loss 0.005968410063993648\n",
      "Epoch 77 num_samples 6600 loss 0.0139271797056742\n",
      "Epoch 77 num_samples 6700 loss 0.007031757031575681\n",
      "Epoch 77 num_samples 6800 loss 0.004500152492334463\n",
      "Epoch 77 num_samples 6900 loss 0.017024556721794447\n",
      "Epoch 77 num_samples 7000 loss 0.010099466111404325\n",
      "Epoch 77 num_samples 7100 loss 0.005662597135601302\n",
      "Epoch 77 num_samples 7200 loss 0.008157130495687176\n",
      "Epoch 77 num_samples 7300 loss 0.008257025849928466\n",
      "Epoch 77 num_samples 7400 loss 0.00608876707868627\n",
      "Epoch 77 num_samples 7500 loss 0.012546014619660626\n",
      "Epoch 77 num_samples 7600 loss 0.008527338464476605\n",
      "Epoch 77 num_samples 7700 loss 0.011460429046118817\n",
      "Epoch 77 num_samples 7800 loss 0.007045825723507586\n",
      "Epoch 77 num_samples 7900 loss 0.008713134255732904\n",
      "Epoch 77 num_samples 8000 loss 0.005749297457100957\n",
      "Epoch 77 num_samples 8100 loss 0.007532933149889216\n",
      "Epoch 77 num_samples 8200 loss 0.008902130814973127\n",
      "Epoch 77 num_samples 8300 loss 0.006833579256887129\n",
      "Epoch 77 num_samples 8400 loss 0.0056803022414923755\n",
      "Epoch 77 num_samples 8500 loss 0.00839119391758605\n",
      "Epoch 77 num_samples 8600 loss 0.008316225134122938\n",
      "Epoch 77 num_samples 8700 loss 0.00827596029064169\n",
      "Epoch 77 num_samples 8800 loss 0.008059411196131383\n",
      "Epoch 77 num_samples 8900 loss 0.00985097875272631\n",
      "Epoch 77 num_samples 9000 loss 0.008290597967155342\n",
      "Epoch 77 num_samples 9100 loss 0.008029444824434557\n",
      "Epoch 77 num_samples 9200 loss 0.008742613424693934\n",
      "Epoch 77 num_samples 9300 loss 0.008433772127907095\n",
      "Epoch 77 num_samples 9400 loss 0.0070743828581203115\n",
      "Epoch 77 num_samples 9500 loss 0.006964633054725186\n",
      "Epoch 77 num_samples 9600 loss 0.007650988802228353\n",
      "Epoch 77 num_samples 9700 loss 0.011566066651627049\n",
      "Epoch 77 num_samples 9800 loss 0.005126542693132206\n",
      "Epoch 77 num_samples 9900 loss 0.015028699528148838\n",
      "Epoch 77 num_samples 10000 loss 0.006923632724902738\n",
      "Epoch 77 num_samples 10100 loss 0.006333882346913954\n",
      "Epoch 77 num_samples 10200 loss 0.009884254417275947\n",
      "Epoch 77 num_samples 10300 loss 0.008007956997190474\n",
      "Epoch 77 num_samples 10400 loss 0.010617870264059843\n",
      "Epoch 77 num_samples 10500 loss 0.007537325831263322\n",
      "Epoch 77 num_samples 10600 loss 0.009323084038724989\n",
      "Epoch 77 num_samples 10700 loss 0.007203706596571293\n",
      "Epoch 77 num_samples 10800 loss 0.009347400717670547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 num_samples 10900 loss 0.007037156966267447\n",
      "Epoch 77 num_samples 11000 loss 0.006486350004920918\n",
      "Epoch 77 num_samples 11100 loss 0.008632371689605102\n",
      "Epoch 77 num_samples 11200 loss 0.006745546674059802\n",
      "Epoch 77 num_samples 11300 loss 0.01101736713965057\n",
      "Epoch 77 num_samples 11400 loss 0.007548447752583393\n",
      "Epoch 77 num_samples 11500 loss 0.007250000778546512\n",
      "Epoch 77 num_samples 11600 loss 0.00712637588405921\n",
      "Epoch 77 num_samples 11700 loss 0.009780531867474723\n",
      "Epoch 77 num_samples 11800 loss 0.007140791506283701\n",
      "Epoch 77 num_samples 11900 loss 0.006281749412763138\n",
      "Epoch 77 num_samples 12000 loss 0.0055133862622831886\n",
      "Epoch 77 num_samples 12100 loss 0.006217093266783064\n",
      "Epoch 77 num_samples 12200 loss 0.00890900352475057\n",
      "Epoch 77 num_samples 12300 loss 0.006472642580509883\n",
      "Epoch 77 num_samples 12400 loss 0.010041904599681479\n",
      "Epoch 77 num_samples 12500 loss 0.008923977292504225\n",
      "Epoch 77 num_samples 12600 loss 0.01096688609437126\n",
      "Epoch 77 num_samples 12700 loss 0.008148613737368223\n",
      "Epoch 77 num_samples 12800 loss 0.012593544299151365\n",
      "Epoch 77 num_samples 12900 loss 0.007086103363092242\n",
      "Epoch 77 num_samples 13000 loss 0.006718134971277414\n",
      "Epoch 77 num_samples 13100 loss 0.010632358772002935\n",
      "Epoch 77 num_samples 13200 loss 0.00462315288341769\n",
      "Epoch 77 num_samples 13300 loss 0.006382749453123628\n",
      "Epoch 77 num_samples 13400 loss 0.004258466446477758\n",
      "Epoch 77 num_samples 13500 loss 0.0058947134875032\n",
      "Epoch 77 num_samples 13600 loss 0.010582827185833261\n",
      "Epoch 77 num_samples 13700 loss 0.007698580759080048\n",
      "Epoch 77 num_samples 13800 loss 0.007524780861517948\n",
      "Epoch 77 num_samples 13900 loss 0.0031609126364687736\n",
      "Epoch 77 num_samples 14000 loss 0.005466397122355637\n",
      "Epoch 77 num_samples 14100 loss 0.007220946088848656\n",
      "Epoch 77 num_samples 14200 loss 0.0066205546621042\n",
      "Epoch 77 num_samples 14300 loss 0.008721763585316615\n",
      "Epoch 77 num_samples 14400 loss 0.00875963094156244\n",
      "Epoch 77 num_samples 14500 loss 0.010740503323311303\n",
      "Epoch 77 num_samples 14600 loss 0.0074446741426750914\n",
      "Epoch 77 num_samples 14700 loss 0.007998129173522195\n",
      "Epoch 77 num_samples 14800 loss 0.007627908030620716\n",
      "Epoch 77 num_samples 14900 loss 0.008945352087728313\n",
      "Epoch 77 num_samples 15000 loss 0.007571361140404843\n",
      "Epoch 77 num_samples 15100 loss 0.008345769761319463\n",
      "Epoch 77 num_samples 15200 loss 0.008103580987607044\n",
      "Epoch 77 num_samples 15300 loss 0.008575667898166545\n",
      "Epoch 77 num_samples 15400 loss 0.006061457243694592\n",
      "Epoch 77 num_samples 15500 loss 0.00828328355630342\n",
      "Epoch 77 num_samples 15600 loss 0.008790317252077748\n",
      "Epoch 77 num_samples 15700 loss 0.005795027019760102\n",
      "Epoch 77 num_samples 15800 loss 0.009537439960810874\n",
      "Epoch 77 num_samples 15900 loss 0.0062501764518090005\n",
      "Epoch 77 num_samples 16000 loss 0.011544869124706803\n",
      "Epoch 77 num_samples 16100 loss 0.0060831894023160825\n",
      "Epoch 77 num_samples 16200 loss 0.009099703968852936\n",
      "Epoch 77 num_samples 16300 loss 0.010482021724264809\n",
      "Epoch 77 num_samples 16400 loss 0.010704769798858363\n",
      "Epoch 77 num_samples 16500 loss 0.00916717198694994\n",
      "Epoch 77 num_samples 16600 loss 0.010230760666538066\n",
      "Epoch 77 num_samples 16700 loss 0.005703404304814289\n",
      "Epoch 77 num_samples 16800 loss 0.005763337882702307\n",
      "Epoch 77 num_samples 16900 loss 0.0066742060930338794\n",
      "Epoch 77 num_samples 17000 loss 0.005136271153969063\n",
      "Epoch 77 num_samples 17100 loss 0.012790451656012418\n",
      "Epoch 77 num_samples 17200 loss 0.009055122249283643\n",
      "Epoch 77 num_samples 17300 loss 0.009211534827448823\n",
      "Epoch 77 num_samples 17400 loss 0.008005178829960009\n",
      "Epoch 77 num_samples 17500 loss 0.008313763868933798\n",
      "Epoch 77 num_samples 17600 loss 0.007426282940431692\n",
      "Epoch 77 num_samples 17700 loss 0.006246890331458175\n",
      "Epoch 77 num_samples 17800 loss 0.006684139506619362\n",
      "Epoch 77 num_samples 17900 loss 0.01032565331872495\n",
      "Epoch 77 num_samples 18000 loss 0.0075349690442091544\n",
      "Epoch 77 num_samples 18100 loss 0.008273013829250098\n",
      "Epoch 77 num_samples 18200 loss 0.008853109524215528\n",
      "Epoch 77 num_samples 18300 loss 0.006497709004920615\n",
      "Epoch 77 num_samples 18400 loss 0.012362787402638006\n",
      "Epoch 77 num_samples 18500 loss 0.0090090329280401\n",
      "Epoch 78 num_samples 0 loss 0.006220142361310914\n",
      "Epoch 78 num_samples 100 loss 0.010983197861864231\n",
      "Epoch 78 num_samples 200 loss 0.0073134893331943665\n",
      "Epoch 78 num_samples 300 loss 0.006191552306193659\n",
      "Epoch 78 num_samples 400 loss 0.0074327246480810705\n",
      "Epoch 78 num_samples 500 loss 0.011287056631947824\n",
      "Epoch 78 num_samples 600 loss 0.011029955556997722\n",
      "Epoch 78 num_samples 700 loss 0.011902775635818905\n",
      "Epoch 78 num_samples 800 loss 0.006999272841188476\n",
      "Epoch 78 num_samples 900 loss 0.012467215755390058\n",
      "Epoch 78 num_samples 1000 loss 0.007451833054104005\n",
      "Epoch 78 num_samples 1100 loss 0.012324346993443123\n",
      "Epoch 78 num_samples 1200 loss 0.007396904109629565\n",
      "Epoch 78 num_samples 1300 loss 0.008753482855947398\n",
      "Epoch 78 num_samples 1400 loss 0.00879223923081509\n",
      "Epoch 78 num_samples 1500 loss 0.010493367354236147\n",
      "Epoch 78 num_samples 1600 loss 0.00771000411373789\n",
      "Epoch 78 num_samples 1700 loss 0.007458072235051971\n",
      "Epoch 78 num_samples 1800 loss 0.0073317713268162745\n",
      "Epoch 78 num_samples 1900 loss 0.008737608133919848\n",
      "Epoch 78 num_samples 2000 loss 0.010298469476383328\n",
      "Epoch 78 num_samples 2100 loss 0.005412635295711752\n",
      "Epoch 78 num_samples 2200 loss 0.006135415388526331\n",
      "Epoch 78 num_samples 2300 loss 0.004101856804871703\n",
      "Epoch 78 num_samples 2400 loss 0.006803375669310103\n",
      "Epoch 78 num_samples 2500 loss 0.009142345588337859\n",
      "Epoch 78 num_samples 2600 loss 0.009953856867561648\n",
      "Epoch 78 num_samples 2700 loss 0.007061590380757328\n",
      "Epoch 78 num_samples 2800 loss 0.009859265248409332\n",
      "Epoch 78 num_samples 2900 loss 0.009110544232279815\n",
      "Epoch 78 num_samples 3000 loss 0.007567082598460125\n",
      "Epoch 78 num_samples 3100 loss 0.0073261774616773774\n",
      "Epoch 78 num_samples 3200 loss 0.012503493394129967\n",
      "Epoch 78 num_samples 3300 loss 0.008240616047706073\n",
      "Epoch 78 num_samples 3400 loss 0.006641470464007375\n",
      "Epoch 78 num_samples 3500 loss 0.006941203220568844\n",
      "Epoch 78 num_samples 3600 loss 0.005287832388086479\n",
      "Epoch 78 num_samples 3700 loss 0.011988814615841038\n",
      "Epoch 78 num_samples 3800 loss 0.006547062723162535\n",
      "Epoch 78 num_samples 3900 loss 0.008227781712389429\n",
      "Epoch 78 num_samples 4000 loss 0.00899288200148864\n",
      "Epoch 78 num_samples 4100 loss 0.011409419746750533\n",
      "Epoch 78 num_samples 4200 loss 0.008552339037456773\n",
      "Epoch 78 num_samples 4300 loss 0.007461690017421293\n",
      "Epoch 78 num_samples 4400 loss 0.008586334516751441\n",
      "Epoch 78 num_samples 4500 loss 0.010466419299324124\n",
      "Epoch 78 num_samples 4600 loss 0.00909492618221331\n",
      "Epoch 78 num_samples 4700 loss 0.005197076634632432\n",
      "Epoch 78 num_samples 4800 loss 0.005544413172916732\n",
      "Epoch 78 num_samples 4900 loss 0.007098704076457566\n",
      "Epoch 78 num_samples 5000 loss 0.0062261947811058805\n",
      "Epoch 78 num_samples 5100 loss 0.011125603517276731\n",
      "Epoch 78 num_samples 5200 loss 0.005446172337114792\n",
      "Epoch 78 num_samples 5300 loss 0.007416299999031037\n",
      "Epoch 78 num_samples 5400 loss 0.010141659616194365\n",
      "Epoch 78 num_samples 5500 loss 0.0061703636884758795\n",
      "Epoch 78 num_samples 5600 loss 0.020222576409733718\n",
      "Epoch 78 num_samples 5700 loss 0.007871217903904387\n",
      "Epoch 78 num_samples 5800 loss 0.007703812289962169\n",
      "Epoch 78 num_samples 5900 loss 0.00984410665216942\n",
      "Epoch 78 num_samples 6000 loss 0.008005196550428017\n",
      "Epoch 78 num_samples 6100 loss 0.007440231906300907\n",
      "Epoch 78 num_samples 6200 loss 0.008435188783226223\n",
      "Epoch 78 num_samples 6300 loss 0.010409279251711116\n",
      "Epoch 78 num_samples 6400 loss 0.006717845914849967\n",
      "Epoch 78 num_samples 6500 loss 0.005828576292930477\n",
      "Epoch 78 num_samples 6600 loss 0.013626451527936925\n",
      "Epoch 78 num_samples 6700 loss 0.006894256650164101\n",
      "Epoch 78 num_samples 6800 loss 0.00440442975034624\n",
      "Epoch 78 num_samples 6900 loss 0.016655562911442302\n",
      "Epoch 78 num_samples 7000 loss 0.00987715949420885\n",
      "Epoch 78 num_samples 7100 loss 0.00551716327929273\n",
      "Epoch 78 num_samples 7200 loss 0.007981071369141883\n",
      "Epoch 78 num_samples 7300 loss 0.008091060208225921\n",
      "Epoch 78 num_samples 7400 loss 0.005959064219765211\n",
      "Epoch 78 num_samples 7500 loss 0.012222902175016488\n",
      "Epoch 78 num_samples 7600 loss 0.008331019651000566\n",
      "Epoch 78 num_samples 7700 loss 0.011186436464863093\n",
      "Epoch 78 num_samples 7800 loss 0.0069090938395245\n",
      "Epoch 78 num_samples 7900 loss 0.008553002944423469\n",
      "Epoch 78 num_samples 8000 loss 0.005627358309672191\n",
      "Epoch 78 num_samples 8100 loss 0.007361034664987695\n",
      "Epoch 78 num_samples 8200 loss 0.00871764265260734\n",
      "Epoch 78 num_samples 8300 loss 0.0067342198504644355\n",
      "Epoch 78 num_samples 8400 loss 0.0055450320767125435\n",
      "Epoch 78 num_samples 8500 loss 0.008229214397926671\n",
      "Epoch 78 num_samples 8600 loss 0.008127659993931552\n",
      "Epoch 78 num_samples 8700 loss 0.008092621563299674\n",
      "Epoch 78 num_samples 8800 loss 0.007882518864134524\n",
      "Epoch 78 num_samples 8900 loss 0.009661903638678944\n",
      "Epoch 78 num_samples 9000 loss 0.00814462447841256\n",
      "Epoch 78 num_samples 9100 loss 0.007855797966397246\n",
      "Epoch 78 num_samples 9200 loss 0.008577786628967082\n",
      "Epoch 78 num_samples 9300 loss 0.008253237157520276\n",
      "Epoch 78 num_samples 9400 loss 0.006944587172395287\n",
      "Epoch 78 num_samples 9500 loss 0.0067753441882427755\n",
      "Epoch 78 num_samples 9600 loss 0.007487790991613722\n",
      "Epoch 78 num_samples 9700 loss 0.011247351210199747\n",
      "Epoch 78 num_samples 9800 loss 0.005014568976995097\n",
      "Epoch 78 num_samples 9900 loss 0.014682896708430015\n",
      "Epoch 78 num_samples 10000 loss 0.006761053747242991\n",
      "Epoch 78 num_samples 10100 loss 0.006194183789826362\n",
      "Epoch 78 num_samples 10200 loss 0.009636704984494699\n",
      "Epoch 78 num_samples 10300 loss 0.007882503927448364\n",
      "Epoch 78 num_samples 10400 loss 0.010376929525806098\n",
      "Epoch 78 num_samples 10500 loss 0.007383834486200867\n",
      "Epoch 78 num_samples 10600 loss 0.009098495347630247\n",
      "Epoch 78 num_samples 10700 loss 0.00703165759870695\n",
      "Epoch 78 num_samples 10800 loss 0.009143725034276271\n",
      "Epoch 78 num_samples 10900 loss 0.006864976247108425\n",
      "Epoch 78 num_samples 11000 loss 0.0063308752969252115\n",
      "Epoch 78 num_samples 11100 loss 0.00843434146276077\n",
      "Epoch 78 num_samples 11200 loss 0.006597411519814813\n",
      "Epoch 78 num_samples 11300 loss 0.010752771946165314\n",
      "Epoch 78 num_samples 11400 loss 0.0073706449170213625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 num_samples 11500 loss 0.007090135499288317\n",
      "Epoch 78 num_samples 11600 loss 0.006953421669186603\n",
      "Epoch 78 num_samples 11700 loss 0.009518655589816358\n",
      "Epoch 78 num_samples 11800 loss 0.006993691638215993\n",
      "Epoch 78 num_samples 11900 loss 0.006124570665494176\n",
      "Epoch 78 num_samples 12000 loss 0.005389222322487365\n",
      "Epoch 78 num_samples 12100 loss 0.006092954583288588\n",
      "Epoch 78 num_samples 12200 loss 0.008692704607319414\n",
      "Epoch 78 num_samples 12300 loss 0.006310592286008749\n",
      "Epoch 78 num_samples 12400 loss 0.009811524300601086\n",
      "Epoch 78 num_samples 12500 loss 0.008693426273357596\n",
      "Epoch 78 num_samples 12600 loss 0.01072285250629784\n",
      "Epoch 78 num_samples 12700 loss 0.007915333768628392\n",
      "Epoch 78 num_samples 12800 loss 0.0122832440335633\n",
      "Epoch 78 num_samples 12900 loss 0.00692784404082738\n",
      "Epoch 78 num_samples 13000 loss 0.006574789844991523\n",
      "Epoch 78 num_samples 13100 loss 0.01034019901047468\n",
      "Epoch 78 num_samples 13200 loss 0.004537348579566772\n",
      "Epoch 78 num_samples 13300 loss 0.006246468772357491\n",
      "Epoch 78 num_samples 13400 loss 0.0041638960542159376\n",
      "Epoch 78 num_samples 13500 loss 0.005752651517954959\n",
      "Epoch 78 num_samples 13600 loss 0.010365153337086916\n",
      "Epoch 78 num_samples 13700 loss 0.007575757726565585\n",
      "Epoch 78 num_samples 13800 loss 0.007366448976620921\n",
      "Epoch 78 num_samples 13900 loss 0.0030953218669122094\n",
      "Epoch 78 num_samples 14000 loss 0.005360833353103083\n",
      "Epoch 78 num_samples 14100 loss 0.0070622170731699675\n",
      "Epoch 78 num_samples 14200 loss 0.006486579878465805\n",
      "Epoch 78 num_samples 14300 loss 0.008549092172678132\n",
      "Epoch 78 num_samples 14400 loss 0.008577828594582716\n",
      "Epoch 78 num_samples 14500 loss 0.010557901087500298\n",
      "Epoch 78 num_samples 14600 loss 0.007246698981164248\n",
      "Epoch 78 num_samples 14700 loss 0.007801523894861233\n",
      "Epoch 78 num_samples 14800 loss 0.007479549158460274\n",
      "Epoch 78 num_samples 14900 loss 0.008747808605349598\n",
      "Epoch 78 num_samples 15000 loss 0.007421911637244709\n",
      "Epoch 78 num_samples 15100 loss 0.00815764350349116\n",
      "Epoch 78 num_samples 15200 loss 0.007913178221578172\n",
      "Epoch 78 num_samples 15300 loss 0.008378354378471958\n",
      "Epoch 78 num_samples 15400 loss 0.005948729255543263\n",
      "Epoch 78 num_samples 15500 loss 0.008071434924132172\n",
      "Epoch 78 num_samples 15600 loss 0.008627819121366285\n",
      "Epoch 78 num_samples 15700 loss 0.0056570796589523265\n",
      "Epoch 78 num_samples 15800 loss 0.009365240002132662\n",
      "Epoch 78 num_samples 15900 loss 0.006132213835106986\n",
      "Epoch 78 num_samples 16000 loss 0.01129669546875118\n",
      "Epoch 78 num_samples 16100 loss 0.005946564300407447\n",
      "Epoch 78 num_samples 16200 loss 0.00888213791949146\n",
      "Epoch 78 num_samples 16300 loss 0.01025322918030081\n",
      "Epoch 78 num_samples 16400 loss 0.010461732828136299\n",
      "Epoch 78 num_samples 16500 loss 0.008980345243671617\n",
      "Epoch 78 num_samples 16600 loss 0.010023343304164158\n",
      "Epoch 78 num_samples 16700 loss 0.005583116582558531\n",
      "Epoch 78 num_samples 16800 loss 0.005658223669352401\n",
      "Epoch 78 num_samples 16900 loss 0.006522716456059428\n",
      "Epoch 78 num_samples 17000 loss 0.005023496758406692\n",
      "Epoch 78 num_samples 17100 loss 0.012506063850401525\n",
      "Epoch 78 num_samples 17200 loss 0.008844475157220139\n",
      "Epoch 78 num_samples 17300 loss 0.009013325304120766\n",
      "Epoch 78 num_samples 17400 loss 0.00779825515613624\n",
      "Epoch 78 num_samples 17500 loss 0.008148611200052109\n",
      "Epoch 78 num_samples 17600 loss 0.007264468155143752\n",
      "Epoch 78 num_samples 17700 loss 0.006120553985002419\n",
      "Epoch 78 num_samples 17800 loss 0.006544989243114132\n",
      "Epoch 78 num_samples 17900 loss 0.010047442985191512\n",
      "Epoch 78 num_samples 18000 loss 0.007391371312975819\n",
      "Epoch 78 num_samples 18100 loss 0.008094444019743225\n",
      "Epoch 78 num_samples 18200 loss 0.008645552399899292\n",
      "Epoch 78 num_samples 18300 loss 0.006350639505563726\n",
      "Epoch 78 num_samples 18400 loss 0.012049724345639463\n",
      "Epoch 78 num_samples 18500 loss 0.008783452705771501\n",
      "Epoch 79 num_samples 0 loss 0.0060777297871546735\n",
      "Epoch 79 num_samples 100 loss 0.010698079635250806\n",
      "Epoch 79 num_samples 200 loss 0.007157922552424645\n",
      "Epoch 79 num_samples 300 loss 0.0060707244933725325\n",
      "Epoch 79 num_samples 400 loss 0.007299747087586512\n",
      "Epoch 79 num_samples 500 loss 0.010975604262465508\n",
      "Epoch 79 num_samples 600 loss 0.010769910147260774\n",
      "Epoch 79 num_samples 700 loss 0.01164776736891009\n",
      "Epoch 79 num_samples 800 loss 0.006833235566125707\n",
      "Epoch 79 num_samples 900 loss 0.012179366065306443\n",
      "Epoch 79 num_samples 1000 loss 0.007276262709107844\n",
      "Epoch 79 num_samples 1100 loss 0.012049352705439598\n",
      "Epoch 79 num_samples 1200 loss 0.007255369425909208\n",
      "Epoch 79 num_samples 1300 loss 0.00857574962863462\n",
      "Epoch 79 num_samples 1400 loss 0.008594523574833136\n",
      "Epoch 79 num_samples 1500 loss 0.010194567942268308\n",
      "Epoch 79 num_samples 1600 loss 0.0075287631940419006\n",
      "Epoch 79 num_samples 1700 loss 0.007284883594360225\n",
      "Epoch 79 num_samples 1800 loss 0.007177705860203055\n",
      "Epoch 79 num_samples 1900 loss 0.008528806088595289\n",
      "Epoch 79 num_samples 2000 loss 0.010107551340672608\n",
      "Epoch 79 num_samples 2100 loss 0.005305013477505964\n",
      "Epoch 79 num_samples 2200 loss 0.005980152116645899\n",
      "Epoch 79 num_samples 2300 loss 0.0040122095554271375\n",
      "Epoch 79 num_samples 2400 loss 0.006657357231689753\n",
      "Epoch 79 num_samples 2500 loss 0.008915134293088935\n",
      "Epoch 79 num_samples 2600 loss 0.009770394426783983\n",
      "Epoch 79 num_samples 2700 loss 0.006907114581260214\n",
      "Epoch 79 num_samples 2800 loss 0.009633333780856132\n",
      "Epoch 79 num_samples 2900 loss 0.008905429685434974\n",
      "Epoch 79 num_samples 3000 loss 0.007402603031914976\n",
      "Epoch 79 num_samples 3100 loss 0.0071541574656615115\n",
      "Epoch 79 num_samples 3200 loss 0.012158039356544213\n",
      "Epoch 79 num_samples 3300 loss 0.008026631112613323\n",
      "Epoch 79 num_samples 3400 loss 0.006481608154720355\n",
      "Epoch 79 num_samples 3500 loss 0.006801546502768919\n",
      "Epoch 79 num_samples 3600 loss 0.005199671587519554\n",
      "Epoch 79 num_samples 3700 loss 0.011727806237643943\n",
      "Epoch 79 num_samples 3800 loss 0.00641549735418752\n",
      "Epoch 79 num_samples 3900 loss 0.00807009541965154\n",
      "Epoch 79 num_samples 4000 loss 0.00879477210799949\n",
      "Epoch 79 num_samples 4100 loss 0.011142947402823058\n",
      "Epoch 79 num_samples 4200 loss 0.008377943826568845\n",
      "Epoch 79 num_samples 4300 loss 0.007301593898854035\n",
      "Epoch 79 num_samples 4400 loss 0.008389882656386023\n",
      "Epoch 79 num_samples 4500 loss 0.010178367888245327\n",
      "Epoch 79 num_samples 4600 loss 0.008876666311098534\n",
      "Epoch 79 num_samples 4700 loss 0.005109223272759506\n",
      "Epoch 79 num_samples 4800 loss 0.0054505977899002725\n",
      "Epoch 79 num_samples 4900 loss 0.006949537701322309\n",
      "Epoch 79 num_samples 5000 loss 0.006088339191787298\n",
      "Epoch 79 num_samples 5100 loss 0.010908014361034194\n",
      "Epoch 79 num_samples 5200 loss 0.005341279288885602\n",
      "Epoch 79 num_samples 5300 loss 0.007286027907441992\n",
      "Epoch 79 num_samples 5400 loss 0.009944299121737584\n",
      "Epoch 79 num_samples 5500 loss 0.006044090380678003\n",
      "Epoch 79 num_samples 5600 loss 0.01964151508084293\n",
      "Epoch 79 num_samples 5700 loss 0.007682597811205287\n",
      "Epoch 79 num_samples 5800 loss 0.007541860063610992\n",
      "Epoch 79 num_samples 5900 loss 0.009573765439175696\n",
      "Epoch 79 num_samples 6000 loss 0.00781561242040511\n",
      "Epoch 79 num_samples 6100 loss 0.007280738205388446\n",
      "Epoch 79 num_samples 6200 loss 0.008246355122494964\n",
      "Epoch 79 num_samples 6300 loss 0.010125534742229063\n",
      "Epoch 79 num_samples 6400 loss 0.0065767280220458925\n",
      "Epoch 79 num_samples 6500 loss 0.0057070196688648565\n",
      "Epoch 79 num_samples 6600 loss 0.013369863185819291\n",
      "Epoch 79 num_samples 6700 loss 0.006744540086989601\n",
      "Epoch 79 num_samples 6800 loss 0.004311017153163466\n",
      "Epoch 79 num_samples 6900 loss 0.01628841294047423\n",
      "Epoch 79 num_samples 7000 loss 0.009651094285648323\n",
      "Epoch 79 num_samples 7100 loss 0.005416378839915574\n",
      "Epoch 79 num_samples 7200 loss 0.007784448691653961\n",
      "Epoch 79 num_samples 7300 loss 0.00792167436417517\n",
      "Epoch 79 num_samples 7400 loss 0.005852452793555934\n",
      "Epoch 79 num_samples 7500 loss 0.011910323993529955\n",
      "Epoch 79 num_samples 7600 loss 0.00811818593908227\n",
      "Epoch 79 num_samples 7700 loss 0.010920121888902906\n",
      "Epoch 79 num_samples 7800 loss 0.006740843492027402\n",
      "Epoch 79 num_samples 7900 loss 0.008344575774870983\n",
      "Epoch 79 num_samples 8000 loss 0.0054871104640570375\n",
      "Epoch 79 num_samples 8100 loss 0.007210800959846279\n",
      "Epoch 79 num_samples 8200 loss 0.008519325685200491\n",
      "Epoch 79 num_samples 8300 loss 0.00653437936863808\n",
      "Epoch 79 num_samples 8400 loss 0.005400347157936256\n",
      "Epoch 79 num_samples 8500 loss 0.008016725935556301\n",
      "Epoch 79 num_samples 8600 loss 0.007965870100065891\n",
      "Epoch 79 num_samples 8700 loss 0.007909354064518658\n",
      "Epoch 79 num_samples 8800 loss 0.0077136091182903625\n",
      "Epoch 79 num_samples 8900 loss 0.009437457996462909\n",
      "Epoch 79 num_samples 9000 loss 0.007982107571926904\n",
      "Epoch 79 num_samples 9100 loss 0.007696621522613812\n",
      "Epoch 79 num_samples 9200 loss 0.008395787780892167\n",
      "Epoch 79 num_samples 9300 loss 0.00809983993034831\n",
      "Epoch 79 num_samples 9400 loss 0.006754611930377661\n",
      "Epoch 79 num_samples 9500 loss 0.006673788290455201\n",
      "Epoch 79 num_samples 9600 loss 0.007366262765605075\n",
      "Epoch 79 num_samples 9700 loss 0.010873705354336153\n",
      "Epoch 79 num_samples 9800 loss 0.004918898581680815\n",
      "Epoch 79 num_samples 9900 loss 0.014307029130819991\n",
      "Epoch 79 num_samples 10000 loss 0.00661355866746232\n",
      "Epoch 79 num_samples 10100 loss 0.006052254770346846\n",
      "Epoch 79 num_samples 10200 loss 0.00943080040849683\n",
      "Epoch 79 num_samples 10300 loss 0.007687589741337156\n",
      "Epoch 79 num_samples 10400 loss 0.01021412953768627\n",
      "Epoch 79 num_samples 10500 loss 0.007245067581762279\n",
      "Epoch 79 num_samples 10600 loss 0.008836570659137526\n",
      "Epoch 79 num_samples 10700 loss 0.0068585457111262895\n",
      "Epoch 79 num_samples 10800 loss 0.008929365816157067\n",
      "Epoch 79 num_samples 10900 loss 0.006711470396274412\n",
      "Epoch 79 num_samples 11000 loss 0.00617623465128061\n",
      "Epoch 79 num_samples 11100 loss 0.008271020156344414\n",
      "Epoch 79 num_samples 11200 loss 0.0064471100951751965\n",
      "Epoch 79 num_samples 11300 loss 0.01048444734552592\n",
      "Epoch 79 num_samples 11400 loss 0.0072272332192879415\n",
      "Epoch 79 num_samples 11500 loss 0.0069202304515435555\n",
      "Epoch 79 num_samples 11600 loss 0.006815823675006922\n",
      "Epoch 79 num_samples 11700 loss 0.00929019716222497\n",
      "Epoch 79 num_samples 11800 loss 0.006860394231598803\n",
      "Epoch 79 num_samples 11900 loss 0.0059941753814110686\n",
      "Epoch 79 num_samples 12000 loss 0.005252565754679\n",
      "Epoch 79 num_samples 12100 loss 0.005916372109228074\n",
      "Epoch 79 num_samples 12200 loss 0.008505453124317521\n",
      "Epoch 79 num_samples 12300 loss 0.00618049070305497\n",
      "Epoch 79 num_samples 12400 loss 0.009590535576328808\n",
      "Epoch 79 num_samples 12500 loss 0.008485011890712801\n",
      "Epoch 79 num_samples 12600 loss 0.01055308639371342\n",
      "Epoch 79 num_samples 12700 loss 0.007764377826768844\n",
      "Epoch 79 num_samples 12800 loss 0.01201720862316775\n",
      "Epoch 79 num_samples 12900 loss 0.006768015355939252\n",
      "Epoch 79 num_samples 13000 loss 0.006432597353132262\n",
      "Epoch 79 num_samples 13100 loss 0.010111191047991101\n",
      "Epoch 79 num_samples 13200 loss 0.00443193082059869\n",
      "Epoch 79 num_samples 13300 loss 0.006127218283846043\n",
      "Epoch 79 num_samples 13400 loss 0.004067000700453884\n",
      "Epoch 79 num_samples 13500 loss 0.005629606217978033\n",
      "Epoch 79 num_samples 13600 loss 0.01012737523734709\n",
      "Epoch 79 num_samples 13700 loss 0.007378755454034142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 num_samples 13800 loss 0.00720656131851225\n",
      "Epoch 79 num_samples 13900 loss 0.003031737976980075\n",
      "Epoch 79 num_samples 14000 loss 0.0052379766273160724\n",
      "Epoch 79 num_samples 14100 loss 0.006895997180119059\n",
      "Epoch 79 num_samples 14200 loss 0.006377197837604954\n",
      "Epoch 79 num_samples 14300 loss 0.008327424798416121\n",
      "Epoch 79 num_samples 14400 loss 0.008359608077530771\n",
      "Epoch 79 num_samples 14500 loss 0.01030476719172247\n",
      "Epoch 79 num_samples 14600 loss 0.00708198226785189\n",
      "Epoch 79 num_samples 14700 loss 0.007622543288671415\n",
      "Epoch 79 num_samples 14800 loss 0.007335359840150133\n",
      "Epoch 79 num_samples 14900 loss 0.008557345138172592\n",
      "Epoch 79 num_samples 15000 loss 0.007255593595770936\n",
      "Epoch 79 num_samples 15100 loss 0.007968814269272782\n",
      "Epoch 79 num_samples 15200 loss 0.007740761396697795\n",
      "Epoch 79 num_samples 15300 loss 0.008209839873335255\n",
      "Epoch 79 num_samples 15400 loss 0.00583911449891199\n",
      "Epoch 79 num_samples 15500 loss 0.007859272904487485\n",
      "Epoch 79 num_samples 15600 loss 0.008386406726613869\n",
      "Epoch 79 num_samples 15700 loss 0.005548212169958057\n",
      "Epoch 79 num_samples 15800 loss 0.009120076818301025\n",
      "Epoch 79 num_samples 15900 loss 0.006001529382717608\n",
      "Epoch 79 num_samples 16000 loss 0.011030588842910093\n",
      "Epoch 79 num_samples 16100 loss 0.005818864788148358\n",
      "Epoch 79 num_samples 16200 loss 0.008693816434053047\n",
      "Epoch 79 num_samples 16300 loss 0.01002341953871853\n",
      "Epoch 79 num_samples 16400 loss 0.010214107277390107\n",
      "Epoch 79 num_samples 16500 loss 0.008753627454690239\n",
      "Epoch 79 num_samples 16600 loss 0.009781388332619467\n",
      "Epoch 79 num_samples 16700 loss 0.005463362131589972\n",
      "Epoch 79 num_samples 16800 loss 0.005535279681682832\n",
      "Epoch 79 num_samples 16900 loss 0.006386865528099401\n",
      "Epoch 79 num_samples 17000 loss 0.004919657945972636\n",
      "Epoch 79 num_samples 17100 loss 0.012208400535528347\n",
      "Epoch 79 num_samples 17200 loss 0.008663611302634341\n",
      "Epoch 79 num_samples 17300 loss 0.00880347066914332\n",
      "Epoch 79 num_samples 17400 loss 0.00759445195196729\n",
      "Epoch 79 num_samples 17500 loss 0.007980682141943255\n",
      "Epoch 79 num_samples 17600 loss 0.00708937684061181\n",
      "Epoch 79 num_samples 17700 loss 0.0059980328191117935\n",
      "Epoch 79 num_samples 17800 loss 0.006381391062580733\n",
      "Epoch 79 num_samples 17900 loss 0.009822591163219352\n",
      "Epoch 79 num_samples 18000 loss 0.00722723932341018\n",
      "Epoch 79 num_samples 18100 loss 0.00790951255056007\n",
      "Epoch 79 num_samples 18200 loss 0.008505559917922581\n",
      "Epoch 79 num_samples 18300 loss 0.006219560359109355\n",
      "Epoch 79 num_samples 18400 loss 0.011804971761193968\n",
      "Epoch 79 num_samples 18500 loss 0.008598324533344904\n",
      "Epoch 80 num_samples 0 loss 0.005965916574446997\n",
      "Epoch 80 num_samples 100 loss 0.010483767351197064\n",
      "Epoch 80 num_samples 200 loss 0.006991078478145813\n",
      "Epoch 80 num_samples 300 loss 0.005937410508327609\n",
      "Epoch 80 num_samples 400 loss 0.007140837363781071\n",
      "Epoch 80 num_samples 500 loss 0.010789342254004288\n",
      "Epoch 80 num_samples 600 loss 0.010514215020145197\n",
      "Epoch 80 num_samples 700 loss 0.011397883212323899\n",
      "Epoch 80 num_samples 800 loss 0.0066815613931821075\n",
      "Epoch 80 num_samples 900 loss 0.011919715850986118\n",
      "Epoch 80 num_samples 1000 loss 0.007102373040855397\n",
      "Epoch 80 num_samples 1100 loss 0.011785773625046937\n",
      "Epoch 80 num_samples 1200 loss 0.007093347348377643\n",
      "Epoch 80 num_samples 1300 loss 0.008377976852855691\n",
      "Epoch 80 num_samples 1400 loss 0.008397754358301599\n",
      "Epoch 80 num_samples 1500 loss 0.00994717238153628\n",
      "Epoch 80 num_samples 1600 loss 0.007384477158066391\n",
      "Epoch 80 num_samples 1700 loss 0.007133508964978723\n",
      "Epoch 80 num_samples 1800 loss 0.007032720651506046\n",
      "Epoch 80 num_samples 1900 loss 0.008404246562731182\n",
      "Epoch 80 num_samples 2000 loss 0.009882667326128492\n",
      "Epoch 80 num_samples 2100 loss 0.005187604128429519\n",
      "Epoch 80 num_samples 2200 loss 0.005877080567178956\n",
      "Epoch 80 num_samples 2300 loss 0.003929603131533838\n",
      "Epoch 80 num_samples 2400 loss 0.006505515500973411\n",
      "Epoch 80 num_samples 2500 loss 0.008751659293381736\n",
      "Epoch 80 num_samples 2600 loss 0.00952813822065197\n",
      "Epoch 80 num_samples 2700 loss 0.006769023151825981\n",
      "Epoch 80 num_samples 2800 loss 0.009401381410561847\n",
      "Epoch 80 num_samples 2900 loss 0.008734104783232131\n",
      "Epoch 80 num_samples 3000 loss 0.0072109445707955865\n",
      "Epoch 80 num_samples 3100 loss 0.006967850049948904\n",
      "Epoch 80 num_samples 3200 loss 0.011855630856858925\n",
      "Epoch 80 num_samples 3300 loss 0.007817356885043503\n",
      "Epoch 80 num_samples 3400 loss 0.006344213608937643\n",
      "Epoch 80 num_samples 3500 loss 0.006641916275405268\n",
      "Epoch 80 num_samples 3600 loss 0.005090311233308275\n",
      "Epoch 80 num_samples 3700 loss 0.011445031151427677\n",
      "Epoch 80 num_samples 3800 loss 0.006252061347988585\n",
      "Epoch 80 num_samples 3900 loss 0.007888919059992668\n",
      "Epoch 80 num_samples 4000 loss 0.008586597884881517\n",
      "Epoch 80 num_samples 4100 loss 0.010873433645424807\n",
      "Epoch 80 num_samples 4200 loss 0.008152972593666808\n",
      "Epoch 80 num_samples 4300 loss 0.007122617672048082\n",
      "Epoch 80 num_samples 4400 loss 0.008177436217387398\n",
      "Epoch 80 num_samples 4500 loss 0.009976219716659991\n",
      "Epoch 80 num_samples 4600 loss 0.008700630065455512\n",
      "Epoch 80 num_samples 4700 loss 0.004972837691516999\n",
      "Epoch 80 num_samples 4800 loss 0.005324765822982335\n",
      "Epoch 80 num_samples 4900 loss 0.006813791969380461\n",
      "Epoch 80 num_samples 5000 loss 0.005986267081871702\n",
      "Epoch 80 num_samples 5100 loss 0.010651576159926589\n",
      "Epoch 80 num_samples 5200 loss 0.005232337072873201\n",
      "Epoch 80 num_samples 5300 loss 0.0071122916019186345\n",
      "Epoch 80 num_samples 5400 loss 0.009745198692714379\n",
      "Epoch 80 num_samples 5500 loss 0.005903850082878876\n",
      "Epoch 80 num_samples 5600 loss 0.019193028548578437\n",
      "Epoch 80 num_samples 5700 loss 0.007524493713020875\n",
      "Epoch 80 num_samples 5800 loss 0.007403317045668253\n",
      "Epoch 80 num_samples 5900 loss 0.009366173547751702\n",
      "Epoch 80 num_samples 6000 loss 0.0076229093937600755\n",
      "Epoch 80 num_samples 6100 loss 0.007129908501827458\n",
      "Epoch 80 num_samples 6200 loss 0.00806718020574485\n",
      "Epoch 80 num_samples 6300 loss 0.009909589342758532\n",
      "Epoch 80 num_samples 6400 loss 0.006434573958607783\n",
      "Epoch 80 num_samples 6500 loss 0.005581497040066159\n",
      "Epoch 80 num_samples 6600 loss 0.013073196762731458\n",
      "Epoch 80 num_samples 6700 loss 0.006646528156828366\n",
      "Epoch 80 num_samples 6800 loss 0.0042085331590691645\n",
      "Epoch 80 num_samples 6900 loss 0.015936699948442518\n",
      "Epoch 80 num_samples 7000 loss 0.009420066458534146\n",
      "Epoch 80 num_samples 7100 loss 0.005312323893189921\n",
      "Epoch 80 num_samples 7200 loss 0.007612056869071051\n",
      "Epoch 80 num_samples 7300 loss 0.007750043969448852\n",
      "Epoch 80 num_samples 7400 loss 0.005754230873855242\n",
      "Epoch 80 num_samples 7500 loss 0.01160184052294161\n",
      "Epoch 80 num_samples 7600 loss 0.00793103350168578\n",
      "Epoch 80 num_samples 7700 loss 0.010678654850511038\n",
      "Epoch 80 num_samples 7800 loss 0.006581275799847265\n",
      "Epoch 80 num_samples 7900 loss 0.008193053889577896\n",
      "Epoch 80 num_samples 8000 loss 0.005382430887402513\n",
      "Epoch 80 num_samples 8100 loss 0.007057886057861128\n",
      "Epoch 80 num_samples 8200 loss 0.008298336744583723\n",
      "Epoch 80 num_samples 8300 loss 0.006400054720624773\n",
      "Epoch 80 num_samples 8400 loss 0.005289772454659871\n",
      "Epoch 80 num_samples 8500 loss 0.007897139037186007\n",
      "Epoch 80 num_samples 8600 loss 0.007747520851623227\n",
      "Epoch 80 num_samples 8700 loss 0.00777437395917212\n",
      "Epoch 80 num_samples 8800 loss 0.0075426496699931775\n",
      "Epoch 80 num_samples 8900 loss 0.00921560920592487\n",
      "Epoch 80 num_samples 9000 loss 0.0077815577232345804\n",
      "Epoch 80 num_samples 9100 loss 0.0075161727017125845\n",
      "Epoch 80 num_samples 9200 loss 0.008237813047642407\n",
      "Epoch 80 num_samples 9300 loss 0.00790351398688425\n",
      "Epoch 80 num_samples 9400 loss 0.006637708699482987\n",
      "Epoch 80 num_samples 9500 loss 0.0065031881458800615\n",
      "Epoch 80 num_samples 9600 loss 0.007176192325772486\n",
      "Epoch 80 num_samples 9700 loss 0.010633625343180145\n",
      "Epoch 80 num_samples 9800 loss 0.004783282688188883\n",
      "Epoch 80 num_samples 9900 loss 0.014003650862153112\n",
      "Epoch 80 num_samples 10000 loss 0.006451598572847691\n",
      "Epoch 80 num_samples 10100 loss 0.005931936843847766\n",
      "Epoch 80 num_samples 10200 loss 0.009207421891822056\n",
      "Epoch 80 num_samples 10300 loss 0.00751408090018791\n",
      "Epoch 80 num_samples 10400 loss 0.009974396475197152\n",
      "Epoch 80 num_samples 10500 loss 0.00709626568378644\n",
      "Epoch 80 num_samples 10600 loss 0.008667027018966626\n",
      "Epoch 80 num_samples 10700 loss 0.006699346816364488\n",
      "Epoch 80 num_samples 10800 loss 0.008726274283504233\n",
      "Epoch 80 num_samples 10900 loss 0.006570072960580178\n",
      "Epoch 80 num_samples 11000 loss 0.006085025971565984\n",
      "Epoch 80 num_samples 11100 loss 0.008120076294965752\n",
      "Epoch 80 num_samples 11200 loss 0.006307251109606917\n",
      "Epoch 80 num_samples 11300 loss 0.010262658928460202\n",
      "Epoch 80 num_samples 11400 loss 0.007042677055341756\n",
      "Epoch 80 num_samples 11500 loss 0.006756078927501456\n",
      "Epoch 80 num_samples 11600 loss 0.006686454195014984\n",
      "Epoch 80 num_samples 11700 loss 0.009080717188891828\n",
      "Epoch 80 num_samples 11800 loss 0.006708823963534569\n",
      "Epoch 80 num_samples 11900 loss 0.005862761770757139\n",
      "Epoch 80 num_samples 12000 loss 0.005148483738567023\n",
      "Epoch 80 num_samples 12100 loss 0.005800080593515349\n",
      "Epoch 80 num_samples 12200 loss 0.008272263458591757\n",
      "Epoch 80 num_samples 12300 loss 0.006049263834837575\n",
      "Epoch 80 num_samples 12400 loss 0.009371963809464668\n",
      "Epoch 80 num_samples 12500 loss 0.008302443593556995\n",
      "Epoch 80 num_samples 12600 loss 0.010309052553158176\n",
      "Epoch 80 num_samples 12700 loss 0.00757268726893621\n",
      "Epoch 80 num_samples 12800 loss 0.011663712136611324\n",
      "Epoch 80 num_samples 12900 loss 0.006621362474119996\n",
      "Epoch 80 num_samples 13000 loss 0.006281532796957239\n",
      "Epoch 80 num_samples 13100 loss 0.009892235559816212\n",
      "Epoch 80 num_samples 13200 loss 0.0043289527469437365\n",
      "Epoch 80 num_samples 13300 loss 0.006003408505046282\n",
      "Epoch 80 num_samples 13400 loss 0.004000909116958562\n",
      "Epoch 80 num_samples 13500 loss 0.005509371950148242\n",
      "Epoch 80 num_samples 13600 loss 0.009911599437023234\n",
      "Epoch 80 num_samples 13700 loss 0.007220011592760755\n",
      "Epoch 80 num_samples 13800 loss 0.00705538930085298\n",
      "Epoch 80 num_samples 13900 loss 0.0029669593641592474\n",
      "Epoch 80 num_samples 14000 loss 0.005109257237090798\n",
      "Epoch 80 num_samples 14100 loss 0.0067337935313937945\n",
      "Epoch 80 num_samples 14200 loss 0.0062562265730978115\n",
      "Epoch 80 num_samples 14300 loss 0.00815006262823509\n",
      "Epoch 80 num_samples 14400 loss 0.008176885108539849\n",
      "Epoch 80 num_samples 14500 loss 0.010107419225824331\n",
      "Epoch 80 num_samples 14600 loss 0.006906095737150144\n",
      "Epoch 80 num_samples 14700 loss 0.007472697158240053\n",
      "Epoch 80 num_samples 14800 loss 0.007178675053135524\n",
      "Epoch 80 num_samples 14900 loss 0.00837278412667149\n",
      "Epoch 80 num_samples 15000 loss 0.007114536381630336\n",
      "Epoch 80 num_samples 15100 loss 0.007782749691475743\n",
      "Epoch 80 num_samples 15200 loss 0.007558681613606861\n",
      "Epoch 80 num_samples 15300 loss 0.008045310339920585\n",
      "Epoch 80 num_samples 15400 loss 0.005714920697959757\n",
      "Epoch 80 num_samples 15500 loss 0.007685095671750345\n",
      "Epoch 80 num_samples 15600 loss 0.008194164366354098\n",
      "Epoch 80 num_samples 15700 loss 0.0054347561635392505\n",
      "Epoch 80 num_samples 15800 loss 0.00889432316123033\n",
      "Epoch 80 num_samples 15900 loss 0.005913543815997738\n",
      "Epoch 80 num_samples 16000 loss 0.010811737901987932\n",
      "Epoch 80 num_samples 16100 loss 0.005721602785090347\n",
      "Epoch 80 num_samples 16200 loss 0.008498130140908548\n",
      "Epoch 80 num_samples 16300 loss 0.009801918568149768\n",
      "Epoch 80 num_samples 16400 loss 0.009969363398875946\n",
      "Epoch 80 num_samples 16500 loss 0.008553471228542551\n",
      "Epoch 80 num_samples 16600 loss 0.009606406588670484\n",
      "Epoch 80 num_samples 16700 loss 0.005329949590952301\n",
      "Epoch 80 num_samples 16800 loss 0.005407381690571811\n",
      "Epoch 80 num_samples 16900 loss 0.006230847188154449\n",
      "Epoch 80 num_samples 17000 loss 0.004812936287534008\n",
      "Epoch 80 num_samples 17100 loss 0.01190632863525353\n",
      "Epoch 80 num_samples 17200 loss 0.008453408453985149\n",
      "Epoch 80 num_samples 17300 loss 0.008602067820638127\n",
      "Epoch 80 num_samples 17400 loss 0.007427222185105149\n",
      "Epoch 80 num_samples 17500 loss 0.007810831081604788\n",
      "Epoch 80 num_samples 17600 loss 0.006939838268144465\n",
      "Epoch 80 num_samples 17700 loss 0.005865018301371789\n",
      "Epoch 80 num_samples 17800 loss 0.006251381761779986\n",
      "Epoch 80 num_samples 17900 loss 0.009598477563033638\n",
      "Epoch 80 num_samples 18000 loss 0.007079838746975919\n",
      "Epoch 80 num_samples 18100 loss 0.007761297925045815\n",
      "Epoch 80 num_samples 18200 loss 0.008307427401930157\n",
      "Epoch 80 num_samples 18300 loss 0.006087758841087668\n",
      "Epoch 80 num_samples 18400 loss 0.011534352533743814\n",
      "Epoch 80 num_samples 18500 loss 0.00842180909191794\n",
      "Epoch 81 num_samples 0 loss 0.005831633457049822\n",
      "Epoch 81 num_samples 100 loss 0.01025094234111454\n",
      "Epoch 81 num_samples 200 loss 0.006828948476567833\n",
      "Epoch 81 num_samples 300 loss 0.005807702862696009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 num_samples 400 loss 0.007003828243361473\n",
      "Epoch 81 num_samples 500 loss 0.010580419779350328\n",
      "Epoch 81 num_samples 600 loss 0.010297793855956612\n",
      "Epoch 81 num_samples 700 loss 0.011114056316879695\n",
      "Epoch 81 num_samples 800 loss 0.006545234052687155\n",
      "Epoch 81 num_samples 900 loss 0.011666517408207549\n",
      "Epoch 81 num_samples 1000 loss 0.006938909098573805\n",
      "Epoch 81 num_samples 1100 loss 0.011498495272738383\n",
      "Epoch 81 num_samples 1200 loss 0.006947748300900614\n",
      "Epoch 81 num_samples 1300 loss 0.00821779819520593\n",
      "Epoch 81 num_samples 1400 loss 0.008203784695646716\n",
      "Epoch 81 num_samples 1500 loss 0.009719409874876296\n",
      "Epoch 81 num_samples 1600 loss 0.007202811481060616\n",
      "Epoch 81 num_samples 1700 loss 0.006962697012495977\n",
      "Epoch 81 num_samples 1800 loss 0.006885049689610202\n",
      "Epoch 81 num_samples 1900 loss 0.008238992429782311\n",
      "Epoch 81 num_samples 2000 loss 0.009613180793033922\n",
      "Epoch 81 num_samples 2100 loss 0.005060017197382861\n",
      "Epoch 81 num_samples 2200 loss 0.005767342317110414\n",
      "Epoch 81 num_samples 2300 loss 0.003827428034805785\n",
      "Epoch 81 num_samples 2400 loss 0.006352680404505702\n",
      "Epoch 81 num_samples 2500 loss 0.008532642117130989\n",
      "Epoch 81 num_samples 2600 loss 0.009315975182008352\n",
      "Epoch 81 num_samples 2700 loss 0.006635850339705513\n",
      "Epoch 81 num_samples 2800 loss 0.009190440010302116\n",
      "Epoch 81 num_samples 2900 loss 0.00852851919518307\n",
      "Epoch 81 num_samples 3000 loss 0.007047792928467863\n",
      "Epoch 81 num_samples 3100 loss 0.006835932926924855\n",
      "Epoch 81 num_samples 3200 loss 0.011535080109287561\n",
      "Epoch 81 num_samples 3300 loss 0.007640439640426537\n",
      "Epoch 81 num_samples 3400 loss 0.006212577223111336\n",
      "Epoch 81 num_samples 3500 loss 0.006524391118964253\n",
      "Epoch 81 num_samples 3600 loss 0.005006242371160754\n",
      "Epoch 81 num_samples 3700 loss 0.011208718779337268\n",
      "Epoch 81 num_samples 3800 loss 0.006111008087500063\n",
      "Epoch 81 num_samples 3900 loss 0.007735965911249381\n",
      "Epoch 81 num_samples 4000 loss 0.008356880359427696\n",
      "Epoch 81 num_samples 4100 loss 0.010599461833647603\n",
      "Epoch 81 num_samples 4200 loss 0.008000963305614053\n",
      "Epoch 81 num_samples 4300 loss 0.0069702285553319455\n",
      "Epoch 81 num_samples 4400 loss 0.007985362914434047\n",
      "Epoch 81 num_samples 4500 loss 0.009754959790112892\n",
      "Epoch 81 num_samples 4600 loss 0.008509341413615845\n",
      "Epoch 81 num_samples 4700 loss 0.0048583044982942305\n",
      "Epoch 81 num_samples 4800 loss 0.005213982659127361\n",
      "Epoch 81 num_samples 4900 loss 0.006670225664253054\n",
      "Epoch 81 num_samples 5000 loss 0.005860930835491158\n",
      "Epoch 81 num_samples 5100 loss 0.010436047646344785\n",
      "Epoch 81 num_samples 5200 loss 0.005113683615645614\n",
      "Epoch 81 num_samples 5300 loss 0.006946607605937665\n",
      "Epoch 81 num_samples 5400 loss 0.009538594454745936\n",
      "Epoch 81 num_samples 5500 loss 0.00578651684835502\n",
      "Epoch 81 num_samples 5600 loss 0.018633758351834184\n",
      "Epoch 81 num_samples 5700 loss 0.00733678326213524\n",
      "Epoch 81 num_samples 5800 loss 0.007219634743483223\n",
      "Epoch 81 num_samples 5900 loss 0.009186509679249437\n",
      "Epoch 81 num_samples 6000 loss 0.00748008995841069\n",
      "Epoch 81 num_samples 6100 loss 0.0070002208071670395\n",
      "Epoch 81 num_samples 6200 loss 0.00787197737942919\n",
      "Epoch 81 num_samples 6300 loss 0.00968654203347542\n",
      "Epoch 81 num_samples 6400 loss 0.006292127133667391\n",
      "Epoch 81 num_samples 6500 loss 0.005455054041747669\n",
      "Epoch 81 num_samples 6600 loss 0.012824209349290978\n",
      "Epoch 81 num_samples 6700 loss 0.006512589044111655\n",
      "Epoch 81 num_samples 6800 loss 0.004125571904561667\n",
      "Epoch 81 num_samples 6900 loss 0.015610259709391788\n",
      "Epoch 81 num_samples 7000 loss 0.009247917373181475\n",
      "Epoch 81 num_samples 7100 loss 0.005199630762162157\n",
      "Epoch 81 num_samples 7200 loss 0.007471344710024535\n",
      "Epoch 81 num_samples 7300 loss 0.007607391536430485\n",
      "Epoch 81 num_samples 7400 loss 0.005623263343063852\n",
      "Epoch 81 num_samples 7500 loss 0.011312647746117914\n",
      "Epoch 81 num_samples 7600 loss 0.007767798689559711\n",
      "Epoch 81 num_samples 7700 loss 0.010423709361806685\n",
      "Epoch 81 num_samples 7800 loss 0.006442142467842278\n",
      "Epoch 81 num_samples 7900 loss 0.008008102693774015\n",
      "Epoch 81 num_samples 8000 loss 0.005270627132229268\n",
      "Epoch 81 num_samples 8100 loss 0.00687496436676566\n",
      "Epoch 81 num_samples 8200 loss 0.008148272088016243\n",
      "Epoch 81 num_samples 8300 loss 0.006281922426703421\n",
      "Epoch 81 num_samples 8400 loss 0.005178049122627898\n",
      "Epoch 81 num_samples 8500 loss 0.00774548155633018\n",
      "Epoch 81 num_samples 8600 loss 0.007582598454874935\n",
      "Epoch 81 num_samples 8700 loss 0.007584997842113982\n",
      "Epoch 81 num_samples 8800 loss 0.007351148985822656\n",
      "Epoch 81 num_samples 8900 loss 0.00902693038769259\n",
      "Epoch 81 num_samples 9000 loss 0.007649578586941459\n",
      "Epoch 81 num_samples 9100 loss 0.007355048416022628\n",
      "Epoch 81 num_samples 9200 loss 0.008074984039390857\n",
      "Epoch 81 num_samples 9300 loss 0.007780848229287456\n",
      "Epoch 81 num_samples 9400 loss 0.006474583326351735\n",
      "Epoch 81 num_samples 9500 loss 0.006388801299716005\n",
      "Epoch 81 num_samples 9600 loss 0.007094134992474611\n",
      "Epoch 81 num_samples 9700 loss 0.010316557156764248\n",
      "Epoch 81 num_samples 9800 loss 0.004695367557092889\n",
      "Epoch 81 num_samples 9900 loss 0.013684797667040213\n",
      "Epoch 81 num_samples 10000 loss 0.006291236865262715\n",
      "Epoch 81 num_samples 10100 loss 0.005791109270444874\n",
      "Epoch 81 num_samples 10200 loss 0.009012450388250385\n",
      "Epoch 81 num_samples 10300 loss 0.007376143080113375\n",
      "Epoch 81 num_samples 10400 loss 0.009794351416613991\n",
      "Epoch 81 num_samples 10500 loss 0.0070004031673841505\n",
      "Epoch 81 num_samples 10600 loss 0.008429688205343473\n",
      "Epoch 81 num_samples 10700 loss 0.006525097401765752\n",
      "Epoch 81 num_samples 10800 loss 0.008574085628538931\n",
      "Epoch 81 num_samples 10900 loss 0.006434077418309413\n",
      "Epoch 81 num_samples 11000 loss 0.005928946020513622\n",
      "Epoch 81 num_samples 11100 loss 0.007931437452141164\n",
      "Epoch 81 num_samples 11200 loss 0.006175305151355472\n",
      "Epoch 81 num_samples 11300 loss 0.010026893109772714\n",
      "Epoch 81 num_samples 11400 loss 0.006894320337348469\n",
      "Epoch 81 num_samples 11500 loss 0.006594090771895183\n",
      "Epoch 81 num_samples 11600 loss 0.006527668503309141\n",
      "Epoch 81 num_samples 11700 loss 0.008810019277775352\n",
      "Epoch 81 num_samples 11800 loss 0.006570745391598366\n",
      "Epoch 81 num_samples 11900 loss 0.005738129951585203\n",
      "Epoch 81 num_samples 12000 loss 0.005040133728299228\n",
      "Epoch 81 num_samples 12100 loss 0.0056841275485266405\n",
      "Epoch 81 num_samples 12200 loss 0.00810423097391015\n",
      "Epoch 81 num_samples 12300 loss 0.00592954309136987\n",
      "Epoch 81 num_samples 12400 loss 0.009162169794394003\n",
      "Epoch 81 num_samples 12500 loss 0.008161525425913892\n",
      "Epoch 81 num_samples 12600 loss 0.010103571329305148\n",
      "Epoch 81 num_samples 12700 loss 0.007437772557029876\n",
      "Epoch 81 num_samples 12800 loss 0.011444495071112218\n",
      "Epoch 81 num_samples 12900 loss 0.006479074628073718\n",
      "Epoch 81 num_samples 13000 loss 0.006165221880677549\n",
      "Epoch 81 num_samples 13100 loss 0.009602911967371786\n",
      "Epoch 81 num_samples 13200 loss 0.004239993947805907\n",
      "Epoch 81 num_samples 13300 loss 0.005868232538741731\n",
      "Epoch 81 num_samples 13400 loss 0.0038895418849399055\n",
      "Epoch 81 num_samples 13500 loss 0.0053741107364440955\n",
      "Epoch 81 num_samples 13600 loss 0.00970541329508082\n",
      "Epoch 81 num_samples 13700 loss 0.007083096349189328\n",
      "Epoch 81 num_samples 13800 loss 0.006926413858512976\n",
      "Epoch 81 num_samples 13900 loss 0.002905857752656469\n",
      "Epoch 81 num_samples 14000 loss 0.005019192212786244\n",
      "Epoch 81 num_samples 14100 loss 0.006589259545398776\n",
      "Epoch 81 num_samples 14200 loss 0.006141306149451808\n",
      "Epoch 81 num_samples 14300 loss 0.007976489501015215\n",
      "Epoch 81 num_samples 14400 loss 0.008018692680809927\n",
      "Epoch 81 num_samples 14500 loss 0.009921763492400733\n",
      "Epoch 81 num_samples 14600 loss 0.006739576728877206\n",
      "Epoch 81 num_samples 14700 loss 0.007302349619549289\n",
      "Epoch 81 num_samples 14800 loss 0.007035023581583765\n",
      "Epoch 81 num_samples 14900 loss 0.008181343788567226\n",
      "Epoch 81 num_samples 15000 loss 0.006963899868096558\n",
      "Epoch 81 num_samples 15100 loss 0.007633483465782993\n",
      "Epoch 81 num_samples 15200 loss 0.007361335609589839\n",
      "Epoch 81 num_samples 15300 loss 0.007860756633512891\n",
      "Epoch 81 num_samples 15400 loss 0.00561382130383718\n",
      "Epoch 81 num_samples 15500 loss 0.00751335639857364\n",
      "Epoch 81 num_samples 15600 loss 0.008029723929629789\n",
      "Epoch 81 num_samples 15700 loss 0.0053257302648485275\n",
      "Epoch 81 num_samples 15800 loss 0.008731409177029003\n",
      "Epoch 81 num_samples 15900 loss 0.005782761216007628\n",
      "Epoch 81 num_samples 16000 loss 0.010585888931344822\n",
      "Epoch 81 num_samples 16100 loss 0.005582958367447027\n",
      "Epoch 81 num_samples 16200 loss 0.008304533694586563\n",
      "Epoch 81 num_samples 16300 loss 0.009577220399911504\n",
      "Epoch 81 num_samples 16400 loss 0.009722947277281875\n",
      "Epoch 81 num_samples 16500 loss 0.008363491785285455\n",
      "Epoch 81 num_samples 16600 loss 0.009403929949039136\n",
      "Epoch 81 num_samples 16700 loss 0.005236525182750831\n",
      "Epoch 81 num_samples 16800 loss 0.005300785538844832\n",
      "Epoch 81 num_samples 16900 loss 0.006097674801094897\n",
      "Epoch 81 num_samples 17000 loss 0.004713892851081624\n",
      "Epoch 81 num_samples 17100 loss 0.011647110158861598\n",
      "Epoch 81 num_samples 17200 loss 0.008240998545457005\n",
      "Epoch 81 num_samples 17300 loss 0.008466143366486508\n",
      "Epoch 81 num_samples 17400 loss 0.007256874643601108\n",
      "Epoch 81 num_samples 17500 loss 0.007653201572415387\n",
      "Epoch 81 num_samples 17600 loss 0.006776874521880423\n",
      "Epoch 81 num_samples 17700 loss 0.005734626287862494\n",
      "Epoch 81 num_samples 17800 loss 0.006120223896975368\n",
      "Epoch 81 num_samples 17900 loss 0.009340958564943085\n",
      "Epoch 81 num_samples 18000 loss 0.006923320582647999\n",
      "Epoch 81 num_samples 18100 loss 0.007579917589382206\n",
      "Epoch 81 num_samples 18200 loss 0.008132276806329573\n",
      "Epoch 81 num_samples 18300 loss 0.005936080504502867\n",
      "Epoch 81 num_samples 18400 loss 0.011265392982615837\n",
      "Epoch 81 num_samples 18500 loss 0.008216706254910036\n",
      "Epoch 82 num_samples 0 loss 0.005714872049983963\n",
      "Epoch 82 num_samples 100 loss 0.010021215204145228\n",
      "Epoch 82 num_samples 200 loss 0.0067047211245326475\n",
      "Epoch 82 num_samples 300 loss 0.0056788715277026605\n",
      "Epoch 82 num_samples 400 loss 0.006876164173041714\n",
      "Epoch 82 num_samples 500 loss 0.010334162857651666\n",
      "Epoch 82 num_samples 600 loss 0.01008946946365184\n",
      "Epoch 82 num_samples 700 loss 0.010941413891211704\n",
      "Epoch 82 num_samples 800 loss 0.00639496532464456\n",
      "Epoch 82 num_samples 900 loss 0.011448399077135867\n",
      "Epoch 82 num_samples 1000 loss 0.006810819195362745\n",
      "Epoch 82 num_samples 1100 loss 0.01125783681731285\n",
      "Epoch 82 num_samples 1200 loss 0.006818578185437803\n",
      "Epoch 82 num_samples 1300 loss 0.008028437939225884\n",
      "Epoch 82 num_samples 1400 loss 0.00802417794141618\n",
      "Epoch 82 num_samples 1500 loss 0.009460228675290068\n",
      "Epoch 82 num_samples 1600 loss 0.007066910596183097\n",
      "Epoch 82 num_samples 1700 loss 0.006809537975478172\n",
      "Epoch 82 num_samples 1800 loss 0.006754960954499432\n",
      "Epoch 82 num_samples 1900 loss 0.00805105417858933\n",
      "Epoch 82 num_samples 2000 loss 0.00947495795327049\n",
      "Epoch 82 num_samples 2100 loss 0.004973638253790343\n",
      "Epoch 82 num_samples 2200 loss 0.0056384066023259126\n",
      "Epoch 82 num_samples 2300 loss 0.003758336650275307\n",
      "Epoch 82 num_samples 2400 loss 0.006221084718184746\n",
      "Epoch 82 num_samples 2500 loss 0.008350697640953343\n",
      "Epoch 82 num_samples 2600 loss 0.009144781348667771\n",
      "Epoch 82 num_samples 2700 loss 0.006508992815417384\n",
      "Epoch 82 num_samples 2800 loss 0.008980461069630881\n",
      "Epoch 82 num_samples 2900 loss 0.008358665839717503\n",
      "Epoch 82 num_samples 3000 loss 0.006877539293966039\n",
      "Epoch 82 num_samples 3100 loss 0.006698202619411722\n",
      "Epoch 82 num_samples 3200 loss 0.011238511857453148\n",
      "Epoch 82 num_samples 3300 loss 0.007450273123044979\n",
      "Epoch 82 num_samples 3400 loss 0.006079391777523386\n",
      "Epoch 82 num_samples 3500 loss 0.006376336789436641\n",
      "Epoch 82 num_samples 3600 loss 0.004901046414948886\n",
      "Epoch 82 num_samples 3700 loss 0.010991031447840664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 num_samples 3800 loss 0.005967454067668682\n",
      "Epoch 82 num_samples 3900 loss 0.007540702830612031\n",
      "Epoch 82 num_samples 4000 loss 0.008173477865113734\n",
      "Epoch 82 num_samples 4100 loss 0.010357537618768196\n",
      "Epoch 82 num_samples 4200 loss 0.007853242514173775\n",
      "Epoch 82 num_samples 4300 loss 0.006806778610239397\n",
      "Epoch 82 num_samples 4400 loss 0.00780657523903533\n",
      "Epoch 82 num_samples 4500 loss 0.009506041439662449\n",
      "Epoch 82 num_samples 4600 loss 0.008317455655615653\n",
      "Epoch 82 num_samples 4700 loss 0.004783720878140153\n",
      "Epoch 82 num_samples 4800 loss 0.0051131070961667234\n",
      "Epoch 82 num_samples 4900 loss 0.00653214222037047\n",
      "Epoch 82 num_samples 5000 loss 0.005743192902557237\n",
      "Epoch 82 num_samples 5100 loss 0.010199401629670505\n",
      "Epoch 82 num_samples 5200 loss 0.005018738346192913\n",
      "Epoch 82 num_samples 5300 loss 0.006794599831405091\n",
      "Epoch 82 num_samples 5400 loss 0.009318420821640352\n",
      "Epoch 82 num_samples 5500 loss 0.005685272791635456\n",
      "Epoch 82 num_samples 5600 loss 0.01822383587038702\n",
      "Epoch 82 num_samples 5700 loss 0.007182883058360552\n",
      "Epoch 82 num_samples 5800 loss 0.0070801376063197785\n",
      "Epoch 82 num_samples 5900 loss 0.00895626975320069\n",
      "Epoch 82 num_samples 6000 loss 0.007346745807658441\n",
      "Epoch 82 num_samples 6100 loss 0.006870496018859509\n",
      "Epoch 82 num_samples 6200 loss 0.007713024720127852\n",
      "Epoch 82 num_samples 6300 loss 0.009442839227653155\n",
      "Epoch 82 num_samples 6400 loss 0.00615965222037107\n",
      "Epoch 82 num_samples 6500 loss 0.0053472583680369236\n",
      "Epoch 82 num_samples 6600 loss 0.012572410115419852\n",
      "Epoch 82 num_samples 6700 loss 0.006393051279753363\n",
      "Epoch 82 num_samples 6800 loss 0.0040466065882482135\n",
      "Epoch 82 num_samples 6900 loss 0.015268402632345454\n",
      "Epoch 82 num_samples 7000 loss 0.009067572429479077\n",
      "Epoch 82 num_samples 7100 loss 0.005089482676701349\n",
      "Epoch 82 num_samples 7200 loss 0.007308005906253563\n",
      "Epoch 82 num_samples 7300 loss 0.00747654242133182\n",
      "Epoch 82 num_samples 7400 loss 0.005510446901308408\n",
      "Epoch 82 num_samples 7500 loss 0.011030952459882289\n",
      "Epoch 82 num_samples 7600 loss 0.007597518360081255\n",
      "Epoch 82 num_samples 7700 loss 0.010192329249938426\n",
      "Epoch 82 num_samples 7800 loss 0.006312364698520259\n",
      "Epoch 82 num_samples 7900 loss 0.007829379356445143\n",
      "Epoch 82 num_samples 8000 loss 0.0051711439371395175\n",
      "Epoch 82 num_samples 8100 loss 0.006718227069765692\n",
      "Epoch 82 num_samples 8200 loss 0.007975996831134263\n",
      "Epoch 82 num_samples 8300 loss 0.006137991596471805\n",
      "Epoch 82 num_samples 8400 loss 0.005059542149082659\n",
      "Epoch 82 num_samples 8500 loss 0.007512387583221826\n",
      "Epoch 82 num_samples 8600 loss 0.007412218744905093\n",
      "Epoch 82 num_samples 8700 loss 0.007474447978226422\n",
      "Epoch 82 num_samples 8800 loss 0.0072080739551719656\n",
      "Epoch 82 num_samples 8900 loss 0.008806333847335323\n",
      "Epoch 82 num_samples 9000 loss 0.007477837868446708\n",
      "Epoch 82 num_samples 9100 loss 0.007210858611936063\n",
      "Epoch 82 num_samples 9200 loss 0.007911767620327631\n",
      "Epoch 82 num_samples 9300 loss 0.00759148854909126\n",
      "Epoch 82 num_samples 9400 loss 0.006346105198685682\n",
      "Epoch 82 num_samples 9500 loss 0.006224886140293363\n",
      "Epoch 82 num_samples 9600 loss 0.006930752027410693\n",
      "Epoch 82 num_samples 9700 loss 0.010057111803724275\n",
      "Epoch 82 num_samples 9800 loss 0.004587242653591355\n",
      "Epoch 82 num_samples 9900 loss 0.013434919719030372\n",
      "Epoch 82 num_samples 10000 loss 0.006171377188530103\n",
      "Epoch 82 num_samples 10100 loss 0.005656842633209398\n",
      "Epoch 82 num_samples 10200 loss 0.008795797115128779\n",
      "Epoch 82 num_samples 10300 loss 0.0072149418605616114\n",
      "Epoch 82 num_samples 10400 loss 0.00955414784112676\n",
      "Epoch 82 num_samples 10500 loss 0.006835307403339251\n",
      "Epoch 82 num_samples 10600 loss 0.008234593705604691\n",
      "Epoch 82 num_samples 10700 loss 0.006405598347958342\n",
      "Epoch 82 num_samples 10800 loss 0.008354523247116587\n",
      "Epoch 82 num_samples 10900 loss 0.006308029323740409\n",
      "Epoch 82 num_samples 11000 loss 0.0058348853112345144\n",
      "Epoch 82 num_samples 11100 loss 0.00779973792593979\n",
      "Epoch 82 num_samples 11200 loss 0.006050771849613803\n",
      "Epoch 82 num_samples 11300 loss 0.009825258777342735\n",
      "Epoch 82 num_samples 11400 loss 0.006758119123923466\n",
      "Epoch 82 num_samples 11500 loss 0.006461641861216747\n",
      "Epoch 82 num_samples 11600 loss 0.006394917737705516\n",
      "Epoch 82 num_samples 11700 loss 0.008640619687474552\n",
      "Epoch 82 num_samples 11800 loss 0.006433703100431629\n",
      "Epoch 82 num_samples 11900 loss 0.005606560075575202\n",
      "Epoch 82 num_samples 12000 loss 0.004926314581046214\n",
      "Epoch 82 num_samples 12100 loss 0.00556289047834681\n",
      "Epoch 82 num_samples 12200 loss 0.007895137084911163\n",
      "Epoch 82 num_samples 12300 loss 0.005820279338424554\n",
      "Epoch 82 num_samples 12400 loss 0.008948086178914275\n",
      "Epoch 82 num_samples 12500 loss 0.007954522648918619\n",
      "Epoch 82 num_samples 12600 loss 0.009875517601440035\n",
      "Epoch 82 num_samples 12700 loss 0.007284866049041947\n",
      "Epoch 82 num_samples 12800 loss 0.011143736144142168\n",
      "Epoch 82 num_samples 12900 loss 0.006337175663093994\n",
      "Epoch 82 num_samples 13000 loss 0.006028599661957405\n",
      "Epoch 82 num_samples 13100 loss 0.009413424648213835\n",
      "Epoch 82 num_samples 13200 loss 0.0041491561826404065\n",
      "Epoch 82 num_samples 13300 loss 0.005751190557041821\n",
      "Epoch 82 num_samples 13400 loss 0.003834881266714401\n",
      "Epoch 82 num_samples 13500 loss 0.005257108178605005\n",
      "Epoch 82 num_samples 13600 loss 0.009499757077289872\n",
      "Epoch 82 num_samples 13700 loss 0.006920409091952942\n",
      "Epoch 82 num_samples 13800 loss 0.006798560621015339\n",
      "Epoch 82 num_samples 13900 loss 0.0028461609778647114\n",
      "Epoch 82 num_samples 14000 loss 0.004905962120976592\n",
      "Epoch 82 num_samples 14100 loss 0.006431704200969488\n",
      "Epoch 82 num_samples 14200 loss 0.006012320303010593\n",
      "Epoch 82 num_samples 14300 loss 0.007807857513587175\n",
      "Epoch 82 num_samples 14400 loss 0.007829520474019616\n",
      "Epoch 82 num_samples 14500 loss 0.00971991633598212\n",
      "Epoch 82 num_samples 14600 loss 0.006586832272869976\n",
      "Epoch 82 num_samples 14700 loss 0.007162273429481154\n",
      "Epoch 82 num_samples 14800 loss 0.00689386900398906\n",
      "Epoch 82 num_samples 14900 loss 0.008007297823184746\n",
      "Epoch 82 num_samples 15000 loss 0.006836815531370537\n",
      "Epoch 82 num_samples 15100 loss 0.007461592620974115\n",
      "Epoch 82 num_samples 15200 loss 0.007212974116798799\n",
      "Epoch 82 num_samples 15300 loss 0.007701127108176216\n",
      "Epoch 82 num_samples 15400 loss 0.005502479118478474\n",
      "Epoch 82 num_samples 15500 loss 0.0073396948377063165\n",
      "Epoch 82 num_samples 15600 loss 0.007868788465978105\n",
      "Epoch 82 num_samples 15700 loss 0.005209907569427601\n",
      "Epoch 82 num_samples 15800 loss 0.008517451555702542\n",
      "Epoch 82 num_samples 15900 loss 0.005682882000604388\n",
      "Epoch 82 num_samples 16000 loss 0.010350511955256856\n",
      "Epoch 82 num_samples 16100 loss 0.005496927539270623\n",
      "Epoch 82 num_samples 16200 loss 0.008122691534470941\n",
      "Epoch 82 num_samples 16300 loss 0.009387999558097111\n",
      "Epoch 82 num_samples 16400 loss 0.009511710458973931\n",
      "Epoch 82 num_samples 16500 loss 0.008180754783414417\n",
      "Epoch 82 num_samples 16600 loss 0.009216894756119634\n",
      "Epoch 82 num_samples 16700 loss 0.005133548525641042\n",
      "Epoch 82 num_samples 16800 loss 0.005188714159694681\n",
      "Epoch 82 num_samples 16900 loss 0.005983560650733326\n",
      "Epoch 82 num_samples 17000 loss 0.004614349045020128\n",
      "Epoch 82 num_samples 17100 loss 0.011395075311609056\n",
      "Epoch 82 num_samples 17200 loss 0.008069751537325792\n",
      "Epoch 82 num_samples 17300 loss 0.008256085873249058\n",
      "Epoch 82 num_samples 17400 loss 0.007081716138449938\n",
      "Epoch 82 num_samples 17500 loss 0.007506443943583115\n",
      "Epoch 82 num_samples 17600 loss 0.006648741107884458\n",
      "Epoch 82 num_samples 17700 loss 0.005628270036591189\n",
      "Epoch 82 num_samples 17800 loss 0.00598913079537709\n",
      "Epoch 82 num_samples 17900 loss 0.009144060299317058\n",
      "Epoch 82 num_samples 18000 loss 0.0067977428788353325\n",
      "Epoch 82 num_samples 18100 loss 0.007441897145950482\n",
      "Epoch 82 num_samples 18200 loss 0.007969658193363632\n",
      "Epoch 82 num_samples 18300 loss 0.005823539738727314\n",
      "Epoch 82 num_samples 18400 loss 0.01104760604673459\n",
      "Epoch 82 num_samples 18500 loss 0.008070158714510991\n",
      "Epoch 83 num_samples 0 loss 0.005589639758894327\n",
      "Epoch 83 num_samples 100 loss 0.00983732747549734\n",
      "Epoch 83 num_samples 200 loss 0.0065657217670326085\n",
      "Epoch 83 num_samples 300 loss 0.005565879300793072\n",
      "Epoch 83 num_samples 400 loss 0.006735508102570395\n",
      "Epoch 83 num_samples 500 loss 0.010155762876291463\n",
      "Epoch 83 num_samples 600 loss 0.009837259439700898\n",
      "Epoch 83 num_samples 700 loss 0.010693543909109489\n",
      "Epoch 83 num_samples 800 loss 0.006258112136442249\n",
      "Epoch 83 num_samples 900 loss 0.011188092521328763\n",
      "Epoch 83 num_samples 1000 loss 0.006654523397736456\n",
      "Epoch 83 num_samples 1100 loss 0.01103382626751471\n",
      "Epoch 83 num_samples 1200 loss 0.006672092147205804\n",
      "Epoch 83 num_samples 1300 loss 0.007880625884695394\n",
      "Epoch 83 num_samples 1400 loss 0.007853949573318489\n",
      "Epoch 83 num_samples 1500 loss 0.009276300763589325\n",
      "Epoch 83 num_samples 1600 loss 0.0069225212887439646\n",
      "Epoch 83 num_samples 1700 loss 0.0066954644248229086\n",
      "Epoch 83 num_samples 1800 loss 0.006618826751029269\n",
      "Epoch 83 num_samples 1900 loss 0.00789943142229459\n",
      "Epoch 83 num_samples 2000 loss 0.009280407356997549\n",
      "Epoch 83 num_samples 2100 loss 0.004870887715150086\n",
      "Epoch 83 num_samples 2200 loss 0.005520980954864426\n",
      "Epoch 83 num_samples 2300 loss 0.003684846435627079\n",
      "Epoch 83 num_samples 2400 loss 0.006092834952692956\n",
      "Epoch 83 num_samples 2500 loss 0.008168904783438912\n",
      "Epoch 83 num_samples 2600 loss 0.008894251172985252\n",
      "Epoch 83 num_samples 2700 loss 0.006383510793326052\n",
      "Epoch 83 num_samples 2800 loss 0.008785222365816962\n",
      "Epoch 83 num_samples 2900 loss 0.008163635782118464\n",
      "Epoch 83 num_samples 3000 loss 0.006711425735554141\n",
      "Epoch 83 num_samples 3100 loss 0.006565574873303825\n",
      "Epoch 83 num_samples 3200 loss 0.010945948706830903\n",
      "Epoch 83 num_samples 3300 loss 0.007298209776612612\n",
      "Epoch 83 num_samples 3400 loss 0.005935108802896325\n",
      "Epoch 83 num_samples 3500 loss 0.006258934822727605\n",
      "Epoch 83 num_samples 3600 loss 0.004822199900285676\n",
      "Epoch 83 num_samples 3700 loss 0.010742520835684761\n",
      "Epoch 83 num_samples 3800 loss 0.005824660671242754\n",
      "Epoch 83 num_samples 3900 loss 0.0073993555753783255\n",
      "Epoch 83 num_samples 4000 loss 0.00800612893344995\n",
      "Epoch 83 num_samples 4100 loss 0.010103625161249227\n",
      "Epoch 83 num_samples 4200 loss 0.007695561039108037\n",
      "Epoch 83 num_samples 4300 loss 0.006650486982455128\n",
      "Epoch 83 num_samples 4400 loss 0.0076695638921299835\n",
      "Epoch 83 num_samples 4500 loss 0.009285395654944916\n",
      "Epoch 83 num_samples 4600 loss 0.008132288456296956\n",
      "Epoch 83 num_samples 4700 loss 0.004665261629678967\n",
      "Epoch 83 num_samples 4800 loss 0.005004714441461045\n",
      "Epoch 83 num_samples 4900 loss 0.0064219138977687175\n",
      "Epoch 83 num_samples 5000 loss 0.005631193129968621\n",
      "Epoch 83 num_samples 5100 loss 0.009988834129942106\n",
      "Epoch 83 num_samples 5200 loss 0.004922115841319847\n",
      "Epoch 83 num_samples 5300 loss 0.006648519997534364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 num_samples 5400 loss 0.00914619379475996\n",
      "Epoch 83 num_samples 5500 loss 0.005562152803688243\n",
      "Epoch 83 num_samples 5600 loss 0.017749425599838206\n",
      "Epoch 83 num_samples 5700 loss 0.007040798952125984\n",
      "Epoch 83 num_samples 5800 loss 0.00693669422219331\n",
      "Epoch 83 num_samples 5900 loss 0.008738902000105284\n",
      "Epoch 83 num_samples 6000 loss 0.007200672278641868\n",
      "Epoch 83 num_samples 6100 loss 0.0067409667504276715\n",
      "Epoch 83 num_samples 6200 loss 0.007548578339409087\n",
      "Epoch 83 num_samples 6300 loss 0.009226934980682014\n",
      "Epoch 83 num_samples 6400 loss 0.006038016608055474\n",
      "Epoch 83 num_samples 6500 loss 0.00524236066185453\n",
      "Epoch 83 num_samples 6600 loss 0.012325726763983328\n",
      "Epoch 83 num_samples 6700 loss 0.006253912388528345\n",
      "Epoch 83 num_samples 6800 loss 0.003962460504964472\n",
      "Epoch 83 num_samples 6900 loss 0.014964118566484975\n",
      "Epoch 83 num_samples 7000 loss 0.008875880872186138\n",
      "Epoch 83 num_samples 7100 loss 0.004996639586580479\n",
      "Epoch 83 num_samples 7200 loss 0.007167056196504451\n",
      "Epoch 83 num_samples 7300 loss 0.007358159536750235\n",
      "Epoch 83 num_samples 7400 loss 0.0054188860211532375\n",
      "Epoch 83 num_samples 7500 loss 0.010776956935748112\n",
      "Epoch 83 num_samples 7600 loss 0.0074328995298564285\n",
      "Epoch 83 num_samples 7700 loss 0.009948949748461739\n",
      "Epoch 83 num_samples 7800 loss 0.006160129543404895\n",
      "Epoch 83 num_samples 7900 loss 0.007687793120572563\n",
      "Epoch 83 num_samples 8000 loss 0.00504652494464639\n",
      "Epoch 83 num_samples 8100 loss 0.006562301478263628\n",
      "Epoch 83 num_samples 8200 loss 0.007788088681466028\n",
      "Epoch 83 num_samples 8300 loss 0.006012439453430335\n",
      "Epoch 83 num_samples 8400 loss 0.0049490808255694685\n",
      "Epoch 83 num_samples 8500 loss 0.007413032551592624\n",
      "Epoch 83 num_samples 8600 loss 0.007249674688725712\n",
      "Epoch 83 num_samples 8700 loss 0.007317939878707256\n",
      "Epoch 83 num_samples 8800 loss 0.007038928885907009\n",
      "Epoch 83 num_samples 8900 loss 0.008640734428126105\n",
      "Epoch 83 num_samples 9000 loss 0.007322903894052834\n",
      "Epoch 83 num_samples 9100 loss 0.007056355396048588\n",
      "Epoch 83 num_samples 9200 loss 0.007782953451376765\n",
      "Epoch 83 num_samples 9300 loss 0.0074459862185229445\n",
      "Epoch 83 num_samples 9400 loss 0.006209278762495935\n",
      "Epoch 83 num_samples 9500 loss 0.0060921821423122365\n",
      "Epoch 83 num_samples 9600 loss 0.006809562501320861\n",
      "Epoch 83 num_samples 9700 loss 0.009824673576638155\n",
      "Epoch 83 num_samples 9800 loss 0.004485387025479982\n",
      "Epoch 83 num_samples 9900 loss 0.013162782509404298\n",
      "Epoch 83 num_samples 10000 loss 0.00601230638959942\n",
      "Epoch 83 num_samples 10100 loss 0.0055417389922787766\n",
      "Epoch 83 num_samples 10200 loss 0.008604054017309133\n",
      "Epoch 83 num_samples 10300 loss 0.007102650445432095\n",
      "Epoch 83 num_samples 10400 loss 0.009380715565221775\n",
      "Epoch 83 num_samples 10500 loss 0.006707763780431324\n",
      "Epoch 83 num_samples 10600 loss 0.008068035332771369\n",
      "Epoch 83 num_samples 10700 loss 0.0062516365188447385\n",
      "Epoch 83 num_samples 10800 loss 0.008174876339644858\n",
      "Epoch 83 num_samples 10900 loss 0.006150242241391235\n",
      "Epoch 83 num_samples 11000 loss 0.005708750943376515\n",
      "Epoch 83 num_samples 11100 loss 0.007633702148714323\n",
      "Epoch 83 num_samples 11200 loss 0.005910006165637378\n",
      "Epoch 83 num_samples 11300 loss 0.009590716607445789\n",
      "Epoch 83 num_samples 11400 loss 0.006590729438136303\n",
      "Epoch 83 num_samples 11500 loss 0.0063011980006128995\n",
      "Epoch 83 num_samples 11600 loss 0.006262700064357285\n",
      "Epoch 83 num_samples 11700 loss 0.008467589680598896\n",
      "Epoch 83 num_samples 11800 loss 0.006303484794091086\n",
      "Epoch 83 num_samples 11900 loss 0.005483932971320773\n",
      "Epoch 83 num_samples 12000 loss 0.0048429135385371965\n",
      "Epoch 83 num_samples 12100 loss 0.005445193099320618\n",
      "Epoch 83 num_samples 12200 loss 0.007724389069425375\n",
      "Epoch 83 num_samples 12300 loss 0.005686258605486032\n",
      "Epoch 83 num_samples 12400 loss 0.008755671013429485\n",
      "Epoch 83 num_samples 12500 loss 0.007789085747243223\n",
      "Epoch 83 num_samples 12600 loss 0.009732749739783686\n",
      "Epoch 83 num_samples 12700 loss 0.007123713260032272\n",
      "Epoch 83 num_samples 12800 loss 0.010916767863984149\n",
      "Epoch 83 num_samples 12900 loss 0.006197202647776898\n",
      "Epoch 83 num_samples 13000 loss 0.005909344767809655\n",
      "Epoch 83 num_samples 13100 loss 0.009179562061192489\n",
      "Epoch 83 num_samples 13200 loss 0.004074936910086091\n",
      "Epoch 83 num_samples 13300 loss 0.005659043382499131\n",
      "Epoch 83 num_samples 13400 loss 0.0037429513388578927\n",
      "Epoch 83 num_samples 13500 loss 0.0051620118966521225\n",
      "Epoch 83 num_samples 13600 loss 0.009319170834571273\n",
      "Epoch 83 num_samples 13700 loss 0.006804776206135184\n",
      "Epoch 83 num_samples 13800 loss 0.00664889764098495\n",
      "Epoch 83 num_samples 13900 loss 0.002787302158468799\n",
      "Epoch 83 num_samples 14000 loss 0.004806980805485063\n",
      "Epoch 83 num_samples 14100 loss 0.006297799439287315\n",
      "Epoch 83 num_samples 14200 loss 0.005909805269702475\n",
      "Epoch 83 num_samples 14300 loss 0.007665635435741824\n",
      "Epoch 83 num_samples 14400 loss 0.007683744232305589\n",
      "Epoch 83 num_samples 14500 loss 0.009524476159206789\n",
      "Epoch 83 num_samples 14600 loss 0.006442325473780537\n",
      "Epoch 83 num_samples 14700 loss 0.00703510521683514\n",
      "Epoch 83 num_samples 14800 loss 0.006740976252309543\n",
      "Epoch 83 num_samples 14900 loss 0.007845930753194544\n",
      "Epoch 83 num_samples 15000 loss 0.0067091583822069785\n",
      "Epoch 83 num_samples 15100 loss 0.007295013820796282\n",
      "Epoch 83 num_samples 15200 loss 0.007043769364290664\n",
      "Epoch 83 num_samples 15300 loss 0.007544981799381707\n",
      "Epoch 83 num_samples 15400 loss 0.005410972109769417\n",
      "Epoch 83 num_samples 15500 loss 0.007159470351304923\n",
      "Epoch 83 num_samples 15600 loss 0.007715965438422418\n",
      "Epoch 83 num_samples 15700 loss 0.005112734930473915\n",
      "Epoch 83 num_samples 15800 loss 0.008321832312292318\n",
      "Epoch 83 num_samples 15900 loss 0.005561205739158422\n",
      "Epoch 83 num_samples 16000 loss 0.010124152783750971\n",
      "Epoch 83 num_samples 16100 loss 0.005389545439293209\n",
      "Epoch 83 num_samples 16200 loss 0.00793240469898441\n",
      "Epoch 83 num_samples 16300 loss 0.009184600705973905\n",
      "Epoch 83 num_samples 16400 loss 0.009332671270809915\n",
      "Epoch 83 num_samples 16500 loss 0.008012038207306739\n",
      "Epoch 83 num_samples 16600 loss 0.009021448957227157\n",
      "Epoch 83 num_samples 16700 loss 0.005035063380336329\n",
      "Epoch 83 num_samples 16800 loss 0.005105140509618843\n",
      "Epoch 83 num_samples 16900 loss 0.0058344002303733974\n",
      "Epoch 83 num_samples 17000 loss 0.0045134965636997645\n",
      "Epoch 83 num_samples 17100 loss 0.011150525075871267\n",
      "Epoch 83 num_samples 17200 loss 0.00790121600466094\n",
      "Epoch 83 num_samples 17300 loss 0.00811021264302824\n",
      "Epoch 83 num_samples 17400 loss 0.006911388695723439\n",
      "Epoch 83 num_samples 17500 loss 0.007374124229826365\n",
      "Epoch 83 num_samples 17600 loss 0.006494548368605377\n",
      "Epoch 83 num_samples 17700 loss 0.005526405942782165\n",
      "Epoch 83 num_samples 17800 loss 0.005866103542406313\n",
      "Epoch 83 num_samples 17900 loss 0.00893220422392026\n",
      "Epoch 83 num_samples 18000 loss 0.006671916125377486\n",
      "Epoch 83 num_samples 18100 loss 0.007302512950274732\n",
      "Epoch 83 num_samples 18200 loss 0.007805901682281759\n",
      "Epoch 83 num_samples 18300 loss 0.005718638078299882\n",
      "Epoch 83 num_samples 18400 loss 0.010771044312234291\n",
      "Epoch 83 num_samples 18500 loss 0.007891579692368462\n",
      "Epoch 84 num_samples 0 loss 0.005503980236634707\n",
      "Epoch 84 num_samples 100 loss 0.009624833838020675\n",
      "Epoch 84 num_samples 200 loss 0.00644991421850529\n",
      "Epoch 84 num_samples 300 loss 0.005450561309569664\n",
      "Epoch 84 num_samples 400 loss 0.0066194707759840874\n",
      "Epoch 84 num_samples 500 loss 0.009953063551185942\n",
      "Epoch 84 num_samples 600 loss 0.009632633654460291\n",
      "Epoch 84 num_samples 700 loss 0.010488590411072952\n",
      "Epoch 84 num_samples 800 loss 0.006143467628303454\n",
      "Epoch 84 num_samples 900 loss 0.010973624036964254\n",
      "Epoch 84 num_samples 1000 loss 0.006522500469625764\n",
      "Epoch 84 num_samples 1100 loss 0.010791091626214454\n",
      "Epoch 84 num_samples 1200 loss 0.006546289681604176\n",
      "Epoch 84 num_samples 1300 loss 0.00770175136697044\n",
      "Epoch 84 num_samples 1400 loss 0.007665737798224472\n",
      "Epoch 84 num_samples 1500 loss 0.009034983126139045\n",
      "Epoch 84 num_samples 1600 loss 0.006767303981941255\n",
      "Epoch 84 num_samples 1700 loss 0.006536836094694116\n",
      "Epoch 84 num_samples 1800 loss 0.006491896875578967\n",
      "Epoch 84 num_samples 1900 loss 0.007745325215315684\n",
      "Epoch 84 num_samples 2000 loss 0.00904849494514845\n",
      "Epoch 84 num_samples 2100 loss 0.004773961631468939\n",
      "Epoch 84 num_samples 2200 loss 0.005429360644190413\n",
      "Epoch 84 num_samples 2300 loss 0.0035887840451439275\n",
      "Epoch 84 num_samples 2400 loss 0.0059503156514923\n",
      "Epoch 84 num_samples 2500 loss 0.007960017549066561\n",
      "Epoch 84 num_samples 2600 loss 0.008739449806127947\n",
      "Epoch 84 num_samples 2700 loss 0.0062863360539134805\n",
      "Epoch 84 num_samples 2800 loss 0.008643600592023671\n",
      "Epoch 84 num_samples 2900 loss 0.008000296367984843\n",
      "Epoch 84 num_samples 3000 loss 0.006600537826759492\n",
      "Epoch 84 num_samples 3100 loss 0.006409604508350731\n",
      "Epoch 84 num_samples 3200 loss 0.010671449736987398\n",
      "Epoch 84 num_samples 3300 loss 0.007130861324012998\n",
      "Epoch 84 num_samples 3400 loss 0.005801568958307039\n",
      "Epoch 84 num_samples 3500 loss 0.006138417464858552\n",
      "Epoch 84 num_samples 3600 loss 0.004749502352566968\n",
      "Epoch 84 num_samples 3700 loss 0.01051092088271466\n",
      "Epoch 84 num_samples 3800 loss 0.005681019190099514\n",
      "Epoch 84 num_samples 3900 loss 0.007233633325838822\n",
      "Epoch 84 num_samples 4000 loss 0.0077925485628993355\n",
      "Epoch 84 num_samples 4100 loss 0.009899852006056387\n",
      "Epoch 84 num_samples 4200 loss 0.00751779340534187\n",
      "Epoch 84 num_samples 4300 loss 0.006509367341918882\n",
      "Epoch 84 num_samples 4400 loss 0.007491399041653909\n",
      "Epoch 84 num_samples 4500 loss 0.009089701332196637\n",
      "Epoch 84 num_samples 4600 loss 0.007965036079469131\n",
      "Epoch 84 num_samples 4700 loss 0.00456897417697536\n",
      "Epoch 84 num_samples 4800 loss 0.004907362923175165\n",
      "Epoch 84 num_samples 4900 loss 0.006285640307790112\n",
      "Epoch 84 num_samples 5000 loss 0.005533452330053834\n",
      "Epoch 84 num_samples 5100 loss 0.009820798838534494\n",
      "Epoch 84 num_samples 5200 loss 0.0048259126952043254\n",
      "Epoch 84 num_samples 5300 loss 0.006513306123205593\n",
      "Epoch 84 num_samples 5400 loss 0.008962496356290522\n",
      "Epoch 84 num_samples 5500 loss 0.005444893157539259\n",
      "Epoch 84 num_samples 5600 loss 0.017273048755809414\n",
      "Epoch 84 num_samples 5700 loss 0.006870975659491891\n",
      "Epoch 84 num_samples 5800 loss 0.0067936285612839285\n",
      "Epoch 84 num_samples 5900 loss 0.008565625605505363\n",
      "Epoch 84 num_samples 6000 loss 0.007043285547402392\n",
      "Epoch 84 num_samples 6100 loss 0.006609110385411954\n",
      "Epoch 84 num_samples 6200 loss 0.007376684455400395\n",
      "Epoch 84 num_samples 6300 loss 0.009032975439517787\n",
      "Epoch 84 num_samples 6400 loss 0.005893285735340885\n",
      "Epoch 84 num_samples 6500 loss 0.005126274410358903\n",
      "Epoch 84 num_samples 6600 loss 0.012109035643636485\n",
      "Epoch 84 num_samples 6700 loss 0.00613290365441995\n",
      "Epoch 84 num_samples 6800 loss 0.003893887623546751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 num_samples 6900 loss 0.014664675873789869\n",
      "Epoch 84 num_samples 7000 loss 0.00872778423931515\n",
      "Epoch 84 num_samples 7100 loss 0.00489758347417507\n",
      "Epoch 84 num_samples 7200 loss 0.007024948134012866\n",
      "Epoch 84 num_samples 7300 loss 0.007205374591428632\n",
      "Epoch 84 num_samples 7400 loss 0.005306838087752144\n",
      "Epoch 84 num_samples 7500 loss 0.010518754398349026\n",
      "Epoch 84 num_samples 7600 loss 0.007243709796892417\n",
      "Epoch 84 num_samples 7700 loss 0.009764918852620581\n",
      "Epoch 84 num_samples 7800 loss 0.0060598755594609074\n",
      "Epoch 84 num_samples 7900 loss 0.0075449302372344864\n",
      "Epoch 84 num_samples 8000 loss 0.004950300317411191\n",
      "Epoch 84 num_samples 8100 loss 0.006424832308234558\n",
      "Epoch 84 num_samples 8200 loss 0.007639720391258799\n",
      "Epoch 84 num_samples 8300 loss 0.0058966662036416696\n",
      "Epoch 84 num_samples 8400 loss 0.004869687553666731\n",
      "Epoch 84 num_samples 8500 loss 0.007220250153815087\n",
      "Epoch 84 num_samples 8600 loss 0.007075977402254446\n",
      "Epoch 84 num_samples 8700 loss 0.007153375707055313\n",
      "Epoch 84 num_samples 8800 loss 0.006882450055283884\n",
      "Epoch 84 num_samples 8900 loss 0.008436706799495897\n",
      "Epoch 84 num_samples 9000 loss 0.007173147981319869\n",
      "Epoch 84 num_samples 9100 loss 0.006924681302368901\n",
      "Epoch 84 num_samples 9200 loss 0.007593453892851062\n",
      "Epoch 84 num_samples 9300 loss 0.0072920573320013615\n",
      "Epoch 84 num_samples 9400 loss 0.006104233762955106\n",
      "Epoch 84 num_samples 9500 loss 0.005967245503702085\n",
      "Epoch 84 num_samples 9600 loss 0.006667612627082069\n",
      "Epoch 84 num_samples 9700 loss 0.009609996886014436\n",
      "Epoch 84 num_samples 9800 loss 0.004403671459312094\n",
      "Epoch 84 num_samples 9900 loss 0.012820342019106121\n",
      "Epoch 84 num_samples 10000 loss 0.005879882420108526\n",
      "Epoch 84 num_samples 10100 loss 0.005425368798114156\n",
      "Epoch 84 num_samples 10200 loss 0.008398962314740547\n",
      "Epoch 84 num_samples 10300 loss 0.006939863374029485\n",
      "Epoch 84 num_samples 10400 loss 0.009207270543000462\n",
      "Epoch 84 num_samples 10500 loss 0.006569286966807688\n",
      "Epoch 84 num_samples 10600 loss 0.007880248699038937\n",
      "Epoch 84 num_samples 10700 loss 0.00613071306432436\n",
      "Epoch 84 num_samples 10800 loss 0.007998853180543816\n",
      "Epoch 84 num_samples 10900 loss 0.00604492895827793\n",
      "Epoch 84 num_samples 11000 loss 0.0055701913917346\n",
      "Epoch 84 num_samples 11100 loss 0.007491217950890533\n",
      "Epoch 84 num_samples 11200 loss 0.005790963623848555\n",
      "Epoch 84 num_samples 11300 loss 0.009369426987937858\n",
      "Epoch 84 num_samples 11400 loss 0.006436128806831638\n",
      "Epoch 84 num_samples 11500 loss 0.00616706612834905\n",
      "Epoch 84 num_samples 11600 loss 0.006158184769181971\n",
      "Epoch 84 num_samples 11700 loss 0.008313059991903696\n",
      "Epoch 84 num_samples 11800 loss 0.0061888728575360576\n",
      "Epoch 84 num_samples 11900 loss 0.00536230702144774\n",
      "Epoch 84 num_samples 12000 loss 0.004731893513479743\n",
      "Epoch 84 num_samples 12100 loss 0.005322223489152742\n",
      "Epoch 84 num_samples 12200 loss 0.007550474155353854\n",
      "Epoch 84 num_samples 12300 loss 0.005599905419587639\n",
      "Epoch 84 num_samples 12400 loss 0.008561099895242763\n",
      "Epoch 84 num_samples 12500 loss 0.0076336318134855655\n",
      "Epoch 84 num_samples 12600 loss 0.009509669505899888\n",
      "Epoch 84 num_samples 12700 loss 0.006959112052900884\n",
      "Epoch 84 num_samples 12800 loss 0.010691217826921444\n",
      "Epoch 84 num_samples 12900 loss 0.006078088543409061\n",
      "Epoch 84 num_samples 13000 loss 0.0057773740034432275\n",
      "Epoch 84 num_samples 13100 loss 0.00900606922676136\n",
      "Epoch 84 num_samples 13200 loss 0.003973495557991931\n",
      "Epoch 84 num_samples 13300 loss 0.005544179924221013\n",
      "Epoch 84 num_samples 13400 loss 0.003681920541863683\n",
      "Epoch 84 num_samples 13500 loss 0.00503642308932029\n",
      "Epoch 84 num_samples 13600 loss 0.009123961239465668\n",
      "Epoch 84 num_samples 13700 loss 0.0066510296043086805\n",
      "Epoch 84 num_samples 13800 loss 0.006547194698431918\n",
      "Epoch 84 num_samples 13900 loss 0.0027356879115209374\n",
      "Epoch 84 num_samples 14000 loss 0.0047059026154125435\n",
      "Epoch 84 num_samples 14100 loss 0.006178951195738678\n",
      "Epoch 84 num_samples 14200 loss 0.00581035385387495\n",
      "Epoch 84 num_samples 14300 loss 0.007472440836663954\n",
      "Epoch 84 num_samples 14400 loss 0.007531588842427828\n",
      "Epoch 84 num_samples 14500 loss 0.00934914174524833\n",
      "Epoch 84 num_samples 14600 loss 0.006316478640666502\n",
      "Epoch 84 num_samples 14700 loss 0.00687469330581399\n",
      "Epoch 84 num_samples 14800 loss 0.006641511248892812\n",
      "Epoch 84 num_samples 14900 loss 0.007699797651051698\n",
      "Epoch 84 num_samples 15000 loss 0.006588824346839959\n",
      "Epoch 84 num_samples 15100 loss 0.007149265218910908\n",
      "Epoch 84 num_samples 15200 loss 0.006875387745533209\n",
      "Epoch 84 num_samples 15300 loss 0.007387203043845041\n",
      "Epoch 84 num_samples 15400 loss 0.005286342827870165\n",
      "Epoch 84 num_samples 15500 loss 0.007013533682795811\n",
      "Epoch 84 num_samples 15600 loss 0.007546984954738489\n",
      "Epoch 84 num_samples 15700 loss 0.005026084246010971\n",
      "Epoch 84 num_samples 15800 loss 0.008151147795542013\n",
      "Epoch 84 num_samples 15900 loss 0.005475846774380855\n",
      "Epoch 84 num_samples 16000 loss 0.00988488768432914\n",
      "Epoch 84 num_samples 16100 loss 0.0052723691804136275\n",
      "Epoch 84 num_samples 16200 loss 0.0077869071751835665\n",
      "Epoch 84 num_samples 16300 loss 0.00901959505927923\n",
      "Epoch 84 num_samples 16400 loss 0.009104563843703853\n",
      "Epoch 84 num_samples 16500 loss 0.007851886452335841\n",
      "Epoch 84 num_samples 16600 loss 0.00884563608568789\n",
      "Epoch 84 num_samples 16700 loss 0.004921092635607924\n",
      "Epoch 84 num_samples 16800 loss 0.004996921801722067\n",
      "Epoch 84 num_samples 16900 loss 0.005724443023983699\n",
      "Epoch 84 num_samples 17000 loss 0.004425767080437555\n",
      "Epoch 84 num_samples 17100 loss 0.010860153756822527\n",
      "Epoch 84 num_samples 17200 loss 0.00773237800236646\n",
      "Epoch 84 num_samples 17300 loss 0.007932124253162866\n",
      "Epoch 84 num_samples 17400 loss 0.006765568143345885\n",
      "Epoch 84 num_samples 17500 loss 0.0072148257005346834\n",
      "Epoch 84 num_samples 17600 loss 0.006362473218758729\n",
      "Epoch 84 num_samples 17700 loss 0.005418927460674242\n",
      "Epoch 84 num_samples 17800 loss 0.005756937392011936\n",
      "Epoch 84 num_samples 17900 loss 0.008716414369974295\n",
      "Epoch 84 num_samples 18000 loss 0.006530784371995293\n",
      "Epoch 84 num_samples 18100 loss 0.007160849873578206\n",
      "Epoch 84 num_samples 18200 loss 0.007659089876782662\n",
      "Epoch 84 num_samples 18300 loss 0.005609936244178064\n",
      "Epoch 84 num_samples 18400 loss 0.01056748087291053\n",
      "Epoch 84 num_samples 18500 loss 0.007734614436068684\n",
      "Epoch 85 num_samples 0 loss 0.005380729898115986\n",
      "Epoch 85 num_samples 100 loss 0.009416803336960296\n",
      "Epoch 85 num_samples 200 loss 0.006307974321246136\n",
      "Epoch 85 num_samples 300 loss 0.005343535467387771\n",
      "Epoch 85 num_samples 400 loss 0.006490085627435686\n",
      "Epoch 85 num_samples 500 loss 0.009753975213510548\n",
      "Epoch 85 num_samples 600 loss 0.00940724473453427\n",
      "Epoch 85 num_samples 700 loss 0.010242313041247692\n",
      "Epoch 85 num_samples 800 loss 0.006017346303370347\n",
      "Epoch 85 num_samples 900 loss 0.010748340439329505\n",
      "Epoch 85 num_samples 1000 loss 0.006374488515671306\n",
      "Epoch 85 num_samples 1100 loss 0.010558929087136603\n",
      "Epoch 85 num_samples 1200 loss 0.006412448825295534\n",
      "Epoch 85 num_samples 1300 loss 0.007578418521532133\n",
      "Epoch 85 num_samples 1400 loss 0.007483426152482665\n",
      "Epoch 85 num_samples 1500 loss 0.008851729400780417\n",
      "Epoch 85 num_samples 1600 loss 0.006645940924308584\n",
      "Epoch 85 num_samples 1700 loss 0.006386228207554161\n",
      "Epoch 85 num_samples 1800 loss 0.006344585095305147\n",
      "Epoch 85 num_samples 1900 loss 0.007577180866653548\n",
      "Epoch 85 num_samples 2000 loss 0.008906120158872917\n",
      "Epoch 85 num_samples 2100 loss 0.0046739846946646894\n",
      "Epoch 85 num_samples 2200 loss 0.005323902995430661\n",
      "Epoch 85 num_samples 2300 loss 0.0035337519837701646\n",
      "Epoch 85 num_samples 2400 loss 0.00584365860527489\n",
      "Epoch 85 num_samples 2500 loss 0.007803678821243517\n",
      "Epoch 85 num_samples 2600 loss 0.008555096249348512\n",
      "Epoch 85 num_samples 2700 loss 0.006153626548196145\n",
      "Epoch 85 num_samples 2800 loss 0.00842951541327432\n",
      "Epoch 85 num_samples 2900 loss 0.007845986944210251\n",
      "Epoch 85 num_samples 3000 loss 0.006443370245713276\n",
      "Epoch 85 num_samples 3100 loss 0.006296901535206103\n",
      "Epoch 85 num_samples 3200 loss 0.010441425679879789\n",
      "Epoch 85 num_samples 3300 loss 0.006983493519776801\n",
      "Epoch 85 num_samples 3400 loss 0.00569882870007099\n",
      "Epoch 85 num_samples 3500 loss 0.006005329984017545\n",
      "Epoch 85 num_samples 3600 loss 0.0046467516059654716\n",
      "Epoch 85 num_samples 3700 loss 0.010285247679586012\n",
      "Epoch 85 num_samples 3800 loss 0.0055657901151939205\n",
      "Epoch 85 num_samples 3900 loss 0.007108087031293563\n",
      "Epoch 85 num_samples 4000 loss 0.0076588389026364025\n",
      "Epoch 85 num_samples 4100 loss 0.00966013539249305\n",
      "Epoch 85 num_samples 4200 loss 0.0073789359540681965\n",
      "Epoch 85 num_samples 4300 loss 0.006370406229954817\n",
      "Epoch 85 num_samples 4400 loss 0.007309646487789163\n",
      "Epoch 85 num_samples 4500 loss 0.008883290157686036\n",
      "Epoch 85 num_samples 4600 loss 0.00783431137856099\n",
      "Epoch 85 num_samples 4700 loss 0.004461895169029274\n",
      "Epoch 85 num_samples 4800 loss 0.00481393329072122\n",
      "Epoch 85 num_samples 4900 loss 0.00616434752941748\n",
      "Epoch 85 num_samples 5000 loss 0.005419343869809685\n",
      "Epoch 85 num_samples 5100 loss 0.009593562893610163\n",
      "Epoch 85 num_samples 5200 loss 0.004716537877837528\n",
      "Epoch 85 num_samples 5300 loss 0.006354767546670019\n",
      "Epoch 85 num_samples 5400 loss 0.008778850268164105\n",
      "Epoch 85 num_samples 5500 loss 0.005342610490591626\n",
      "Epoch 85 num_samples 5600 loss 0.016875463196872022\n",
      "Epoch 85 num_samples 5700 loss 0.006742009854929838\n",
      "Epoch 85 num_samples 5800 loss 0.0066613719956202765\n",
      "Epoch 85 num_samples 5900 loss 0.008408099359561248\n",
      "Epoch 85 num_samples 6000 loss 0.006918419626161045\n",
      "Epoch 85 num_samples 6100 loss 0.00647252373291645\n",
      "Epoch 85 num_samples 6200 loss 0.007217429564148581\n",
      "Epoch 85 num_samples 6300 loss 0.0088629348692526\n",
      "Epoch 85 num_samples 6400 loss 0.005800875736550277\n",
      "Epoch 85 num_samples 6500 loss 0.005035483311610776\n",
      "Epoch 85 num_samples 6600 loss 0.011876708763237398\n",
      "Epoch 85 num_samples 6700 loss 0.006038309970421154\n",
      "Epoch 85 num_samples 6800 loss 0.003826780114175728\n",
      "Epoch 85 num_samples 6900 loss 0.014407654847053229\n",
      "Epoch 85 num_samples 7000 loss 0.008491531417963221\n",
      "Epoch 85 num_samples 7100 loss 0.004786036111256523\n",
      "Epoch 85 num_samples 7200 loss 0.006859847180439408\n",
      "Epoch 85 num_samples 7300 loss 0.007075616759394072\n",
      "Epoch 85 num_samples 7400 loss 0.005222543271665707\n",
      "Epoch 85 num_samples 7500 loss 0.010284821365300609\n",
      "Epoch 85 num_samples 7600 loss 0.007125688788181868\n",
      "Epoch 85 num_samples 7700 loss 0.009543753367494488\n",
      "Epoch 85 num_samples 7800 loss 0.005901928744201088\n",
      "Epoch 85 num_samples 7900 loss 0.007399877222839175\n",
      "Epoch 85 num_samples 8000 loss 0.004839987015466974\n",
      "Epoch 85 num_samples 8100 loss 0.006297535913364082\n",
      "Epoch 85 num_samples 8200 loss 0.007487612850301384\n",
      "Epoch 85 num_samples 8300 loss 0.005780738163032468\n",
      "Epoch 85 num_samples 8400 loss 0.004736990795181347\n",
      "Epoch 85 num_samples 8500 loss 0.007075858118909278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 num_samples 8600 loss 0.006937818158762921\n",
      "Epoch 85 num_samples 8700 loss 0.0070206751186442295\n",
      "Epoch 85 num_samples 8800 loss 0.006760967689253066\n",
      "Epoch 85 num_samples 8900 loss 0.008267542970963812\n",
      "Epoch 85 num_samples 9000 loss 0.0070382463024103925\n",
      "Epoch 85 num_samples 9100 loss 0.006789100389797733\n",
      "Epoch 85 num_samples 9200 loss 0.007458619431929229\n",
      "Epoch 85 num_samples 9300 loss 0.007169842180103168\n",
      "Epoch 85 num_samples 9400 loss 0.005972797964434951\n",
      "Epoch 85 num_samples 9500 loss 0.005861586802126208\n",
      "Epoch 85 num_samples 9600 loss 0.006578967956439756\n",
      "Epoch 85 num_samples 9700 loss 0.009365689512474995\n",
      "Epoch 85 num_samples 9800 loss 0.004324255647643397\n",
      "Epoch 85 num_samples 9900 loss 0.012602896919062379\n",
      "Epoch 85 num_samples 10000 loss 0.005734905830368402\n",
      "Epoch 85 num_samples 10100 loss 0.005314257562277999\n",
      "Epoch 85 num_samples 10200 loss 0.008246469259171265\n",
      "Epoch 85 num_samples 10300 loss 0.00681345550261929\n",
      "Epoch 85 num_samples 10400 loss 0.009018148190750523\n",
      "Epoch 85 num_samples 10500 loss 0.0064438769172345855\n",
      "Epoch 85 num_samples 10600 loss 0.007732458770434842\n",
      "Epoch 85 num_samples 10700 loss 0.0059981314735223544\n",
      "Epoch 85 num_samples 10800 loss 0.007876108833283055\n",
      "Epoch 85 num_samples 10900 loss 0.00592730986390515\n",
      "Epoch 85 num_samples 11000 loss 0.005504064627915005\n",
      "Epoch 85 num_samples 11100 loss 0.007353804363046835\n",
      "Epoch 85 num_samples 11200 loss 0.005669012719857246\n",
      "Epoch 85 num_samples 11300 loss 0.009194088457103353\n",
      "Epoch 85 num_samples 11400 loss 0.006314302127725153\n",
      "Epoch 85 num_samples 11500 loss 0.006033644749863878\n",
      "Epoch 85 num_samples 11600 loss 0.006019759192931893\n",
      "Epoch 85 num_samples 11700 loss 0.008102349853337973\n",
      "Epoch 85 num_samples 11800 loss 0.006059630389472175\n",
      "Epoch 85 num_samples 11900 loss 0.005244721172192804\n",
      "Epoch 85 num_samples 12000 loss 0.004650500994560392\n",
      "Epoch 85 num_samples 12100 loss 0.005214370369367147\n",
      "Epoch 85 num_samples 12200 loss 0.007392696124290379\n",
      "Epoch 85 num_samples 12300 loss 0.005484272271364577\n",
      "Epoch 85 num_samples 12400 loss 0.008384105619040044\n",
      "Epoch 85 num_samples 12500 loss 0.007484742229816523\n",
      "Epoch 85 num_samples 12600 loss 0.009322229430816422\n",
      "Epoch 85 num_samples 12700 loss 0.006822611147254513\n",
      "Epoch 85 num_samples 12800 loss 0.01043432233821377\n",
      "Epoch 85 num_samples 12900 loss 0.00596060781828586\n",
      "Epoch 85 num_samples 13000 loss 0.005677615547946506\n",
      "Epoch 85 num_samples 13100 loss 0.008784024386307867\n",
      "Epoch 85 num_samples 13200 loss 0.003907273517389943\n",
      "Epoch 85 num_samples 13300 loss 0.005425687915414054\n",
      "Epoch 85 num_samples 13400 loss 0.003606795961627457\n",
      "Epoch 85 num_samples 13500 loss 0.004934153068420997\n",
      "Epoch 85 num_samples 13600 loss 0.008926843926502483\n",
      "Epoch 85 num_samples 13700 loss 0.006512286029685932\n",
      "Epoch 85 num_samples 13800 loss 0.006407771588113164\n",
      "Epoch 85 num_samples 13900 loss 0.0026779172844366653\n",
      "Epoch 85 num_samples 14000 loss 0.004600871006919893\n",
      "Epoch 85 num_samples 14100 loss 0.006046241289897649\n",
      "Epoch 85 num_samples 14200 loss 0.005676490102451069\n",
      "Epoch 85 num_samples 14300 loss 0.007335410396756476\n",
      "Epoch 85 num_samples 14400 loss 0.007397426945734756\n",
      "Epoch 85 num_samples 14500 loss 0.009171247067889337\n",
      "Epoch 85 num_samples 14600 loss 0.006158287007946411\n",
      "Epoch 85 num_samples 14700 loss 0.006757878928281585\n",
      "Epoch 85 num_samples 14800 loss 0.006492032168408717\n",
      "Epoch 85 num_samples 14900 loss 0.007538966654038132\n",
      "Epoch 85 num_samples 15000 loss 0.006455584809434427\n",
      "Epoch 85 num_samples 15100 loss 0.006997264766631582\n",
      "Epoch 85 num_samples 15200 loss 0.006728015713746356\n",
      "Epoch 85 num_samples 15300 loss 0.007241431398868554\n",
      "Epoch 85 num_samples 15400 loss 0.0052101607771156576\n",
      "Epoch 85 num_samples 15500 loss 0.006868546790549109\n",
      "Epoch 85 num_samples 15600 loss 0.007394572068516616\n",
      "Epoch 85 num_samples 15700 loss 0.00492668334784416\n",
      "Epoch 85 num_samples 15800 loss 0.007960011703970558\n",
      "Epoch 85 num_samples 15900 loss 0.005357033734191549\n",
      "Epoch 85 num_samples 16000 loss 0.009696415090702048\n",
      "Epoch 85 num_samples 16100 loss 0.0051823561421863494\n",
      "Epoch 85 num_samples 16200 loss 0.007621070609830274\n",
      "Epoch 85 num_samples 16300 loss 0.008816486277606526\n",
      "Epoch 85 num_samples 16400 loss 0.008935609337894872\n",
      "Epoch 85 num_samples 16500 loss 0.007682823097758754\n",
      "Epoch 85 num_samples 16600 loss 0.008660075516683604\n",
      "Epoch 85 num_samples 16700 loss 0.004847716616648408\n",
      "Epoch 85 num_samples 16800 loss 0.004894305432466804\n",
      "Epoch 85 num_samples 16900 loss 0.005610602954711908\n",
      "Epoch 85 num_samples 17000 loss 0.004335056201732571\n",
      "Epoch 85 num_samples 17100 loss 0.01063638858635444\n",
      "Epoch 85 num_samples 17200 loss 0.007573600529538502\n",
      "Epoch 85 num_samples 17300 loss 0.007789848404977164\n",
      "Epoch 85 num_samples 17400 loss 0.006603001572372091\n",
      "Epoch 85 num_samples 17500 loss 0.007077130390831845\n",
      "Epoch 85 num_samples 17600 loss 0.006234013310130289\n",
      "Epoch 85 num_samples 17700 loss 0.005333556879517436\n",
      "Epoch 85 num_samples 17800 loss 0.005641108813118563\n",
      "Epoch 85 num_samples 17900 loss 0.008541814717723018\n",
      "Epoch 85 num_samples 18000 loss 0.006415750509919629\n",
      "Epoch 85 num_samples 18100 loss 0.007020911620579003\n",
      "Epoch 85 num_samples 18200 loss 0.007506381486852807\n",
      "Epoch 85 num_samples 18300 loss 0.005487910953411322\n",
      "Epoch 85 num_samples 18400 loss 0.010333322963238814\n",
      "Epoch 85 num_samples 18500 loss 0.007592930862350215\n",
      "Epoch 86 num_samples 0 loss 0.005280067872961069\n",
      "Epoch 86 num_samples 100 loss 0.009232658637655888\n",
      "Epoch 86 num_samples 200 loss 0.006189755531180271\n",
      "Epoch 86 num_samples 300 loss 0.005241411801429194\n",
      "Epoch 86 num_samples 400 loss 0.006390544133850111\n",
      "Epoch 86 num_samples 500 loss 0.009556991545669455\n",
      "Epoch 86 num_samples 600 loss 0.009219909123770622\n",
      "Epoch 86 num_samples 700 loss 0.010073831698800707\n",
      "Epoch 86 num_samples 800 loss 0.005905838160385122\n",
      "Epoch 86 num_samples 900 loss 0.010522742789389467\n",
      "Epoch 86 num_samples 1000 loss 0.006248211397339899\n",
      "Epoch 86 num_samples 1100 loss 0.0103384804145966\n",
      "Epoch 86 num_samples 1200 loss 0.00631517969991163\n",
      "Epoch 86 num_samples 1300 loss 0.007395215409932137\n",
      "Epoch 86 num_samples 1400 loss 0.007362783674987574\n",
      "Epoch 86 num_samples 1500 loss 0.008618912497020523\n",
      "Epoch 86 num_samples 1600 loss 0.00649812490373219\n",
      "Epoch 86 num_samples 1700 loss 0.006252927845684058\n",
      "Epoch 86 num_samples 1800 loss 0.006238512589812185\n",
      "Epoch 86 num_samples 1900 loss 0.007438305999381934\n",
      "Epoch 86 num_samples 2000 loss 0.008705632737893938\n",
      "Epoch 86 num_samples 2100 loss 0.004583023848227282\n",
      "Epoch 86 num_samples 2200 loss 0.005220954726810503\n",
      "Epoch 86 num_samples 2300 loss 0.0034585146223169104\n",
      "Epoch 86 num_samples 2400 loss 0.005712807721992618\n",
      "Epoch 86 num_samples 2500 loss 0.007647210106859988\n",
      "Epoch 86 num_samples 2600 loss 0.00838058769935482\n",
      "Epoch 86 num_samples 2700 loss 0.006058680377582751\n",
      "Epoch 86 num_samples 2800 loss 0.008276214212456369\n",
      "Epoch 86 num_samples 2900 loss 0.007677412471412587\n",
      "Epoch 86 num_samples 3000 loss 0.00630367678701694\n",
      "Epoch 86 num_samples 3100 loss 0.006163502211354293\n",
      "Epoch 86 num_samples 3200 loss 0.010183542671408544\n",
      "Epoch 86 num_samples 3300 loss 0.006845408703960854\n",
      "Epoch 86 num_samples 3400 loss 0.005575387017931898\n",
      "Epoch 86 num_samples 3500 loss 0.005911574311557818\n",
      "Epoch 86 num_samples 3600 loss 0.0045709633089408615\n",
      "Epoch 86 num_samples 3700 loss 0.01005911212415283\n",
      "Epoch 86 num_samples 3800 loss 0.005454879886489585\n",
      "Epoch 86 num_samples 3900 loss 0.006974989947492145\n",
      "Epoch 86 num_samples 4000 loss 0.007476439980060226\n",
      "Epoch 86 num_samples 4100 loss 0.009456310118755393\n",
      "Epoch 86 num_samples 4200 loss 0.007229128026542484\n",
      "Epoch 86 num_samples 4300 loss 0.006219219676895847\n",
      "Epoch 86 num_samples 4400 loss 0.007187084012777635\n",
      "Epoch 86 num_samples 4500 loss 0.008702239607795459\n",
      "Epoch 86 num_samples 4600 loss 0.007669233022054562\n",
      "Epoch 86 num_samples 4700 loss 0.004392925779539099\n",
      "Epoch 86 num_samples 4800 loss 0.0047243142965804645\n",
      "Epoch 86 num_samples 4900 loss 0.006049189568912722\n",
      "Epoch 86 num_samples 5000 loss 0.005320135574500422\n",
      "Epoch 86 num_samples 5100 loss 0.00944288636129605\n",
      "Epoch 86 num_samples 5200 loss 0.004648190083612288\n",
      "Epoch 86 num_samples 5300 loss 0.0062329284196957655\n",
      "Epoch 86 num_samples 5400 loss 0.008619060077400513\n",
      "Epoch 86 num_samples 5500 loss 0.005241768078618363\n",
      "Epoch 86 num_samples 5600 loss 0.016494480972022937\n",
      "Epoch 86 num_samples 5700 loss 0.006596907841690338\n",
      "Epoch 86 num_samples 5800 loss 0.006546348483147707\n",
      "Epoch 86 num_samples 5900 loss 0.008213154453046432\n",
      "Epoch 86 num_samples 6000 loss 0.00679617650031858\n",
      "Epoch 86 num_samples 6100 loss 0.006364942846106163\n",
      "Epoch 86 num_samples 6200 loss 0.007088957525448426\n",
      "Epoch 86 num_samples 6300 loss 0.00866262737225958\n",
      "Epoch 86 num_samples 6400 loss 0.005664448401207689\n",
      "Epoch 86 num_samples 6500 loss 0.004933031287415188\n",
      "Epoch 86 num_samples 6600 loss 0.011660309413591785\n",
      "Epoch 86 num_samples 6700 loss 0.0059377354479874045\n",
      "Epoch 86 num_samples 6800 loss 0.0037354247227235236\n",
      "Epoch 86 num_samples 6900 loss 0.014091501405761174\n",
      "Epoch 86 num_samples 7000 loss 0.00835442382084411\n",
      "Epoch 86 num_samples 7100 loss 0.004691110740790843\n",
      "Epoch 86 num_samples 7200 loss 0.00672498302087107\n",
      "Epoch 86 num_samples 7300 loss 0.006953398668547277\n",
      "Epoch 86 num_samples 7400 loss 0.005126134310148751\n",
      "Epoch 86 num_samples 7500 loss 0.010054618590073956\n",
      "Epoch 86 num_samples 7600 loss 0.006947019200889662\n",
      "Epoch 86 num_samples 7700 loss 0.009326894718667043\n",
      "Epoch 86 num_samples 7800 loss 0.005782692060648183\n",
      "Epoch 86 num_samples 7900 loss 0.007244170469873439\n",
      "Epoch 86 num_samples 8000 loss 0.004761176186649456\n",
      "Epoch 86 num_samples 8100 loss 0.006171016478562814\n",
      "Epoch 86 num_samples 8200 loss 0.007323345185098698\n",
      "Epoch 86 num_samples 8300 loss 0.005644410983323083\n",
      "Epoch 86 num_samples 8400 loss 0.004651807000642969\n",
      "Epoch 86 num_samples 8500 loss 0.006970591403280149\n",
      "Epoch 86 num_samples 8600 loss 0.006757530860291402\n",
      "Epoch 86 num_samples 8700 loss 0.006879596324938786\n",
      "Epoch 86 num_samples 8800 loss 0.006608901636798448\n",
      "Epoch 86 num_samples 8900 loss 0.008083523626532644\n",
      "Epoch 86 num_samples 9000 loss 0.006907787623498649\n",
      "Epoch 86 num_samples 9100 loss 0.0066511135800375685\n",
      "Epoch 86 num_samples 9200 loss 0.0073317887961627005\n",
      "Epoch 86 num_samples 9300 loss 0.007039064639012435\n",
      "Epoch 86 num_samples 9400 loss 0.005864930139545187\n",
      "Epoch 86 num_samples 9500 loss 0.005760820370657442\n",
      "Epoch 86 num_samples 9600 loss 0.006448593097470339\n",
      "Epoch 86 num_samples 9700 loss 0.009144688431541441\n",
      "Epoch 86 num_samples 9800 loss 0.004222270568312219\n",
      "Epoch 86 num_samples 9900 loss 0.012312081676585106\n",
      "Epoch 86 num_samples 10000 loss 0.0056090565932091704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 num_samples 10100 loss 0.005206923567639421\n",
      "Epoch 86 num_samples 10200 loss 0.008077563936361751\n",
      "Epoch 86 num_samples 10300 loss 0.006685401134724957\n",
      "Epoch 86 num_samples 10400 loss 0.008868725427926362\n",
      "Epoch 86 num_samples 10500 loss 0.006332233632772711\n",
      "Epoch 86 num_samples 10600 loss 0.007580649618242358\n",
      "Epoch 86 num_samples 10700 loss 0.005865867009098302\n",
      "Epoch 86 num_samples 10800 loss 0.007706201377915989\n",
      "Epoch 86 num_samples 10900 loss 0.005799798848484025\n",
      "Epoch 86 num_samples 11000 loss 0.0053872244146599725\n",
      "Epoch 86 num_samples 11100 loss 0.007211731311670058\n",
      "Epoch 86 num_samples 11200 loss 0.005567407038654657\n",
      "Epoch 86 num_samples 11300 loss 0.00899932212352871\n",
      "Epoch 86 num_samples 11400 loss 0.006198544329386806\n",
      "Epoch 86 num_samples 11500 loss 0.005905838770032912\n",
      "Epoch 86 num_samples 11600 loss 0.005895205622657294\n",
      "Epoch 86 num_samples 11700 loss 0.00792792929192103\n",
      "Epoch 86 num_samples 11800 loss 0.005951922435975477\n",
      "Epoch 86 num_samples 11900 loss 0.005148547342500737\n",
      "Epoch 86 num_samples 12000 loss 0.004542737949336565\n",
      "Epoch 86 num_samples 12100 loss 0.005110193987009662\n",
      "Epoch 86 num_samples 12200 loss 0.0072247693888785125\n",
      "Epoch 86 num_samples 12300 loss 0.005366053684704962\n",
      "Epoch 86 num_samples 12400 loss 0.008228908946443493\n",
      "Epoch 86 num_samples 12500 loss 0.007329281642615439\n",
      "Epoch 86 num_samples 12600 loss 0.009136726260407974\n",
      "Epoch 86 num_samples 12700 loss 0.00667830696526489\n",
      "Epoch 86 num_samples 12800 loss 0.010229890750012523\n",
      "Epoch 86 num_samples 12900 loss 0.005844782039865006\n",
      "Epoch 86 num_samples 13000 loss 0.005562976493803884\n",
      "Epoch 86 num_samples 13100 loss 0.008601150273051347\n",
      "Epoch 86 num_samples 13200 loss 0.0038296871978881013\n",
      "Epoch 86 num_samples 13300 loss 0.005323053105676021\n",
      "Epoch 86 num_samples 13400 loss 0.0035159990351224606\n",
      "Epoch 86 num_samples 13500 loss 0.00485258617171845\n",
      "Epoch 86 num_samples 13600 loss 0.008756623139147294\n",
      "Epoch 86 num_samples 13700 loss 0.0063752812458571124\n",
      "Epoch 86 num_samples 13800 loss 0.0062869176533015825\n",
      "Epoch 86 num_samples 13900 loss 0.0026283277432513873\n",
      "Epoch 86 num_samples 14000 loss 0.004519192869266674\n",
      "Epoch 86 num_samples 14100 loss 0.005938898007723179\n",
      "Epoch 86 num_samples 14200 loss 0.00560639924944769\n",
      "Epoch 86 num_samples 14300 loss 0.007197031874715818\n",
      "Epoch 86 num_samples 14400 loss 0.00724418851181079\n",
      "Epoch 86 num_samples 14500 loss 0.009007140378934232\n",
      "Epoch 86 num_samples 14600 loss 0.006030803047807001\n",
      "Epoch 86 num_samples 14700 loss 0.006618251817431011\n",
      "Epoch 86 num_samples 14800 loss 0.006366710810622582\n",
      "Epoch 86 num_samples 14900 loss 0.007377454028350971\n",
      "Epoch 86 num_samples 15000 loss 0.006320678459082344\n",
      "Epoch 86 num_samples 15100 loss 0.006869602675007411\n",
      "Epoch 86 num_samples 15200 loss 0.006577673812948432\n",
      "Epoch 86 num_samples 15300 loss 0.007101091251145979\n",
      "Epoch 86 num_samples 15400 loss 0.005106107118965412\n",
      "Epoch 86 num_samples 15500 loss 0.0067370126990522385\n",
      "Epoch 86 num_samples 15600 loss 0.007237512434854258\n",
      "Epoch 86 num_samples 15700 loss 0.004844360199214557\n",
      "Epoch 86 num_samples 15800 loss 0.007801987195193975\n",
      "Epoch 86 num_samples 15900 loss 0.0052639001615786656\n",
      "Epoch 86 num_samples 16000 loss 0.009469338800071423\n",
      "Epoch 86 num_samples 16100 loss 0.00507357852788181\n",
      "Epoch 86 num_samples 16200 loss 0.007460081132197367\n",
      "Epoch 86 num_samples 16300 loss 0.008652811131369152\n",
      "Epoch 86 num_samples 16400 loss 0.008724017649848126\n",
      "Epoch 86 num_samples 16500 loss 0.0075403583277874895\n",
      "Epoch 86 num_samples 16600 loss 0.008517291157576991\n",
      "Epoch 86 num_samples 16700 loss 0.004750089594616183\n",
      "Epoch 86 num_samples 16800 loss 0.00480974574904773\n",
      "Epoch 86 num_samples 16900 loss 0.00549160359419187\n",
      "Epoch 86 num_samples 17000 loss 0.004247532831303428\n",
      "Epoch 86 num_samples 17100 loss 0.010425668227804134\n",
      "Epoch 86 num_samples 17200 loss 0.007422947968624255\n",
      "Epoch 86 num_samples 17300 loss 0.0076358432209199\n",
      "Epoch 86 num_samples 17400 loss 0.0064707229144393506\n",
      "Epoch 86 num_samples 17500 loss 0.0069385475695272905\n",
      "Epoch 86 num_samples 17600 loss 0.006095343657717583\n",
      "Epoch 86 num_samples 17700 loss 0.005214514063554283\n",
      "Epoch 86 num_samples 17800 loss 0.005532754969998602\n",
      "Epoch 86 num_samples 17900 loss 0.008329476416810309\n",
      "Epoch 86 num_samples 18000 loss 0.006301775599190701\n",
      "Epoch 86 num_samples 18100 loss 0.006892134609715876\n",
      "Epoch 86 num_samples 18200 loss 0.007373329319947605\n",
      "Epoch 86 num_samples 18300 loss 0.005376393459933326\n",
      "Epoch 86 num_samples 18400 loss 0.010136293941808393\n",
      "Epoch 86 num_samples 18500 loss 0.0074267763955987946\n",
      "Epoch 87 num_samples 0 loss 0.005182941609875784\n",
      "Epoch 87 num_samples 100 loss 0.00902619890607147\n",
      "Epoch 87 num_samples 200 loss 0.006061524085684789\n",
      "Epoch 87 num_samples 300 loss 0.005147164765880036\n",
      "Epoch 87 num_samples 400 loss 0.006276034286953007\n",
      "Epoch 87 num_samples 500 loss 0.009397392379442706\n",
      "Epoch 87 num_samples 600 loss 0.008999942175890834\n",
      "Epoch 87 num_samples 700 loss 0.009862549382587486\n",
      "Epoch 87 num_samples 800 loss 0.0057843664130738225\n",
      "Epoch 87 num_samples 900 loss 0.010339949604148475\n",
      "Epoch 87 num_samples 1000 loss 0.006117393801639297\n",
      "Epoch 87 num_samples 1100 loss 0.01013486372389643\n",
      "Epoch 87 num_samples 1200 loss 0.006184597873182345\n",
      "Epoch 87 num_samples 1300 loss 0.007264052558380847\n",
      "Epoch 87 num_samples 1400 loss 0.0071745417934284015\n",
      "Epoch 87 num_samples 1500 loss 0.008475071744984181\n",
      "Epoch 87 num_samples 1600 loss 0.006369924659519635\n",
      "Epoch 87 num_samples 1700 loss 0.00613813835892335\n",
      "Epoch 87 num_samples 1800 loss 0.0061238395481224474\n",
      "Epoch 87 num_samples 1900 loss 0.0073160765489392885\n",
      "Epoch 87 num_samples 2000 loss 0.00854246591429739\n",
      "Epoch 87 num_samples 2100 loss 0.004498758603545052\n",
      "Epoch 87 num_samples 2200 loss 0.005125204928624216\n",
      "Epoch 87 num_samples 2300 loss 0.0033958104365110816\n",
      "Epoch 87 num_samples 2400 loss 0.00560754323063329\n",
      "Epoch 87 num_samples 2500 loss 0.0074819952078905095\n",
      "Epoch 87 num_samples 2600 loss 0.008182550909048859\n",
      "Epoch 87 num_samples 2700 loss 0.005959924759391844\n",
      "Epoch 87 num_samples 2800 loss 0.008116303505991053\n",
      "Epoch 87 num_samples 2900 loss 0.007526838066228757\n",
      "Epoch 87 num_samples 3000 loss 0.006173470421394288\n",
      "Epoch 87 num_samples 3100 loss 0.006045302345045591\n",
      "Epoch 87 num_samples 3200 loss 0.009941245759391976\n",
      "Epoch 87 num_samples 3300 loss 0.006690209954211539\n",
      "Epoch 87 num_samples 3400 loss 0.005471007279643767\n",
      "Epoch 87 num_samples 3500 loss 0.005799487416396192\n",
      "Epoch 87 num_samples 3600 loss 0.00449194574916171\n",
      "Epoch 87 num_samples 3700 loss 0.009865885833018654\n",
      "Epoch 87 num_samples 3800 loss 0.005341221630057655\n",
      "Epoch 87 num_samples 3900 loss 0.006849085223313008\n",
      "Epoch 87 num_samples 4000 loss 0.007336081606085683\n",
      "Epoch 87 num_samples 4100 loss 0.009259257926685334\n",
      "Epoch 87 num_samples 4200 loss 0.007089318698019047\n",
      "Epoch 87 num_samples 4300 loss 0.0060956285773158024\n",
      "Epoch 87 num_samples 4400 loss 0.007028281707267421\n",
      "Epoch 87 num_samples 4500 loss 0.008546516714977394\n",
      "Epoch 87 num_samples 4600 loss 0.0075364312959459445\n",
      "Epoch 87 num_samples 4700 loss 0.00429930202399658\n",
      "Epoch 87 num_samples 4800 loss 0.00462181219675317\n",
      "Epoch 87 num_samples 4900 loss 0.0059405765803268494\n",
      "Epoch 87 num_samples 5000 loss 0.005223780688011737\n",
      "Epoch 87 num_samples 5100 loss 0.009234247614545239\n",
      "Epoch 87 num_samples 5200 loss 0.00454431937171343\n",
      "Epoch 87 num_samples 5300 loss 0.006127108765894285\n",
      "Epoch 87 num_samples 5400 loss 0.008459444995402387\n",
      "Epoch 87 num_samples 5500 loss 0.005150000100752583\n",
      "Epoch 87 num_samples 5600 loss 0.01608310465767817\n",
      "Epoch 87 num_samples 5700 loss 0.00649374825905277\n",
      "Epoch 87 num_samples 5800 loss 0.006421244236568189\n",
      "Epoch 87 num_samples 5900 loss 0.008032428133085391\n",
      "Epoch 87 num_samples 6000 loss 0.006679645165876377\n",
      "Epoch 87 num_samples 6100 loss 0.006254093726742742\n",
      "Epoch 87 num_samples 6200 loss 0.0069480867875066155\n",
      "Epoch 87 num_samples 6300 loss 0.00849043310662159\n",
      "Epoch 87 num_samples 6400 loss 0.005551439624566599\n",
      "Epoch 87 num_samples 6500 loss 0.004835612593272009\n",
      "Epoch 87 num_samples 6600 loss 0.011444156858572141\n",
      "Epoch 87 num_samples 6700 loss 0.005844055998736692\n",
      "Epoch 87 num_samples 6800 loss 0.0036590125377077166\n",
      "Epoch 87 num_samples 6900 loss 0.013823212588291688\n",
      "Epoch 87 num_samples 7000 loss 0.008190166592710036\n",
      "Epoch 87 num_samples 7100 loss 0.004616566026169675\n",
      "Epoch 87 num_samples 7200 loss 0.006609001553281298\n",
      "Epoch 87 num_samples 7300 loss 0.006807164262740006\n",
      "Epoch 87 num_samples 7400 loss 0.005013974781122552\n",
      "Epoch 87 num_samples 7500 loss 0.009819032231263824\n",
      "Epoch 87 num_samples 7600 loss 0.006833593954116648\n",
      "Epoch 87 num_samples 7700 loss 0.009141645638127157\n",
      "Epoch 87 num_samples 7800 loss 0.005680125259662454\n",
      "Epoch 87 num_samples 7900 loss 0.007100421273279696\n",
      "Epoch 87 num_samples 8000 loss 0.004665570268174101\n",
      "Epoch 87 num_samples 8100 loss 0.00606150586131399\n",
      "Epoch 87 num_samples 8200 loss 0.0071654412275445\n",
      "Epoch 87 num_samples 8300 loss 0.0055403053882734565\n",
      "Epoch 87 num_samples 8400 loss 0.004564827986843802\n",
      "Epoch 87 num_samples 8500 loss 0.006831645995956135\n",
      "Epoch 87 num_samples 8600 loss 0.006605350777756257\n",
      "Epoch 87 num_samples 8700 loss 0.006754896145793637\n",
      "Epoch 87 num_samples 8800 loss 0.006464425518803757\n",
      "Epoch 87 num_samples 8900 loss 0.007909633034142067\n",
      "Epoch 87 num_samples 9000 loss 0.006762088336074024\n",
      "Epoch 87 num_samples 9100 loss 0.006513459992853644\n",
      "Epoch 87 num_samples 9200 loss 0.007191323631521613\n",
      "Epoch 87 num_samples 9300 loss 0.006869581545058701\n",
      "Epoch 87 num_samples 9400 loss 0.0057608034436147405\n",
      "Epoch 87 num_samples 9500 loss 0.0056303783007869155\n",
      "Epoch 87 num_samples 9600 loss 0.006325348280391872\n",
      "Epoch 87 num_samples 9700 loss 0.008961574707306647\n",
      "Epoch 87 num_samples 9800 loss 0.004130403189225458\n",
      "Epoch 87 num_samples 9900 loss 0.012110656169009675\n",
      "Epoch 87 num_samples 10000 loss 0.005510512325641181\n",
      "Epoch 87 num_samples 10100 loss 0.0051053225975259305\n",
      "Epoch 87 num_samples 10200 loss 0.007912937094499627\n",
      "Epoch 87 num_samples 10300 loss 0.006541186120230349\n",
      "Epoch 87 num_samples 10400 loss 0.008703229612175907\n",
      "Epoch 87 num_samples 10500 loss 0.006203687867626424\n",
      "Epoch 87 num_samples 10600 loss 0.0074073463486331705\n",
      "Epoch 87 num_samples 10700 loss 0.005763060324570138\n",
      "Epoch 87 num_samples 10800 loss 0.007539398148032861\n",
      "Epoch 87 num_samples 10900 loss 0.005690599862333958\n",
      "Epoch 87 num_samples 11000 loss 0.005284230586669298\n",
      "Epoch 87 num_samples 11100 loss 0.007101053161465765\n",
      "Epoch 87 num_samples 11200 loss 0.00547379648771585\n",
      "Epoch 87 num_samples 11300 loss 0.008815523018736495\n",
      "Epoch 87 num_samples 11400 loss 0.006051340905669176\n",
      "Epoch 87 num_samples 11500 loss 0.005793900138229229\n",
      "Epoch 87 num_samples 11600 loss 0.005798141709554937\n",
      "Epoch 87 num_samples 11700 loss 0.007766184127766756\n",
      "Epoch 87 num_samples 11800 loss 0.005841414597148216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 num_samples 11900 loss 0.005039811533867972\n",
      "Epoch 87 num_samples 12000 loss 0.004474938263309224\n",
      "Epoch 87 num_samples 12100 loss 0.005000999638239298\n",
      "Epoch 87 num_samples 12200 loss 0.007087610849729411\n",
      "Epoch 87 num_samples 12300 loss 0.005292006488285693\n",
      "Epoch 87 num_samples 12400 loss 0.008042013160853614\n",
      "Epoch 87 num_samples 12500 loss 0.007199158448937434\n",
      "Epoch 87 num_samples 12600 loss 0.008960063133923479\n",
      "Epoch 87 num_samples 12700 loss 0.006549178570860734\n",
      "Epoch 87 num_samples 12800 loss 0.00999178903856768\n",
      "Epoch 87 num_samples 12900 loss 0.005709011951569799\n",
      "Epoch 87 num_samples 13000 loss 0.005447421233233645\n",
      "Epoch 87 num_samples 13100 loss 0.008436242379149316\n",
      "Epoch 87 num_samples 13200 loss 0.0037466499738435487\n",
      "Epoch 87 num_samples 13300 loss 0.005220172771247501\n",
      "Epoch 87 num_samples 13400 loss 0.003480128346355913\n",
      "Epoch 87 num_samples 13500 loss 0.004758427626755038\n",
      "Epoch 87 num_samples 13600 loss 0.008593785016280884\n",
      "Epoch 87 num_samples 13700 loss 0.006245398019515336\n",
      "Epoch 87 num_samples 13800 loss 0.006184865669560126\n",
      "Epoch 87 num_samples 13900 loss 0.002576770136570842\n",
      "Epoch 87 num_samples 14000 loss 0.0044268012576004255\n",
      "Epoch 87 num_samples 14100 loss 0.005800670914545063\n",
      "Epoch 87 num_samples 14200 loss 0.005510148306333154\n",
      "Epoch 87 num_samples 14300 loss 0.00704833847465129\n",
      "Epoch 87 num_samples 14400 loss 0.007097625511932448\n",
      "Epoch 87 num_samples 14500 loss 0.00882403791149667\n",
      "Epoch 87 num_samples 14600 loss 0.0058970396183280595\n",
      "Epoch 87 num_samples 14700 loss 0.0065013063173502035\n",
      "Epoch 87 num_samples 14800 loss 0.006245443734744589\n",
      "Epoch 87 num_samples 14900 loss 0.007242551580182547\n",
      "Epoch 87 num_samples 15000 loss 0.006211363718214835\n",
      "Epoch 87 num_samples 15100 loss 0.006754353808000073\n",
      "Epoch 87 num_samples 15200 loss 0.006430233202425904\n",
      "Epoch 87 num_samples 15300 loss 0.006965875187575952\n",
      "Epoch 87 num_samples 15400 loss 0.005010021299444338\n",
      "Epoch 87 num_samples 15500 loss 0.0065558440693031204\n",
      "Epoch 87 num_samples 15600 loss 0.007082521199372847\n",
      "Epoch 87 num_samples 15700 loss 0.004745747003145806\n",
      "Epoch 87 num_samples 15800 loss 0.007628018171616233\n",
      "Epoch 87 num_samples 15900 loss 0.005169706174737945\n",
      "Epoch 87 num_samples 16000 loss 0.009268598742738\n",
      "Epoch 87 num_samples 16100 loss 0.004970587318914692\n",
      "Epoch 87 num_samples 16200 loss 0.007312248343599506\n",
      "Epoch 87 num_samples 16300 loss 0.00849035265930265\n",
      "Epoch 87 num_samples 16400 loss 0.008529220093871226\n",
      "Epoch 87 num_samples 16500 loss 0.007367048654479238\n",
      "Epoch 87 num_samples 16600 loss 0.00837829471349616\n",
      "Epoch 87 num_samples 16700 loss 0.004642331798302623\n",
      "Epoch 87 num_samples 16800 loss 0.004708750949476121\n",
      "Epoch 87 num_samples 16900 loss 0.005393582838481229\n",
      "Epoch 87 num_samples 17000 loss 0.004173657337269599\n",
      "Epoch 87 num_samples 17100 loss 0.010210416255074666\n",
      "Epoch 87 num_samples 17200 loss 0.007271419082050045\n",
      "Epoch 87 num_samples 17300 loss 0.007482064715235202\n",
      "Epoch 87 num_samples 17400 loss 0.006347452995339651\n",
      "Epoch 87 num_samples 17500 loss 0.006809512001558454\n",
      "Epoch 87 num_samples 17600 loss 0.0059791718806628215\n",
      "Epoch 87 num_samples 17700 loss 0.005103546083371351\n",
      "Epoch 87 num_samples 17800 loss 0.005408774921799129\n",
      "Epoch 87 num_samples 17900 loss 0.008164184766066259\n",
      "Epoch 87 num_samples 18000 loss 0.006193046545893132\n",
      "Epoch 87 num_samples 18100 loss 0.006767113223026992\n",
      "Epoch 87 num_samples 18200 loss 0.007207677279147387\n",
      "Epoch 87 num_samples 18300 loss 0.005276058032322217\n",
      "Epoch 87 num_samples 18400 loss 0.009916612294430244\n",
      "Epoch 87 num_samples 18500 loss 0.007292431963025685\n",
      "Epoch 88 num_samples 0 loss 0.005064697022489961\n",
      "Epoch 88 num_samples 100 loss 0.008859649615372202\n",
      "Epoch 88 num_samples 200 loss 0.005941583802368164\n",
      "Epoch 88 num_samples 300 loss 0.005025818725436028\n",
      "Epoch 88 num_samples 400 loss 0.006143960531453898\n",
      "Epoch 88 num_samples 500 loss 0.009213159861740452\n",
      "Epoch 88 num_samples 600 loss 0.00884962682899454\n",
      "Epoch 88 num_samples 700 loss 0.009677222462688276\n",
      "Epoch 88 num_samples 800 loss 0.005679662950672155\n",
      "Epoch 88 num_samples 900 loss 0.010142081030631118\n",
      "Epoch 88 num_samples 1000 loss 0.005994247159812119\n",
      "Epoch 88 num_samples 1100 loss 0.009920714435606581\n",
      "Epoch 88 num_samples 1200 loss 0.006048921342066456\n",
      "Epoch 88 num_samples 1300 loss 0.007143346199318189\n",
      "Epoch 88 num_samples 1400 loss 0.007031677263098441\n",
      "Epoch 88 num_samples 1500 loss 0.008288423371136817\n",
      "Epoch 88 num_samples 1600 loss 0.006266395319937867\n",
      "Epoch 88 num_samples 1700 loss 0.006013892950526346\n",
      "Epoch 88 num_samples 1800 loss 0.006012625675943262\n",
      "Epoch 88 num_samples 1900 loss 0.007176124442264873\n",
      "Epoch 88 num_samples 2000 loss 0.008406104794589711\n",
      "Epoch 88 num_samples 2100 loss 0.004408368828159553\n",
      "Epoch 88 num_samples 2200 loss 0.005033671453792026\n",
      "Epoch 88 num_samples 2300 loss 0.003328151209244118\n",
      "Epoch 88 num_samples 2400 loss 0.005502158570826247\n",
      "Epoch 88 num_samples 2500 loss 0.007335750373823847\n",
      "Epoch 88 num_samples 2600 loss 0.008016828695061368\n",
      "Epoch 88 num_samples 2700 loss 0.005850996842609726\n",
      "Epoch 88 num_samples 2800 loss 0.00793799567496098\n",
      "Epoch 88 num_samples 2900 loss 0.0073963767472468\n",
      "Epoch 88 num_samples 3000 loss 0.006045495504384251\n",
      "Epoch 88 num_samples 3100 loss 0.005923134574039516\n",
      "Epoch 88 num_samples 3200 loss 0.009724763616073624\n",
      "Epoch 88 num_samples 3300 loss 0.006552654833968279\n",
      "Epoch 88 num_samples 3400 loss 0.005370035610540966\n",
      "Epoch 88 num_samples 3500 loss 0.005686591364364082\n",
      "Epoch 88 num_samples 3600 loss 0.004425064594840101\n",
      "Epoch 88 num_samples 3700 loss 0.009697616655507411\n",
      "Epoch 88 num_samples 3800 loss 0.005219771218307191\n",
      "Epoch 88 num_samples 3900 loss 0.006729175820344251\n",
      "Epoch 88 num_samples 4000 loss 0.007166215018110004\n",
      "Epoch 88 num_samples 4100 loss 0.009026968540643483\n",
      "Epoch 88 num_samples 4200 loss 0.006945256944938608\n",
      "Epoch 88 num_samples 4300 loss 0.005995614526892265\n",
      "Epoch 88 num_samples 4400 loss 0.006889527296727284\n",
      "Epoch 88 num_samples 4500 loss 0.008367537648942215\n",
      "Epoch 88 num_samples 4600 loss 0.0073876308362631\n",
      "Epoch 88 num_samples 4700 loss 0.004212729866149989\n",
      "Epoch 88 num_samples 4800 loss 0.0045449341873473855\n",
      "Epoch 88 num_samples 4900 loss 0.005830608356107958\n",
      "Epoch 88 num_samples 5000 loss 0.005122679503012373\n",
      "Epoch 88 num_samples 5100 loss 0.009066764627059694\n",
      "Epoch 88 num_samples 5200 loss 0.004468668775795478\n",
      "Epoch 88 num_samples 5300 loss 0.00599119855862701\n",
      "Epoch 88 num_samples 5400 loss 0.00828785795196924\n",
      "Epoch 88 num_samples 5500 loss 0.005043754361750547\n",
      "Epoch 88 num_samples 5600 loss 0.015721857085252568\n",
      "Epoch 88 num_samples 5700 loss 0.006339909967187272\n",
      "Epoch 88 num_samples 5800 loss 0.006306130701069851\n",
      "Epoch 88 num_samples 5900 loss 0.007876808440162721\n",
      "Epoch 88 num_samples 6000 loss 0.006556919127991655\n",
      "Epoch 88 num_samples 6100 loss 0.006130692912748375\n",
      "Epoch 88 num_samples 6200 loss 0.006773400756941197\n",
      "Epoch 88 num_samples 6300 loss 0.008321381153146092\n",
      "Epoch 88 num_samples 6400 loss 0.005454631784675324\n",
      "Epoch 88 num_samples 6500 loss 0.004748996981085748\n",
      "Epoch 88 num_samples 6600 loss 0.011222119114826344\n",
      "Epoch 88 num_samples 6700 loss 0.005729234787990212\n",
      "Epoch 88 num_samples 6800 loss 0.003614168854587996\n",
      "Epoch 88 num_samples 6900 loss 0.013554073777962423\n",
      "Epoch 88 num_samples 7000 loss 0.008042943128030385\n",
      "Epoch 88 num_samples 7100 loss 0.004519170185479791\n",
      "Epoch 88 num_samples 7200 loss 0.006465515428402906\n",
      "Epoch 88 num_samples 7300 loss 0.006692978662102396\n",
      "Epoch 88 num_samples 7400 loss 0.004936591840695223\n",
      "Epoch 88 num_samples 7500 loss 0.00962886920388293\n",
      "Epoch 88 num_samples 7600 loss 0.006694799275697582\n",
      "Epoch 88 num_samples 7700 loss 0.00895870692603849\n",
      "Epoch 88 num_samples 7800 loss 0.005581931488981269\n",
      "Epoch 88 num_samples 7900 loss 0.006956919929972215\n",
      "Epoch 88 num_samples 8000 loss 0.00458427196052909\n",
      "Epoch 88 num_samples 8100 loss 0.005938225823195309\n",
      "Epoch 88 num_samples 8200 loss 0.007052694971966997\n",
      "Epoch 88 num_samples 8300 loss 0.005439581228896222\n",
      "Epoch 88 num_samples 8400 loss 0.004478188944278015\n",
      "Epoch 88 num_samples 8500 loss 0.0067426668044853\n",
      "Epoch 88 num_samples 8600 loss 0.006469170476447621\n",
      "Epoch 88 num_samples 8700 loss 0.006641787103158703\n",
      "Epoch 88 num_samples 8800 loss 0.0063515252634015465\n",
      "Epoch 88 num_samples 8900 loss 0.007752583375727394\n",
      "Epoch 88 num_samples 9000 loss 0.006646439411634902\n",
      "Epoch 88 num_samples 9100 loss 0.006397834304355103\n",
      "Epoch 88 num_samples 9200 loss 0.0070750248072839585\n",
      "Epoch 88 num_samples 9300 loss 0.006739233388226855\n",
      "Epoch 88 num_samples 9400 loss 0.005629899553310209\n",
      "Epoch 88 num_samples 9500 loss 0.005547019423183767\n",
      "Epoch 88 num_samples 9600 loss 0.006239116109094634\n",
      "Epoch 88 num_samples 9700 loss 0.008754089291218636\n",
      "Epoch 88 num_samples 9800 loss 0.0040626478886551\n",
      "Epoch 88 num_samples 9900 loss 0.011855987278078241\n",
      "Epoch 88 num_samples 10000 loss 0.005387520722331423\n",
      "Epoch 88 num_samples 10100 loss 0.005003279030151841\n",
      "Epoch 88 num_samples 10200 loss 0.007744943150712911\n",
      "Epoch 88 num_samples 10300 loss 0.006440521603538474\n",
      "Epoch 88 num_samples 10400 loss 0.008536045743767639\n",
      "Epoch 88 num_samples 10500 loss 0.006102401606476542\n",
      "Epoch 88 num_samples 10600 loss 0.007283963497820165\n",
      "Epoch 88 num_samples 10700 loss 0.005632032655532224\n",
      "Epoch 88 num_samples 10800 loss 0.007406259407896407\n",
      "Epoch 88 num_samples 10900 loss 0.0055935608125452976\n",
      "Epoch 88 num_samples 11000 loss 0.0052080813446281\n",
      "Epoch 88 num_samples 11100 loss 0.006965880400759528\n",
      "Epoch 88 num_samples 11200 loss 0.005357955796953536\n",
      "Epoch 88 num_samples 11300 loss 0.008647967409897792\n",
      "Epoch 88 num_samples 11400 loss 0.005936795108841918\n",
      "Epoch 88 num_samples 11500 loss 0.005669655487134511\n",
      "Epoch 88 num_samples 11600 loss 0.005684145194221106\n",
      "Epoch 88 num_samples 11700 loss 0.007620202584174153\n",
      "Epoch 88 num_samples 11800 loss 0.00573204670147363\n",
      "Epoch 88 num_samples 11900 loss 0.004932523743027474\n",
      "Epoch 88 num_samples 12000 loss 0.004373108073704044\n",
      "Epoch 88 num_samples 12100 loss 0.004895293602530629\n",
      "Epoch 88 num_samples 12200 loss 0.006918347667651762\n",
      "Epoch 88 num_samples 12300 loss 0.005203144146798635\n",
      "Epoch 88 num_samples 12400 loss 0.007896478380788396\n",
      "Epoch 88 num_samples 12500 loss 0.007047236202747327\n",
      "Epoch 88 num_samples 12600 loss 0.008784927427850708\n",
      "Epoch 88 num_samples 12700 loss 0.006403036938960232\n",
      "Epoch 88 num_samples 12800 loss 0.009784382135483908\n",
      "Epoch 88 num_samples 12900 loss 0.005615259312746842\n",
      "Epoch 88 num_samples 13000 loss 0.005361148435291766\n",
      "Epoch 88 num_samples 13100 loss 0.008269724703176568\n",
      "Epoch 88 num_samples 13200 loss 0.00367755462114678\n",
      "Epoch 88 num_samples 13300 loss 0.005122484309770608\n",
      "Epoch 88 num_samples 13400 loss 0.0033954891724158887\n",
      "Epoch 88 num_samples 13500 loss 0.004669110924846509\n",
      "Epoch 88 num_samples 13600 loss 0.008420122184255469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 num_samples 13700 loss 0.006140686647063898\n",
      "Epoch 88 num_samples 13800 loss 0.006076151629913849\n",
      "Epoch 88 num_samples 13900 loss 0.002527055130177541\n",
      "Epoch 88 num_samples 14000 loss 0.004344382658681958\n",
      "Epoch 88 num_samples 14100 loss 0.005699349701972442\n",
      "Epoch 88 num_samples 14200 loss 0.005427384858971793\n",
      "Epoch 88 num_samples 14300 loss 0.006912265633361623\n",
      "Epoch 88 num_samples 14400 loss 0.006969662069186489\n",
      "Epoch 88 num_samples 14500 loss 0.008674334016282498\n",
      "Epoch 88 num_samples 14600 loss 0.005786214335279356\n",
      "Epoch 88 num_samples 14700 loss 0.006383067028757198\n",
      "Epoch 88 num_samples 14800 loss 0.006135622194122752\n",
      "Epoch 88 num_samples 14900 loss 0.007104125531227897\n",
      "Epoch 88 num_samples 15000 loss 0.006101002307412479\n",
      "Epoch 88 num_samples 15100 loss 0.0066191017474112705\n",
      "Epoch 88 num_samples 15200 loss 0.006310352111605746\n",
      "Epoch 88 num_samples 15300 loss 0.006823833813365963\n",
      "Epoch 88 num_samples 15400 loss 0.0049241641617825335\n",
      "Epoch 88 num_samples 15500 loss 0.00641554059142508\n",
      "Epoch 88 num_samples 15600 loss 0.0069507593058160165\n",
      "Epoch 88 num_samples 15700 loss 0.004654726441039107\n",
      "Epoch 88 num_samples 15800 loss 0.007477481823717202\n",
      "Epoch 88 num_samples 15900 loss 0.005085309235750113\n",
      "Epoch 88 num_samples 16000 loss 0.009106739678535824\n",
      "Epoch 88 num_samples 16100 loss 0.00487693864444046\n",
      "Epoch 88 num_samples 16200 loss 0.007173728042248329\n",
      "Epoch 88 num_samples 16300 loss 0.008313326590014191\n",
      "Epoch 88 num_samples 16400 loss 0.008369392825192397\n",
      "Epoch 88 num_samples 16500 loss 0.007224662916358756\n",
      "Epoch 88 num_samples 16600 loss 0.00820041154334696\n",
      "Epoch 88 num_samples 16700 loss 0.004572927993040864\n",
      "Epoch 88 num_samples 16800 loss 0.004640072167531574\n",
      "Epoch 88 num_samples 16900 loss 0.005284758478304764\n",
      "Epoch 88 num_samples 17000 loss 0.004089805287447494\n",
      "Epoch 88 num_samples 17100 loss 0.009980852402129389\n",
      "Epoch 88 num_samples 17200 loss 0.007137644045616478\n",
      "Epoch 88 num_samples 17300 loss 0.007340436691040977\n",
      "Epoch 88 num_samples 17400 loss 0.006209875123592161\n",
      "Epoch 88 num_samples 17500 loss 0.006674182946969222\n",
      "Epoch 88 num_samples 17600 loss 0.005864562596840425\n",
      "Epoch 88 num_samples 17700 loss 0.0050242601180470236\n",
      "Epoch 88 num_samples 17800 loss 0.005310085328428887\n",
      "Epoch 88 num_samples 17900 loss 0.007983964230746671\n",
      "Epoch 88 num_samples 18000 loss 0.00607783390229364\n",
      "Epoch 88 num_samples 18100 loss 0.006643180503554102\n",
      "Epoch 88 num_samples 18200 loss 0.007112750896368247\n",
      "Epoch 88 num_samples 18300 loss 0.005185654177094443\n",
      "Epoch 88 num_samples 18400 loss 0.009707747490270358\n",
      "Epoch 88 num_samples 18500 loss 0.0071536403555289615\n",
      "Epoch 89 num_samples 0 loss 0.00499095993114974\n",
      "Epoch 89 num_samples 100 loss 0.008656136387514675\n",
      "Epoch 89 num_samples 200 loss 0.0058411797503954924\n",
      "Epoch 89 num_samples 300 loss 0.0049448732245864335\n",
      "Epoch 89 num_samples 400 loss 0.006037476975743816\n",
      "Epoch 89 num_samples 500 loss 0.009041686979442836\n",
      "Epoch 89 num_samples 600 loss 0.0086675274337059\n",
      "Epoch 89 num_samples 700 loss 0.009488997529322283\n",
      "Epoch 89 num_samples 800 loss 0.00556460883915279\n",
      "Epoch 89 num_samples 900 loss 0.009933582320057815\n",
      "Epoch 89 num_samples 1000 loss 0.005875698139603751\n",
      "Epoch 89 num_samples 1100 loss 0.009733731560747211\n",
      "Epoch 89 num_samples 1200 loss 0.005960862738662458\n",
      "Epoch 89 num_samples 1300 loss 0.00700357484710932\n",
      "Epoch 89 num_samples 1400 loss 0.0068884729194375735\n",
      "Epoch 89 num_samples 1500 loss 0.008130175729357259\n",
      "Epoch 89 num_samples 1600 loss 0.006131945417904674\n",
      "Epoch 89 num_samples 1700 loss 0.005886833782724072\n",
      "Epoch 89 num_samples 1800 loss 0.005897056356473976\n",
      "Epoch 89 num_samples 1900 loss 0.0070643673972711\n",
      "Epoch 89 num_samples 2000 loss 0.00820109013094502\n",
      "Epoch 89 num_samples 2100 loss 0.004317552295992642\n",
      "Epoch 89 num_samples 2200 loss 0.004953613611061474\n",
      "Epoch 89 num_samples 2300 loss 0.0032488260258783587\n",
      "Epoch 89 num_samples 2400 loss 0.005384005250372709\n",
      "Epoch 89 num_samples 2500 loss 0.007216691293314462\n",
      "Epoch 89 num_samples 2600 loss 0.007881570926429127\n",
      "Epoch 89 num_samples 2700 loss 0.005761600339962842\n",
      "Epoch 89 num_samples 2800 loss 0.007806149937018867\n",
      "Epoch 89 num_samples 2900 loss 0.0072208786934990265\n",
      "Epoch 89 num_samples 3000 loss 0.005934151147625046\n",
      "Epoch 89 num_samples 3100 loss 0.005827537039470802\n",
      "Epoch 89 num_samples 3200 loss 0.009519047697098016\n",
      "Epoch 89 num_samples 3300 loss 0.006408930727657266\n",
      "Epoch 89 num_samples 3400 loss 0.005258010620841783\n",
      "Epoch 89 num_samples 3500 loss 0.005596597679488995\n",
      "Epoch 89 num_samples 3600 loss 0.0043530256935399945\n",
      "Epoch 89 num_samples 3700 loss 0.009473758626978721\n",
      "Epoch 89 num_samples 3800 loss 0.005110174778783017\n",
      "Epoch 89 num_samples 3900 loss 0.006604856791476983\n",
      "Epoch 89 num_samples 4000 loss 0.007012458006164174\n",
      "Epoch 89 num_samples 4100 loss 0.008860071481763583\n",
      "Epoch 89 num_samples 4200 loss 0.0068355649808919195\n",
      "Epoch 89 num_samples 4300 loss 0.005868030506533675\n",
      "Epoch 89 num_samples 4400 loss 0.006755638237851017\n",
      "Epoch 89 num_samples 4500 loss 0.008199854451798348\n",
      "Epoch 89 num_samples 4600 loss 0.00725251679470017\n",
      "Epoch 89 num_samples 4700 loss 0.00413213250223807\n",
      "Epoch 89 num_samples 4800 loss 0.004470708183151716\n",
      "Epoch 89 num_samples 4900 loss 0.00572383547107258\n",
      "Epoch 89 num_samples 5000 loss 0.005046343537690533\n",
      "Epoch 89 num_samples 5100 loss 0.00889724274943378\n",
      "Epoch 89 num_samples 5200 loss 0.00438088996111303\n",
      "Epoch 89 num_samples 5300 loss 0.005890807630897696\n",
      "Epoch 89 num_samples 5400 loss 0.008151244307335812\n",
      "Epoch 89 num_samples 5500 loss 0.0049462989081865034\n",
      "Epoch 89 num_samples 5600 loss 0.015362073673728199\n",
      "Epoch 89 num_samples 5700 loss 0.0062482251573122635\n",
      "Epoch 89 num_samples 5800 loss 0.0061681049390742695\n",
      "Epoch 89 num_samples 5900 loss 0.0077335111084685425\n",
      "Epoch 89 num_samples 6000 loss 0.006431546803323973\n",
      "Epoch 89 num_samples 6100 loss 0.0060147402993348306\n",
      "Epoch 89 num_samples 6200 loss 0.006645651335396265\n",
      "Epoch 89 num_samples 6300 loss 0.008135767733689812\n",
      "Epoch 89 num_samples 6400 loss 0.005350351428576652\n",
      "Epoch 89 num_samples 6500 loss 0.004651903463287302\n",
      "Epoch 89 num_samples 6600 loss 0.011019785728853107\n",
      "Epoch 89 num_samples 6700 loss 0.005620276430739583\n",
      "Epoch 89 num_samples 6800 loss 0.0035450110963370406\n",
      "Epoch 89 num_samples 6900 loss 0.013312449422141302\n",
      "Epoch 89 num_samples 7000 loss 0.007898298450684764\n",
      "Epoch 89 num_samples 7100 loss 0.004443150596585529\n",
      "Epoch 89 num_samples 7200 loss 0.0063495608024613315\n",
      "Epoch 89 num_samples 7300 loss 0.006582110342755226\n",
      "Epoch 89 num_samples 7400 loss 0.0048493325768348685\n",
      "Epoch 89 num_samples 7500 loss 0.009409729808060173\n",
      "Epoch 89 num_samples 7600 loss 0.0065437772734161315\n",
      "Epoch 89 num_samples 7700 loss 0.008769397081662971\n",
      "Epoch 89 num_samples 7800 loss 0.0054719852377972085\n",
      "Epoch 89 num_samples 7900 loss 0.006833366470750262\n",
      "Epoch 89 num_samples 8000 loss 0.004498784043937596\n",
      "Epoch 89 num_samples 8100 loss 0.005840975194714556\n",
      "Epoch 89 num_samples 8200 loss 0.006898076031694514\n",
      "Epoch 89 num_samples 8300 loss 0.005320364136400073\n",
      "Epoch 89 num_samples 8400 loss 0.0043789462559684356\n",
      "Epoch 89 num_samples 8500 loss 0.0066115204392040924\n",
      "Epoch 89 num_samples 8600 loss 0.0063298651591674705\n",
      "Epoch 89 num_samples 8700 loss 0.006508204293025654\n",
      "Epoch 89 num_samples 8800 loss 0.006214670020367252\n",
      "Epoch 89 num_samples 8900 loss 0.0076159567905868635\n",
      "Epoch 89 num_samples 9000 loss 0.006521180211043598\n",
      "Epoch 89 num_samples 9100 loss 0.006270657000993627\n",
      "Epoch 89 num_samples 9200 loss 0.006943264156755963\n",
      "Epoch 89 num_samples 9300 loss 0.006652727920698023\n",
      "Epoch 89 num_samples 9400 loss 0.005541521925239951\n",
      "Epoch 89 num_samples 9500 loss 0.00542389466657442\n",
      "Epoch 89 num_samples 9600 loss 0.006139839465462649\n",
      "Epoch 89 num_samples 9700 loss 0.008577457933730184\n",
      "Epoch 89 num_samples 9800 loss 0.003986579198830989\n",
      "Epoch 89 num_samples 9900 loss 0.011624318656883686\n",
      "Epoch 89 num_samples 10000 loss 0.0052695527663383325\n",
      "Epoch 89 num_samples 10100 loss 0.004898892311562004\n",
      "Epoch 89 num_samples 10200 loss 0.007608820453751359\n",
      "Epoch 89 num_samples 10300 loss 0.0063300799538951935\n",
      "Epoch 89 num_samples 10400 loss 0.008386831520912715\n",
      "Epoch 89 num_samples 10500 loss 0.00601628648087841\n",
      "Epoch 89 num_samples 10600 loss 0.007133319408261466\n",
      "Epoch 89 num_samples 10700 loss 0.005528699784200124\n",
      "Epoch 89 num_samples 10800 loss 0.007258106427971067\n",
      "Epoch 89 num_samples 10900 loss 0.005474459037768027\n",
      "Epoch 89 num_samples 11000 loss 0.005083067848020052\n",
      "Epoch 89 num_samples 11100 loss 0.00683731214413651\n",
      "Epoch 89 num_samples 11200 loss 0.0052598105247995955\n",
      "Epoch 89 num_samples 11300 loss 0.008465760586138063\n",
      "Epoch 89 num_samples 11400 loss 0.005807091165448396\n",
      "Epoch 89 num_samples 11500 loss 0.0055336760315525466\n",
      "Epoch 89 num_samples 11600 loss 0.005572645498136807\n",
      "Epoch 89 num_samples 11700 loss 0.00747601714018952\n",
      "Epoch 89 num_samples 11800 loss 0.005628206113324912\n",
      "Epoch 89 num_samples 11900 loss 0.0048422624135265714\n",
      "Epoch 89 num_samples 12000 loss 0.0043027838680813\n",
      "Epoch 89 num_samples 12100 loss 0.004798739277745968\n",
      "Epoch 89 num_samples 12200 loss 0.006781600374193957\n",
      "Epoch 89 num_samples 12300 loss 0.005113218086024487\n",
      "Epoch 89 num_samples 12400 loss 0.007753315676777397\n",
      "Epoch 89 num_samples 12500 loss 0.006916347862794523\n",
      "Epoch 89 num_samples 12600 loss 0.00865350874928355\n",
      "Epoch 89 num_samples 12700 loss 0.0062874087052572905\n",
      "Epoch 89 num_samples 12800 loss 0.009593235596279004\n",
      "Epoch 89 num_samples 12900 loss 0.0054984685669277255\n",
      "Epoch 89 num_samples 13000 loss 0.005253779198649151\n",
      "Epoch 89 num_samples 13100 loss 0.008087796925773098\n",
      "Epoch 89 num_samples 13200 loss 0.0036096632095813735\n",
      "Epoch 89 num_samples 13300 loss 0.005032223662160504\n",
      "Epoch 89 num_samples 13400 loss 0.003343701474957782\n",
      "Epoch 89 num_samples 13500 loss 0.004571753875052189\n",
      "Epoch 89 num_samples 13600 loss 0.008278461356478566\n",
      "Epoch 89 num_samples 13700 loss 0.006021358000975673\n",
      "Epoch 89 num_samples 13800 loss 0.005959306240853355\n",
      "Epoch 89 num_samples 13900 loss 0.002479886015657381\n",
      "Epoch 89 num_samples 14000 loss 0.0042510178918386335\n",
      "Epoch 89 num_samples 14100 loss 0.0055854300905487705\n",
      "Epoch 89 num_samples 14200 loss 0.005315665738112371\n",
      "Epoch 89 num_samples 14300 loss 0.006777187745376129\n",
      "Epoch 89 num_samples 14400 loss 0.006821135631288824\n",
      "Epoch 89 num_samples 14500 loss 0.008530300419131913\n",
      "Epoch 89 num_samples 14600 loss 0.0056572536903027595\n",
      "Epoch 89 num_samples 14700 loss 0.00625754559650318\n",
      "Epoch 89 num_samples 14800 loss 0.006007416725337937\n",
      "Epoch 89 num_samples 14900 loss 0.006978091817720916\n",
      "Epoch 89 num_samples 15000 loss 0.00599583115121035\n",
      "Epoch 89 num_samples 15100 loss 0.00649797176636584\n",
      "Epoch 89 num_samples 15200 loss 0.006167712802077717\n",
      "Epoch 89 num_samples 15300 loss 0.006696779929625086\n",
      "Epoch 89 num_samples 15400 loss 0.004848755918050419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 num_samples 15500 loss 0.006302822287929598\n",
      "Epoch 89 num_samples 15600 loss 0.006810275228035166\n",
      "Epoch 89 num_samples 15700 loss 0.004578009339653013\n",
      "Epoch 89 num_samples 15800 loss 0.007325795543590938\n",
      "Epoch 89 num_samples 15900 loss 0.004986426550984761\n",
      "Epoch 89 num_samples 16000 loss 0.00891087698362508\n",
      "Epoch 89 num_samples 16100 loss 0.004788896593529537\n",
      "Epoch 89 num_samples 16200 loss 0.007043028528909835\n",
      "Epoch 89 num_samples 16300 loss 0.008154951092138258\n",
      "Epoch 89 num_samples 16400 loss 0.008193322634957433\n",
      "Epoch 89 num_samples 16500 loss 0.007083725511727961\n",
      "Epoch 89 num_samples 16600 loss 0.00807762363980864\n",
      "Epoch 89 num_samples 16700 loss 0.004495194282655126\n",
      "Epoch 89 num_samples 16800 loss 0.004538541110605968\n",
      "Epoch 89 num_samples 16900 loss 0.005198980578539058\n",
      "Epoch 89 num_samples 17000 loss 0.004009789121214699\n",
      "Epoch 89 num_samples 17100 loss 0.0097597529814011\n",
      "Epoch 89 num_samples 17200 loss 0.006993406728761762\n",
      "Epoch 89 num_samples 17300 loss 0.007182119827750684\n",
      "Epoch 89 num_samples 17400 loss 0.006095170811381458\n",
      "Epoch 89 num_samples 17500 loss 0.006554032771733704\n",
      "Epoch 89 num_samples 17600 loss 0.005750255496763132\n",
      "Epoch 89 num_samples 17700 loss 0.0049266288037357105\n",
      "Epoch 89 num_samples 17800 loss 0.005198940650931384\n",
      "Epoch 89 num_samples 17900 loss 0.007830732900972947\n",
      "Epoch 89 num_samples 18000 loss 0.005975306534956009\n",
      "Epoch 89 num_samples 18100 loss 0.0065186588258543425\n",
      "Epoch 89 num_samples 18200 loss 0.006958842793367875\n",
      "Epoch 89 num_samples 18300 loss 0.005079990811645336\n",
      "Epoch 89 num_samples 18400 loss 0.009533974391731731\n",
      "Epoch 89 num_samples 18500 loss 0.00703326462433949\n",
      "Epoch 90 num_samples 0 loss 0.0048786688605634695\n",
      "Epoch 90 num_samples 100 loss 0.008494654006957059\n",
      "Epoch 90 num_samples 200 loss 0.005733215714581988\n",
      "Epoch 90 num_samples 300 loss 0.004841977892201648\n",
      "Epoch 90 num_samples 400 loss 0.005947382207718967\n",
      "Epoch 90 num_samples 500 loss 0.008871904922655646\n",
      "Epoch 90 num_samples 600 loss 0.008503236013635921\n",
      "Epoch 90 num_samples 700 loss 0.009311515207681212\n",
      "Epoch 90 num_samples 800 loss 0.005467123789931409\n",
      "Epoch 90 num_samples 900 loss 0.009738647413556137\n",
      "Epoch 90 num_samples 1000 loss 0.005771102430741843\n",
      "Epoch 90 num_samples 1100 loss 0.009532759983222647\n",
      "Epoch 90 num_samples 1200 loss 0.005839771301902752\n",
      "Epoch 90 num_samples 1300 loss 0.0068747928613722585\n",
      "Epoch 90 num_samples 1400 loss 0.006737170054777935\n",
      "Epoch 90 num_samples 1500 loss 0.007959718058313874\n",
      "Epoch 90 num_samples 1600 loss 0.006027618029600938\n",
      "Epoch 90 num_samples 1700 loss 0.005765502527741221\n",
      "Epoch 90 num_samples 1800 loss 0.005792490436697747\n",
      "Epoch 90 num_samples 1900 loss 0.006932958141312586\n",
      "Epoch 90 num_samples 2000 loss 0.008043583558371759\n",
      "Epoch 90 num_samples 2100 loss 0.004234727056466586\n",
      "Epoch 90 num_samples 2200 loss 0.004845950107064863\n",
      "Epoch 90 num_samples 2300 loss 0.003196173947456385\n",
      "Epoch 90 num_samples 2400 loss 0.0052946710950210665\n",
      "Epoch 90 num_samples 2500 loss 0.00704921804260116\n",
      "Epoch 90 num_samples 2600 loss 0.007725493600191891\n",
      "Epoch 90 num_samples 2700 loss 0.005662581457876315\n",
      "Epoch 90 num_samples 2800 loss 0.007617078859196779\n",
      "Epoch 90 num_samples 2900 loss 0.00709663410441092\n",
      "Epoch 90 num_samples 3000 loss 0.005815974459599367\n",
      "Epoch 90 num_samples 3100 loss 0.005711376651550581\n",
      "Epoch 90 num_samples 3200 loss 0.009326786218189853\n",
      "Epoch 90 num_samples 3300 loss 0.006277775844332245\n",
      "Epoch 90 num_samples 3400 loss 0.005146479575784765\n",
      "Epoch 90 num_samples 3500 loss 0.005487875027686209\n",
      "Epoch 90 num_samples 3600 loss 0.004283347076344909\n",
      "Epoch 90 num_samples 3700 loss 0.009282274063216089\n",
      "Epoch 90 num_samples 3800 loss 0.00500289685827127\n",
      "Epoch 90 num_samples 3900 loss 0.006487923770431403\n",
      "Epoch 90 num_samples 4000 loss 0.0068680087203054005\n",
      "Epoch 90 num_samples 4100 loss 0.008653100785950654\n",
      "Epoch 90 num_samples 4200 loss 0.006693297948839687\n",
      "Epoch 90 num_samples 4300 loss 0.005742430214562118\n",
      "Epoch 90 num_samples 4400 loss 0.006623383615973393\n",
      "Epoch 90 num_samples 4500 loss 0.008022649676650458\n",
      "Epoch 90 num_samples 4600 loss 0.007135440827243474\n",
      "Epoch 90 num_samples 4700 loss 0.004042080178348777\n",
      "Epoch 90 num_samples 4800 loss 0.00439446473790912\n",
      "Epoch 90 num_samples 4900 loss 0.005621665056537616\n",
      "Epoch 90 num_samples 5000 loss 0.004940532919861826\n",
      "Epoch 90 num_samples 5100 loss 0.008734535632458714\n",
      "Epoch 90 num_samples 5200 loss 0.004304402115755563\n",
      "Epoch 90 num_samples 5300 loss 0.0057637070724722485\n",
      "Epoch 90 num_samples 5400 loss 0.0079849841320252\n",
      "Epoch 90 num_samples 5500 loss 0.004865220174922456\n",
      "Epoch 90 num_samples 5600 loss 0.015032335993909778\n",
      "Epoch 90 num_samples 5700 loss 0.006083621745518986\n",
      "Epoch 90 num_samples 5800 loss 0.006069004252097413\n",
      "Epoch 90 num_samples 5900 loss 0.007581205014892471\n",
      "Epoch 90 num_samples 6000 loss 0.006325802094914301\n",
      "Epoch 90 num_samples 6100 loss 0.005903994834166443\n",
      "Epoch 90 num_samples 6200 loss 0.006518450319835315\n",
      "Epoch 90 num_samples 6300 loss 0.008004827051089326\n",
      "Epoch 90 num_samples 6400 loss 0.005245496515797045\n",
      "Epoch 90 num_samples 6500 loss 0.004570404659680522\n",
      "Epoch 90 num_samples 6600 loss 0.010834145322293796\n",
      "Epoch 90 num_samples 6700 loss 0.005540914635322999\n",
      "Epoch 90 num_samples 6800 loss 0.003489550754344187\n",
      "Epoch 90 num_samples 6900 loss 0.013078246675092735\n",
      "Epoch 90 num_samples 7000 loss 0.007754736730414589\n",
      "Epoch 90 num_samples 7100 loss 0.0043553949662317945\n",
      "Epoch 90 num_samples 7200 loss 0.006222404399774386\n",
      "Epoch 90 num_samples 7300 loss 0.006469031355251974\n",
      "Epoch 90 num_samples 7400 loss 0.004774516841215179\n",
      "Epoch 90 num_samples 7500 loss 0.009223227757032859\n",
      "Epoch 90 num_samples 7600 loss 0.006409889571212457\n",
      "Epoch 90 num_samples 7700 loss 0.008609658048474017\n",
      "Epoch 90 num_samples 7800 loss 0.005368065692873849\n",
      "Epoch 90 num_samples 7900 loss 0.006725348651601788\n",
      "Epoch 90 num_samples 8000 loss 0.004404108736847276\n",
      "Epoch 90 num_samples 8100 loss 0.00570377843545677\n",
      "Epoch 90 num_samples 8200 loss 0.006789143827033901\n",
      "Epoch 90 num_samples 8300 loss 0.005228758235196494\n",
      "Epoch 90 num_samples 8400 loss 0.004308406863576908\n",
      "Epoch 90 num_samples 8500 loss 0.006464323541908467\n",
      "Epoch 90 num_samples 8600 loss 0.0062052463645333785\n",
      "Epoch 90 num_samples 8700 loss 0.006369440720497064\n",
      "Epoch 90 num_samples 8800 loss 0.006097753099935797\n",
      "Epoch 90 num_samples 8900 loss 0.007470579402757833\n",
      "Epoch 90 num_samples 9000 loss 0.006406541684302388\n",
      "Epoch 90 num_samples 9100 loss 0.006165606092670273\n",
      "Epoch 90 num_samples 9200 loss 0.00679493752867526\n",
      "Epoch 90 num_samples 9300 loss 0.006516104443243156\n",
      "Epoch 90 num_samples 9400 loss 0.005422287285910789\n",
      "Epoch 90 num_samples 9500 loss 0.005350093242303639\n",
      "Epoch 90 num_samples 9600 loss 0.006029352944384294\n",
      "Epoch 90 num_samples 9700 loss 0.008349267559189686\n",
      "Epoch 90 num_samples 9800 loss 0.0038920251298998993\n",
      "Epoch 90 num_samples 9900 loss 0.011402853631888452\n",
      "Epoch 90 num_samples 10000 loss 0.005169685373804434\n",
      "Epoch 90 num_samples 10100 loss 0.004794526383485525\n",
      "Epoch 90 num_samples 10200 loss 0.007459095607017621\n",
      "Epoch 90 num_samples 10300 loss 0.006199497565690426\n",
      "Epoch 90 num_samples 10400 loss 0.008238638689453093\n",
      "Epoch 90 num_samples 10500 loss 0.005899128832228464\n",
      "Epoch 90 num_samples 10600 loss 0.006983172410182831\n",
      "Epoch 90 num_samples 10700 loss 0.00543084743392141\n",
      "Epoch 90 num_samples 10800 loss 0.007126048208254054\n",
      "Epoch 90 num_samples 10900 loss 0.005400438967508422\n",
      "Epoch 90 num_samples 11000 loss 0.005018296873298228\n",
      "Epoch 90 num_samples 11100 loss 0.006735771483420474\n",
      "Epoch 90 num_samples 11200 loss 0.005167171557481163\n",
      "Epoch 90 num_samples 11300 loss 0.00830029642808671\n",
      "Epoch 90 num_samples 11400 loss 0.0057133227526724424\n",
      "Epoch 90 num_samples 11500 loss 0.005444111358343886\n",
      "Epoch 90 num_samples 11600 loss 0.005474740566455518\n",
      "Epoch 90 num_samples 11700 loss 0.007329039829910697\n",
      "Epoch 90 num_samples 11800 loss 0.005522901425424156\n",
      "Epoch 90 num_samples 11900 loss 0.004759295197330115\n",
      "Epoch 90 num_samples 12000 loss 0.004218442630258758\n",
      "Epoch 90 num_samples 12100 loss 0.004701016338115313\n",
      "Epoch 90 num_samples 12200 loss 0.006626047200249476\n",
      "Epoch 90 num_samples 12300 loss 0.005046754635089856\n",
      "Epoch 90 num_samples 12400 loss 0.00758659111385374\n",
      "Epoch 90 num_samples 12500 loss 0.0067576169306773955\n",
      "Epoch 90 num_samples 12600 loss 0.008455176455879124\n",
      "Epoch 90 num_samples 12700 loss 0.006145750256898229\n",
      "Epoch 90 num_samples 12800 loss 0.009371939837214384\n",
      "Epoch 90 num_samples 12900 loss 0.005402854575406819\n",
      "Epoch 90 num_samples 13000 loss 0.0051492077765817965\n",
      "Epoch 90 num_samples 13100 loss 0.007925697893695776\n",
      "Epoch 90 num_samples 13200 loss 0.003544012258285493\n",
      "Epoch 90 num_samples 13300 loss 0.004946626313710858\n",
      "Epoch 90 num_samples 13400 loss 0.0032792857942149176\n",
      "Epoch 90 num_samples 13500 loss 0.004502211300511686\n",
      "Epoch 90 num_samples 13600 loss 0.0081025464738818\n",
      "Epoch 90 num_samples 13700 loss 0.00589912098901103\n",
      "Epoch 90 num_samples 13800 loss 0.005872260045531641\n",
      "Epoch 90 num_samples 13900 loss 0.002435687676297986\n",
      "Epoch 90 num_samples 14000 loss 0.004172066320413582\n",
      "Epoch 90 num_samples 14100 loss 0.005479704061168206\n",
      "Epoch 90 num_samples 14200 loss 0.005225228040558132\n",
      "Epoch 90 num_samples 14300 loss 0.0066641228043569315\n",
      "Epoch 90 num_samples 14400 loss 0.006699757412425666\n",
      "Epoch 90 num_samples 14500 loss 0.008373270992404556\n",
      "Epoch 90 num_samples 14600 loss 0.005539813312488683\n",
      "Epoch 90 num_samples 14700 loss 0.0061436888614077746\n",
      "Epoch 90 num_samples 14800 loss 0.005915150476393698\n",
      "Epoch 90 num_samples 14900 loss 0.006830402088541044\n",
      "Epoch 90 num_samples 15000 loss 0.005886289280165082\n",
      "Epoch 90 num_samples 15100 loss 0.006383885092604588\n",
      "Epoch 90 num_samples 15200 loss 0.006065591439612836\n",
      "Epoch 90 num_samples 15300 loss 0.006570417822964165\n",
      "Epoch 90 num_samples 15400 loss 0.004759645708369163\n",
      "Epoch 90 num_samples 15500 loss 0.006168286359915266\n",
      "Epoch 90 num_samples 15600 loss 0.006696632265483596\n",
      "Epoch 90 num_samples 15700 loss 0.004492190655865201\n",
      "Epoch 90 num_samples 15800 loss 0.007175883250510884\n",
      "Epoch 90 num_samples 15900 loss 0.0049078800596180075\n",
      "Epoch 90 num_samples 16000 loss 0.00874671255173904\n",
      "Epoch 90 num_samples 16100 loss 0.004699087896814289\n",
      "Epoch 90 num_samples 16200 loss 0.0069105234014627094\n",
      "Epoch 90 num_samples 16300 loss 0.008001357106842723\n",
      "Epoch 90 num_samples 16400 loss 0.008029907859810505\n",
      "Epoch 90 num_samples 16500 loss 0.00693896323863089\n",
      "Epoch 90 num_samples 16600 loss 0.007911038740655995\n",
      "Epoch 90 num_samples 16700 loss 0.004424639387583098\n",
      "Epoch 90 num_samples 16800 loss 0.004472188317363541\n",
      "Epoch 90 num_samples 16900 loss 0.005094279502224337\n",
      "Epoch 90 num_samples 17000 loss 0.003942375643234187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 num_samples 17100 loss 0.009563431795752766\n",
      "Epoch 90 num_samples 17200 loss 0.006872382360958915\n",
      "Epoch 90 num_samples 17300 loss 0.007073008484241331\n",
      "Epoch 90 num_samples 17400 loss 0.0059506456575674415\n",
      "Epoch 90 num_samples 17500 loss 0.0064446275704051195\n",
      "Epoch 90 num_samples 17600 loss 0.005627755144803187\n",
      "Epoch 90 num_samples 17700 loss 0.0048588578953230824\n",
      "Epoch 90 num_samples 17800 loss 0.005089250964282889\n",
      "Epoch 90 num_samples 17900 loss 0.007655642872548796\n",
      "Epoch 90 num_samples 18000 loss 0.005876794016109517\n",
      "Epoch 90 num_samples 18100 loss 0.00641681091347453\n",
      "Epoch 90 num_samples 18200 loss 0.006841329855207956\n",
      "Epoch 90 num_samples 18300 loss 0.0049846108071775605\n",
      "Epoch 90 num_samples 18400 loss 0.009337522501962861\n",
      "Epoch 90 num_samples 18500 loss 0.00689346167320145\n",
      "Epoch 91 num_samples 0 loss 0.004808059203977193\n",
      "Epoch 91 num_samples 100 loss 0.008328109176477928\n",
      "Epoch 91 num_samples 200 loss 0.005649181991802115\n",
      "Epoch 91 num_samples 300 loss 0.004766026603716303\n",
      "Epoch 91 num_samples 400 loss 0.005843909533223735\n",
      "Epoch 91 num_samples 500 loss 0.00868723095638286\n",
      "Epoch 91 num_samples 600 loss 0.008335571346999469\n",
      "Epoch 91 num_samples 700 loss 0.009168895842722818\n",
      "Epoch 91 num_samples 800 loss 0.005371501551424953\n",
      "Epoch 91 num_samples 900 loss 0.009558683032813393\n",
      "Epoch 91 num_samples 1000 loss 0.005655110823455105\n",
      "Epoch 91 num_samples 1100 loss 0.009325052590017917\n",
      "Epoch 91 num_samples 1200 loss 0.005754935180681226\n",
      "Epoch 91 num_samples 1300 loss 0.006741049326562263\n",
      "Epoch 91 num_samples 1400 loss 0.0066177930217415915\n",
      "Epoch 91 num_samples 1500 loss 0.007775929105822977\n",
      "Epoch 91 num_samples 1600 loss 0.005885214417453376\n",
      "Epoch 91 num_samples 1700 loss 0.005668866417442608\n",
      "Epoch 91 num_samples 1800 loss 0.0056949685198213595\n",
      "Epoch 91 num_samples 1900 loss 0.006815595415452009\n",
      "Epoch 91 num_samples 2000 loss 0.00788336346971457\n",
      "Epoch 91 num_samples 2100 loss 0.004161773992266363\n",
      "Epoch 91 num_samples 2200 loss 0.0047775353912026895\n",
      "Epoch 91 num_samples 2300 loss 0.003127570961958004\n",
      "Epoch 91 num_samples 2400 loss 0.005180388586237591\n",
      "Epoch 91 num_samples 2500 loss 0.006936537602007655\n",
      "Epoch 91 num_samples 2600 loss 0.0075819163941687594\n",
      "Epoch 91 num_samples 2700 loss 0.005571420901803726\n",
      "Epoch 91 num_samples 2800 loss 0.007487590991382715\n",
      "Epoch 91 num_samples 2900 loss 0.006969896356781838\n",
      "Epoch 91 num_samples 3000 loss 0.005679735841382387\n",
      "Epoch 91 num_samples 3100 loss 0.005591056991221439\n",
      "Epoch 91 num_samples 3200 loss 0.009126942816029559\n",
      "Epoch 91 num_samples 3300 loss 0.006165935317251053\n",
      "Epoch 91 num_samples 3400 loss 0.005062521056442528\n",
      "Epoch 91 num_samples 3500 loss 0.005397151772978024\n",
      "Epoch 91 num_samples 3600 loss 0.00420950750339058\n",
      "Epoch 91 num_samples 3700 loss 0.009119681415229902\n",
      "Epoch 91 num_samples 3800 loss 0.004901048567432038\n",
      "Epoch 91 num_samples 3900 loss 0.006371227448330448\n",
      "Epoch 91 num_samples 4000 loss 0.006735315451400104\n",
      "Epoch 91 num_samples 4100 loss 0.00849019256242695\n",
      "Epoch 91 num_samples 4200 loss 0.0065955692081071686\n",
      "Epoch 91 num_samples 4300 loss 0.005627459590195715\n",
      "Epoch 91 num_samples 4400 loss 0.00649394423644313\n",
      "Epoch 91 num_samples 4500 loss 0.007862835598211718\n",
      "Epoch 91 num_samples 4600 loss 0.006993418092484076\n",
      "Epoch 91 num_samples 4700 loss 0.003976784288778184\n",
      "Epoch 91 num_samples 4800 loss 0.004310943609081009\n",
      "Epoch 91 num_samples 4900 loss 0.005533489390862761\n",
      "Epoch 91 num_samples 5000 loss 0.00486860053249639\n",
      "Epoch 91 num_samples 5100 loss 0.008572791836832608\n",
      "Epoch 91 num_samples 5200 loss 0.0042283617378690574\n",
      "Epoch 91 num_samples 5300 loss 0.005663207122352482\n",
      "Epoch 91 num_samples 5400 loss 0.007847099696376238\n",
      "Epoch 91 num_samples 5500 loss 0.004767489905949784\n",
      "Epoch 91 num_samples 5600 loss 0.014720104222594049\n",
      "Epoch 91 num_samples 5700 loss 0.006005703486521079\n",
      "Epoch 91 num_samples 5800 loss 0.005938224916054703\n",
      "Epoch 91 num_samples 5900 loss 0.007445504413325607\n",
      "Epoch 91 num_samples 6000 loss 0.0062380555893003335\n",
      "Epoch 91 num_samples 6100 loss 0.005798306260692037\n",
      "Epoch 91 num_samples 6200 loss 0.0063953325034002495\n",
      "Epoch 91 num_samples 6300 loss 0.007845757048129906\n",
      "Epoch 91 num_samples 6400 loss 0.005154836180002365\n",
      "Epoch 91 num_samples 6500 loss 0.004483103145929105\n",
      "Epoch 91 num_samples 6600 loss 0.010626632576158996\n",
      "Epoch 91 num_samples 6700 loss 0.005453088678996822\n",
      "Epoch 91 num_samples 6800 loss 0.0034162397841395477\n",
      "Epoch 91 num_samples 6900 loss 0.012804336957000057\n",
      "Epoch 91 num_samples 7000 loss 0.007603309789186914\n",
      "Epoch 91 num_samples 7100 loss 0.004269310740999922\n",
      "Epoch 91 num_samples 7200 loss 0.006097795758552936\n",
      "Epoch 91 num_samples 7300 loss 0.006352371519916956\n",
      "Epoch 91 num_samples 7400 loss 0.004688358279519369\n",
      "Epoch 91 num_samples 7500 loss 0.009037729506840871\n",
      "Epoch 91 num_samples 7600 loss 0.00628609206683468\n",
      "Epoch 91 num_samples 7700 loss 0.008428332675355964\n",
      "Epoch 91 num_samples 7800 loss 0.005288008191385163\n",
      "Epoch 91 num_samples 7900 loss 0.006591121430032392\n",
      "Epoch 91 num_samples 8000 loss 0.004335603020159624\n",
      "Epoch 91 num_samples 8100 loss 0.005613371412047924\n",
      "Epoch 91 num_samples 8200 loss 0.006660453056632116\n",
      "Epoch 91 num_samples 8300 loss 0.005138918595803521\n",
      "Epoch 91 num_samples 8400 loss 0.004217447628282556\n",
      "Epoch 91 num_samples 8500 loss 0.0063817585524505085\n",
      "Epoch 91 num_samples 8600 loss 0.006078468163788961\n",
      "Epoch 91 num_samples 8700 loss 0.006273700540290326\n",
      "Epoch 91 num_samples 8800 loss 0.0059894663860904475\n",
      "Epoch 91 num_samples 8900 loss 0.007314039295163508\n",
      "Epoch 91 num_samples 9000 loss 0.006283568379290889\n",
      "Epoch 91 num_samples 9100 loss 0.0060475430380764585\n",
      "Epoch 91 num_samples 9200 loss 0.006709187015126277\n",
      "Epoch 91 num_samples 9300 loss 0.006406558317678748\n",
      "Epoch 91 num_samples 9400 loss 0.005323430948515768\n",
      "Epoch 91 num_samples 9500 loss 0.005229473647546028\n",
      "Epoch 91 num_samples 9600 loss 0.005942570145868083\n",
      "Epoch 91 num_samples 9700 loss 0.008190243036277672\n",
      "Epoch 91 num_samples 9800 loss 0.003829101444555798\n",
      "Epoch 91 num_samples 9900 loss 0.01120187999594558\n",
      "Epoch 91 num_samples 10000 loss 0.005073129057001456\n",
      "Epoch 91 num_samples 10100 loss 0.004711274266889669\n",
      "Epoch 91 num_samples 10200 loss 0.00733430263523806\n",
      "Epoch 91 num_samples 10300 loss 0.006088074757473963\n",
      "Epoch 91 num_samples 10400 loss 0.0080768185919959\n",
      "Epoch 91 num_samples 10500 loss 0.005811710481539654\n",
      "Epoch 91 num_samples 10600 loss 0.0068471804510674425\n",
      "Epoch 91 num_samples 10700 loss 0.00533270349202578\n",
      "Epoch 91 num_samples 10800 loss 0.006989254622845088\n",
      "Epoch 91 num_samples 10900 loss 0.005295885929860447\n",
      "Epoch 91 num_samples 11000 loss 0.004911748415465605\n",
      "Epoch 91 num_samples 11100 loss 0.006626331748604631\n",
      "Epoch 91 num_samples 11200 loss 0.005067564105526163\n",
      "Epoch 91 num_samples 11300 loss 0.008137537867142101\n",
      "Epoch 91 num_samples 11400 loss 0.005597213630688708\n",
      "Epoch 91 num_samples 11500 loss 0.005323078340294715\n",
      "Epoch 91 num_samples 11600 loss 0.005373003656516071\n",
      "Epoch 91 num_samples 11700 loss 0.007185144987661184\n",
      "Epoch 91 num_samples 11800 loss 0.0054270645253541635\n",
      "Epoch 91 num_samples 11900 loss 0.004664716862917156\n",
      "Epoch 91 num_samples 12000 loss 0.004140105312179356\n",
      "Epoch 91 num_samples 12100 loss 0.004614863914446567\n",
      "Epoch 91 num_samples 12200 loss 0.00651721993269536\n",
      "Epoch 91 num_samples 12300 loss 0.004956953128978805\n",
      "Epoch 91 num_samples 12400 loss 0.007454562243824432\n",
      "Epoch 91 num_samples 12500 loss 0.006640717977056138\n",
      "Epoch 91 num_samples 12600 loss 0.008346515312326377\n",
      "Epoch 91 num_samples 12700 loss 0.006046362762594372\n",
      "Epoch 91 num_samples 12800 loss 0.009183904187818092\n",
      "Epoch 91 num_samples 12900 loss 0.005303396449123307\n",
      "Epoch 91 num_samples 13000 loss 0.005060995188315437\n",
      "Epoch 91 num_samples 13100 loss 0.007773169302439515\n",
      "Epoch 91 num_samples 13200 loss 0.0034953957673755937\n",
      "Epoch 91 num_samples 13300 loss 0.004858487097655929\n",
      "Epoch 91 num_samples 13400 loss 0.003226530605158539\n",
      "Epoch 91 num_samples 13500 loss 0.004420702964564345\n",
      "Epoch 91 num_samples 13600 loss 0.007960225479504273\n",
      "Epoch 91 num_samples 13700 loss 0.005791817655953755\n",
      "Epoch 91 num_samples 13800 loss 0.0057611367068838345\n",
      "Epoch 91 num_samples 13900 loss 0.0023906624304720347\n",
      "Epoch 91 num_samples 14000 loss 0.004092499697464262\n",
      "Epoch 91 num_samples 14100 loss 0.005373844681664173\n",
      "Epoch 91 num_samples 14200 loss 0.005150326628139841\n",
      "Epoch 91 num_samples 14300 loss 0.006523066837996961\n",
      "Epoch 91 num_samples 14400 loss 0.006574937199857118\n",
      "Epoch 91 num_samples 14500 loss 0.00822040035386447\n",
      "Epoch 91 num_samples 14600 loss 0.00542840124201567\n",
      "Epoch 91 num_samples 14700 loss 0.006030751851691476\n",
      "Epoch 91 num_samples 14800 loss 0.005800973400884839\n",
      "Epoch 91 num_samples 14900 loss 0.006705280878351716\n",
      "Epoch 91 num_samples 15000 loss 0.005787754730043675\n",
      "Epoch 91 num_samples 15100 loss 0.006254369173477191\n",
      "Epoch 91 num_samples 15200 loss 0.00592831645130758\n",
      "Epoch 91 num_samples 15300 loss 0.0064779781704704335\n",
      "Epoch 91 num_samples 15400 loss 0.004670848576318427\n",
      "Epoch 91 num_samples 15500 loss 0.006045220626319649\n",
      "Epoch 91 num_samples 15600 loss 0.00656131420713832\n",
      "Epoch 91 num_samples 15700 loss 0.004413749567774077\n",
      "Epoch 91 num_samples 15800 loss 0.007037447476102143\n",
      "Epoch 91 num_samples 15900 loss 0.004810637643507788\n",
      "Epoch 91 num_samples 16000 loss 0.00859684570632186\n",
      "Epoch 91 num_samples 16100 loss 0.004618829683722702\n",
      "Epoch 91 num_samples 16200 loss 0.006774498493600566\n",
      "Epoch 91 num_samples 16300 loss 0.007822158016992677\n",
      "Epoch 91 num_samples 16400 loss 0.007883793241568321\n",
      "Epoch 91 num_samples 16500 loss 0.006812434086198575\n",
      "Epoch 91 num_samples 16600 loss 0.007786054426648108\n",
      "Epoch 91 num_samples 16700 loss 0.004345101620091978\n",
      "Epoch 91 num_samples 16800 loss 0.00438104311421641\n",
      "Epoch 91 num_samples 16900 loss 0.00501267415191631\n",
      "Epoch 91 num_samples 17000 loss 0.0038653233755037864\n",
      "Epoch 91 num_samples 17100 loss 0.00933855511741856\n",
      "Epoch 91 num_samples 17200 loss 0.006743472992687999\n",
      "Epoch 91 num_samples 17300 loss 0.006934826139455046\n",
      "Epoch 91 num_samples 17400 loss 0.005846662884048976\n",
      "Epoch 91 num_samples 17500 loss 0.006329174215568822\n",
      "Epoch 91 num_samples 17600 loss 0.0055237320054892765\n",
      "Epoch 91 num_samples 17700 loss 0.004752978352446243\n",
      "Epoch 91 num_samples 17800 loss 0.004992423509570928\n",
      "Epoch 91 num_samples 17900 loss 0.007495887619619595\n",
      "Epoch 91 num_samples 18000 loss 0.005775828547915271\n",
      "Epoch 91 num_samples 18100 loss 0.006293005759837851\n",
      "Epoch 91 num_samples 18200 loss 0.006734878310186016\n",
      "Epoch 91 num_samples 18300 loss 0.004887697755060228\n",
      "Epoch 91 num_samples 18400 loss 0.00916349832054627\n",
      "Epoch 91 num_samples 18500 loss 0.006779280087333189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 num_samples 0 loss 0.00471668920114558\n",
      "Epoch 92 num_samples 100 loss 0.008169474308580886\n",
      "Epoch 92 num_samples 200 loss 0.005528873972265933\n",
      "Epoch 92 num_samples 300 loss 0.004677673088908671\n",
      "Epoch 92 num_samples 400 loss 0.005750729590978359\n",
      "Epoch 92 num_samples 500 loss 0.00855966446301981\n",
      "Epoch 92 num_samples 600 loss 0.008178259323768339\n",
      "Epoch 92 num_samples 700 loss 0.008976083746390284\n",
      "Epoch 92 num_samples 800 loss 0.005274369586125458\n",
      "Epoch 92 num_samples 900 loss 0.009374113073797083\n",
      "Epoch 92 num_samples 1000 loss 0.005540360124688264\n",
      "Epoch 92 num_samples 1100 loss 0.009154668515315656\n",
      "Epoch 92 num_samples 1200 loss 0.00564686678838067\n",
      "Epoch 92 num_samples 1300 loss 0.006642556313493082\n",
      "Epoch 92 num_samples 1400 loss 0.006474409049158885\n",
      "Epoch 92 num_samples 1500 loss 0.007656009612574961\n",
      "Epoch 92 num_samples 1600 loss 0.005797762275407733\n",
      "Epoch 92 num_samples 1700 loss 0.0055505876797291775\n",
      "Epoch 92 num_samples 1800 loss 0.00559409117875777\n",
      "Epoch 92 num_samples 1900 loss 0.0067069007663649914\n",
      "Epoch 92 num_samples 2000 loss 0.00775173873389278\n",
      "Epoch 92 num_samples 2100 loss 0.004077604668175237\n",
      "Epoch 92 num_samples 2200 loss 0.004687236790640597\n",
      "Epoch 92 num_samples 2300 loss 0.003076294066714488\n",
      "Epoch 92 num_samples 2400 loss 0.005085530246594227\n",
      "Epoch 92 num_samples 2500 loss 0.0067934350980727075\n",
      "Epoch 92 num_samples 2600 loss 0.007430335315725321\n",
      "Epoch 92 num_samples 2700 loss 0.005494071347832721\n",
      "Epoch 92 num_samples 2800 loss 0.007328992447316072\n",
      "Epoch 92 num_samples 2900 loss 0.006831093924120659\n",
      "Epoch 92 num_samples 3000 loss 0.005593130819167192\n",
      "Epoch 92 num_samples 3100 loss 0.005490528214366213\n",
      "Epoch 92 num_samples 3200 loss 0.008931994872780463\n",
      "Epoch 92 num_samples 3300 loss 0.0060587130961944555\n",
      "Epoch 92 num_samples 3400 loss 0.004966153881261706\n",
      "Epoch 92 num_samples 3500 loss 0.005293009595348929\n",
      "Epoch 92 num_samples 3600 loss 0.004144840222376371\n",
      "Epoch 92 num_samples 3700 loss 0.008957855946789635\n",
      "Epoch 92 num_samples 3800 loss 0.004803830774668091\n",
      "Epoch 92 num_samples 3900 loss 0.006244168621393711\n",
      "Epoch 92 num_samples 4000 loss 0.006591442245870604\n",
      "Epoch 92 num_samples 4100 loss 0.008325162896553058\n",
      "Epoch 92 num_samples 4200 loss 0.006470838515653107\n",
      "Epoch 92 num_samples 4300 loss 0.005522834477313796\n",
      "Epoch 92 num_samples 4400 loss 0.006364853655329373\n",
      "Epoch 92 num_samples 4500 loss 0.007709131182608533\n",
      "Epoch 92 num_samples 4600 loss 0.006877086357938536\n",
      "Epoch 92 num_samples 4700 loss 0.0038904778840347814\n",
      "Epoch 92 num_samples 4800 loss 0.004246040041547456\n",
      "Epoch 92 num_samples 4900 loss 0.0054272302176326895\n",
      "Epoch 92 num_samples 5000 loss 0.004776902181639986\n",
      "Epoch 92 num_samples 5100 loss 0.008424570182762436\n",
      "Epoch 92 num_samples 5200 loss 0.004149231267077645\n",
      "Epoch 92 num_samples 5300 loss 0.005570430723936998\n",
      "Epoch 92 num_samples 5400 loss 0.007704654590008143\n",
      "Epoch 92 num_samples 5500 loss 0.004685914819125431\n",
      "Epoch 92 num_samples 5600 loss 0.01439361087538507\n",
      "Epoch 92 num_samples 5700 loss 0.005869958649324355\n",
      "Epoch 92 num_samples 5800 loss 0.0058432259907697445\n",
      "Epoch 92 num_samples 5900 loss 0.007311017943227777\n",
      "Epoch 92 num_samples 6000 loss 0.006137358372417212\n",
      "Epoch 92 num_samples 6100 loss 0.00569896479865845\n",
      "Epoch 92 num_samples 6200 loss 0.0062680972912483625\n",
      "Epoch 92 num_samples 6300 loss 0.007710616871343441\n",
      "Epoch 92 num_samples 6400 loss 0.005049868109602188\n",
      "Epoch 92 num_samples 6500 loss 0.004399707511038788\n",
      "Epoch 92 num_samples 6600 loss 0.010452790944188758\n",
      "Epoch 92 num_samples 6700 loss 0.005362184546455212\n",
      "Epoch 92 num_samples 6800 loss 0.0033633672002262023\n",
      "Epoch 92 num_samples 6900 loss 0.01258815176901467\n",
      "Epoch 92 num_samples 7000 loss 0.007463566738692573\n",
      "Epoch 92 num_samples 7100 loss 0.004196405633925002\n",
      "Epoch 92 num_samples 7200 loss 0.006005241441385927\n",
      "Epoch 92 num_samples 7300 loss 0.006252691334615494\n",
      "Epoch 92 num_samples 7400 loss 0.00460778027902643\n",
      "Epoch 92 num_samples 7500 loss 0.008871922778428033\n",
      "Epoch 92 num_samples 7600 loss 0.006161927843159776\n",
      "Epoch 92 num_samples 7700 loss 0.008269797419024675\n",
      "Epoch 92 num_samples 7800 loss 0.00518102346713502\n",
      "Epoch 92 num_samples 7900 loss 0.0064735658651911\n",
      "Epoch 92 num_samples 8000 loss 0.004255513953559121\n",
      "Epoch 92 num_samples 8100 loss 0.005498554152230744\n",
      "Epoch 92 num_samples 8200 loss 0.006527863945392589\n",
      "Epoch 92 num_samples 8300 loss 0.005036869289975394\n",
      "Epoch 92 num_samples 8400 loss 0.004145832629225691\n",
      "Epoch 92 num_samples 8500 loss 0.0062548410061872926\n",
      "Epoch 92 num_samples 8600 loss 0.0059569026970177465\n",
      "Epoch 92 num_samples 8700 loss 0.006147671025622656\n",
      "Epoch 92 num_samples 8800 loss 0.005880764721490923\n",
      "Epoch 92 num_samples 8900 loss 0.007180811296937127\n",
      "Epoch 92 num_samples 9000 loss 0.006180038015682338\n",
      "Epoch 92 num_samples 9100 loss 0.005952055056056385\n",
      "Epoch 92 num_samples 9200 loss 0.006588376218902148\n",
      "Epoch 92 num_samples 9300 loss 0.006292945140401267\n",
      "Epoch 92 num_samples 9400 loss 0.005227763020913188\n",
      "Epoch 92 num_samples 9500 loss 0.0051449630461346775\n",
      "Epoch 92 num_samples 9600 loss 0.005831992809945288\n",
      "Epoch 92 num_samples 9700 loss 0.008006463293776703\n",
      "Epoch 92 num_samples 9800 loss 0.003751095020318596\n",
      "Epoch 92 num_samples 9900 loss 0.01097318476439856\n",
      "Epoch 92 num_samples 10000 loss 0.004956235082018905\n",
      "Epoch 92 num_samples 10100 loss 0.004614400179750448\n",
      "Epoch 92 num_samples 10200 loss 0.007195182994376417\n",
      "Epoch 92 num_samples 10300 loss 0.005999261989347072\n",
      "Epoch 92 num_samples 10400 loss 0.007931893803896788\n",
      "Epoch 92 num_samples 10500 loss 0.005699318094548159\n",
      "Epoch 92 num_samples 10600 loss 0.006728644029604987\n",
      "Epoch 92 num_samples 10700 loss 0.005233398753813068\n",
      "Epoch 92 num_samples 10800 loss 0.006848718539933577\n",
      "Epoch 92 num_samples 10900 loss 0.005191462460303734\n",
      "Epoch 92 num_samples 11000 loss 0.004838979663413615\n",
      "Epoch 92 num_samples 11100 loss 0.006518696693507845\n",
      "Epoch 92 num_samples 11200 loss 0.004976700486838715\n",
      "Epoch 92 num_samples 11300 loss 0.007994559527628526\n",
      "Epoch 92 num_samples 11400 loss 0.005501310439752011\n",
      "Epoch 92 num_samples 11500 loss 0.005221000123030719\n",
      "Epoch 92 num_samples 11600 loss 0.0052914782214504566\n",
      "Epoch 92 num_samples 11700 loss 0.0070516497507002295\n",
      "Epoch 92 num_samples 11800 loss 0.005330774229601145\n",
      "Epoch 92 num_samples 11900 loss 0.00457054461226579\n",
      "Epoch 92 num_samples 12000 loss 0.004055387111823118\n",
      "Epoch 92 num_samples 12100 loss 0.00452708382578894\n",
      "Epoch 92 num_samples 12200 loss 0.006367380042481266\n",
      "Epoch 92 num_samples 12300 loss 0.00488681495599384\n",
      "Epoch 92 num_samples 12400 loss 0.007308598273842074\n",
      "Epoch 92 num_samples 12500 loss 0.0065044073755364026\n",
      "Epoch 92 num_samples 12600 loss 0.00815801512140143\n",
      "Epoch 92 num_samples 12700 loss 0.0059226511507038514\n",
      "Epoch 92 num_samples 12800 loss 0.00899272813118751\n",
      "Epoch 92 num_samples 12900 loss 0.005207273841119648\n",
      "Epoch 92 num_samples 13000 loss 0.00496735607715238\n",
      "Epoch 92 num_samples 13100 loss 0.007623466807568123\n",
      "Epoch 92 num_samples 13200 loss 0.003432795097642992\n",
      "Epoch 92 num_samples 13300 loss 0.004764188927023594\n",
      "Epoch 92 num_samples 13400 loss 0.0031589183268325117\n",
      "Epoch 92 num_samples 13500 loss 0.004338013497839365\n",
      "Epoch 92 num_samples 13600 loss 0.007823940200660127\n",
      "Epoch 92 num_samples 13700 loss 0.005686784751343319\n",
      "Epoch 92 num_samples 13800 loss 0.0056681346264639\n",
      "Epoch 92 num_samples 13900 loss 0.0023451255364008126\n",
      "Epoch 92 num_samples 14000 loss 0.004020465451595337\n",
      "Epoch 92 num_samples 14100 loss 0.005277868212670254\n",
      "Epoch 92 num_samples 14200 loss 0.005054229248255739\n",
      "Epoch 92 num_samples 14300 loss 0.006432494007060978\n",
      "Epoch 92 num_samples 14400 loss 0.006453645914690523\n",
      "Epoch 92 num_samples 14500 loss 0.008079329458071936\n",
      "Epoch 92 num_samples 14600 loss 0.0053263281117411345\n",
      "Epoch 92 num_samples 14700 loss 0.005935056337059977\n",
      "Epoch 92 num_samples 14800 loss 0.005697132946843086\n",
      "Epoch 92 num_samples 14900 loss 0.00657785765335398\n",
      "Epoch 92 num_samples 15000 loss 0.005699378907276255\n",
      "Epoch 92 num_samples 15100 loss 0.006147187768446312\n",
      "Epoch 92 num_samples 15200 loss 0.005820638429105736\n",
      "Epoch 92 num_samples 15300 loss 0.006344185536497032\n",
      "Epoch 92 num_samples 15400 loss 0.004597595604120548\n",
      "Epoch 92 num_samples 15500 loss 0.005916950128610615\n",
      "Epoch 92 num_samples 15600 loss 0.0064454107503386935\n",
      "Epoch 92 num_samples 15700 loss 0.004343338042149628\n",
      "Epoch 92 num_samples 15800 loss 0.00690557970342929\n",
      "Epoch 92 num_samples 15900 loss 0.004728356404942956\n",
      "Epoch 92 num_samples 16000 loss 0.008419781637702003\n",
      "Epoch 92 num_samples 16100 loss 0.004549799603649409\n",
      "Epoch 92 num_samples 16200 loss 0.0066425125626085\n",
      "Epoch 92 num_samples 16300 loss 0.0077136542310402715\n",
      "Epoch 92 num_samples 16400 loss 0.007724803279457266\n",
      "Epoch 92 num_samples 16500 loss 0.0066794139562800494\n",
      "Epoch 92 num_samples 16600 loss 0.007646664183759843\n",
      "Epoch 92 num_samples 16700 loss 0.0042634687108553185\n",
      "Epoch 92 num_samples 16800 loss 0.004309390339371073\n",
      "Epoch 92 num_samples 16900 loss 0.0049198962566192\n",
      "Epoch 92 num_samples 17000 loss 0.0037933076817593266\n",
      "Epoch 92 num_samples 17100 loss 0.009170582374305021\n",
      "Epoch 92 num_samples 17200 loss 0.006633445915674414\n",
      "Epoch 92 num_samples 17300 loss 0.006796735717783747\n",
      "Epoch 92 num_samples 17400 loss 0.005718646505270688\n",
      "Epoch 92 num_samples 17500 loss 0.006222312953553516\n",
      "Epoch 92 num_samples 17600 loss 0.005403861639398175\n",
      "Epoch 92 num_samples 17700 loss 0.004677646764979925\n",
      "Epoch 92 num_samples 17800 loss 0.004902274205445351\n",
      "Epoch 92 num_samples 17900 loss 0.007342889366676308\n",
      "Epoch 92 num_samples 18000 loss 0.005686846360848312\n",
      "Epoch 92 num_samples 18100 loss 0.006191875596681962\n",
      "Epoch 92 num_samples 18200 loss 0.006601739499099447\n",
      "Epoch 92 num_samples 18300 loss 0.004804707334337907\n",
      "Epoch 92 num_samples 18400 loss 0.008991017043269043\n",
      "Epoch 92 num_samples 18500 loss 0.006658903783109563\n",
      "Epoch 93 num_samples 0 loss 0.004628945431701026\n",
      "Epoch 93 num_samples 100 loss 0.008011382232743211\n",
      "Epoch 93 num_samples 200 loss 0.005453409606196513\n",
      "Epoch 93 num_samples 300 loss 0.0045858209168727114\n",
      "Epoch 93 num_samples 400 loss 0.005644989705653054\n",
      "Epoch 93 num_samples 500 loss 0.008394948127528123\n",
      "Epoch 93 num_samples 600 loss 0.008032799425708313\n",
      "Epoch 93 num_samples 700 loss 0.008835676181367144\n",
      "Epoch 93 num_samples 800 loss 0.005186302499260867\n",
      "Epoch 93 num_samples 900 loss 0.009204388698018609\n",
      "Epoch 93 num_samples 1000 loss 0.005452915500561971\n",
      "Epoch 93 num_samples 1100 loss 0.008970763601806368\n",
      "Epoch 93 num_samples 1200 loss 0.005568866086920763\n",
      "Epoch 93 num_samples 1300 loss 0.006516562249234854\n",
      "Epoch 93 num_samples 1400 loss 0.006375343242653605\n",
      "Epoch 93 num_samples 1500 loss 0.007489629649525078\n",
      "Epoch 93 num_samples 1600 loss 0.005687796366931747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 num_samples 1700 loss 0.00543963553100356\n",
      "Epoch 93 num_samples 1800 loss 0.005500613042166418\n",
      "Epoch 93 num_samples 1900 loss 0.0065979513993051206\n",
      "Epoch 93 num_samples 2000 loss 0.007617853578375605\n",
      "Epoch 93 num_samples 2100 loss 0.004009645747433261\n",
      "Epoch 93 num_samples 2200 loss 0.004609550407041598\n",
      "Epoch 93 num_samples 2300 loss 0.0030208576659276776\n",
      "Epoch 93 num_samples 2400 loss 0.005004649086647551\n",
      "Epoch 93 num_samples 2500 loss 0.006675281829488444\n",
      "Epoch 93 num_samples 2600 loss 0.007298190269543889\n",
      "Epoch 93 num_samples 2700 loss 0.005393424281161051\n",
      "Epoch 93 num_samples 2800 loss 0.007206602724218521\n",
      "Epoch 93 num_samples 2900 loss 0.00671546965365667\n",
      "Epoch 93 num_samples 3000 loss 0.005489123723033669\n",
      "Epoch 93 num_samples 3100 loss 0.0053868396205133924\n",
      "Epoch 93 num_samples 3200 loss 0.008734663584911151\n",
      "Epoch 93 num_samples 3300 loss 0.005937717965537591\n",
      "Epoch 93 num_samples 3400 loss 0.004871296175989913\n",
      "Epoch 93 num_samples 3500 loss 0.005211340353800614\n",
      "Epoch 93 num_samples 3600 loss 0.004084109099089777\n",
      "Epoch 93 num_samples 3700 loss 0.008778741984226825\n",
      "Epoch 93 num_samples 3800 loss 0.004712348189465977\n",
      "Epoch 93 num_samples 3900 loss 0.006156934848770901\n",
      "Epoch 93 num_samples 4000 loss 0.006461607007402685\n",
      "Epoch 93 num_samples 4100 loss 0.008162928270912915\n",
      "Epoch 93 num_samples 4200 loss 0.006378751548896686\n",
      "Epoch 93 num_samples 4300 loss 0.005417593902504973\n",
      "Epoch 93 num_samples 4400 loss 0.006257247564641837\n",
      "Epoch 93 num_samples 4500 loss 0.007555666338178675\n",
      "Epoch 93 num_samples 4600 loss 0.006769013095405381\n",
      "Epoch 93 num_samples 4700 loss 0.003824241620892804\n",
      "Epoch 93 num_samples 4800 loss 0.004169511910173017\n",
      "Epoch 93 num_samples 4900 loss 0.005342583093726121\n",
      "Epoch 93 num_samples 5000 loss 0.004702187571178626\n",
      "Epoch 93 num_samples 5100 loss 0.008253764737385587\n",
      "Epoch 93 num_samples 5200 loss 0.004071090538698481\n",
      "Epoch 93 num_samples 5300 loss 0.005464719671221431\n",
      "Epoch 93 num_samples 5400 loss 0.007554785172681997\n",
      "Epoch 93 num_samples 5500 loss 0.004595924724955748\n",
      "Epoch 93 num_samples 5600 loss 0.014054703252262829\n",
      "Epoch 93 num_samples 5700 loss 0.005780514673846926\n",
      "Epoch 93 num_samples 5800 loss 0.005748943928457875\n",
      "Epoch 93 num_samples 5900 loss 0.007167620947113631\n",
      "Epoch 93 num_samples 6000 loss 0.006038742546239495\n",
      "Epoch 93 num_samples 6100 loss 0.005605419554186316\n",
      "Epoch 93 num_samples 6200 loss 0.0061354466408470665\n",
      "Epoch 93 num_samples 6300 loss 0.007563017989201479\n",
      "Epoch 93 num_samples 6400 loss 0.00497934861198951\n",
      "Epoch 93 num_samples 6500 loss 0.004324307488424368\n",
      "Epoch 93 num_samples 6600 loss 0.01026269731052435\n",
      "Epoch 93 num_samples 6700 loss 0.005286828270299681\n",
      "Epoch 93 num_samples 6800 loss 0.003307331069980425\n",
      "Epoch 93 num_samples 6900 loss 0.012357051314626872\n",
      "Epoch 93 num_samples 7000 loss 0.007350188662403632\n",
      "Epoch 93 num_samples 7100 loss 0.004118112349800915\n",
      "Epoch 93 num_samples 7200 loss 0.005897778517366369\n",
      "Epoch 93 num_samples 7300 loss 0.006158746088258208\n",
      "Epoch 93 num_samples 7400 loss 0.004538517287036622\n",
      "Epoch 93 num_samples 7500 loss 0.00869825036672378\n",
      "Epoch 93 num_samples 7600 loss 0.006057570435601214\n",
      "Epoch 93 num_samples 7700 loss 0.008123605205646124\n",
      "Epoch 93 num_samples 7800 loss 0.0050918455079731195\n",
      "Epoch 93 num_samples 7900 loss 0.006354291020259592\n",
      "Epoch 93 num_samples 8000 loss 0.0041817780198934494\n",
      "Epoch 93 num_samples 8100 loss 0.00538810428093009\n",
      "Epoch 93 num_samples 8200 loss 0.0064139258532218135\n",
      "Epoch 93 num_samples 8300 loss 0.004945040111324982\n",
      "Epoch 93 num_samples 8400 loss 0.004070742007721336\n",
      "Epoch 93 num_samples 8500 loss 0.006162265522938931\n",
      "Epoch 93 num_samples 8600 loss 0.005847940111257492\n",
      "Epoch 93 num_samples 8700 loss 0.006045942882516282\n",
      "Epoch 93 num_samples 8800 loss 0.005761698396747855\n",
      "Epoch 93 num_samples 8900 loss 0.007046544236904266\n",
      "Epoch 93 num_samples 9000 loss 0.006048612126334408\n",
      "Epoch 93 num_samples 9100 loss 0.005849003595399181\n",
      "Epoch 93 num_samples 9200 loss 0.006486468109307377\n",
      "Epoch 93 num_samples 9300 loss 0.006188267594741816\n",
      "Epoch 93 num_samples 9400 loss 0.0051302133958989905\n",
      "Epoch 93 num_samples 9500 loss 0.005048077881204741\n",
      "Epoch 93 num_samples 9600 loss 0.005725502046563215\n",
      "Epoch 93 num_samples 9700 loss 0.007842719294581581\n",
      "Epoch 93 num_samples 9800 loss 0.003686762421362062\n",
      "Epoch 93 num_samples 9900 loss 0.010773784375158057\n",
      "Epoch 93 num_samples 10000 loss 0.004843837798817467\n",
      "Epoch 93 num_samples 10100 loss 0.004523173275585959\n",
      "Epoch 93 num_samples 10200 loss 0.00707486599706266\n",
      "Epoch 93 num_samples 10300 loss 0.005887781720926506\n",
      "Epoch 93 num_samples 10400 loss 0.0078062279903920295\n",
      "Epoch 93 num_samples 10500 loss 0.00560847050597623\n",
      "Epoch 93 num_samples 10600 loss 0.006607384873335964\n",
      "Epoch 93 num_samples 10700 loss 0.005125134049890525\n",
      "Epoch 93 num_samples 10800 loss 0.0067484318535788405\n",
      "Epoch 93 num_samples 10900 loss 0.005112988542605191\n",
      "Epoch 93 num_samples 11000 loss 0.0047665724131232\n",
      "Epoch 93 num_samples 11100 loss 0.006396549906388366\n",
      "Epoch 93 num_samples 11200 loss 0.004874952336926602\n",
      "Epoch 93 num_samples 11300 loss 0.00784650630327107\n",
      "Epoch 93 num_samples 11400 loss 0.005392920627700994\n",
      "Epoch 93 num_samples 11500 loss 0.005109931896087888\n",
      "Epoch 93 num_samples 11600 loss 0.005178440769801522\n",
      "Epoch 93 num_samples 11700 loss 0.00691517228662249\n",
      "Epoch 93 num_samples 11800 loss 0.005241020897633524\n",
      "Epoch 93 num_samples 11900 loss 0.004498267557858517\n",
      "Epoch 93 num_samples 12000 loss 0.003992365298859931\n",
      "Epoch 93 num_samples 12100 loss 0.004442858692898388\n",
      "Epoch 93 num_samples 12200 loss 0.0062535760352368085\n",
      "Epoch 93 num_samples 12300 loss 0.004797842212153317\n",
      "Epoch 93 num_samples 12400 loss 0.007160812706119945\n",
      "Epoch 93 num_samples 12500 loss 0.006395821806513206\n",
      "Epoch 93 num_samples 12600 loss 0.008033910657625046\n",
      "Epoch 93 num_samples 12700 loss 0.005793558213755794\n",
      "Epoch 93 num_samples 12800 loss 0.00884308471828476\n",
      "Epoch 93 num_samples 12900 loss 0.0051154726818725856\n",
      "Epoch 93 num_samples 13000 loss 0.004888131068913553\n",
      "Epoch 93 num_samples 13100 loss 0.007492850673601424\n",
      "Epoch 93 num_samples 13200 loss 0.0033715702133556235\n",
      "Epoch 93 num_samples 13300 loss 0.004693590853041702\n",
      "Epoch 93 num_samples 13400 loss 0.0030987496962630464\n",
      "Epoch 93 num_samples 13500 loss 0.004269850469694438\n",
      "Epoch 93 num_samples 13600 loss 0.007679392020891771\n",
      "Epoch 93 num_samples 13700 loss 0.005574807657047995\n",
      "Epoch 93 num_samples 13800 loss 0.005563359826471148\n",
      "Epoch 93 num_samples 13900 loss 0.0023051648314351887\n",
      "Epoch 93 num_samples 14000 loss 0.003931680385438888\n",
      "Epoch 93 num_samples 14100 loss 0.0051789277510645\n",
      "Epoch 93 num_samples 14200 loss 0.004970885416044669\n",
      "Epoch 93 num_samples 14300 loss 0.00632307005874136\n",
      "Epoch 93 num_samples 14400 loss 0.006332234239408738\n",
      "Epoch 93 num_samples 14500 loss 0.007931611095588402\n",
      "Epoch 93 num_samples 14600 loss 0.005215267310272042\n",
      "Epoch 93 num_samples 14700 loss 0.005804823016150012\n",
      "Epoch 93 num_samples 14800 loss 0.005600327368878547\n",
      "Epoch 93 num_samples 14900 loss 0.006462215725156713\n",
      "Epoch 93 num_samples 15000 loss 0.005596465171876299\n",
      "Epoch 93 num_samples 15100 loss 0.006032686319730521\n",
      "Epoch 93 num_samples 15200 loss 0.005701031840100706\n",
      "Epoch 93 num_samples 15300 loss 0.0062157733558650145\n",
      "Epoch 93 num_samples 15400 loss 0.0045126182564484306\n",
      "Epoch 93 num_samples 15500 loss 0.005815184147756221\n",
      "Epoch 93 num_samples 15600 loss 0.00634111372007684\n",
      "Epoch 93 num_samples 15700 loss 0.00425992600612385\n",
      "Epoch 93 num_samples 15800 loss 0.006769802286459356\n",
      "Epoch 93 num_samples 15900 loss 0.004631573038277708\n",
      "Epoch 93 num_samples 16000 loss 0.008270935934012678\n",
      "Epoch 93 num_samples 16100 loss 0.004467636995513963\n",
      "Epoch 93 num_samples 16200 loss 0.00652736938313661\n",
      "Epoch 93 num_samples 16300 loss 0.007555250777391538\n",
      "Epoch 93 num_samples 16400 loss 0.007579463100710437\n",
      "Epoch 93 num_samples 16500 loss 0.006568928889782617\n",
      "Epoch 93 num_samples 16600 loss 0.007508175159505448\n",
      "Epoch 93 num_samples 16700 loss 0.0041908785068740404\n",
      "Epoch 93 num_samples 16800 loss 0.004232004771878336\n",
      "Epoch 93 num_samples 16900 loss 0.004839318269235276\n",
      "Epoch 93 num_samples 17000 loss 0.0037285696178276507\n",
      "Epoch 93 num_samples 17100 loss 0.008994697483216222\n",
      "Epoch 93 num_samples 17200 loss 0.006515747163934455\n",
      "Epoch 93 num_samples 17300 loss 0.006663969518987802\n",
      "Epoch 93 num_samples 17400 loss 0.005622394791601479\n",
      "Epoch 93 num_samples 17500 loss 0.006105368173781422\n",
      "Epoch 93 num_samples 17600 loss 0.005309006558491364\n",
      "Epoch 93 num_samples 17700 loss 0.004592495059975452\n",
      "Epoch 93 num_samples 17800 loss 0.004811578778930145\n",
      "Epoch 93 num_samples 17900 loss 0.007210394862462654\n",
      "Epoch 93 num_samples 18000 loss 0.005580360049126269\n",
      "Epoch 93 num_samples 18100 loss 0.006077015958216379\n",
      "Epoch 93 num_samples 18200 loss 0.006493304994332495\n",
      "Epoch 93 num_samples 18300 loss 0.0047331864653623835\n",
      "Epoch 93 num_samples 18400 loss 0.008835729867305171\n",
      "Epoch 93 num_samples 18500 loss 0.006544113201606137\n",
      "Epoch 94 num_samples 0 loss 0.004555354849607827\n",
      "Epoch 94 num_samples 100 loss 0.007840818875302804\n",
      "Epoch 94 num_samples 200 loss 0.005364910156659313\n",
      "Epoch 94 num_samples 300 loss 0.004508094187683096\n",
      "Epoch 94 num_samples 400 loss 0.00556392134951093\n",
      "Epoch 94 num_samples 500 loss 0.008263499307361581\n",
      "Epoch 94 num_samples 600 loss 0.00785984158788472\n",
      "Epoch 94 num_samples 700 loss 0.008671719439666655\n",
      "Epoch 94 num_samples 800 loss 0.005103087777677682\n",
      "Epoch 94 num_samples 900 loss 0.009051775874063042\n",
      "Epoch 94 num_samples 1000 loss 0.005341473911951288\n",
      "Epoch 94 num_samples 1100 loss 0.008798354456084036\n",
      "Epoch 94 num_samples 1200 loss 0.005462830970060226\n",
      "Epoch 94 num_samples 1300 loss 0.006411131714251738\n",
      "Epoch 94 num_samples 1400 loss 0.006273265289968173\n",
      "Epoch 94 num_samples 1500 loss 0.007346679986132901\n",
      "Epoch 94 num_samples 1600 loss 0.005582972250377802\n",
      "Epoch 94 num_samples 1700 loss 0.005346653027642443\n",
      "Epoch 94 num_samples 1800 loss 0.005396389527867179\n",
      "Epoch 94 num_samples 1900 loss 0.006493302386774178\n",
      "Epoch 94 num_samples 2000 loss 0.0074707738228503425\n",
      "Epoch 94 num_samples 2100 loss 0.0039415578885824715\n",
      "Epoch 94 num_samples 2200 loss 0.004541064575800016\n",
      "Epoch 94 num_samples 2300 loss 0.002963630241341687\n",
      "Epoch 94 num_samples 2400 loss 0.0049030134618058595\n",
      "Epoch 94 num_samples 2500 loss 0.006554888270758674\n",
      "Epoch 94 num_samples 2600 loss 0.007159649238116861\n",
      "Epoch 94 num_samples 2700 loss 0.005321169228046834\n",
      "Epoch 94 num_samples 2800 loss 0.007076463800396565\n",
      "Epoch 94 num_samples 2900 loss 0.006591581487473313\n",
      "Epoch 94 num_samples 3000 loss 0.00536293230041473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 num_samples 3100 loss 0.005299244005283878\n",
      "Epoch 94 num_samples 3200 loss 0.00854484449804308\n",
      "Epoch 94 num_samples 3300 loss 0.005825983222025471\n",
      "Epoch 94 num_samples 3400 loss 0.00479322082514848\n",
      "Epoch 94 num_samples 3500 loss 0.005120056552536508\n",
      "Epoch 94 num_samples 3600 loss 0.004012764318720138\n",
      "Epoch 94 num_samples 3700 loss 0.00863297636142932\n",
      "Epoch 94 num_samples 3800 loss 0.004613375719152641\n",
      "Epoch 94 num_samples 3900 loss 0.006033324047757935\n",
      "Epoch 94 num_samples 4000 loss 0.006336621651116327\n",
      "Epoch 94 num_samples 4100 loss 0.008010897573671247\n",
      "Epoch 94 num_samples 4200 loss 0.006252960708570665\n",
      "Epoch 94 num_samples 4300 loss 0.005325404321492068\n",
      "Epoch 94 num_samples 4400 loss 0.006129723275631824\n",
      "Epoch 94 num_samples 4500 loss 0.0073886737955668694\n",
      "Epoch 94 num_samples 4600 loss 0.006643229303732221\n",
      "Epoch 94 num_samples 4700 loss 0.003743853682197536\n",
      "Epoch 94 num_samples 4800 loss 0.004100491776248048\n",
      "Epoch 94 num_samples 4900 loss 0.005255201930617161\n",
      "Epoch 94 num_samples 5000 loss 0.0046225226878471\n",
      "Epoch 94 num_samples 5100 loss 0.008106576231630627\n",
      "Epoch 94 num_samples 5200 loss 0.004001040756486952\n",
      "Epoch 94 num_samples 5300 loss 0.005365960250678369\n",
      "Epoch 94 num_samples 5400 loss 0.0074284546044112295\n",
      "Epoch 94 num_samples 5500 loss 0.0045232532022204605\n",
      "Epoch 94 num_samples 5600 loss 0.01378549751052939\n",
      "Epoch 94 num_samples 5700 loss 0.005666203825506644\n",
      "Epoch 94 num_samples 5800 loss 0.005652152922260393\n",
      "Epoch 94 num_samples 5900 loss 0.007037719447920529\n",
      "Epoch 94 num_samples 6000 loss 0.00591415405340628\n",
      "Epoch 94 num_samples 6100 loss 0.005504241881206909\n",
      "Epoch 94 num_samples 6200 loss 0.006056246766601181\n",
      "Epoch 94 num_samples 6300 loss 0.007429414587862107\n",
      "Epoch 94 num_samples 6400 loss 0.004891095915228588\n",
      "Epoch 94 num_samples 6500 loss 0.004240984652343412\n",
      "Epoch 94 num_samples 6600 loss 0.010074300065211475\n",
      "Epoch 94 num_samples 6700 loss 0.005200375770987496\n",
      "Epoch 94 num_samples 6800 loss 0.0032497571536990273\n",
      "Epoch 94 num_samples 6900 loss 0.012141135836862535\n",
      "Epoch 94 num_samples 7000 loss 0.007195411466618356\n",
      "Epoch 94 num_samples 7100 loss 0.004049617908792864\n",
      "Epoch 94 num_samples 7200 loss 0.005805397658650571\n",
      "Epoch 94 num_samples 7300 loss 0.0060409716582102745\n",
      "Epoch 94 num_samples 7400 loss 0.004465575573062197\n",
      "Epoch 94 num_samples 7500 loss 0.008529372706328113\n",
      "Epoch 94 num_samples 7600 loss 0.005926257337995582\n",
      "Epoch 94 num_samples 7700 loss 0.007994113529462755\n",
      "Epoch 94 num_samples 7800 loss 0.004996100008072749\n",
      "Epoch 94 num_samples 7900 loss 0.006252676513674227\n",
      "Epoch 94 num_samples 8000 loss 0.004109254431158925\n",
      "Epoch 94 num_samples 8100 loss 0.005293475125467681\n",
      "Epoch 94 num_samples 8200 loss 0.006297644236920164\n",
      "Epoch 94 num_samples 8300 loss 0.004860197171614155\n",
      "Epoch 94 num_samples 8400 loss 0.003997300413211822\n",
      "Epoch 94 num_samples 8500 loss 0.006007692887080232\n",
      "Epoch 94 num_samples 8600 loss 0.005725695928589724\n",
      "Epoch 94 num_samples 8700 loss 0.005938304611877959\n",
      "Epoch 94 num_samples 8800 loss 0.005664718925020824\n",
      "Epoch 94 num_samples 8900 loss 0.006931566891799389\n",
      "Epoch 94 num_samples 9000 loss 0.005944605036226883\n",
      "Epoch 94 num_samples 9100 loss 0.005744391149021144\n",
      "Epoch 94 num_samples 9200 loss 0.006363098165870393\n",
      "Epoch 94 num_samples 9300 loss 0.006071199658058199\n",
      "Epoch 94 num_samples 9400 loss 0.005044714599949278\n",
      "Epoch 94 num_samples 9500 loss 0.004962507317610662\n",
      "Epoch 94 num_samples 9600 loss 0.005628463412606512\n",
      "Epoch 94 num_samples 9700 loss 0.0076631007216857875\n",
      "Epoch 94 num_samples 9800 loss 0.003605616631516788\n",
      "Epoch 94 num_samples 9900 loss 0.010596782583024336\n",
      "Epoch 94 num_samples 10000 loss 0.004778612989915193\n",
      "Epoch 94 num_samples 10100 loss 0.004441162819298347\n",
      "Epoch 94 num_samples 10200 loss 0.006940205230735583\n",
      "Epoch 94 num_samples 10300 loss 0.0057717316080151074\n",
      "Epoch 94 num_samples 10400 loss 0.007664177927440889\n",
      "Epoch 94 num_samples 10500 loss 0.005520943577947707\n",
      "Epoch 94 num_samples 10600 loss 0.006486916810871783\n",
      "Epoch 94 num_samples 10700 loss 0.005031426993044624\n",
      "Epoch 94 num_samples 10800 loss 0.006622437017488403\n",
      "Epoch 94 num_samples 10900 loss 0.005027011518338224\n",
      "Epoch 94 num_samples 11000 loss 0.004680099025999096\n",
      "Epoch 94 num_samples 11100 loss 0.006307438332687207\n",
      "Epoch 94 num_samples 11200 loss 0.004805934532263352\n",
      "Epoch 94 num_samples 11300 loss 0.007697016250646156\n",
      "Epoch 94 num_samples 11400 loss 0.005308998025767956\n",
      "Epoch 94 num_samples 11500 loss 0.005025406009809636\n",
      "Epoch 94 num_samples 11600 loss 0.005098675024609411\n",
      "Epoch 94 num_samples 11700 loss 0.006786945755150657\n",
      "Epoch 94 num_samples 11800 loss 0.005145554018157794\n",
      "Epoch 94 num_samples 11900 loss 0.0044114205111951245\n",
      "Epoch 94 num_samples 12000 loss 0.0039100465681023025\n",
      "Epoch 94 num_samples 12100 loss 0.00436307298194807\n",
      "Epoch 94 num_samples 12200 loss 0.006112156538949023\n",
      "Epoch 94 num_samples 12300 loss 0.004743850596689223\n",
      "Epoch 94 num_samples 12400 loss 0.00703282883400703\n",
      "Epoch 94 num_samples 12500 loss 0.0062730843279061475\n",
      "Epoch 94 num_samples 12600 loss 0.007860874537836128\n",
      "Epoch 94 num_samples 12700 loss 0.005717093117039429\n",
      "Epoch 94 num_samples 12800 loss 0.008653650874179263\n",
      "Epoch 94 num_samples 12900 loss 0.005029651126565278\n",
      "Epoch 94 num_samples 13000 loss 0.004796810041267296\n",
      "Epoch 94 num_samples 13100 loss 0.007337903555154945\n",
      "Epoch 94 num_samples 13200 loss 0.003318813554378447\n",
      "Epoch 94 num_samples 13300 loss 0.004613805422776094\n",
      "Epoch 94 num_samples 13400 loss 0.003063247844316059\n",
      "Epoch 94 num_samples 13500 loss 0.004181020635275329\n",
      "Epoch 94 num_samples 13600 loss 0.007544311462481947\n",
      "Epoch 94 num_samples 13700 loss 0.005479664376495711\n",
      "Epoch 94 num_samples 13800 loss 0.005483039223138004\n",
      "Epoch 94 num_samples 13900 loss 0.0022685257737216874\n",
      "Epoch 94 num_samples 14000 loss 0.003871954372915454\n",
      "Epoch 94 num_samples 14100 loss 0.005078073160824909\n",
      "Epoch 94 num_samples 14200 loss 0.0048875500933536495\n",
      "Epoch 94 num_samples 14300 loss 0.0062040332263478505\n",
      "Epoch 94 num_samples 14400 loss 0.006229306594545169\n",
      "Epoch 94 num_samples 14500 loss 0.007819489082560584\n",
      "Epoch 94 num_samples 14600 loss 0.005108701950467524\n",
      "Epoch 94 num_samples 14700 loss 0.005706795863682983\n",
      "Epoch 94 num_samples 14800 loss 0.0055091283154251845\n",
      "Epoch 94 num_samples 14900 loss 0.006337817714995381\n",
      "Epoch 94 num_samples 15000 loss 0.005509997334085887\n",
      "Epoch 94 num_samples 15100 loss 0.005932707380097431\n",
      "Epoch 94 num_samples 15200 loss 0.005602660580164818\n",
      "Epoch 94 num_samples 15300 loss 0.0061226541911710035\n",
      "Epoch 94 num_samples 15400 loss 0.004430048383061322\n",
      "Epoch 94 num_samples 15500 loss 0.005696384332842424\n",
      "Epoch 94 num_samples 15600 loss 0.006215251549305303\n",
      "Epoch 94 num_samples 15700 loss 0.004185075592604279\n",
      "Epoch 94 num_samples 15800 loss 0.006656271901022494\n",
      "Epoch 94 num_samples 15900 loss 0.004565821933141506\n",
      "Epoch 94 num_samples 16000 loss 0.008126768731886176\n",
      "Epoch 94 num_samples 16100 loss 0.004392999759890309\n",
      "Epoch 94 num_samples 16200 loss 0.006410581050486221\n",
      "Epoch 94 num_samples 16300 loss 0.0074227512236724365\n",
      "Epoch 94 num_samples 16400 loss 0.007415820523540748\n",
      "Epoch 94 num_samples 16500 loss 0.006452497628306242\n",
      "Epoch 94 num_samples 16600 loss 0.007384251083405985\n",
      "Epoch 94 num_samples 16700 loss 0.004117484197780669\n",
      "Epoch 94 num_samples 16800 loss 0.004154581474975701\n",
      "Epoch 94 num_samples 16900 loss 0.004751963272379848\n",
      "Epoch 94 num_samples 17000 loss 0.0036652077053323036\n",
      "Epoch 94 num_samples 17100 loss 0.008811790070667019\n",
      "Epoch 94 num_samples 17200 loss 0.006390642726009369\n",
      "Epoch 94 num_samples 17300 loss 0.0065454726768871315\n",
      "Epoch 94 num_samples 17400 loss 0.005528392186023373\n",
      "Epoch 94 num_samples 17500 loss 0.006003048347461488\n",
      "Epoch 94 num_samples 17600 loss 0.00521634549663476\n",
      "Epoch 94 num_samples 17700 loss 0.0045195498790667095\n",
      "Epoch 94 num_samples 17800 loss 0.004721589350389635\n",
      "Epoch 94 num_samples 17900 loss 0.007055034523278822\n",
      "Epoch 94 num_samples 18000 loss 0.00550992117066704\n",
      "Epoch 94 num_samples 18100 loss 0.005983851858090928\n",
      "Epoch 94 num_samples 18200 loss 0.00639365537988208\n",
      "Epoch 94 num_samples 18300 loss 0.004646049357122705\n",
      "Epoch 94 num_samples 18400 loss 0.008671891284291433\n",
      "Epoch 94 num_samples 18500 loss 0.006439842854299077\n",
      "Epoch 95 num_samples 0 loss 0.004467551840017304\n",
      "Epoch 95 num_samples 100 loss 0.007722668899099794\n",
      "Epoch 95 num_samples 200 loss 0.005265641804503904\n",
      "Epoch 95 num_samples 300 loss 0.004443482428223588\n",
      "Epoch 95 num_samples 400 loss 0.0054810468384153994\n",
      "Epoch 95 num_samples 500 loss 0.008120729585369213\n",
      "Epoch 95 num_samples 600 loss 0.0077244365423858015\n",
      "Epoch 95 num_samples 700 loss 0.00848685111610995\n",
      "Epoch 95 num_samples 800 loss 0.005015022238144305\n",
      "Epoch 95 num_samples 900 loss 0.008894110208987447\n",
      "Epoch 95 num_samples 1000 loss 0.005243611787034538\n",
      "Epoch 95 num_samples 1100 loss 0.008638954648695834\n",
      "Epoch 95 num_samples 1200 loss 0.005354933071496268\n",
      "Epoch 95 num_samples 1300 loss 0.006313117451622925\n",
      "Epoch 95 num_samples 1400 loss 0.006133344826354791\n",
      "Epoch 95 num_samples 1500 loss 0.0072142904821240516\n",
      "Epoch 95 num_samples 1600 loss 0.005491702802795397\n",
      "Epoch 95 num_samples 1700 loss 0.0052453675269416985\n",
      "Epoch 95 num_samples 1800 loss 0.005300128143800134\n",
      "Epoch 95 num_samples 1900 loss 0.00638631925708382\n",
      "Epoch 95 num_samples 2000 loss 0.007349030102931472\n",
      "Epoch 95 num_samples 2100 loss 0.0038774814123605683\n",
      "Epoch 95 num_samples 2200 loss 0.004458412530899866\n",
      "Epoch 95 num_samples 2300 loss 0.002919678657935844\n",
      "Epoch 95 num_samples 2400 loss 0.0048215135943282025\n",
      "Epoch 95 num_samples 2500 loss 0.006448470425675987\n",
      "Epoch 95 num_samples 2600 loss 0.007026043384237295\n",
      "Epoch 95 num_samples 2700 loss 0.00522624017956856\n",
      "Epoch 95 num_samples 2800 loss 0.006942524685466389\n",
      "Epoch 95 num_samples 2900 loss 0.0064840919642494685\n",
      "Epoch 95 num_samples 3000 loss 0.0052725880201819455\n",
      "Epoch 95 num_samples 3100 loss 0.005203171039270591\n",
      "Epoch 95 num_samples 3200 loss 0.008367782456339366\n",
      "Epoch 95 num_samples 3300 loss 0.005740126030677924\n",
      "Epoch 95 num_samples 3400 loss 0.004706938872529889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 num_samples 3500 loss 0.005041846634678648\n",
      "Epoch 95 num_samples 3600 loss 0.003962798390194582\n",
      "Epoch 95 num_samples 3700 loss 0.00846378811352062\n",
      "Epoch 95 num_samples 3800 loss 0.004536604483481636\n",
      "Epoch 95 num_samples 3900 loss 0.0059471066173775065\n",
      "Epoch 95 num_samples 4000 loss 0.006230074689090714\n",
      "Epoch 95 num_samples 4100 loss 0.007855398884952689\n",
      "Epoch 95 num_samples 4200 loss 0.006143902980089315\n",
      "Epoch 95 num_samples 4300 loss 0.005224456782058523\n",
      "Epoch 95 num_samples 4400 loss 0.006028768994213478\n",
      "Epoch 95 num_samples 4500 loss 0.007266133629151093\n",
      "Epoch 95 num_samples 4600 loss 0.006539910729130441\n",
      "Epoch 95 num_samples 4700 loss 0.0036731467449068705\n",
      "Epoch 95 num_samples 4800 loss 0.0040268768473602015\n",
      "Epoch 95 num_samples 4900 loss 0.005177980700089859\n",
      "Epoch 95 num_samples 5000 loss 0.0045464386983044055\n",
      "Epoch 95 num_samples 5100 loss 0.00795970590297024\n",
      "Epoch 95 num_samples 5200 loss 0.003931968310248488\n",
      "Epoch 95 num_samples 5300 loss 0.005272849439465017\n",
      "Epoch 95 num_samples 5400 loss 0.007325652738138967\n",
      "Epoch 95 num_samples 5500 loss 0.004441779217184012\n",
      "Epoch 95 num_samples 5600 loss 0.01351117398915641\n",
      "Epoch 95 num_samples 5700 loss 0.005563795107189051\n",
      "Epoch 95 num_samples 5800 loss 0.0055577879590253355\n",
      "Epoch 95 num_samples 5900 loss 0.0069001913892168185\n",
      "Epoch 95 num_samples 6000 loss 0.005843776891878269\n",
      "Epoch 95 num_samples 6100 loss 0.005422873733518416\n",
      "Epoch 95 num_samples 6200 loss 0.005964179450131348\n",
      "Epoch 95 num_samples 6300 loss 0.007293266198858418\n",
      "Epoch 95 num_samples 6400 loss 0.004805376397617161\n",
      "Epoch 95 num_samples 6500 loss 0.00417007765278321\n",
      "Epoch 95 num_samples 6600 loss 0.009927598599705694\n",
      "Epoch 95 num_samples 6700 loss 0.005121576718216185\n",
      "Epoch 95 num_samples 6800 loss 0.003192634796442204\n",
      "Epoch 95 num_samples 6900 loss 0.01192131768456371\n",
      "Epoch 95 num_samples 7000 loss 0.0071072066571945414\n",
      "Epoch 95 num_samples 7100 loss 0.003983744516708338\n",
      "Epoch 95 num_samples 7200 loss 0.005703867389929129\n",
      "Epoch 95 num_samples 7300 loss 0.005942744064920209\n",
      "Epoch 95 num_samples 7400 loss 0.004393049004852173\n",
      "Epoch 95 num_samples 7500 loss 0.008377174986044025\n",
      "Epoch 95 num_samples 7600 loss 0.005833721535940386\n",
      "Epoch 95 num_samples 7700 loss 0.007825339989865447\n",
      "Epoch 95 num_samples 7800 loss 0.004915526907979027\n",
      "Epoch 95 num_samples 7900 loss 0.006137497964950045\n",
      "Epoch 95 num_samples 8000 loss 0.004030782611476316\n",
      "Epoch 95 num_samples 8100 loss 0.005201710651250519\n",
      "Epoch 95 num_samples 8200 loss 0.0061774118774665186\n",
      "Epoch 95 num_samples 8300 loss 0.00477561380818994\n",
      "Epoch 95 num_samples 8400 loss 0.003925610724795871\n",
      "Epoch 95 num_samples 8500 loss 0.005966027660019095\n",
      "Epoch 95 num_samples 8600 loss 0.005624003995328186\n",
      "Epoch 95 num_samples 8700 loss 0.005834374231840964\n",
      "Epoch 95 num_samples 8800 loss 0.0055609708623429975\n",
      "Epoch 95 num_samples 8900 loss 0.006781642420573076\n",
      "Epoch 95 num_samples 9000 loss 0.005850503839923877\n",
      "Epoch 95 num_samples 9100 loss 0.005665685522721484\n",
      "Epoch 95 num_samples 9200 loss 0.006274120769488305\n",
      "Epoch 95 num_samples 9300 loss 0.005955838925257362\n",
      "Epoch 95 num_samples 9400 loss 0.004937258511094173\n",
      "Epoch 95 num_samples 9500 loss 0.0048927417928425355\n",
      "Epoch 95 num_samples 9600 loss 0.005548474956532674\n",
      "Epoch 95 num_samples 9700 loss 0.0075363756940244175\n",
      "Epoch 95 num_samples 9800 loss 0.0035443621253841186\n",
      "Epoch 95 num_samples 9900 loss 0.010415392922649208\n",
      "Epoch 95 num_samples 10000 loss 0.0046746003746576704\n",
      "Epoch 95 num_samples 10100 loss 0.004363408841434657\n",
      "Epoch 95 num_samples 10200 loss 0.006816392165233144\n",
      "Epoch 95 num_samples 10300 loss 0.005677464204090852\n",
      "Epoch 95 num_samples 10400 loss 0.0075375624574080665\n",
      "Epoch 95 num_samples 10500 loss 0.005432102754224553\n",
      "Epoch 95 num_samples 10600 loss 0.006375573777196724\n",
      "Epoch 95 num_samples 10700 loss 0.004946133549422147\n",
      "Epoch 95 num_samples 10800 loss 0.0065003679898855285\n",
      "Epoch 95 num_samples 10900 loss 0.004929872871721839\n",
      "Epoch 95 num_samples 11000 loss 0.004606197459342281\n",
      "Epoch 95 num_samples 11100 loss 0.00620949736242974\n",
      "Epoch 95 num_samples 11200 loss 0.004713169030778726\n",
      "Epoch 95 num_samples 11300 loss 0.0075638853118337466\n",
      "Epoch 95 num_samples 11400 loss 0.005205660917053549\n",
      "Epoch 95 num_samples 11500 loss 0.0049138001213511594\n",
      "Epoch 95 num_samples 11600 loss 0.005004159979631109\n",
      "Epoch 95 num_samples 11700 loss 0.006638293353369959\n",
      "Epoch 95 num_samples 11800 loss 0.005068682508011592\n",
      "Epoch 95 num_samples 11900 loss 0.0043369036505047235\n",
      "Epoch 95 num_samples 12000 loss 0.003844800427003031\n",
      "Epoch 95 num_samples 12100 loss 0.004286108283941161\n",
      "Epoch 95 num_samples 12200 loss 0.006025555389976586\n",
      "Epoch 95 num_samples 12300 loss 0.004665786522970696\n",
      "Epoch 95 num_samples 12400 loss 0.006905311098141988\n",
      "Epoch 95 num_samples 12500 loss 0.006148371753296351\n",
      "Epoch 95 num_samples 12600 loss 0.0077678233582527435\n",
      "Epoch 95 num_samples 12700 loss 0.005601407119948787\n",
      "Epoch 95 num_samples 12800 loss 0.008506440612168107\n",
      "Epoch 95 num_samples 12900 loss 0.004944837270162668\n",
      "Epoch 95 num_samples 13000 loss 0.0047205545368426485\n",
      "Epoch 95 num_samples 13100 loss 0.007184161693507265\n",
      "Epoch 95 num_samples 13200 loss 0.0032582944668482195\n",
      "Epoch 95 num_samples 13300 loss 0.004546687991163218\n",
      "Epoch 95 num_samples 13400 loss 0.002999438170524501\n",
      "Epoch 95 num_samples 13500 loss 0.004113260740463953\n",
      "Epoch 95 num_samples 13600 loss 0.007400982562276591\n",
      "Epoch 95 num_samples 13700 loss 0.00538872560668435\n",
      "Epoch 95 num_samples 13800 loss 0.005390967119830482\n",
      "Epoch 95 num_samples 13900 loss 0.0022249305286110286\n",
      "Epoch 95 num_samples 14000 loss 0.0038089275920871178\n",
      "Epoch 95 num_samples 14100 loss 0.004986330018455736\n",
      "Epoch 95 num_samples 14200 loss 0.004819941407912802\n",
      "Epoch 95 num_samples 14300 loss 0.0061029593429563975\n",
      "Epoch 95 num_samples 14400 loss 0.006124342981416678\n",
      "Epoch 95 num_samples 14500 loss 0.007673972485447243\n",
      "Epoch 95 num_samples 14600 loss 0.005005171086400691\n",
      "Epoch 95 num_samples 14700 loss 0.005606174784285991\n",
      "Epoch 95 num_samples 14800 loss 0.005404313934406371\n",
      "Epoch 95 num_samples 14900 loss 0.0062336670944316865\n",
      "Epoch 95 num_samples 15000 loss 0.005415257636659259\n",
      "Epoch 95 num_samples 15100 loss 0.005825639680968987\n",
      "Epoch 95 num_samples 15200 loss 0.005499022370359241\n",
      "Epoch 95 num_samples 15300 loss 0.006006272213664767\n",
      "Epoch 95 num_samples 15400 loss 0.004374153733107457\n",
      "Epoch 95 num_samples 15500 loss 0.005568152086992031\n",
      "Epoch 95 num_samples 15600 loss 0.00611788876080331\n",
      "Epoch 95 num_samples 15700 loss 0.004112399818462801\n",
      "Epoch 95 num_samples 15800 loss 0.006523242839195888\n",
      "Epoch 95 num_samples 15900 loss 0.004483250131449172\n",
      "Epoch 95 num_samples 16000 loss 0.0079975589950465\n",
      "Epoch 95 num_samples 16100 loss 0.004321263496577034\n",
      "Epoch 95 num_samples 16200 loss 0.006290923783688954\n",
      "Epoch 95 num_samples 16300 loss 0.007277375707574323\n",
      "Epoch 95 num_samples 16400 loss 0.007280638440735071\n",
      "Epoch 95 num_samples 16500 loss 0.006333789305659776\n",
      "Epoch 95 num_samples 16600 loss 0.007262863922076737\n",
      "Epoch 95 num_samples 16700 loss 0.004047115112766385\n",
      "Epoch 95 num_samples 16800 loss 0.00408536033278188\n",
      "Epoch 95 num_samples 16900 loss 0.004671432172219924\n",
      "Epoch 95 num_samples 17000 loss 0.0035949811677252674\n",
      "Epoch 95 num_samples 17100 loss 0.00864648232518968\n",
      "Epoch 95 num_samples 17200 loss 0.006280374734918684\n",
      "Epoch 95 num_samples 17300 loss 0.00645035338811335\n",
      "Epoch 95 num_samples 17400 loss 0.005422018692452177\n",
      "Epoch 95 num_samples 17500 loss 0.0059021219909244985\n",
      "Epoch 95 num_samples 17600 loss 0.005121155808885757\n",
      "Epoch 95 num_samples 17700 loss 0.004428131703167941\n",
      "Epoch 95 num_samples 17800 loss 0.004647977355204836\n",
      "Epoch 95 num_samples 17900 loss 0.006923735892018252\n",
      "Epoch 95 num_samples 18000 loss 0.00540930933026525\n",
      "Epoch 95 num_samples 18100 loss 0.005881697046966266\n",
      "Epoch 95 num_samples 18200 loss 0.006281636602874505\n",
      "Epoch 95 num_samples 18300 loss 0.004563992726312129\n",
      "Epoch 95 num_samples 18400 loss 0.008502790751491114\n",
      "Epoch 95 num_samples 18500 loss 0.006332637863993479\n",
      "Epoch 96 num_samples 0 loss 0.00439145162389254\n",
      "Epoch 96 num_samples 100 loss 0.0075671538043606355\n",
      "Epoch 96 num_samples 200 loss 0.005186937367221446\n",
      "Epoch 96 num_samples 300 loss 0.004359433885568211\n",
      "Epoch 96 num_samples 400 loss 0.005386292140909845\n",
      "Epoch 96 num_samples 500 loss 0.007973820898390029\n",
      "Epoch 96 num_samples 600 loss 0.007584697655623368\n",
      "Epoch 96 num_samples 700 loss 0.008344688271034371\n",
      "Epoch 96 num_samples 800 loss 0.0049407804689331645\n",
      "Epoch 96 num_samples 900 loss 0.008736080259757511\n",
      "Epoch 96 num_samples 1000 loss 0.005157325210116799\n",
      "Epoch 96 num_samples 1100 loss 0.008461384210883011\n",
      "Epoch 96 num_samples 1200 loss 0.0052815245559994575\n",
      "Epoch 96 num_samples 1300 loss 0.006204022300201628\n",
      "Epoch 96 num_samples 1400 loss 0.006032838861225586\n",
      "Epoch 96 num_samples 1500 loss 0.007069211993895774\n",
      "Epoch 96 num_samples 1600 loss 0.005380900956205006\n",
      "Epoch 96 num_samples 1700 loss 0.005155037468240079\n",
      "Epoch 96 num_samples 1800 loss 0.0052175234498084856\n",
      "Epoch 96 num_samples 1900 loss 0.006280333927950057\n",
      "Epoch 96 num_samples 2000 loss 0.007215673748636753\n",
      "Epoch 96 num_samples 2100 loss 0.0038093641872138416\n",
      "Epoch 96 num_samples 2200 loss 0.0043856952689542384\n",
      "Epoch 96 num_samples 2300 loss 0.002863223475473034\n",
      "Epoch 96 num_samples 2400 loss 0.004736202268115191\n",
      "Epoch 96 num_samples 2500 loss 0.0063246768743004745\n",
      "Epoch 96 num_samples 2600 loss 0.006911175803465472\n",
      "Epoch 96 num_samples 2700 loss 0.005161084730048311\n",
      "Epoch 96 num_samples 2800 loss 0.0068297463756470545\n",
      "Epoch 96 num_samples 2900 loss 0.006352907348261709\n",
      "Epoch 96 num_samples 3000 loss 0.00517125958986412\n",
      "Epoch 96 num_samples 3100 loss 0.005112591556736925\n",
      "Epoch 96 num_samples 3200 loss 0.008197346220666446\n",
      "Epoch 96 num_samples 3300 loss 0.005622728166985743\n",
      "Epoch 96 num_samples 3400 loss 0.0046227643382024215\n",
      "Epoch 96 num_samples 3500 loss 0.004950995498757962\n",
      "Epoch 96 num_samples 3600 loss 0.0039057138336904764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 num_samples 3700 loss 0.008299534675626094\n",
      "Epoch 96 num_samples 3800 loss 0.004442226385726906\n",
      "Epoch 96 num_samples 3900 loss 0.005833101535074722\n",
      "Epoch 96 num_samples 4000 loss 0.0060801114840429845\n",
      "Epoch 96 num_samples 4100 loss 0.007696184662027948\n",
      "Epoch 96 num_samples 4200 loss 0.0060647554744496165\n",
      "Epoch 96 num_samples 4300 loss 0.005126883600029156\n",
      "Epoch 96 num_samples 4400 loss 0.005909168271398215\n",
      "Epoch 96 num_samples 4500 loss 0.00712772566271462\n",
      "Epoch 96 num_samples 4600 loss 0.006435373840638502\n",
      "Epoch 96 num_samples 4700 loss 0.0036125264702816986\n",
      "Epoch 96 num_samples 4800 loss 0.003962463734404789\n",
      "Epoch 96 num_samples 4900 loss 0.005091288130708188\n",
      "Epoch 96 num_samples 5000 loss 0.004482088248502365\n",
      "Epoch 96 num_samples 5100 loss 0.007828212576191942\n",
      "Epoch 96 num_samples 5200 loss 0.0038640635928704824\n",
      "Epoch 96 num_samples 5300 loss 0.005179635348425772\n",
      "Epoch 96 num_samples 5400 loss 0.00718856063404141\n",
      "Epoch 96 num_samples 5500 loss 0.004370084111639928\n",
      "Epoch 96 num_samples 5600 loss 0.01325650121346339\n",
      "Epoch 96 num_samples 5700 loss 0.005468817068899239\n",
      "Epoch 96 num_samples 5800 loss 0.0054652632998699446\n",
      "Epoch 96 num_samples 5900 loss 0.006799606194439045\n",
      "Epoch 96 num_samples 6000 loss 0.005749721611700012\n",
      "Epoch 96 num_samples 6100 loss 0.005331066454932923\n",
      "Epoch 96 num_samples 6200 loss 0.005834152080692695\n",
      "Epoch 96 num_samples 6300 loss 0.007161839207795681\n",
      "Epoch 96 num_samples 6400 loss 0.004725817838400434\n",
      "Epoch 96 num_samples 6500 loss 0.004091484239254298\n",
      "Epoch 96 num_samples 6600 loss 0.009758034766794812\n",
      "Epoch 96 num_samples 6700 loss 0.005043870042713181\n",
      "Epoch 96 num_samples 6800 loss 0.0031433942016668125\n",
      "Epoch 96 num_samples 6900 loss 0.011712192656626614\n",
      "Epoch 96 num_samples 7000 loss 0.00698852595304525\n",
      "Epoch 96 num_samples 7100 loss 0.003906444975673285\n",
      "Epoch 96 num_samples 7200 loss 0.005606725461516772\n",
      "Epoch 96 num_samples 7300 loss 0.005851020983695231\n",
      "Epoch 96 num_samples 7400 loss 0.004320814007734047\n",
      "Epoch 96 num_samples 7500 loss 0.008218803564664551\n",
      "Epoch 96 num_samples 7600 loss 0.005716958737020154\n",
      "Epoch 96 num_samples 7700 loss 0.0076975900596133505\n",
      "Epoch 96 num_samples 7800 loss 0.004827547097537059\n",
      "Epoch 96 num_samples 7900 loss 0.006037327314562734\n",
      "Epoch 96 num_samples 8000 loss 0.00397154809086852\n",
      "Epoch 96 num_samples 8100 loss 0.005101530018480733\n",
      "Epoch 96 num_samples 8200 loss 0.006088146930943097\n",
      "Epoch 96 num_samples 8300 loss 0.0046889555513903855\n",
      "Epoch 96 num_samples 8400 loss 0.003868630128559904\n",
      "Epoch 96 num_samples 8500 loss 0.005849178476570569\n",
      "Epoch 96 num_samples 8600 loss 0.005520756722804549\n",
      "Epoch 96 num_samples 8700 loss 0.005729549693756505\n",
      "Epoch 96 num_samples 8800 loss 0.005467847569448826\n",
      "Epoch 96 num_samples 8900 loss 0.006668993072135366\n",
      "Epoch 96 num_samples 9000 loss 0.005740977355670562\n",
      "Epoch 96 num_samples 9100 loss 0.005562452626929266\n",
      "Epoch 96 num_samples 9200 loss 0.006152535721159758\n",
      "Epoch 96 num_samples 9300 loss 0.005875755666888052\n",
      "Epoch 96 num_samples 9400 loss 0.004859301852635642\n",
      "Epoch 96 num_samples 9500 loss 0.004798485989866199\n",
      "Epoch 96 num_samples 9600 loss 0.005451951911930165\n",
      "Epoch 96 num_samples 9700 loss 0.007387913240295174\n",
      "Epoch 96 num_samples 9800 loss 0.0034708905779027776\n",
      "Epoch 96 num_samples 9900 loss 0.010192137356275128\n",
      "Epoch 96 num_samples 10000 loss 0.004589516403797568\n",
      "Epoch 96 num_samples 10100 loss 0.004277716390096876\n",
      "Epoch 96 num_samples 10200 loss 0.0066991640763584825\n",
      "Epoch 96 num_samples 10300 loss 0.005582868549149051\n",
      "Epoch 96 num_samples 10400 loss 0.007430683871267631\n",
      "Epoch 96 num_samples 10500 loss 0.005348125045636321\n",
      "Epoch 96 num_samples 10600 loss 0.0062704034005398816\n",
      "Epoch 96 num_samples 10700 loss 0.00485773623646206\n",
      "Epoch 96 num_samples 10800 loss 0.006384112934368089\n",
      "Epoch 96 num_samples 10900 loss 0.004849746204284129\n",
      "Epoch 96 num_samples 11000 loss 0.004525139947258075\n",
      "Epoch 96 num_samples 11100 loss 0.006106292050062536\n",
      "Epoch 96 num_samples 11200 loss 0.004637020610613421\n",
      "Epoch 96 num_samples 11300 loss 0.0074166898939364645\n",
      "Epoch 96 num_samples 11400 loss 0.0051276951655671345\n",
      "Epoch 96 num_samples 11500 loss 0.004828803696262349\n",
      "Epoch 96 num_samples 11600 loss 0.0049256025134298215\n",
      "Epoch 96 num_samples 11700 loss 0.00653798138879948\n",
      "Epoch 96 num_samples 11800 loss 0.004976373344195163\n",
      "Epoch 96 num_samples 11900 loss 0.00426042339653209\n",
      "Epoch 96 num_samples 12000 loss 0.003775179897923653\n",
      "Epoch 96 num_samples 12100 loss 0.004214271933856312\n",
      "Epoch 96 num_samples 12200 loss 0.005893550625167468\n",
      "Epoch 96 num_samples 12300 loss 0.004594577358154042\n",
      "Epoch 96 num_samples 12400 loss 0.006776735752507108\n",
      "Epoch 96 num_samples 12500 loss 0.006044086018976288\n",
      "Epoch 96 num_samples 12600 loss 0.007614355778378685\n",
      "Epoch 96 num_samples 12700 loss 0.005507335875312897\n",
      "Epoch 96 num_samples 12800 loss 0.008340610743104961\n",
      "Epoch 96 num_samples 12900 loss 0.0048655669825843125\n",
      "Epoch 96 num_samples 13000 loss 0.0046360741974836965\n",
      "Epoch 96 num_samples 13100 loss 0.007071193599179098\n",
      "Epoch 96 num_samples 13200 loss 0.003203540458954779\n",
      "Epoch 96 num_samples 13300 loss 0.004465147257186439\n",
      "Epoch 96 num_samples 13400 loss 0.0029421246813566104\n",
      "Epoch 96 num_samples 13500 loss 0.004054641314150597\n",
      "Epoch 96 num_samples 13600 loss 0.00727756491989614\n",
      "Epoch 96 num_samples 13700 loss 0.005283673404841716\n",
      "Epoch 96 num_samples 13800 loss 0.005312420099587345\n",
      "Epoch 96 num_samples 13900 loss 0.002187138633029187\n",
      "Epoch 96 num_samples 14000 loss 0.0037423299076822223\n",
      "Epoch 96 num_samples 14100 loss 0.004909350340756315\n",
      "Epoch 96 num_samples 14200 loss 0.004746293401611787\n",
      "Epoch 96 num_samples 14300 loss 0.006004127149239997\n",
      "Epoch 96 num_samples 14400 loss 0.006030263940806045\n",
      "Epoch 96 num_samples 14500 loss 0.007546818221102356\n",
      "Epoch 96 num_samples 14600 loss 0.004907591769953603\n",
      "Epoch 96 num_samples 14700 loss 0.005522719847943673\n",
      "Epoch 96 num_samples 14800 loss 0.005336198851186163\n",
      "Epoch 96 num_samples 14900 loss 0.006122594120315135\n",
      "Epoch 96 num_samples 15000 loss 0.005325694546677877\n",
      "Epoch 96 num_samples 15100 loss 0.005736631568922983\n",
      "Epoch 96 num_samples 15200 loss 0.00540118081658006\n",
      "Epoch 96 num_samples 15300 loss 0.005907908314569587\n",
      "Epoch 96 num_samples 15400 loss 0.004295565797071293\n",
      "Epoch 96 num_samples 15500 loss 0.0054680457576148445\n",
      "Epoch 96 num_samples 15600 loss 0.006007512982975776\n",
      "Epoch 96 num_samples 15700 loss 0.004054579242065193\n",
      "Epoch 96 num_samples 15800 loss 0.006422860227655771\n",
      "Epoch 96 num_samples 15900 loss 0.00441495883501497\n",
      "Epoch 96 num_samples 16000 loss 0.00785040154771953\n",
      "Epoch 96 num_samples 16100 loss 0.004239727646385571\n",
      "Epoch 96 num_samples 16200 loss 0.006189434682977142\n",
      "Epoch 96 num_samples 16300 loss 0.007155469840913924\n",
      "Epoch 96 num_samples 16400 loss 0.00713150428010516\n",
      "Epoch 96 num_samples 16500 loss 0.006219567212651069\n",
      "Epoch 96 num_samples 16600 loss 0.007140630087406303\n",
      "Epoch 96 num_samples 16700 loss 0.003982550614617494\n",
      "Epoch 96 num_samples 16800 loss 0.004011996249496717\n",
      "Epoch 96 num_samples 16900 loss 0.004604330924439937\n",
      "Epoch 96 num_samples 17000 loss 0.0035326311924681808\n",
      "Epoch 96 num_samples 17100 loss 0.008481587531071135\n",
      "Epoch 96 num_samples 17200 loss 0.0061767452711788936\n",
      "Epoch 96 num_samples 17300 loss 0.006324303056980738\n",
      "Epoch 96 num_samples 17400 loss 0.0053160663313667625\n",
      "Epoch 96 num_samples 17500 loss 0.005805330277629414\n",
      "Epoch 96 num_samples 17600 loss 0.0050285863400123445\n",
      "Epoch 96 num_samples 17700 loss 0.0043609062314649795\n",
      "Epoch 96 num_samples 17800 loss 0.004551047464609984\n",
      "Epoch 96 num_samples 17900 loss 0.006784248462690588\n",
      "Epoch 96 num_samples 18000 loss 0.005335407098955387\n",
      "Epoch 96 num_samples 18100 loss 0.005781759251228519\n",
      "Epoch 96 num_samples 18200 loss 0.006178182098421956\n",
      "Epoch 96 num_samples 18300 loss 0.004488649118454354\n",
      "Epoch 96 num_samples 18400 loss 0.008354809424620137\n",
      "Epoch 96 num_samples 18500 loss 0.006226995634185115\n",
      "Epoch 97 num_samples 0 loss 0.004313777550074044\n",
      "Epoch 97 num_samples 100 loss 0.00744896028256538\n",
      "Epoch 97 num_samples 200 loss 0.005094170697028939\n",
      "Epoch 97 num_samples 300 loss 0.004291543801733131\n",
      "Epoch 97 num_samples 400 loss 0.005307696944859767\n",
      "Epoch 97 num_samples 500 loss 0.007843265782584107\n",
      "Epoch 97 num_samples 600 loss 0.007462455657311786\n",
      "Epoch 97 num_samples 700 loss 0.00821000533010288\n",
      "Epoch 97 num_samples 800 loss 0.004853826560088829\n",
      "Epoch 97 num_samples 900 loss 0.008568722755797804\n",
      "Epoch 97 num_samples 1000 loss 0.005063965715261417\n",
      "Epoch 97 num_samples 1100 loss 0.008324415751643718\n",
      "Epoch 97 num_samples 1200 loss 0.005192681348245095\n",
      "Epoch 97 num_samples 1300 loss 0.006115942571224961\n",
      "Epoch 97 num_samples 1400 loss 0.005918548850282845\n",
      "Epoch 97 num_samples 1500 loss 0.006940533285697461\n",
      "Epoch 97 num_samples 1600 loss 0.005291603458149966\n",
      "Epoch 97 num_samples 1700 loss 0.005054308777651451\n",
      "Epoch 97 num_samples 1800 loss 0.0051373858964783034\n",
      "Epoch 97 num_samples 1900 loss 0.006169240642758033\n",
      "Epoch 97 num_samples 2000 loss 0.007111337469942143\n",
      "Epoch 97 num_samples 2100 loss 0.003754875298995861\n",
      "Epoch 97 num_samples 2200 loss 0.004317500269560657\n",
      "Epoch 97 num_samples 2300 loss 0.0028184904798740917\n",
      "Epoch 97 num_samples 2400 loss 0.004650104936792291\n",
      "Epoch 97 num_samples 2500 loss 0.006223758019705766\n",
      "Epoch 97 num_samples 2600 loss 0.006786805305133423\n",
      "Epoch 97 num_samples 2700 loss 0.005080221215188847\n",
      "Epoch 97 num_samples 2800 loss 0.00670983704219414\n",
      "Epoch 97 num_samples 2900 loss 0.006258376245680728\n",
      "Epoch 97 num_samples 3000 loss 0.005073892160124863\n",
      "Epoch 97 num_samples 3100 loss 0.005029695461762679\n",
      "Epoch 97 num_samples 3200 loss 0.008022385153663384\n",
      "Epoch 97 num_samples 3300 loss 0.0055277898820580516\n",
      "Epoch 97 num_samples 3400 loss 0.004540883986697369\n",
      "Epoch 97 num_samples 3500 loss 0.004886770711431237\n",
      "Epoch 97 num_samples 3600 loss 0.003843229739634817\n",
      "Epoch 97 num_samples 3700 loss 0.008174825308163942\n",
      "Epoch 97 num_samples 3800 loss 0.004371083653419701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 num_samples 3900 loss 0.005746957977088021\n",
      "Epoch 97 num_samples 4000 loss 0.005997637530588535\n",
      "Epoch 97 num_samples 4100 loss 0.0075579573394350865\n",
      "Epoch 97 num_samples 4200 loss 0.00596158890294501\n",
      "Epoch 97 num_samples 4300 loss 0.00503534412656642\n",
      "Epoch 97 num_samples 4400 loss 0.005794181838649834\n",
      "Epoch 97 num_samples 4500 loss 0.006982548461102396\n",
      "Epoch 97 num_samples 4600 loss 0.00633165393117742\n",
      "Epoch 97 num_samples 4700 loss 0.003552830490966501\n",
      "Epoch 97 num_samples 4800 loss 0.003903472994304119\n",
      "Epoch 97 num_samples 4900 loss 0.0050071519240303545\n",
      "Epoch 97 num_samples 5000 loss 0.004404091710848471\n",
      "Epoch 97 num_samples 5100 loss 0.007699086498149188\n",
      "Epoch 97 num_samples 5200 loss 0.003806968813114846\n",
      "Epoch 97 num_samples 5300 loss 0.005099137763749159\n",
      "Epoch 97 num_samples 5400 loss 0.007073934412907987\n",
      "Epoch 97 num_samples 5500 loss 0.004297141747548273\n",
      "Epoch 97 num_samples 5600 loss 0.012981857775804725\n",
      "Epoch 97 num_samples 5700 loss 0.005380077763589061\n",
      "Epoch 97 num_samples 5800 loss 0.005365945405204777\n",
      "Epoch 97 num_samples 5900 loss 0.006671692944369359\n",
      "Epoch 97 num_samples 6000 loss 0.005649810309773727\n",
      "Epoch 97 num_samples 6100 loss 0.005237638257103019\n",
      "Epoch 97 num_samples 6200 loss 0.005746489327284355\n",
      "Epoch 97 num_samples 6300 loss 0.007031891947923782\n",
      "Epoch 97 num_samples 6400 loss 0.004653575979418062\n",
      "Epoch 97 num_samples 6500 loss 0.004022688039809327\n",
      "Epoch 97 num_samples 6600 loss 0.009589124676140634\n",
      "Epoch 97 num_samples 6700 loss 0.004967427162674283\n",
      "Epoch 97 num_samples 6800 loss 0.003094354274792864\n",
      "Epoch 97 num_samples 6900 loss 0.011505976563035954\n",
      "Epoch 97 num_samples 7000 loss 0.0068748249159712475\n",
      "Epoch 97 num_samples 7100 loss 0.0038511846210071976\n",
      "Epoch 97 num_samples 7200 loss 0.005518240537688015\n",
      "Epoch 97 num_samples 7300 loss 0.00575834753771196\n",
      "Epoch 97 num_samples 7400 loss 0.0042555359036469936\n",
      "Epoch 97 num_samples 7500 loss 0.008067760109649939\n",
      "Epoch 97 num_samples 7600 loss 0.005617658495601077\n",
      "Epoch 97 num_samples 7700 loss 0.007575426507391095\n",
      "Epoch 97 num_samples 7800 loss 0.00474728118426383\n",
      "Epoch 97 num_samples 7900 loss 0.005945850518089473\n",
      "Epoch 97 num_samples 8000 loss 0.00388973019529974\n",
      "Epoch 97 num_samples 8100 loss 0.00502306667958941\n",
      "Epoch 97 num_samples 8200 loss 0.005955805316670868\n",
      "Epoch 97 num_samples 8300 loss 0.004604892807938145\n",
      "Epoch 97 num_samples 8400 loss 0.003792945691344341\n",
      "Epoch 97 num_samples 8500 loss 0.005720412797352323\n",
      "Epoch 97 num_samples 8600 loss 0.005417723881329926\n",
      "Epoch 97 num_samples 8700 loss 0.005641617014526979\n",
      "Epoch 97 num_samples 8800 loss 0.005381601189585171\n",
      "Epoch 97 num_samples 8900 loss 0.0065678315856748425\n",
      "Epoch 97 num_samples 9000 loss 0.005645448059327654\n",
      "Epoch 97 num_samples 9100 loss 0.0054823708684228764\n",
      "Epoch 97 num_samples 9200 loss 0.006052414801003366\n",
      "Epoch 97 num_samples 9300 loss 0.00577452584205895\n",
      "Epoch 97 num_samples 9400 loss 0.004752583041282945\n",
      "Epoch 97 num_samples 9500 loss 0.004730859527782733\n",
      "Epoch 97 num_samples 9600 loss 0.005362463068515619\n",
      "Epoch 97 num_samples 9700 loss 0.007245930195095492\n",
      "Epoch 97 num_samples 9800 loss 0.0034163094032754232\n",
      "Epoch 97 num_samples 9900 loss 0.01005802938769068\n",
      "Epoch 97 num_samples 10000 loss 0.004501744328321861\n",
      "Epoch 97 num_samples 10100 loss 0.004203193294907975\n",
      "Epoch 97 num_samples 10200 loss 0.00659015271086599\n",
      "Epoch 97 num_samples 10300 loss 0.005474887081687925\n",
      "Epoch 97 num_samples 10400 loss 0.007312374660128212\n",
      "Epoch 97 num_samples 10500 loss 0.005253148838535904\n",
      "Epoch 97 num_samples 10600 loss 0.006137025117675343\n",
      "Epoch 97 num_samples 10700 loss 0.004764932716634062\n",
      "Epoch 97 num_samples 10800 loss 0.006275760205813785\n",
      "Epoch 97 num_samples 10900 loss 0.004763623418440488\n",
      "Epoch 97 num_samples 11000 loss 0.004459964218490342\n",
      "Epoch 97 num_samples 11100 loss 0.006000941428885967\n",
      "Epoch 97 num_samples 11200 loss 0.00455765472651811\n",
      "Epoch 97 num_samples 11300 loss 0.007302240281509273\n",
      "Epoch 97 num_samples 11400 loss 0.0050227479771463145\n",
      "Epoch 97 num_samples 11500 loss 0.004738301762880997\n",
      "Epoch 97 num_samples 11600 loss 0.004844855307996448\n",
      "Epoch 97 num_samples 11700 loss 0.006414119278120438\n",
      "Epoch 97 num_samples 11800 loss 0.004905211015960211\n",
      "Epoch 97 num_samples 11900 loss 0.004191369997683942\n",
      "Epoch 97 num_samples 12000 loss 0.0037133370076571524\n",
      "Epoch 97 num_samples 12100 loss 0.004148925497859899\n",
      "Epoch 97 num_samples 12200 loss 0.0058013008317206235\n",
      "Epoch 97 num_samples 12300 loss 0.004529569283060724\n",
      "Epoch 97 num_samples 12400 loss 0.006646532756047441\n",
      "Epoch 97 num_samples 12500 loss 0.005953102039220325\n",
      "Epoch 97 num_samples 12600 loss 0.00749231351400472\n",
      "Epoch 97 num_samples 12700 loss 0.005395875138847313\n",
      "Epoch 97 num_samples 12800 loss 0.008177730520705164\n",
      "Epoch 97 num_samples 12900 loss 0.0047858158383453885\n",
      "Epoch 97 num_samples 13000 loss 0.004555738240916517\n",
      "Epoch 97 num_samples 13100 loss 0.006932515557091065\n",
      "Epoch 97 num_samples 13200 loss 0.003152184568654757\n",
      "Epoch 97 num_samples 13300 loss 0.0044038219627434904\n",
      "Epoch 97 num_samples 13400 loss 0.002907393969987884\n",
      "Epoch 97 num_samples 13500 loss 0.003985242544557427\n",
      "Epoch 97 num_samples 13600 loss 0.007154853343945201\n",
      "Epoch 97 num_samples 13700 loss 0.005192384323669404\n",
      "Epoch 97 num_samples 13800 loss 0.005218825864695067\n",
      "Epoch 97 num_samples 13900 loss 0.002152445635370343\n",
      "Epoch 97 num_samples 14000 loss 0.003671139219770216\n",
      "Epoch 97 num_samples 14100 loss 0.0048086528996209256\n",
      "Epoch 97 num_samples 14200 loss 0.004666609060179886\n",
      "Epoch 97 num_samples 14300 loss 0.005885948238015086\n",
      "Epoch 97 num_samples 14400 loss 0.005932806947827838\n",
      "Epoch 97 num_samples 14500 loss 0.00742549486158928\n",
      "Epoch 97 num_samples 14600 loss 0.0048116127478966065\n",
      "Epoch 97 num_samples 14700 loss 0.005417319500049631\n",
      "Epoch 97 num_samples 14800 loss 0.005234605576961459\n",
      "Epoch 97 num_samples 14900 loss 0.00602342496543758\n",
      "Epoch 97 num_samples 15000 loss 0.005241683029990005\n",
      "Epoch 97 num_samples 15100 loss 0.005632727871716361\n",
      "Epoch 97 num_samples 15200 loss 0.005314163908794598\n",
      "Epoch 97 num_samples 15300 loss 0.005814889456128962\n",
      "Epoch 97 num_samples 15400 loss 0.004231116392017088\n",
      "Epoch 97 num_samples 15500 loss 0.005357697924519554\n",
      "Epoch 97 num_samples 15600 loss 0.005901378002278513\n",
      "Epoch 97 num_samples 15700 loss 0.003980389131301946\n",
      "Epoch 97 num_samples 15800 loss 0.006308023633042075\n",
      "Epoch 97 num_samples 15900 loss 0.004332990959047881\n",
      "Epoch 97 num_samples 16000 loss 0.007714952133618478\n",
      "Epoch 97 num_samples 16100 loss 0.0041627628596034826\n",
      "Epoch 97 num_samples 16200 loss 0.006078010913066263\n",
      "Epoch 97 num_samples 16300 loss 0.007020289934422932\n",
      "Epoch 97 num_samples 16400 loss 0.00701122241277312\n",
      "Epoch 97 num_samples 16500 loss 0.006118805233338068\n",
      "Epoch 97 num_samples 16600 loss 0.0070297065524553\n",
      "Epoch 97 num_samples 16700 loss 0.003918966181432257\n",
      "Epoch 97 num_samples 16800 loss 0.003958230260999171\n",
      "Epoch 97 num_samples 16900 loss 0.004523103532062208\n",
      "Epoch 97 num_samples 17000 loss 0.003470404352055699\n",
      "Epoch 97 num_samples 17100 loss 0.00831318545129027\n",
      "Epoch 97 num_samples 17200 loss 0.006066438390563455\n",
      "Epoch 97 num_samples 17300 loss 0.006232421495981746\n",
      "Epoch 97 num_samples 17400 loss 0.005224796998506717\n",
      "Epoch 97 num_samples 17500 loss 0.0057025532030156485\n",
      "Epoch 97 num_samples 17600 loss 0.00494536176380001\n",
      "Epoch 97 num_samples 17700 loss 0.004278817259503891\n",
      "Epoch 97 num_samples 17800 loss 0.004469544827405353\n",
      "Epoch 97 num_samples 17900 loss 0.006667617989374459\n",
      "Epoch 97 num_samples 18000 loss 0.005254498942320267\n",
      "Epoch 97 num_samples 18100 loss 0.005688997944441772\n",
      "Epoch 97 num_samples 18200 loss 0.006074877877679647\n",
      "Epoch 97 num_samples 18300 loss 0.004405910971657074\n",
      "Epoch 97 num_samples 18400 loss 0.008208843093538164\n",
      "Epoch 97 num_samples 18500 loss 0.006123415426783766\n",
      "Epoch 98 num_samples 0 loss 0.004256944284524987\n",
      "Epoch 98 num_samples 100 loss 0.007323436116593818\n",
      "Epoch 98 num_samples 200 loss 0.004997469553839825\n",
      "Epoch 98 num_samples 300 loss 0.004215701821204947\n",
      "Epoch 98 num_samples 400 loss 0.005219999253714308\n",
      "Epoch 98 num_samples 500 loss 0.007696160440488166\n",
      "Epoch 98 num_samples 600 loss 0.007303843088610318\n",
      "Epoch 98 num_samples 700 loss 0.008050318205373863\n",
      "Epoch 98 num_samples 800 loss 0.004783585586882645\n",
      "Epoch 98 num_samples 900 loss 0.008432944789775455\n",
      "Epoch 98 num_samples 1000 loss 0.004965543430135695\n",
      "Epoch 98 num_samples 1100 loss 0.008143961548450769\n",
      "Epoch 98 num_samples 1200 loss 0.0051010708587229045\n",
      "Epoch 98 num_samples 1300 loss 0.006003699790120104\n",
      "Epoch 98 num_samples 1400 loss 0.005817059942829808\n",
      "Epoch 98 num_samples 1500 loss 0.006813490474420154\n",
      "Epoch 98 num_samples 1600 loss 0.00520213414314046\n",
      "Epoch 98 num_samples 1700 loss 0.004979054524353441\n",
      "Epoch 98 num_samples 1800 loss 0.005046916564030125\n",
      "Epoch 98 num_samples 1900 loss 0.006087021215093416\n",
      "Epoch 98 num_samples 2000 loss 0.0069579644743281025\n",
      "Epoch 98 num_samples 2100 loss 0.003678267561798026\n",
      "Epoch 98 num_samples 2200 loss 0.004252450038774701\n",
      "Epoch 98 num_samples 2300 loss 0.0027617085459078245\n",
      "Epoch 98 num_samples 2400 loss 0.004561199483226518\n",
      "Epoch 98 num_samples 2500 loss 0.006116078325114715\n",
      "Epoch 98 num_samples 2600 loss 0.006669885306738443\n",
      "Epoch 98 num_samples 2700 loss 0.004999904126038809\n",
      "Epoch 98 num_samples 2800 loss 0.006601836086696634\n",
      "Epoch 98 num_samples 2900 loss 0.006139866508690418\n",
      "Epoch 98 num_samples 3000 loss 0.004986235515645764\n",
      "Epoch 98 num_samples 3100 loss 0.004961403026641458\n",
      "Epoch 98 num_samples 3200 loss 0.007879123852171351\n",
      "Epoch 98 num_samples 3300 loss 0.005420439976257645\n",
      "Epoch 98 num_samples 3400 loss 0.004466075024019262\n",
      "Epoch 98 num_samples 3500 loss 0.004803609800502717\n",
      "Epoch 98 num_samples 3600 loss 0.00378650873409647\n",
      "Epoch 98 num_samples 3700 loss 0.008020116207161605\n",
      "Epoch 98 num_samples 3800 loss 0.0042945825109242\n",
      "Epoch 98 num_samples 3900 loss 0.005654266852875615\n",
      "Epoch 98 num_samples 4000 loss 0.0058685735876524425\n",
      "Epoch 98 num_samples 4100 loss 0.007423770732656013\n",
      "Epoch 98 num_samples 4200 loss 0.005865502443773151\n",
      "Epoch 98 num_samples 4300 loss 0.004955436978142897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 num_samples 4400 loss 0.005695253590816985\n",
      "Epoch 98 num_samples 4500 loss 0.006857519299382631\n",
      "Epoch 98 num_samples 4600 loss 0.006226229831244431\n",
      "Epoch 98 num_samples 4700 loss 0.003489471843491867\n",
      "Epoch 98 num_samples 4800 loss 0.0038300134677337464\n",
      "Epoch 98 num_samples 4900 loss 0.0049351345844107055\n",
      "Epoch 98 num_samples 5000 loss 0.004336001096416619\n",
      "Epoch 98 num_samples 5100 loss 0.007570382350425567\n",
      "Epoch 98 num_samples 5200 loss 0.0037485494720160663\n",
      "Epoch 98 num_samples 5300 loss 0.005012141471257111\n",
      "Epoch 98 num_samples 5400 loss 0.006962458691250872\n",
      "Epoch 98 num_samples 5500 loss 0.004231812013736776\n",
      "Epoch 98 num_samples 5600 loss 0.01276960636793946\n",
      "Epoch 98 num_samples 5700 loss 0.005287511169769066\n",
      "Epoch 98 num_samples 5800 loss 0.005285278709686738\n",
      "Epoch 98 num_samples 5900 loss 0.006551596354823399\n",
      "Epoch 98 num_samples 6000 loss 0.005567686201399793\n",
      "Epoch 98 num_samples 6100 loss 0.00515387505654757\n",
      "Epoch 98 num_samples 6200 loss 0.005636637815286782\n",
      "Epoch 98 num_samples 6300 loss 0.006901419561558605\n",
      "Epoch 98 num_samples 6400 loss 0.00457916614160459\n",
      "Epoch 98 num_samples 6500 loss 0.003956689099958203\n",
      "Epoch 98 num_samples 6600 loss 0.009452351224172815\n",
      "Epoch 98 num_samples 6700 loss 0.0049047809224736175\n",
      "Epoch 98 num_samples 6800 loss 0.0030388434092414067\n",
      "Epoch 98 num_samples 6900 loss 0.011324467755788764\n",
      "Epoch 98 num_samples 7000 loss 0.006759135917884667\n",
      "Epoch 98 num_samples 7100 loss 0.0037878001795656735\n",
      "Epoch 98 num_samples 7200 loss 0.0054363352116871795\n",
      "Epoch 98 num_samples 7300 loss 0.00566143044834593\n",
      "Epoch 98 num_samples 7400 loss 0.004180091152411718\n",
      "Epoch 98 num_samples 7500 loss 0.007919144756057248\n",
      "Epoch 98 num_samples 7600 loss 0.005517370985766328\n",
      "Epoch 98 num_samples 7700 loss 0.007438477723850418\n",
      "Epoch 98 num_samples 7800 loss 0.00466898724660918\n",
      "Epoch 98 num_samples 7900 loss 0.005842223747184801\n",
      "Epoch 98 num_samples 8000 loss 0.0038330581172100853\n",
      "Epoch 98 num_samples 8100 loss 0.004934327409081686\n",
      "Epoch 98 num_samples 8200 loss 0.005870012610565869\n",
      "Epoch 98 num_samples 8300 loss 0.00453387191446604\n",
      "Epoch 98 num_samples 8400 loss 0.0037280168736498628\n",
      "Epoch 98 num_samples 8500 loss 0.005653420694709652\n",
      "Epoch 98 num_samples 8600 loss 0.00532250958198248\n",
      "Epoch 98 num_samples 8700 loss 0.005542708451544857\n",
      "Epoch 98 num_samples 8800 loss 0.0052902048729546024\n",
      "Epoch 98 num_samples 8900 loss 0.006449873463282175\n",
      "Epoch 98 num_samples 9000 loss 0.005551267373314267\n",
      "Epoch 98 num_samples 9100 loss 0.005386115956101114\n",
      "Epoch 98 num_samples 9200 loss 0.005969807279278066\n",
      "Epoch 98 num_samples 9300 loss 0.005671045584133094\n",
      "Epoch 98 num_samples 9400 loss 0.0046783538281892755\n",
      "Epoch 98 num_samples 9500 loss 0.004645004244185794\n",
      "Epoch 98 num_samples 9600 loss 0.00528484281511255\n",
      "Epoch 98 num_samples 9700 loss 0.007119190316965562\n",
      "Epoch 98 num_samples 9800 loss 0.0033445097795983193\n",
      "Epoch 98 num_samples 9900 loss 0.009875079231909861\n",
      "Epoch 98 num_samples 10000 loss 0.004418757269361532\n",
      "Epoch 98 num_samples 10100 loss 0.0041288011876015355\n",
      "Epoch 98 num_samples 10200 loss 0.006474765434193444\n",
      "Epoch 98 num_samples 10300 loss 0.005390207551652556\n",
      "Epoch 98 num_samples 10400 loss 0.007206121050388359\n",
      "Epoch 98 num_samples 10500 loss 0.005177221607375349\n",
      "Epoch 98 num_samples 10600 loss 0.006043057005407293\n",
      "Epoch 98 num_samples 10700 loss 0.004696596278134609\n",
      "Epoch 98 num_samples 10800 loss 0.006177111101507989\n",
      "Epoch 98 num_samples 10900 loss 0.004697954567340212\n",
      "Epoch 98 num_samples 11000 loss 0.004383777678644281\n",
      "Epoch 98 num_samples 11100 loss 0.005915961216122773\n",
      "Epoch 98 num_samples 11200 loss 0.004464523658624007\n",
      "Epoch 98 num_samples 11300 loss 0.007186067256689591\n",
      "Epoch 98 num_samples 11400 loss 0.0049478664401139535\n",
      "Epoch 98 num_samples 11500 loss 0.004644704590541459\n",
      "Epoch 98 num_samples 11600 loss 0.0047646450608400965\n",
      "Epoch 98 num_samples 11700 loss 0.006297597230782307\n",
      "Epoch 98 num_samples 11800 loss 0.00482964283185493\n",
      "Epoch 98 num_samples 11900 loss 0.004121361928416712\n",
      "Epoch 98 num_samples 12000 loss 0.003639039589081835\n",
      "Epoch 98 num_samples 12100 loss 0.004077221913132827\n",
      "Epoch 98 num_samples 12200 loss 0.005668106145711286\n",
      "Epoch 98 num_samples 12300 loss 0.004462260961642356\n",
      "Epoch 98 num_samples 12400 loss 0.0065356710665351895\n",
      "Epoch 98 num_samples 12500 loss 0.0058219396907837105\n",
      "Epoch 98 num_samples 12600 loss 0.007363827745874475\n",
      "Epoch 98 num_samples 12700 loss 0.0053004916159912815\n",
      "Epoch 98 num_samples 12800 loss 0.008037554447826866\n",
      "Epoch 98 num_samples 12900 loss 0.004708140642289779\n",
      "Epoch 98 num_samples 13000 loss 0.004487277140429773\n",
      "Epoch 98 num_samples 13100 loss 0.006820363869493897\n",
      "Epoch 98 num_samples 13200 loss 0.0031005312133063636\n",
      "Epoch 98 num_samples 13300 loss 0.004326502976097652\n",
      "Epoch 98 num_samples 13400 loss 0.0028533417973213232\n",
      "Epoch 98 num_samples 13500 loss 0.0039113707520971085\n",
      "Epoch 98 num_samples 13600 loss 0.007038877593203787\n",
      "Epoch 98 num_samples 13700 loss 0.005113201181584968\n",
      "Epoch 98 num_samples 13800 loss 0.005139605245923695\n",
      "Epoch 98 num_samples 13900 loss 0.002118757758852548\n",
      "Epoch 98 num_samples 14000 loss 0.0036074999889994445\n",
      "Epoch 98 num_samples 14100 loss 0.004741603420485778\n",
      "Epoch 98 num_samples 14200 loss 0.004610702070627123\n",
      "Epoch 98 num_samples 14300 loss 0.005788316582428494\n",
      "Epoch 98 num_samples 14400 loss 0.005826162619592894\n",
      "Epoch 98 num_samples 14500 loss 0.007281671956856131\n",
      "Epoch 98 num_samples 14600 loss 0.004718887158646963\n",
      "Epoch 98 num_samples 14700 loss 0.005342607638403409\n",
      "Epoch 98 num_samples 14800 loss 0.005153711279805953\n",
      "Epoch 98 num_samples 14900 loss 0.005920418593540533\n",
      "Epoch 98 num_samples 15000 loss 0.0051603653548932945\n",
      "Epoch 98 num_samples 15100 loss 0.005547593656210698\n",
      "Epoch 98 num_samples 15200 loss 0.005213301645301252\n",
      "Epoch 98 num_samples 15300 loss 0.005710318939009513\n",
      "Epoch 98 num_samples 15400 loss 0.004153114900553395\n",
      "Epoch 98 num_samples 15500 loss 0.005253145533751079\n",
      "Epoch 98 num_samples 15600 loss 0.005814239288815347\n",
      "Epoch 98 num_samples 15700 loss 0.003918600803238134\n",
      "Epoch 98 num_samples 15800 loss 0.00619307810788797\n",
      "Epoch 98 num_samples 15900 loss 0.004261286515637457\n",
      "Epoch 98 num_samples 16000 loss 0.007592761636894385\n",
      "Epoch 98 num_samples 16100 loss 0.004091727403899617\n",
      "Epoch 98 num_samples 16200 loss 0.005968793082984338\n",
      "Epoch 98 num_samples 16300 loss 0.006914641398265599\n",
      "Epoch 98 num_samples 16400 loss 0.006860294359655814\n",
      "Epoch 98 num_samples 16500 loss 0.006008602125426865\n",
      "Epoch 98 num_samples 16600 loss 0.006926562068716446\n",
      "Epoch 98 num_samples 16700 loss 0.0038563962495715897\n",
      "Epoch 98 num_samples 16800 loss 0.003894548177099611\n",
      "Epoch 98 num_samples 16900 loss 0.0044597245875237414\n",
      "Epoch 98 num_samples 17000 loss 0.003411504379981476\n",
      "Epoch 98 num_samples 17100 loss 0.008163988664048305\n",
      "Epoch 98 num_samples 17200 loss 0.00597244813382495\n",
      "Epoch 98 num_samples 17300 loss 0.00612122328399926\n",
      "Epoch 98 num_samples 17400 loss 0.005135095828994403\n",
      "Epoch 98 num_samples 17500 loss 0.005620027770488406\n",
      "Epoch 98 num_samples 17600 loss 0.004847241624910352\n",
      "Epoch 98 num_samples 17700 loss 0.004207559108743108\n",
      "Epoch 98 num_samples 17800 loss 0.004387674907551144\n",
      "Epoch 98 num_samples 17900 loss 0.006531025036438959\n",
      "Epoch 98 num_samples 18000 loss 0.005180364173095491\n",
      "Epoch 98 num_samples 18100 loss 0.0055991777324497114\n",
      "Epoch 98 num_samples 18200 loss 0.005974202601689326\n",
      "Epoch 98 num_samples 18300 loss 0.004340675918233807\n",
      "Epoch 98 num_samples 18400 loss 0.008071824397498303\n",
      "Epoch 98 num_samples 18500 loss 0.006031548954489351\n",
      "Epoch 99 num_samples 0 loss 0.004158819239883636\n",
      "Epoch 99 num_samples 100 loss 0.007190177534093661\n",
      "Epoch 99 num_samples 200 loss 0.004938326840717536\n",
      "Epoch 99 num_samples 300 loss 0.004160172651769981\n",
      "Epoch 99 num_samples 400 loss 0.0051470035848880415\n",
      "Epoch 99 num_samples 500 loss 0.0075782083396477365\n",
      "Epoch 99 num_samples 600 loss 0.00719513910054106\n",
      "Epoch 99 num_samples 700 loss 0.007934965324460875\n",
      "Epoch 99 num_samples 800 loss 0.004708181060644415\n",
      "Epoch 99 num_samples 900 loss 0.008294423178739798\n",
      "Epoch 99 num_samples 1000 loss 0.004902148369846477\n",
      "Epoch 99 num_samples 1100 loss 0.008029560897019582\n",
      "Epoch 99 num_samples 1200 loss 0.005037012872507424\n",
      "Epoch 99 num_samples 1300 loss 0.005927171516788992\n",
      "Epoch 99 num_samples 1400 loss 0.005742976684036497\n",
      "Epoch 99 num_samples 1500 loss 0.006693953718060463\n",
      "Epoch 99 num_samples 1600 loss 0.005123949783649104\n",
      "Epoch 99 num_samples 1700 loss 0.004887398890730385\n",
      "Epoch 99 num_samples 1800 loss 0.0049678448143473655\n",
      "Epoch 99 num_samples 1900 loss 0.005978964613279549\n",
      "Epoch 99 num_samples 2000 loss 0.006878293853365671\n",
      "Epoch 99 num_samples 2100 loss 0.003625367886446187\n",
      "Epoch 99 num_samples 2200 loss 0.0041781358560721345\n",
      "Epoch 99 num_samples 2300 loss 0.0027319002318115203\n",
      "Epoch 99 num_samples 2400 loss 0.004495025895764346\n",
      "Epoch 99 num_samples 2500 loss 0.006014026098152619\n",
      "Epoch 99 num_samples 2600 loss 0.0065751989878890926\n",
      "Epoch 99 num_samples 2700 loss 0.004931337685098697\n",
      "Epoch 99 num_samples 2800 loss 0.00648052122508262\n",
      "Epoch 99 num_samples 2900 loss 0.006055489734977965\n",
      "Epoch 99 num_samples 3000 loss 0.004897453915288538\n",
      "Epoch 99 num_samples 3100 loss 0.004851627775821376\n",
      "Epoch 99 num_samples 3200 loss 0.007712188795859776\n",
      "Epoch 99 num_samples 3300 loss 0.005333310574990235\n",
      "Epoch 99 num_samples 3400 loss 0.004389653170569626\n",
      "Epoch 99 num_samples 3500 loss 0.004717389320373157\n",
      "Epoch 99 num_samples 3600 loss 0.003736777841694168\n",
      "Epoch 99 num_samples 3700 loss 0.00789168501910306\n",
      "Epoch 99 num_samples 3800 loss 0.004211221225017098\n",
      "Epoch 99 num_samples 3900 loss 0.005560513199640183\n",
      "Epoch 99 num_samples 4000 loss 0.005775997102535924\n",
      "Epoch 99 num_samples 4100 loss 0.007287519865311134\n",
      "Epoch 99 num_samples 4200 loss 0.005761845679607951\n",
      "Epoch 99 num_samples 4300 loss 0.004873421066511843\n",
      "Epoch 99 num_samples 4400 loss 0.005589136061696382\n",
      "Epoch 99 num_samples 4500 loss 0.006739185896224421\n",
      "Epoch 99 num_samples 4600 loss 0.0061402420233303045\n",
      "Epoch 99 num_samples 4700 loss 0.0034342176691895456\n",
      "Epoch 99 num_samples 4800 loss 0.003771965652289475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 num_samples 4900 loss 0.0048506084877778\n",
      "Epoch 99 num_samples 5000 loss 0.004271938194473777\n",
      "Epoch 99 num_samples 5100 loss 0.007439306878806975\n",
      "Epoch 99 num_samples 5200 loss 0.003678305078294011\n",
      "Epoch 99 num_samples 5300 loss 0.00492938687030525\n",
      "Epoch 99 num_samples 5400 loss 0.006844995901266808\n",
      "Epoch 99 num_samples 5500 loss 0.004162113493881437\n",
      "Epoch 99 num_samples 5600 loss 0.01249116732970653\n",
      "Epoch 99 num_samples 5700 loss 0.0051935562957588855\n",
      "Epoch 99 num_samples 5800 loss 0.00519657593153086\n",
      "Epoch 99 num_samples 5900 loss 0.00643591098127574\n",
      "Epoch 99 num_samples 6000 loss 0.005469437239966432\n",
      "Epoch 99 num_samples 6100 loss 0.005081002908745278\n",
      "Epoch 99 num_samples 6200 loss 0.005542675869957562\n",
      "Epoch 99 num_samples 6300 loss 0.006795489431706988\n",
      "Epoch 99 num_samples 6400 loss 0.004502112580190431\n",
      "Epoch 99 num_samples 6500 loss 0.003885827047878846\n",
      "Epoch 99 num_samples 6600 loss 0.009280595107831321\n",
      "Epoch 99 num_samples 6700 loss 0.004833789424508882\n",
      "Epoch 99 num_samples 6800 loss 0.0029921845696073103\n",
      "Epoch 99 num_samples 6900 loss 0.011126781149936654\n",
      "Epoch 99 num_samples 7000 loss 0.0066645676402456696\n",
      "Epoch 99 num_samples 7100 loss 0.003721026848914476\n",
      "Epoch 99 num_samples 7200 loss 0.005345545887981948\n",
      "Epoch 99 num_samples 7300 loss 0.005568108314395938\n",
      "Epoch 99 num_samples 7400 loss 0.004133185921513381\n",
      "Epoch 99 num_samples 7500 loss 0.007796978287994603\n",
      "Epoch 99 num_samples 7600 loss 0.005426780862690119\n",
      "Epoch 99 num_samples 7700 loss 0.007287608206426663\n",
      "Epoch 99 num_samples 7800 loss 0.004599853860973305\n",
      "Epoch 99 num_samples 7900 loss 0.005748548958952503\n",
      "Epoch 99 num_samples 8000 loss 0.0037542835213877283\n",
      "Epoch 99 num_samples 8100 loss 0.00483691469200848\n",
      "Epoch 99 num_samples 8200 loss 0.00577106962512476\n",
      "Epoch 99 num_samples 8300 loss 0.004450744440411512\n",
      "Epoch 99 num_samples 8400 loss 0.0036673487188803324\n",
      "Epoch 99 num_samples 8500 loss 0.005556248457726197\n",
      "Epoch 99 num_samples 8600 loss 0.005236960708717899\n",
      "Epoch 99 num_samples 8700 loss 0.00545702419558415\n",
      "Epoch 99 num_samples 8800 loss 0.005198262778476976\n",
      "Epoch 99 num_samples 8900 loss 0.006322318507613319\n",
      "Epoch 99 num_samples 9000 loss 0.0054528895983660675\n",
      "Epoch 99 num_samples 9100 loss 0.005309636639639217\n",
      "Epoch 99 num_samples 9200 loss 0.005872331707014464\n",
      "Epoch 99 num_samples 9300 loss 0.005593113040854756\n",
      "Epoch 99 num_samples 9400 loss 0.004611574660556506\n",
      "Epoch 99 num_samples 9500 loss 0.004565158976779261\n",
      "Epoch 99 num_samples 9600 loss 0.005197463048806218\n",
      "Epoch 99 num_samples 9700 loss 0.006991422813778638\n",
      "Epoch 99 num_samples 9800 loss 0.0032955856488460656\n",
      "Epoch 99 num_samples 9900 loss 0.009697082544192843\n",
      "Epoch 99 num_samples 10000 loss 0.00433473750578512\n",
      "Epoch 99 num_samples 10100 loss 0.004051245454549186\n",
      "Epoch 99 num_samples 10200 loss 0.006363979019288887\n",
      "Epoch 99 num_samples 10300 loss 0.0052971560668994685\n",
      "Epoch 99 num_samples 10400 loss 0.007079339701909198\n",
      "Epoch 99 num_samples 10500 loss 0.0051072767078511674\n",
      "Epoch 99 num_samples 10600 loss 0.005938024692653017\n",
      "Epoch 99 num_samples 10700 loss 0.004621230228395443\n",
      "Epoch 99 num_samples 10800 loss 0.00607545890076421\n",
      "Epoch 99 num_samples 10900 loss 0.004609161843768768\n",
      "Epoch 99 num_samples 11000 loss 0.0043195340640240195\n",
      "Epoch 99 num_samples 11100 loss 0.005823002326463244\n",
      "Epoch 99 num_samples 11200 loss 0.004391698655847199\n",
      "Epoch 99 num_samples 11300 loss 0.007054001751721972\n",
      "Epoch 99 num_samples 11400 loss 0.004867577432238686\n",
      "Epoch 99 num_samples 11500 loss 0.004555383240787821\n",
      "Epoch 99 num_samples 11600 loss 0.0046881502687699935\n",
      "Epoch 99 num_samples 11700 loss 0.0061946413183431494\n",
      "Epoch 99 num_samples 11800 loss 0.004763250860186\n",
      "Epoch 99 num_samples 11900 loss 0.004054377580683044\n",
      "Epoch 99 num_samples 12000 loss 0.003573599103960949\n",
      "Epoch 99 num_samples 12100 loss 0.004015208697887988\n",
      "Epoch 99 num_samples 12200 loss 0.005591805585695714\n",
      "Epoch 99 num_samples 12300 loss 0.004391589742747037\n",
      "Epoch 99 num_samples 12400 loss 0.006407925089872626\n",
      "Epoch 99 num_samples 12500 loss 0.0057331353202236856\n",
      "Epoch 99 num_samples 12600 loss 0.0072460976250650596\n",
      "Epoch 99 num_samples 12700 loss 0.005205170466173318\n",
      "Epoch 99 num_samples 12800 loss 0.007896298945899946\n",
      "Epoch 99 num_samples 12900 loss 0.004635988092183785\n",
      "Epoch 99 num_samples 13000 loss 0.004413680478864468\n",
      "Epoch 99 num_samples 13100 loss 0.006699573793038744\n",
      "Epoch 99 num_samples 13200 loss 0.0030472409951840377\n",
      "Epoch 99 num_samples 13300 loss 0.004262816523947766\n",
      "Epoch 99 num_samples 13400 loss 0.002797952975201044\n",
      "Epoch 99 num_samples 13500 loss 0.0038493345319275864\n",
      "Epoch 99 num_samples 13600 loss 0.006916675301859945\n",
      "Epoch 99 num_samples 13700 loss 0.005031971424918889\n",
      "Epoch 99 num_samples 13800 loss 0.005058476030438284\n",
      "Epoch 99 num_samples 13900 loss 0.002080507004024386\n",
      "Epoch 99 num_samples 14000 loss 0.003559173558269556\n",
      "Epoch 99 num_samples 14100 loss 0.0046670781350677355\n",
      "Epoch 99 num_samples 14200 loss 0.004553539028338251\n",
      "Epoch 99 num_samples 14300 loss 0.005683939576384238\n",
      "Epoch 99 num_samples 14400 loss 0.005725107696635767\n",
      "Epoch 99 num_samples 14500 loss 0.007179082163544286\n",
      "Epoch 99 num_samples 14600 loss 0.004631619474460526\n",
      "Epoch 99 num_samples 14700 loss 0.005241006251056917\n",
      "Epoch 99 num_samples 14800 loss 0.005075121795700771\n",
      "Epoch 99 num_samples 14900 loss 0.005821000483845628\n",
      "Epoch 99 num_samples 15000 loss 0.005072416085335815\n",
      "Epoch 99 num_samples 15100 loss 0.005441269109433738\n",
      "Epoch 99 num_samples 15200 loss 0.005146073834414236\n",
      "Epoch 99 num_samples 15300 loss 0.005611385566810717\n",
      "Epoch 99 num_samples 15400 loss 0.004094593081523169\n",
      "Epoch 99 num_samples 15500 loss 0.005151471495950553\n",
      "Epoch 99 num_samples 15600 loss 0.005707529170828294\n",
      "Epoch 99 num_samples 15700 loss 0.003864518239875414\n",
      "Epoch 99 num_samples 15800 loss 0.006081647161675725\n",
      "Epoch 99 num_samples 15900 loss 0.004186624427875232\n",
      "Epoch 99 num_samples 16000 loss 0.007456712117495762\n",
      "Epoch 99 num_samples 16100 loss 0.004020322949194291\n",
      "Epoch 99 num_samples 16200 loss 0.005880899585376143\n",
      "Epoch 99 num_samples 16300 loss 0.006796226803518346\n",
      "Epoch 99 num_samples 16400 loss 0.006754180662868675\n",
      "Epoch 99 num_samples 16500 loss 0.0058965493526250325\n",
      "Epoch 99 num_samples 16600 loss 0.006804065169317038\n",
      "Epoch 99 num_samples 16700 loss 0.0037998417447844242\n",
      "Epoch 99 num_samples 16800 loss 0.0038274906508711302\n",
      "Epoch 99 num_samples 16900 loss 0.004391619062193084\n",
      "Epoch 99 num_samples 17000 loss 0.0033501449889876424\n",
      "Epoch 99 num_samples 17100 loss 0.00800458931193311\n",
      "Epoch 99 num_samples 17200 loss 0.00587509291750292\n",
      "Epoch 99 num_samples 17300 loss 0.006031767292568502\n",
      "Epoch 99 num_samples 17400 loss 0.005040572466246615\n",
      "Epoch 99 num_samples 17500 loss 0.005520251493800834\n",
      "Epoch 99 num_samples 17600 loss 0.004773655355808225\n",
      "Epoch 99 num_samples 17700 loss 0.004142522261612052\n",
      "Epoch 99 num_samples 17800 loss 0.0043220368624526904\n",
      "Epoch 99 num_samples 17900 loss 0.006427742423947478\n",
      "Epoch 99 num_samples 18000 loss 0.0050849797196476166\n",
      "Epoch 99 num_samples 18100 loss 0.005509136585656014\n",
      "Epoch 99 num_samples 18200 loss 0.0058810579995675115\n",
      "Epoch 99 num_samples 18300 loss 0.004271193032651696\n",
      "Epoch 99 num_samples 18400 loss 0.007937938932563789\n",
      "Epoch 99 num_samples 18500 loss 0.005930979308990054\n",
      "label: 3 predict: 3\n",
      "label: 1 predict: 1\n",
      "label: 3 predict: 3\n",
      "label: 4 predict: 4\n",
      "label: 9 predict: 9\n",
      "label: 1 predict: 1\n",
      "label: 4 predict: 4\n",
      "label: 7 predict: 7\n",
      "label: 8 predict: 8\n",
      "label: 4 predict: 4\n",
      "label: O predict: 8\n",
      "label: 6 predict: 6\n",
      "label: 4 predict: 4\n",
      "label: O predict: O\n",
      "label: 9 predict: 9\n",
      "label: 4 predict: 4\n",
      "label: 9 predict: 9\n",
      "label: 4 predict: 4\n",
      "label: 7 predict: 7\n",
      "label: 5 predict: 5\n",
      "label: O predict: O\n",
      "label: Z predict: Z\n",
      "label: 2 predict: 2\n",
      "label: 5 predict: 5\n",
      "label: Z predict: 2\n",
      "label: 2 predict: 2\n",
      "label: O predict: O\n",
      "label: 3 predict: 3\n",
      "label: Z predict: Z\n",
      "label: 4 predict: 4\n",
      "label: 3 predict: 3\n",
      "label: 6 predict: 6\n",
      "label: 5 predict: 6\n",
      "label: O predict: O\n",
      "label: 6 predict: 6\n",
      "label: 1 predict: 1\n",
      "label: 5 predict: 5\n",
      "label: Z predict: Z\n",
      "label: 2 predict: 2\n",
      "label: 7 predict: 7\n",
      "label: 8 predict: 8\n",
      "label: 4 predict: 4\n",
      "label: 7 predict: 7\n",
      "label: 9 predict: 9\n",
      "label: 7 predict: 7\n",
      "label: 5 predict: 5\n",
      "label: 8 predict: 8\n",
      "label: Z predict: Z\n",
      "label: 6 predict: 6\n",
      "label: 9 predict: 5\n",
      "label: Z predict: Z\n",
      "label: 6 predict: 6\n",
      "label: 2 predict: O\n",
      "label: 2 predict: 2\n",
      "label: 5 predict: 5\n",
      "label: 6 predict: 6\n",
      "label: 8 predict: 8\n",
      "label: 9 predict: 9\n",
      "label: Z predict: Z\n",
      "label: 2 predict: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 6 predict: 6\n",
      "label: 9 predict: 9\n",
      "label: O predict: O\n",
      "label: 9 predict: 9\n",
      "label: 1 predict: 1\n",
      "label: 7 predict: 7\n",
      "label: 8 predict: 8\n",
      "label: 3 predict: 3\n",
      "label: 3 predict: 3\n",
      "label: 2 predict: 2\n",
      "label: 5 predict: 5\n",
      "label: O predict: O\n",
      "label: 7 predict: 7\n",
      "label: 6 predict: 6\n",
      "label: 2 predict: 2\n",
      "label: 5 predict: 5\n",
      "label: 4 predict: 4\n",
      "label: 9 predict: 9\n",
      "label: 3 predict: 3\n",
      "label: 5 predict: 5\n",
      "label: 7 predict: 7\n",
      "label: 2 predict: 2\n",
      "label: 7 predict: 7\n",
      "label: 1 predict: 1\n",
      "label: 8 predict: 8\n",
      "label: Z predict: Z\n",
      "label: 6 predict: 6\n",
      "label: Z predict: Z\n",
      "label: 8 predict: 8\n",
      "label: O predict: O\n",
      "label: 1 predict: 1\n",
      "label: 8 predict: 8\n",
      "label: 3 predict: 3\n",
      "label: 4 predict: 4\n",
      "label: 1 predict: 1\n",
      "label: 7 predict: 7\n",
      "label: 8 predict: 8\n",
      "label: 6 predict: 6\n",
      "label: 1 predict: 1\n",
      "label: 8 predict: 8\n",
      "label: 3 predict: 3\n",
      "label: 9 predict: 9\n",
      "label: 2 predict: 2\n",
      "label: O predict: O\n",
      "label: Z predict: Z\n",
      "label: 1 predict: 1\n",
      "label: 3 predict: 3\n",
      "label: O predict: O\n",
      "label: 1 predict: 1\n",
      "label: 5 predict: 5\n",
      "Acc: 0.955\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # for the memory of forever 24 Kobe and 2 Gigi.\n",
    "    np.random.seed(242)\n",
    "    # We splice the raw feat with left 5 frames and right 5 frames\n",
    "    # So the input here is 39 * (5 + 1 + 5) = 429\n",
    "    dnn = DNN(429, 11, 128, 1)\n",
    "    dnn.set_learning_rate(5e-1)\n",
    "    train(dnn)\n",
    "    test(dnn)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
